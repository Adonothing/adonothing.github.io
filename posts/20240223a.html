<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><div id="myscoll"></div><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>论文阅读：一种基于目测的未知目标运动分析方位角方法 | Adunas🍀の异世界</title><meta name="keywords" content="视觉导航"><meta name="author" content="阿杜那斯🍀"><meta name="copyright" content="阿杜那斯🍀"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="🧵本文研究了使用移动单目相机估计移动目标物体运动的问题">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：一种基于目测的未知目标运动分析方位角方法">
<meta property="og:url" content="https://www.adunas.top/posts/20240223a.html">
<meta property="og:site_name" content="Adunas🍀の异世界">
<meta property="og:description" content="🧵本文研究了使用移动单目相机估计移动目标物体运动的问题">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://source.fomal.cc/img/default_cover_6.webp">
<meta property="article:published_time" content="2024-02-23T14:30:12.000Z">
<meta property="article:modified_time" content="2024-02-23T14:30:12.000Z">
<meta property="article:author" content="阿杜那斯🍀">
<meta property="article:tag" content="视觉导航">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://source.fomal.cc/img/default_cover_6.webp"><link rel="shortcut icon" href="/"><link rel="canonical" href="https://www.adunas.top/posts/20240223a"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文阅读：一种基于目测的未知目标运动分析方位角方法',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-23 22:30:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><style id="themeColor"></style><style id="rightSide"></style><style id="transPercent"></style><style id="blurNum"></style><style id="settingStyle"></style><span id="fps"></span><style id="defineBg"></style><style id="menu_shadow"></style><link rel="stylesheet" href="//at.alicdn.com/t/c/font_4353813_47f1tj73u94.css" media="defer" onload="this.media='all'"><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Adunas🍀の异世界" type="application/atom+xml">
</head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/AsitaA.jpg" onerror="onerror=null;src='/assets/r1.jpg'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pinweishenghuo"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-yinle">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying1">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-youxishoubing">                   </use></svg><span class="menu_word" style="font-size:17px"> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xiangzi"></use></svg><span class="menu_word" style="font-size:17px"> 八宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/gallery/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tubiaozhizuomoban">                   </use></svg><span class="menu_word" style="font-size:17px"> 画廊</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-nvwumao">                   </use></svg><span class="menu_word" style="font-size:17px"> 动画</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/nav/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-zhifengche">                   </use></svg><span class="menu_word" style="font-size:17px"> 网址导航</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/social/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-wangye"></use></svg><span class="menu_word" style="font-size:17px"> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/site/census/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--tongjibiao">                   </use></svg><span class="menu_word" style="font-size:17px"> 网站统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/echarts/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shujutongji1">                   </use></svg><span class="menu_word" style="font-size:17px"> 文章统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/time/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xianxingshalou">                   </use></svg><span class="menu_word" style="font-size:17px"> 旧时光</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 唠叨</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-love-sign">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Adunas🍀の异世界</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pinweishenghuo"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-yinle">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying1">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-youxishoubing">                   </use></svg><span class="menu_word" style="font-size:17px"> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xiangzi"></use></svg><span class="menu_word" style="font-size:17px"> 八宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/gallery/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tubiaozhizuomoban">                   </use></svg><span class="menu_word" style="font-size:17px"> 画廊</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-nvwumao">                   </use></svg><span class="menu_word" style="font-size:17px"> 动画</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/nav/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-zhifengche">                   </use></svg><span class="menu_word" style="font-size:17px"> 网址导航</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/social/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-wangye"></use></svg><span class="menu_word" style="font-size:17px"> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/site/census/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--tongjibiao">                   </use></svg><span class="menu_word" style="font-size:17px"> 网站统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/echarts/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shujutongji1">                   </use></svg><span class="menu_word" style="font-size:17px"> 文章统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/time/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xianxingshalou">                   </use></svg><span class="menu_word" style="font-size:17px"> 旧时光</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 唠叨</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-love-sign">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="search faa-parent animated-hover" title="检索站内任何你想要的信息"><svg class="faa-tada icon" style="height:24px;width:24px;fill:currentColor;position:relative;top:6px" aria-hidden="true"><use xlink:href="#icon-valentine_-search-love-find-heart"></use></svg><span> 搜索</span></a></div><a class="meihua faa-parent animated-hover" onclick="toggleWinbox()" title="美化设置-自定义你的风格" id="meihua-button"><svg class="faa-tada icon" style="height:26px;width:26px;fill:currentColor;position:relative;top:8px" aria-hidden="true"><use xlink:href="#icon-tupian1"></use></svg></a><a class="sun_moon faa-parent animated-hover" onclick="switchNightMode()" title="浅色和深色模式转换" id="nightmode-button"><svg class="faa-tada" style="height:25px;width:25px;fill:currentColor;position:relative;top:7px" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon">       </use></svg></a><div id="toggle-menu"><a><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-info"><h1 class="post-title">论文阅读：一种基于目测的未知目标运动分析方位角方法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于 </span><time class="post-meta-date-created" datetime="2024-02-23T14:30:12.000Z" title="发表于 2024-02-23 22:30:12">2024-02-23</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-23T14:30:12.000Z" title="更新于 2024-02-23 22:30:12">2024-02-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB/">阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">1.2w</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>75分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文阅读：一种基于目测的未知目标运动分析方位角方法"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="note blue no-icon flat"><ol type="1">
<li>b站视频：<a
target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1EC411z7Lz/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">【【IJRR最新成果】利用被忽视的视觉信息大幅提升目标定位可观性】</a></li>
<li>论文资源：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.17117">A Bearing-Angle
Approach for Unknown Target Motion Analysis Based on Visual
Measurements</a></li>
</ol>
</div>
<h1 id="阅读导航"><a
href="./20240224b.html#一种基于目测的未知目标运动分析方位角方法">阅读导航</a></h1>
<h1
id="a-bearing-angle-approach-for-unknown-target-motion-analysis-based-on-visual-measurements">A
Bearing-Angle Approach for Unknown Target Motion Analysis Based on
Visual Measurements</h1>
<h2 id="abstract">Abstract</h2>
<p>  Vision-based estimation of the motion of a moving target is usually
formulated as a <em>bearing-only</em> estimation problem where the
visual measurement is modeled as a bearing vector. Although the
bearing-only approach has been studied for decades, a <em>fundamental
limitation</em> of this approach is that it requires extra lateral
motion of the observer to enhance the target's observability.
Unfortunately, the extra lateral motion conflicts with the desired
motion of the observer in many tasks. It is well-known that, once a
target has been detected in an image, a bounding box that surrounds the
target can be obtained. Surprisingly, this common visual measurement
especially its size information has not been well explored up to now. In
this paper, we propose a new <em>bearing-angle</em> approach to estimate
the motion of a target by modeling its image bounding box as
bearing-angle measurements. Both theoretical analysis and experimental
results show that this approach can significantly enhance the
observability <em>without</em> relying on additional lateral motion of
the observer. The benefit of the bearing-angle approach comes with no
additional cost because a bounding box is a standard output of object
detection algorithms. The approach simply exploits the information that
has not been fully exploited in the past. No additional sensing devices
or special detection algorithms are required.</p>
<h2 id="keywords">Keywords</h2>
<p>Bearing-only target motion estimation, Pseudo-linear Kalman filter,
Observability enhancement</p>
<h2 id="introduction">Introduction</h2>
<p>  This paper studies the problem of estimating the motion of a moving
target object using a moving monocular camera. The target's geometric
information such as its physical size is <em>unknown</em> in advance.
This problem is important in many
fields<!--  \citep{Qiu2019, Griffin2021, Tekin2018} -->. Our present
work is particularly motivated by the task of aerial target pursuit,
where a micro aerial vehicle (MAV) uses its onboard camera to detect,
localize, and then pursue another flying MAV. The task of aerial target
pursuit, originally motivated by the interesting bird-catching-bird
behaviors in nature<!--  \citep{Brighton2019} -->, potentially provides
an effective approach to the defense of misused
MAV<!--  \citep{Rothe2019, Dressel2019, Vrba2020} -->.</p>
<p><a id= "fig_architecture_outdoor"></a> <img
src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_outdoor.png"
alt="Fig.1 An observer MAV observes a target MAV with a monocular camera. The bearing g and angle \theta can be obtained from the bounding box that surrounds the target in the image." /></p>
<p>  When a target has been detected in an image by a vision detection
algorithm, we usually obtain a <em>bounding box</em> that surrounds the
target's image (see <a href="#fig_architecture_outdoor">Fig.1</a>). The
bounding box carries two types of useful information that can be used to
estimate the target's motion.</p>
<p>  The first type of useful information is the <em>center point</em>
of the bounding box. The pixel coordinate of the center point can be
used to calculate the spatial <em>bearing vector</em> pointing from the
camera to the target based on the pin-hole camera
model<!--  \citep{Ma2012} -->. Using the bearing vector to estimate the
target's motion is referred to as <em>bearing-only</em> target motion
estimation<!--  \citep{Fogel1988, He2019, Li2022} -->. As a problem that
has been studied for more than 40 years, bearing-only target motion
estimation was originally studied to estimate the motion of ships on the
ocean surface<!--  \citep{hoelzer1978modified} -->, and regained
increasing research attention in recent years in vision-based target
estimation tasks<!--  \citep{Ponda2009, Anjaly2018, He2019} -->.</p>
<p>  Bearing-only target motion estimation requires an <em>observability
condition</em>: The observer must have higher-order motion than the
target and, more importantly, the higher-order motion must contain
components that are orthogonal to the target's bearing
vector<!--  \citep{Fogel1988} -->. Motivated by this observability
condition, enormous works have studied how an observer should move to
enhance the
observability<!--  \citep{Hammel1989, Sabet2016, Anjaly2018, He2019} -->.
For instance, in our recent work<!--  \citep{Li2022} -->, we proposed a
helical guidance law so that a MAV moves along a helical curve to
optimize the observability in the 3D space.</p>
<p>  A <em>limitation</em> of the observability condition of the classic
bearing-only approach is that the observer must move in the lateral
directions that are orthogonal to the bearing vector of the target. Such
additional lateral motion is usually unfavorable because it may conflict
with the desired motion of the observer in many tasks. For example, in
an aerial target pursuit task, the pursuer is desired to approach the
target as fast as possible and then keep stationary relative to the
target. Then, the additional lateral motion would conflict with the
desired motion. It is, therefore, important to study other ways that can
enhance the observability while avoiding unfavorable lateral motion.</p>
<p>  The second type of useful information of a bounding box is its
<em>size</em> (either width or height). The size of a bounding box is
jointly determined by several factors such as the target's distance, the
target's physical size, and the orientation of the camera. The target's
physical size is usually unknown in many tasks, especially in those
antagonistic ones such as aerial pursuit of misused MAVs. As a result,
the size of the bounding box cannot directly infer the target's
distance. Nevertheless, it carries valuable information for localizing
the target.</p>
<p>  Surprisingly, the size information of the bounding box has not been
well explored so far. The work that is closely relevant to ours is the
state-of-the-art one in<!--  \citep{Griffin2021} -->, where the size of
a bounding box is used to localize unknown target objects. Although the
approach in<!--  \citep{Griffin2021} --> is inspiring, it relies on two
assumptions: The target objects are stationary and the camera can only
translate without rotating. It is still an open problem how to estimate
a target's motion when the two assumptions are not valid. Moreover, the
theoretical role of the size of a bounding box in target motion
estimation has not been fully understood so far. Although the work
in<!--  \citep{Vrba2020} --> also utilizes the size of the bounding box
to estimate the target's position, it is assumed that the target's
physical size is known in advance.</p>
<p>  Estimating the motion of moving objects is also a fundamental
problem in dynamic SLAM. For example, the works
in<!--  \citep{Yang2019,Qiu2019} --> firstly estimate the camera's pose
and secondly estimate the target object's pose subject to a scale
factor, and finally estimate the scale factor from multi-view
measurements. To estimate the target object's pose subject to a scale
factor,<!--  \citep{Yang2019} --> and<!--  \citep{Qiu2019} --> rely on
detecting, respectively, a 3D bounding box and sufficient feature points
inside the 2D bounding box. Different
from<!--  \citep{Yang2019,Qiu2019} -->, our proposed approach merely
utilizes a 2D image bounding box without further extracting feature
points or a 3D bounding box inside the 2D bounding box. As a result, one
benefit is that this approach is more computationally efficient.
Moreover, this approach can handle the challenging small-target case
where the target object is far and hence its image is small. In this
case, it would be unreliable to extract sufficient stable features or
conduct 3D detection.</p>
<p>  The aforementioned approaches
in<!--  \citep{Griffin2021,Yang2019,Qiu2019} --> are all based on
multiple views. It is also possible to estimate the target's depth from
a single view/image<!--  \citep{Tekin2018, Vrba2020} -->. The
single-view approach however requires prior information of the objects.
Moreover, it would be unable to successfully localize target objects
with different sizes but similar appearances. In this paper, we focus on
the multi-view case.</p>
<p>  In this paper, we propose a novel <em>bearing-angle</em> target
motion estimation approach that models a bounding box as bearing-angle
measurements. This approach can enhance the observability by fully
exploiting the information in a bounding box rather than relying on the
additional lateral motion of the observer. The benefit of the proposed
bearing-angle approach comes with no additional cost since the bounding
box is a standard output of object detection algorithms. The approach
simply exploits the angle information that has not been fully exploited
in the past. No additional sensing devices or special detection
algorithms are required.</p>
<p>  The technical novelties of this approach are threefold.</p>
<ol type="1">
<li><p>The proposed approach does not directly use the size of a
bounding box because the size is variant to the orientation of the
camera. That is, even if the target's relative position is unchanged,
the size of the bounding box still varies when the camera rotates.
Motivated by this problem, we convert the size of the bounding box to an
angle subtended by the target (see <a
href="#fig_architecture_outdoor">Fig.1</a>). The merit of using the
angle measurement is that it is <em>invariant</em> to the camera's
orientation change (see <a href="#fig_cam_rotate">Fig.2</a>) and hence
can greatly facilitate the estimator design. In this way, the assumption
in<!--  \citep{Griffin2021} --> that the camera can only translate but
not rotate can be avoided.</p></li>
<li><p>Although the bearing-angle approach incorporates an additional
angle measurement, it is nontrivial to see how to properly use this
measurement because the angle does not directly infer the target's
distance given that the target's size is unknown. We notice that the
angle is a joint nonlinear function of the target's physical size and
relative distance. Hence, the state vector, which only consists of the
target's position and velocity in the conventional bearing-only
approach, is augmented by the unknown target's physical size. Since the
bearing and angle measurements are all nonlinear functions of the
target's state, we establish a pseudo-linear Kalman filter to properly
utilize the measurements to enhance estimation stability. Both
simulation and real-world experiments verify the effectiveness of the
proposed estimator.</p></li>
<li><p>Although an additional angle measurement is used, an additional
unknown, the target's physical size, is also introduced into the
estimator. It is, therefore, nontrivial to see how the additional angle
measurement can help improve the observability. Motivated by this
problem, we prove the necessary and sufficient observability condition
for bearing-angle target motion estimation. In particular, we show that
the target's motion can be recovered if and only if the observer has a
higher-order motion than the target. Different from the bearing-only
case, the higher-order motion is <em>not</em> required to be in the
lateral directions that are orthogonal to the bearing vector. This is an
important enhancement of the observability. As we show in various
experiments, the bearing-angle approach can successfully recover the
target's motion in many scenarios where the bearing-only approach
fails.</p></li>
</ol>
<h2 id="related-work">Related Work</h2>
<h3 id="algorithms-for-bearing-only-target-motion-estimation">Algorithms
for bearing-only target motion estimation</h3>
<p>  Bearing-only target motion analysis aims to estimate the target's
motion states, such as position and velocity, using bearing measurement
only. It was originally motivated by ship localization and tracking in
the ocean<!--  \citep{hoelzer1978modified} -->. With the rapid
development of small-scale mobile robots equipped with cameras, the
bearing-only approach regained increasing attention in recent
years<!--  \citep{Ponda2009, Anjaly2018, He2019} -->.</p>
<p>  Kalman filter-based estimators are widely used in the bearing-only
target motion. One challenge of applying the Kalman filter to the
bearing-only estimation is the nonlinearity of the bearing measurement.
The conventional extended Kalman filter (EKF) exhibits divergence
problems when applied to bearing-only target motion
estimation<!--  \citep{Aidala1979, Lin2002} -->. Several methods have
been proposed to solve this problem. They can be divided into two types.
The first type is the modified polar EKF, which was first proposed
in<!--  \citep{hoelzer1978modified} -->. In this approach, three
observable quantities are separated from the unobservable ones to
prevent divergence. The work in<!--  \citep{Stallard1991} --> extends
this approach to the case of spherical coordinates to track targets in
3D space. The second type is the pseudo-linear Kalman filter, which is
first proposed in<!--  \citep{Lingren1978} --> to solve the instability
problem by transforming the nonlinear measurement equation into a
pseudo-linear one. However, this transformation makes the noise become
non-Gaussian and highly correlated to the measurement matrix and then
causes estimation bias. Nevertheless, the work
in<!--  \citep{Aidala1982} --> theoretically proves that the velocity
estimation has no bias, and the position estimation bias can be removed
by the observer's maneuvers.</p>
<p>  Recently, other estimation algorithms based on advanced but more
complex filters have been proposed. The work
in<!--  \citep{Farina1999} --> uses the maximum likelihood (MLE)
algorithm to estimate the target's motion using bearing-only
measurements. The comparison with the Cramer-Rao lower bound indicates
that the MLE-based estimator is effective against measurement errors.
The work in<!--  \citep{Dogancay2005} --> proposes a constrained total
least-squares algorithm, which can improve the estimation accuracy when
the error of bearing measurement is large. Three different algorithms
are used and compared in<!--  \citep{Lin2002} -->. The results show that
the EKF, the pseudo-linear filter, and the particle filter have similar
performances in most situations, while the EKF loses track when the
initial estimate error is large.</p>
<p>  Another type of approach, called bearing-only trajectory
triangulation<!--  \citep{Avidan2000} -->, estimates the target's
position from the perspective of trajectory fitting. It reconstructs the
trajectory by intersecting parametric trajectory to a series of sight
rays obtained from bearing measurement. Once the trajectory is
successfully fitted, the target's position at each time instant can be
estimated by the intersection of the bearing and the trajectory. The
trajectory fitting relies on the assumption of the trajectory's shape.
However, in many applications, the target's trajectory is complex and
unknown in advance. Many consecutive studies aim to relax this
assumption in various ways based on
hypersurfaces<!--  \citep{Kaminski2004} -->, parametric temporal
polynomials<!--  \citep{Yu2009} -->, or compact basis
vectors<!--  \citep{Park2015} -->.</p>
<h3
id="observability-analysis-of-bearing-only-target-motion-estimation">Observability
analysis of bearing-only target motion estimation</h3>
<p>  Observability is a fundamental problem in bearing-only target
motion estimation. Early works mainly focus on whether the system is
observable or not. For example, the work in<!--  \citep{Lingren1978} -->
uses the rank of observation matrix to determine the observability. The
work in<!--  \citep{Fogel1988} --> extends the observability criterion
in<!--  \citep{Nardone1981} --> to the Nth-order target dynamics and
inspires us for the observability analysis in
Section<!--  \ref{sec_observability_criteria} --> <a
href="#sec_observability_criteria">Observability Analysis by Solving
Linear Equations</a>. All these conditions indicate that the observer
must have extra high-order motion in the lateral direction. The
observability condition can be significantly relaxed in our
approach.</p>
<p>  Unlike the works on determining whether the system is observable or
not, some studies focus on quantifying the observability degree. The
work in<!--  \citep{Hammel1989} --> first introduces the Fisher
information matrix (FIM) into the observability analysis. The works
in<!--  \citep{Sabet2016} --> and<!--  \citep{Anjaly2018} --> use
FIM-based objective functions to maximize observability. We also use the
FIM in our former work<!--  \citep{Li2022} --> to optimize the 3D
helical guidance law for better observability. Another method called the
geometric method uses the geometric relationship between the target and
the observer in two consecutive time instants to derive the measure of
observability<!--  \citep{He2019, Woffinden2009} -->, and the results
are consistent with those derived using FIM. Compared to the
bearing-only approach, the observability degree of our bearing-angle
method is sufficient to estimate the target's motion in many common
scenarios such as tracking and guidance (see experiment results in
Figs.~<span class="math inline">\(\ref{fig_matlab_3}\)</span> and~<span
class="math inline">\(\ref{fig_outdoor_1}\)</span>).</p>
<h2 id="problem-formulation">Problem Formulation</h2>
<p><a id= "fig_cam_rotate"></a> <img
src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_cam_rotate.png"
alt="Fig.2 The size of the bounding box varies when the camera rotates. By contrast, the angle subtended by the target object is invariant to the camera&#39;s orientation change." /></p>
<p>  Consider a target object moving in the 3D space. Its position and
velocity at time <span class="math inline">\(t_k\)</span> are denoted as
<span class="math inline">\(p_T(t_k) \in \mathbb{R}^3\)</span> and <span
class="math inline">\(v_T(t_k) \in \mathbb{R}^3\)</span>, respectively.
Suppose there is an observer carrying a monocular camera to observe the
target. The position of the observer is denoted as <span
class="math inline">\(p_o(t_k) \in \mathbb{R}^3\)</span>. Here, we
assume that the observer/camera's pose including its position and
orientation can be obtained in other ways. For example, it can be
measured directly by RTK GPS<!--  \citep{Li2022} --> or estimated by
visual inertial odometry<!--  \citep{Qiu2019} -->. In the rest of the
paper, the dependence of a variable on <span
class="math inline">\(t_k\)</span> is dropped when the context is
clear.</p>
<p>  If the target object can be detected by a vision algorithm, we can
obtain a bounding box surrounding the target object in the image. Two
types of information carried by the bounding box can be used to estimate
the motion of the target.</p>
<p>  First, the center point of the bounding box can be used to
calculate the <em>bearing</em> vector of the target. In particular,
denote <span class="math inline">\(g \in \mathbb{R}^3\)</span> as the
unit bearing vector pointing from $p_o $ to $p_T $. Suppose <span
class="math inline">\(P_\text{cam}\in \mathbb{R}^{3\times3}\)</span> is
the intrinsic parameter matrix of the
camera<!--  \citep[Section~\ref{section_bearing-angle-target-motion-estimator}]{Ma2012} -->,
and <span class="math inline">\(R_\text{c}^\text{w} \in
\mathbb{R}^{3\times 3}\)</span> is the rotation from the camera frame to
the world frame. Then, the bearing vector <span
class="math inline">\(g\)</span> can be calculated as</p>
<p><span class="math display">\[
\begin{align*}
g =
\dfrac{
R_\text{c}^\text{w}
P_\text{cam}^{-1}
q_{\rm pix}
}{
\|R_\text{c}^\text{w}
P_\text{cam}^{-1}
q_{\rm pix}
\|
},
\end{align*}%\label{eq_bearing_information}
\]</span></p>
<p>where <span class="math inline">\(q_{\rm pix} =[x_{\rm pix} , y_{\rm
pix} , 1]^\mathrm{T} \in \mathbb{R}^3\)</span>. Here, <span
class="math inline">\((x_{\rm pix} ,y_{\rm pix})\)</span> is the pixel
coordinate of the center point of the bounding box.</p>
<p>  Second, the size of the bounding box can be used to calculate the
<em>angle</em> subtended by the target in the camera's field of view.
The reason that we convert the bounding box's size to the angle is that
the angle is invariant to the camera's orientation change (see <a
href="#fig_cam_rotate">Fig.2</a>). In particular, let $s_{} $ denote the
size of the bounding box. It can be either the width or the height. Let
<span class="math inline">\(\theta \in (0,\pi/2)\)</span> be the angle.
According to the pin-hole camera
model<!--  \citep[Section~\ref{section_bearing-angle-target-motion-estimator}]{Ma2012} -->
and the law of cosine (see <a href="#fig_cam_rotate">Fig.2</a>), the
angle can be calculated as <span class="math display">\[\begin{align*}
\theta = \arccos\left(\dfrac{l_\mathrm{left}^2 + l_\mathrm{right}^2 -
s_\mathrm{pix}^2}{2l_\mathrm{left}l_\mathrm{right}}\right),
\end{align*}\]</span>% where <span
class="math inline">\(l_\mathrm{left}=\sqrt{(f/\alpha)^2+(\delta
x-s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}\)</span> and <span
class="math inline">\(l_\mathrm{right}=\sqrt{(f/\alpha)^2+(\delta
x+s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}\)</span> are the
distances in pixel from the camera center to the middle points of the
left and right sides of the bounding box, respectively (Fig.~<span
class="math inline">\(\ref{fig_architecture_outdoor}\)</span>).
Moreover, <span class="math inline">\(f\)</span> and <span
class="math inline">\(\alpha\)</span> denote the camera's focal length
and single pixel size, respectively. <span
class="math inline">\(i_{\text{width}}\)</span> and <span
class="math inline">\(i_{\text{height}}\)</span> represent the width and
the height of the whole image in pixels, respectively. <span
class="math inline">\(\delta
x=\|x_\text{pix}-i_\text{width}/2\|\in\mathbb{R}\)</span> and <span
class="math inline">\(\delta y =
\|y_\text{pix}-i_\text{height}/2\|\in\mathbb{R}\)</span> are the
distances between the center of the bounding box and the center of the
image.</p>
<p>  Our goal is to estimate the target's position and velocity, <span
class="math inline">\(p_T\)</span> and <span
class="math inline">\(v_T\)</span>, based on the noisy measurements of
the bearing vector <span class="math inline">\(g\)</span> and the angle
<span class="math inline">\(\theta\)</span> together with the observer's
own position <span class="math inline">\(p_o\)</span>. To achieve this
goal, we propose a new bearing-angle target motion estimator (Fig.~<span
class="math inline">\(\ref{fig_architecture_algorithm}\)</span>). The
estimator is introduced in detail in Section~<span
class="math inline">\(\ref{section_bearing-angle-target-motion-estimator}\)</span>.
The observability of this estimator is analyzed based on Kalman's
observability criterion in Section~<span
class="math inline">\(\ref{sec_analysis_of_observability_matrix}\)</span>.
We further prove a necessary and sufficient observability condition of
the observer in Section~<span
class="math inline">\(\ref{sec_observability_criteria}\)</span>.
Numerical simulation results are given in Section~<span
class="math inline">\(\ref{sec_matlab_simulation}\)</span>. More
realistic AirSim simulation results are given in Section~<span
class="math inline">\(\ref{sec_airsim_simulation}\)</span>. Finally,
real-world experiments are given in Section~<span
class="math inline">\(\ref{sec_real_world_experimental_validation}\)</span>.</p>
<p>This section designs a bearing-angle target motion estimator based on
the framework of pseudo-linear Kalman filtering. The key here is to
establish appropriate measurement and state transition equations.</p>
<h3 id="states-transition-equation">States transition equation</h3>
<p> The state vector of the target is designed as <span
class="math display">\[\begin{align*}
x=
\left[
  \begin{array}{c}
    p_T \\
    v_T \\
    \ell \\
  \end{array}
\right]\in \mathbb{R}^7,
\end{align*}\]</span>% where $p_T $ and $v_T $ are target's global
position and velocity, respectively. Here, <span
class="math inline">\(\ell&gt;0\)</span> is a scalar that represents the
physical size of the target object in the dimension that is orthogonal
to the bearing vector (see <a href="#fig_cam_rotate">Fig.2</a>). In this
paper, <span class="math inline">\(\ell\)</span> is assumed to be
constant or varying slowly, which means that the physical size of the
target object should be approximately invariant from different viewing
angles. Here, <span class="math inline">\(\ell\)</span> corresponds to
<span class="math inline">\(\theta\)</span>, which further corresponds
to either the width or height of the bounding box. Whether <span
class="math inline">\(\ell\)</span> should correspond to the width or
height depends on in which dimension the physical size of the target
object is invariant when viewed from different angles. More explanation
is given in Section~<span
class="math inline">\(\ref{sec_dynamical_model_of_size}\)</span>.</p>
<p>  Different from the bearing-only case where the state merely
consists of the position and velocity, the state here is augmented by
the target's physical size. This is due to the fact that the angle
measurement is a function of the target's physical size, which should be
estimated as well. One may wonder whether the state vector can also
incorporate the target's acceleration. To estimate high-order motion
(e.g., acceleration) of the target, the observer must have higher-order
motion (e.g., nonzero jerk) according to the observability condition
presented in Section~<span
class="math inline">\(\ref{sec_observability_criteria}\)</span>.
Otherwise, the estimation would diverge. Therefore, it is preferred to
exclude the acceleration and merely estimate the position and
velocity.</p>
<p>  If no information of the target's motion is available, it is common
to model the target's motion as a discrete-time noise-driven double
integrator:</p>
<p><span class="math display">\[
\begin{align}
    x(t_{k+1})=Fx(t_k) +q(t_k) ,
\end{align}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\begin{align}
F=
\begin{bmatrix}
I_{3\times3} &amp; \delta tI_{3\times3} &amp; 0_{3\times1}  \\
0_{3\times3} &amp; I_{3\times3}  &amp; 0_{3\times1}   \\
0_{1\times 3} &amp; 0_{1\times 3} &amp; 1
\end{bmatrix}\in\mathbb{R}^{7\times 7},
\end{align}
\]</span></p>
<p>with <span class="math inline">\(\delta t\)</span> as the sampling
time, and <span class="math inline">\(I\)</span> and <span
class="math inline">\(0\)</span> as the identity and zero matrices,
respectively. Here, <span class="math inline">\(q
\in\mathbb{R}^7\)</span> is a zero-mean process noise satisfying <span
class="math inline">\(q \sim \mathcal{N}(0,{\Sigma}_q)\)</span>, where
the covariance matrix is</p>
<p><span class="math display">\[
\begin{align}
{\Sigma}_q=\text{diag}(0, 0, 0, \sigma_v^2, \sigma_v^2, \sigma_v^2,
\sigma_\ell^2)\in\mathbb{R}^{7\times7}.
\end{align}%\label{eq_covariance_q}
\]</span></p>
<p>Here, <span class="math inline">\(\sigma_v\in\mathbb{R}\)</span> and
<span class="math inline">\(\sigma_\ell\in\mathbb{R}\)</span> are the
standard deviations of the target's velocity and size, respectively.
When the target's shape is irregular, <span
class="math inline">\(\ell\)</span> may vary when viewed from different
angles. By letting <span class="math inline">\(\sigma_\ell\ne0\)</span>,
we can handle the case where <span class="math inline">\(\ell\)</span>
varies slowly. The dynamic modeling of <span
class="math inline">\(\ell\)</span> is discussed in the following
subsection.</p>
<p>  Since the target's physical size <span
class="math inline">\(\ell\)</span> is a state variable to be estimated,
it is important to discuss its dynamic model. In fact, the dynamic model
of <span class="math inline">\(\ell\)</span> in <span
class="math inline">\(\eqref{eq_state_transition}\)</span> assumes that
<span class="math inline">\(\ell\)</span> varies slowly. We next justify
this modeling and provide more discussion.</p>
<p>First of all, <span class="math inline">\(\ell\)</span> corresponds
to the physical size of the target object in the dimension that is
orthogonal to the bearing vector. Its dynamics can be categorized into
three cases.</p>
<p><em>1) <span class="math inline">\(\ell\)</span> is invariant.</em>
In theory, when <span class="math inline">\(\ell\)</span> is invariant,
a change of <span class="math inline">\(\theta\)</span> implies a change
of <span class="math inline">\(r\)</span>. As a result, the measurement
of <span class="math inline">\(\theta\)</span> can help improve the
system's observability, as proven in Section~<span
class="math inline">\(\ref{sec_observability_criteria}\)</span>. An
ideal case where <span class="math inline">\(\ell\)</span> is invariant
is that the target object is a sphere or cylinder so that <span
class="math inline">\(\ell\)</span> corresponds to its
diameter<!--  \citep{Vrba2020} -->. In practice, the target object does
not have to be the ideal case. For example, consider an autonomous
driving scenario where a focal vehicle uses a camera to localize its
surrounding vehicles in the 2D plane. Although the physical size of a
surrounding vehicle changes greatly when viewed from behind or side, the
height of the vehicle is <em>invariant</em> from different side-view
angles. In this case, <span class="math inline">\(\ell\)</span>
corresponds to the height of the vehicle, and we need to use the height
of the image bounding box to calculate <span
class="math inline">\(\theta\)</span>.</p>
<p><em>2) <span class="math inline">\(\ell\)</span> varies slowly.</em>
If there does not exist any dimension in which the physical size of the
target remains invariant, <span class="math inline">\(\ell\)</span> may
vary slowly when the target is viewed from different angles. For
example, in the tasks of aerial target pursuit, if the target is a
quadcopter or hexacopter, then <span class="math inline">\(\ell\)</span>
is approximately equal to the wheelbase but may vary slightly when
viewed from different angles since the MAV is not a perfect cylinder. In
this case, <span class="math inline">\(\ell\)</span> corresponds to the
wheelbase of the MAV, and we need to use the width of the image bounding
box to calculate <span class="math inline">\(\theta\)</span>.</p>
<p>If <span class="math inline">\(\ell\)</span> varies slowly, it can
still be treated as invariant within short time intervals. As long as
the observability condition (Section~<span
class="math inline">\(\ref{sec_observability_criteria}\)</span>) is
satisfied, the motion of the target as well as <span
class="math inline">\(\ell\)</span> can be successfully estimated. This
fact is supported by the experimental results in Section~<span
class="math inline">\(\ref{sec_sim_res_circular_scenario}\)</span>. It
is however worth nothing that the performance of the proposed
bearing-angle approach would degenerate to the conventional bearing-only
one because the additional information brought by <span
class="math inline">\(\theta\)</span> is used to estimate the
time-varying <span class="math inline">\(\ell\)</span> rather than
helping improve the system's observability.</p>
<p><em>3) <span class="math inline">\(\ell\)</span> varies rapidly.</em>
If <span class="math inline">\(\ell\)</span> varies rapidly due to
certain reasons, it would be difficult to distinguish whether the change
of <span class="math inline">\(\theta\)</span> is caused by the change
of <span class="math inline">\(\ell\)</span> or the change of <span
class="math inline">\(r\)</span>. For example, when a MAV is used to
track a ground vehicle, <span class="math inline">\(\ell\)</span> in any
dimension may vary rapidly when the relative motion between the MAV and
the ground vehicle is highly dynamic. In such scenarios, the additional
information brought by <span class="math inline">\(\theta\)</span> is no
longer sufficient to estimate the rapidly varying <span
class="math inline">\(\ell\)</span> in this case. Additional visual
information such as a 3D bounding box that indicates the target's 3D
attitude is required. This is an important topic for future research but
out of the scope of the present paper.</p>
<p>The bearing vector <span class="math inline">\(g\)</span> and the
subtended angle $$ are both nonlinear functions of the target's
position. In particular,</p>
<p><span class="math display">\[
\begin{align}
    g &amp;=\dfrac{p_T -p_o }{r },
    \theta &amp;=2\arctan\left(\dfrac{\ell}{2r }\right)\approx
\dfrac{\ell}{r },
\end{align}
\]</span> \</p>
<p>where <span class="math display">\[r =\|\my{p}_T -\my{p}_o
\|\]</span> is the distance between the target and the observer. It is
notable that there is an approximation in <span
class="math inline">\(\eqref{eq_theta_measure}\)</span>. This
approximation is accurate. Specifically, when <span
class="math inline">\(r&gt;3\ell\)</span>, which is common in practice,
it can be verified that the approximation error is less than <span
class="math inline">\(0.08\%\)</span>. The approximation error further
decreases as <span class="math inline">\(r\)</span> increases.</p>
<p>In practice, measurements always contain noises. First, denote <span
class="math inline">\(\hat{\my{g}} \in\mathbb{R}^3\)</span> as the
noise-corrupted bearing measurement. Then, we have <span
class="math display">\[\begin{align}
\label{eq_noised_g_mear}
\hat{\my{g}}  = \my{R}\left(\my{\eta} , \epsilon \right) \my{g} ,
\end{align}\]</span> where <span
class="math inline">\(\my{R}\left(\my{\eta} , \epsilon \right) \in
\mathbb{R}^{3\times 3}\)</span> is a rotation matrix that perturbs <span
class="math inline">\(\my{g}\)</span>. Here, <span
class="math inline">\(\my{\eta} \in\mathbb{R}^3\)</span> is a unit
vector representing a random rotation axis, and <span
class="math inline">\(\epsilon \in \mathbb{R}\)</span> is a random
rotation angle. This rotation matrix would rotate the vector $ $ by an
angle $$ around the axis $ $. The productive noise in <span
class="math inline">\(\eqref{eq_noised_g_mear}\)</span> can be
transformed into an additive one: <span
class="math display">\[\begin{align}\label{eq_noised_g_mear_add}
    \hat{\my{g}}  = \my{g}  + \my{\mu} ,
\end{align}\]</span> where <span class="math inline">\(\my{\mu}
=(\my{R}\left(\my{\eta} , \epsilon \right) - \my{I}_{3\times3})\my{g}
\in\mathbb{R}^3\)</span> is the measurement noise of the bearing vector.
The covariance of <span class="math inline">\(\mu\)</span> is derived in
our previous work<!--  \citep{Li2022} -->. Since the covariance is
complex and involves unknown true values, we can approximately treat it
as a Gaussian noise: <span class="math inline">\(\mu\sim\mathcal{N}(0,
\sigma_\mu^2 I_{3\times 3})\)</span><!--  \citep{Li2022} -->.</p>
<p>Substituting <span
class="math inline">\(\eqref{eq_bearing_measure}\)</span> into <span
class="math inline">\(\eqref{eq_noised_g_mear_add}\)</span> gives the
<em>nonlinear bearing measurement equation:</em> <span
class="math display">\[\begin{align}\label{eq_bearing_measure_noise}
    \hat{\my{g}} &amp;=\dfrac{\my{p}_T -\my{p}_o }{r } + \my{\mu} .
\end{align}\]</span></p>
<p>Second, denote <span class="math inline">\(\hat{\theta}
\in\mathbb{R}\)</span> as the noise-corrupted measurement of the
subtended angle. Then, we have <span
class="math display">\[\begin{align}\label{eq_noise_theta}
    \hat{\theta} =\theta  + w ,
\end{align}\]</span> where <span class="math inline">\(w \sim
\mathcal{N}(0, \sigma^2_w)\)</span> is the measurement noise.
Substituting <span
class="math inline">\(\eqref{eq_theta_measure}\)</span> into <span
class="math inline">\(\eqref{eq_noise_theta}\)</span> yields the
<em>nonlinear angle measurement equation:</em> <span
class="math display">\[\begin{align}\label{eq_theta_measure_noise}
    \hat{\theta} &amp;=\dfrac{\ell}{r } + w.
\end{align}\]</span></p>
<p>The measurement equations <span
class="math inline">\(\eqref{eq_bearing_measure_noise}\)</span> and
<span class="math inline">\(\eqref{eq_theta_measure_noise}\)</span> are
nonlinear in the target's state. In the following, we convert the two
equations to be pseudo-linear and then apply pseudo-linear Kalman
filtering to achieve better estimation
stability<!--  \citep{Lin2002} -->.</p>
<p>First, to convert the 3D bearing measurement to pseudo-linear, we
introduce a useful orthogonal projection matrix: <span
class="math display">\[\begin{align*}
    \my{P}_{\hat{\my{g}} }\doteq\my{I}_{3\times 3}-\hat{\my{g}}
\hat{\my{g}}^\mathrm{T}  \in \mathbb{R}^{3\times 3}.
\end{align*}\]</span>% This matrix plays an important role in the
analysis of bearing-related estimation and control
problems<!--  \citep{Zhao2019} -->. It has an important property: <span
class="math display">\[\my{P}_{\hat{\my{g}} }\hat{\my{g}}
=\my{0}_{3\times 1}.\]</span> As a result, multiplying <span
class="math inline">\(r\my{P}_{\hat{\my{g}} }\)</span> on both side of
<span class="math inline">\(\eqref{eq_bearing_measure_noise}\)</span>
yields <span class="math display">\[\begin{align*}
\my{0}_{3\times 1}=\my{P}_{\hat{\my{g}} }(\my{p}_T -\my{p}_o) +
r\my{P}_{\hat{\my{g}} }\my{\mu}
\end{align*}\]</span> and consequently <span
class="math display">\[\begin{align*}
\my{P}_{\hat{\my{g}} }\my{p}_o =\my{P}_{\hat{\my{g}} }\my{p}_T  +
r\my{P}_{\hat{\my{g}} }\my{\mu}.
\end{align*}\]</span>% Rewriting this equation in terms of the target's
state variables yields the <em>pseudo-linear bearing measurement
equation:</em> <span
class="math display">\[\begin{align}\label{eq_pseudo_linear_measurement_g_equation}
\my{P}_{\hat{\my{g}} }\my{p}_o =
\begin{bmatrix}
\my{P}_{\hat{\my{g}} } &amp;
\my{0}_{3\times4}
\end{bmatrix}
\left[
  \begin{array}{c}
    p_T \\
    v_T \\
    \ell \\
  \end{array}
\right]  +  r\my{P}_{\hat{\my{g}} }\my{\mu} .
\end{align}\]</span> Here, $_{ }_o $ on the left-hand side is the new
measurement, which is pseudo-linear in the target's state variables. The
reason that it is called "pseudo" is because the measurements also
appear on the right-hand side of the equation, especially in the
measurement matrix.</p>
<p>Second, we convert the nonlinear angle measurement in <span
class="math inline">\(\eqref{eq_theta_measure_noise}\)</span> to be
pseudo-linear. To that end, multiplying $r $ on both side of <span
class="math inline">\(\eqref{eq_theta_measure_noise}\)</span> yields
<span class="math display">\[\begin{align}\label{eq_theta_pseudo_tem}
\hat{\theta} r\hat{\my{g}}  = \ell\hat{\my{g}} +wr\hat{\my{g}} .
\end{align}\]</span> It follows from <span
class="math inline">\(\eqref{eq_bearing_measure_noise}\)</span> that
<span class="math inline">\(r\my{\hat{g}}=\my{p}_T
-\my{p}_o+r\mu\)</span>, substituting which into the left-hand side of
<span class="math inline">\(\eqref{eq_theta_pseudo_tem}\)</span> gives
<span class="math display">\[\begin{align*}
\hat{\theta} (\my{p}_T -\my{p}_o+r\mu)  = \ell\hat{\my{g}}
+wr\hat{\my{g}}.
\end{align*}\]</span> Reorganizing the above equation gives <span
class="math display">\[\begin{align*}
\hat{\theta} \my{p}_o  = &amp;\hat{\theta} \my{p}_T  - \ell\hat{\my{g}}
+ r(\hat{\theta}  \my{\mu}  - w \hat{\my{g}}).
\end{align*}\]</span> Rewriting this equation in terms of the target's
state variables yields the <em>pseudo-linear angle measurement
equation:</em> <span
class="math display">\[\begin{align}\label{eq_pseudo_linear_measurement_theta_equation}
\begin{aligned}
\hat{\theta} \my{p}_o  =&amp;
\begin{bmatrix}
\hat{\theta} \my{I}_{3\times 3} &amp; \my{0}_{3\times 3}  &amp;
-\hat{\my{g}}
\end{bmatrix}
\left[
  \begin{array}{c}
    p_T \\
    v_T \\
    \ell \\
  \end{array}
\right]
+ r(\hat{\theta}  \my{\mu}  - w \hat{\my{g}} ),
\end{aligned}
\end{align}\]</span> where $ _o $ is the new measurement that is
pseudo-linear in the target's state variables.</p>
<p>Combining <span
class="math inline">\(\eqref{eq_pseudo_linear_measurement_g_equation}\)</span>
and <span
class="math inline">\(\eqref{eq_pseudo_linear_measurement_theta_equation}\)</span>
gives the compact form of the measurement equation: <span
class="math display">\[\begin{align}\label{eq_pseudo_linear_measurement_equations}
\my{z} = \my{H} \my{x}  + \my{\nu} ,
\end{align}\]</span> where Here, <span
class="math inline">\(\nu\)</span> can be rewritten as a matrix form
<span class="math display">\[\begin{align*}
    \nu=E
    \begin{bmatrix}
        \mu \\ w
    \end{bmatrix},
\end{align*}\]</span> where <span
class="math display">\[\begin{align}\label{eq_E_mat}
    E=r
    \begin{bmatrix}
        P_{\hat{g}} &amp; 0_{3\times 1}\\
        \hat{\theta}I_{3\times 3} &amp; -\hat{g}
    \end{bmatrix}\in\mathbb{R}^{6\times 4}.
\end{align}\]</span> As a result, <span
class="math inline">\(\nu\)</span> can be approximately treated as a
linear transformation of Gaussian noises. Its covariance matrix can be
calculated as <span
class="math display">\[\begin{align*}%\label{eq_final_measurement_noise_covariance}
\my{\Sigma}_{\my{\nu}}  = E
\begin{bmatrix}
\sigma_\mu^2 I_{3\times 3} &amp; 0_{3\times1}\\
0_{1\times 3} &amp; \sigma_w^2
\end{bmatrix}
E^\mathrm{T}\in\mathbb{R}^{6\times6}.
\end{align*}\]</span> Although the quantities in <span
class="math inline">\(E\)</span> such as <span
class="math inline">\(\hat{g}\)</span> and <span
class="math inline">\(\hat{\theta}\)</span> contain measurement noises,
it is a common practice to treat them as deterministic quantities.
Otherwise, if, for example, <span class="math inline">\(\hat{g}\)</span>
is split to <span class="math inline">\(\hat{g}=g+\mu\)</span> and we
consider the noise separately, the expression of <span
class="math inline">\(\nu\)</span> would be a complex function of the
true values and the noises. Since the true values are unknown, the
covariance cannot be calculated. Moreover, $r $ in <span
class="math inline">\(\eqref{eq_E_mat}\)</span> is the true target
range, which is unknown. We can use the estimated value <span
class="math inline">\(\hat{r} =\|\hat{\my{p}}_T -\my{p}_o \|\)</span> to
replace it in implementation. Here, <span
class="math inline">\(\hat{p}_T\in\mathbb{R}^3\)</span> is the estimated
value of the target's position. This technique has been used in
bearing-only target estimation .</p>
<p>With the state transition equation <span
class="math inline">\(\eqref{eq_state_transition}\)</span> and the
measurement equation <span
class="math inline">\(\eqref{eq_pseudo_linear_measurement_equations}\)</span>,
the bearing-angle estimator can be realized by the Kalman filter. For a
quick reference, we list the steps below. The prediction steps are <span
class="math display">\[\begin{align*}
\hat{\my{x}}^{-}(t_k) &amp;= \my{F}\hat{\my{x}}(t_{k-1}), \\
\my{P}^{-}(t_k) &amp;= \my{F}\my{P}(t_{k-1})\my{F}^\mathrm{T} +
\my{\Sigma}_q,
\end{align*}\]</span> where <span
class="math inline">\(\hat{\my{x}}^{-}(t_k)\in\mathbb{R}^7\)</span> and
<span
class="math inline">\(\my{P}^{-}(t_k)\in\mathbb{R}^{7\times7}\)</span>
are the prior estimated state and covariance matrix, respectively. The
correction steps are <span class="math display">\[\begin{align*}
\my{K}(t_k) &amp;=
\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)\left[\my{H}(t_k)\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)+\my{\Sigma}_\nu\right]^{\dagger},
\\
\hat{\my{x}}(t_k) &amp;= \hat{\my{x}}^{-}(t_k) +
\my{K}(t_k)\left[\my{z}(t_k)-\my{H}(t_k)\hat{\my{x}}^{-}(t_k)\right], \\
\my{P}(t_k) &amp;=\left[\my{I}_{7\times 7} -\my{K}(t_k)\my{H}(t_k)
\right]\my{P}^{-}(t_k),
\end{align*}\]</span> where <span
class="math inline">\(\my{K}(t_k)\in\mathbb{R}^{7\times6}\)</span> is
the Kalman gain matrix, $(t_k) $ and <span
class="math inline">\(\my{P}(t_k)\)</span> are posterior estimated state
and covariance matrix, and symbol <span
class="math inline">\(\dagger\)</span> denotes the pseudoinverse. The
usage of pseudoinverse in the Kalman filter is a common practice to
prevent the situation that <span
class="math inline">\(\my{H}(t_k)\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)+\my{\Sigma}_\nu\)</span>
is rank deficient .</p>
<p>Although an additional angle measurement is adopted in the
bearing-angle estimator, it is nontrivial to see whether this additional
measurement can improve the system's observability because an additional
unknown variable, the target's physical size, is also required to
estimate. It is therefore necessary to study the observability
conditions under which the target's motion can be successfully
estimated.</p>
<p>In this and the next sections, we present two methods to analyze the
observability conditions. The first method, as presented in this
section, relies on Kalman's observability criterion, which is to check
the rank of the observability matrix of a linear system. The second
method, as presented in the next section, relies on solving a set of
linear equations. Both methods have been adopted in the literature to
analyze the observability of estimators . For the bearing-angle
estimator, the first method considers the specific dynamics of the
filter but is not able to handle the case when the target's motion has a
higher order. The second method can handle the high-order motion of the
target but does not consider the dynamics of the filter. We will show
that the conclusions given by the two methods are consistent. In both of
the methods, we consider the case where <span
class="math inline">\(\ell\)</span> is invariant.</p>
<p>Consider a time horizon of <span class="math inline">\(k\geq
3\)</span> consecutive steps. The observability matrix of the system of
<span class="math inline">\(\eqref{eq_matrix_H}\)</span> and <span
class="math inline">\(\eqref{eq_matrix_A}\)</span> can be calculated as
<span class="math display">\[\begin{align}\label{eq_Qo}
    \my{Q}=
    \begin{bmatrix}
    \my{H}(t_1) \\
    \my{H}(t_2)\my{F} \\
    \my{H}(t_3)\my{F}^2 \\
    \cdots \\
    \my{H}(t_k)\my{F}^{k-1} \\
    \end{bmatrix}\in\mathbb{R}^{6k\times7}.
\end{align}\]</span> Substituting the expressions of <span
class="math inline">\(F\)</span> and <span
class="math inline">\(H\)</span> in <span
class="math inline">\(\eqref{eq_matrix_A}\)</span> and <span
class="math inline">\(\eqref{eq_matrix_H}\)</span> into <span
class="math inline">\(\eqref{eq_Qo}\)</span> yields <span
class="math display">\[\begin{align*}
\my{Q}=
\left[
\begin{array}{ccc}
\my{P}_g(t_1) &amp; \my{0}_{3\times 3} &amp; \my{0}_{3\times 1} \\
\theta(t_1)\my{I}_{3\times 3} &amp; \my{0}_{3\times 3}  &amp;
-\my{g}(t_1) \\
\hdashline
\my{P}_g(t_2) &amp; \delta t\my{P}_{g}(t_2) &amp; \my{0}_{3\times 1} \\
\theta(t_2)\my{I}_{3\times 3} &amp; \delta t\theta(t_2)\my{I}_{3\times
3}  &amp; -\my{g}(t_2) \\
\hdashline
\vdots &amp; \vdots &amp; \vdots \\
\hdashline
\my{P}_g(t_k) &amp; (k-1)\delta t\my{P}_{g}(t_k) &amp; \my{0}_{3\times
1} \\
\theta(t_k)\my{I}_{3\times 3} &amp; (k-1)\delta
t\theta(t_k)\my{I}_{3\times 3}  &amp; -\my{g}(t_k)\\
\end{array}
\right].
\end{align*}\]</span> Note that the noises in the bearing and angle
measurements are neglected when we analyze the fundamental observability
property. After a series of elementary row transformations in <span
class="math inline">\(\my{Q}\)</span>, we can obtain <span
class="math display">\[\begin{align}\label{eq_Qo_2}
\my{Q}
\rightarrow
\begin{bmatrix}
\my{I}_{3\times 3} &amp; \my{0}_{3\times 3} &amp;
-\my{g}(t_1)/\theta(t_1) \\
\my{0}_{3\times 3} &amp; \my{I}_{3\times 3} &amp;
-\delta\my{v}(t_2)/\ell \\
\vdots &amp; \vdots &amp; \vdots \\
\my{0}_{3\times 3} &amp; \my{I}_{3\times 3} &amp;
-\delta\my{v}(t_k)/\ell \\
\hdashline
\my{0}_{3k\times 3} &amp; \my{0}_{3k\times 3} &amp; \my{0}_{3k\times 1}
\end{bmatrix},
\end{align}\]</span> where <span class="math display">\[\begin{align*}
\delta\my{v}(t_k) \doteq \my{v}_T(t_k) - \my{v}_o(t_k)
\end{align*}\]</span>% is the relative velocity.</p>
<p>In the following two subsections, we analyze the rank of the
observability matrix in two scenarios where the observer moves with zero
and nonzero acceleration, respectively. In the two scenarios, the target
is always assumed to move with a constant velocity: <span
class="math display">\[\begin{align*}
\my{v}_T(t_k) = \my{v}_T^\text{const}.
\end{align*}\]</span></p>
<p>Denoted <span class="math inline">\(\my{v}_o\in \mathbb{R}^3\)</span>
as the velocity of the observer. Consider the case where the observer
has a constant velocity <span
class="math inline">\(\my{v}_o^\text{case1}(t_i)=\my{v}_o^\text{const}\)</span>
for any <span class="math inline">\(i\in\{1,\dots,k\}\)</span>. Then,
the relative velocity is also constant: <span
class="math display">\[\begin{align}\label{eq_delta_vel_case1}
\delta \my{v}^\text{case1}(t_i) = \my{v}_T^\text{const} -
\my{v}_o^\text{const} = \delta\my{v}^\text{const}.
\end{align}\]</span> Substituting <span
class="math inline">\(\eqref{eq_delta_vel_case1}\)</span> into <span
class="math inline">\(\eqref{eq_Qo_2}\)</span> and conducting elementary
row transformation yields <span
class="math display">\[\begin{align}\label{eq_Qo_3}
\my{Q}^\text{case1}
\rightarrow
\left[
\begin{array}{cc:c}
\my{I}_{3\times 3} &amp; \my{0}_{3\times 3} &amp;
-\my{g}(t_1)/\theta(t_1) \\
\my{0}_{3\times 3} &amp; \my{I}_{3\times 3} &amp;
-\delta\my{v}^\text{const}/\ell \\
\hdashline
\my{0}_{6(k-1)\times 3} &amp; \my{0}_{6(k-1)\times 3} &amp;
\my{0}_{6(k-1)\times 1}
\end{array}\right].
\end{align}\]</span> Since the upper <span
class="math inline">\(6\times7\)</span> block of <span
class="math inline">\(\eqref{eq_Qo_3}\)</span> has full row rank and the
lower block is zero, the rank of <span
class="math inline">\(\my{Q}^\text{case1}\)</span> is <span
class="math display">\[\begin{align*}
\text{rank}\left(\my{Q}^\text{case1}\right) = 6.
\end{align*}\]</span> Since the number of states is seven and the rank
is six, we know there is . To identify this unobservable mode, we
calculate the unobservable subspace, which is the null space of <span
class="math inline">\(\my{Q}\)</span>: <span
class="math display">\[\begin{align}\label{eq_unobservable_subspace}
\text{Null}\left(\my{Q}^\text{case1}\right) = \text{span}\left\{
\begin{bmatrix}
\my{g}(t_1)/\theta(t_1)  \\
\delta\my{v}^\text{const}/\ell \\
1
\end{bmatrix}\right\}.
\end{align}\]</span> According to <span
class="math inline">\(\eqref{eq_unobservable_subspace}\)</span>, the
unobservable mode is <span class="math display">\[\begin{align}
x^T
\left[
\begin{array}{c}
\my{g}(t_1)/\theta(t_1)  \\
\delta\my{v}^\text{const}/\ell \\
1
\end{array}
\right]
=
\my{p}_T^\mathrm{T}\dfrac{\my{g}(t_1)}{\theta(t_1)}+
\my{v}_T^\mathrm{T}\dfrac{\delta\my{v}^\text{const}}{\ell} + \ell.
\label{eq_unobservable_mode}
\end{align}\]</span>% Although there is only one unobservable mode, this
mode given in <span
class="math inline">\(\eqref{eq_unobservable_mode}\)</span> involves all
the states including the target's position, velocity, and physical size.
It suggests that the estimation of the three quantities is coupled. In
conclusion, we know that, if the target moves with a constant velocity,
its states are unobservable when the observer moves with a constant
velocity.</p>
<p>We now consider the case where the observer has nonzero acceleration
so that its velocity is time-varying across the time horizon from <span
class="math inline">\(t_1\)</span> to <span
class="math inline">\(t_k\)</span>.</p>
<p>Denote <span
class="math inline">\(\my{a}_o(t_i)\in\mathbb{R}\)</span> as the
observer's acceleration, which can be approximated as <span
class="math display">\[\begin{align}\label{eq_acc}
\my{a}_o(t_i) &amp;\approx
\dfrac{\my{v}_o(t_i) - \my{v}_o(t_{i-1})}{\delta t} \nonumber\\
&amp;=-\dfrac{\left[\my{v}_T^\text{const} - \my{v}_o(t_i)\right] -
\left[\my{v}_T^\text{const} - \my{v}_o(t_{i-1})\right]}{\delta t}
\nonumber\\
&amp;=-\dfrac{\delta \my{v}(t_i) - \delta \my{v}(t_{i-1})}{\delta t}.
\end{align}\]</span> Substituting <span
class="math inline">\(\eqref{eq_acc}\)</span> into <span
class="math inline">\(\eqref{eq_Qo_2}\)</span> and performing elementary
row transformation yields <span
class="math display">\[\begin{align}\label{eq_Q_case2_final}
\my{Q}^\text{case2}
\rightarrow
\left[\begin{array}{ccc}
\my{I}_{3\times 3} &amp; \my{0}_{3\times 3} &amp;
-\my{g}(t_1)/\theta(t_1) \\
\my{0}_{3\times 3} &amp; \my{I}_{3\times 3} &amp;
-\delta\my{v}(t_2)/\ell \\
\my{0}_{3\times 3} &amp; \my{0}_{3\times 3} &amp; \delta t
\my{a}_o(t_3)/\ell \\
\hdashline
\vdots &amp; \vdots &amp;\vdots \\
\my{0}_{3\times 3} &amp; \my{0}_{3\times 3} &amp; \delta t
\my{a}_o(t_k)/\ell \\
\my{0}_{3k\times 3} &amp; \my{0}_{3k\times 3} &amp; \my{0}_{3k\times 1}
\end{array}\right].
\end{align}\]</span> The upper <span
class="math inline">\(6\times7\)</span> block in <span
class="math inline">\(\eqref{eq_Q_case2_final}\)</span> has full column
rank. Therefore, if <span class="math inline">\(a_o(t_i)\ne0\)</span>
for any <span class="math inline">\(i\geq3\)</span>, then <span
class="math display">\[\begin{align*}
\text{rank}\left(\my{Q}^\text{case2}\right) = 7,
\end{align*}\]</span> Which is the same as the number of estimated
states. Therefore, the target's state is observable when the observer
moves with nonzero acceleration.</p>
<p>From the above analysis, we know that when the target has a constant
velocity, its states including its position, velocity, and physical size
are observable if and only if the observer has non-zero
accelerations.</p>
<p>The critical difference of this condition from the bearing-only case
is that the target's states are still observable towards or backward the
target. By contrast, for a bearing-only estimator, moving along the
bearing vector is insufficient to recover the target's motion.
Therefore, the additional lateral motion of the observer required in the
bearing-only case is required in the bearing-angle case anymore, which
provides better flexibility for designing the observer's motion.</p>
<p>This section extends the observability condition obtained in the last
section to more general cases where the target's velocity does not have
to be constant.</p>
<p>The observability problem that we aim to solve is to determine
whether <span class="math inline">\(\my{p}_T(t)\)</span> can be
recovered from <span class="math inline">\(\my{p}_o(t)\)</span> and
<span class="math inline">\(g(t),\theta(t)\)</span>.</p>
<p>Suppose the target's motion can be described by an <span
class="math inline">\(n\)</span>th-order polynomial during a time
interval: <span
class="math display">\[\begin{align}\label{eq_target_nth_Order}
    \my{p}_T(t)=\my{b}_0+\my{b}_1t+\cdots+\my{b}_nt^n,
\end{align}\]</span> where <span class="math inline">\(\my{b}_0,
\my{b}_1, \cdots, \my{b}_n\in\mathbb{R}^3\)</span> are unknown constant
vectors. If we can determine the values of <span
class="math inline">\(\{b_i\}_{i=0}^n\)</span>, then we can determine
the target's motion and hence it is observable. Although polynomials
cannot represent all trajectories, they can effectively approximate a
majority of them according to the method of Taylor expansion. This is
especially true if we consider a short time horizon. This kind of
technique has been adopted in the observability analysis of bearing-only
target motion estimation tasks~.</p>
<p>Suppose the observer's motion is described by <span
class="math display">\[\begin{align*}
    \my{p}_o(t)=\my{c}_0+\my{c}_1t+\cdots+\my{c}_nt^n+\my{h}(t),
\end{align*}\]</span>% where <span class="math inline">\(\my{c}_0,
\my{c}_1, \cdots, \my{c}_n\in\mathbb{R}^3\)</span> are constant
parameters, and <span
class="math display">\[\begin{align}\label{eq_definition_h}
\my{h}(t) = \my{d}_1 t^{n+1}+\my{d}_2t^{n+2}+\cdots
\end{align}\]</span> represents motion with <span
class="math inline">\(\my{d}_1, \my{d}_2,
\cdots\in\mathbb{R}^3\)</span>. It can be verified that the derivatives
of <span class="math inline">\(\my{h}(t)\)</span> satisfy <span
class="math inline">\(\my{h}^{(i)}(0)=\my{0}_{3\times 1}\)</span> for
<span class="math inline">\(i=0,1,\cdots, n\)</span>. % Let <span
class="math inline">\(\my{s}(t)\in\mathbb{R}^3\)</span> be the relative
motion between the target and the observer: <span
class="math display">\[\begin{align}\label{eq_relative_motion}
    \my{s}(t)&amp;\doteq\my{p}_T(t)-\my{p}_o(t)  \nonumber\\
    &amp;\doteq\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t),
\end{align}\]</span> where <span class="math inline">\(\my{s}_i =
\my{d}_i - \my{c}_i\in\R^3\)</span> for <span class="math inline">\(i =
0,1,\cdots, n\)</span>.</p>
<p>If we can determine <span
class="math inline">\(\{s_i\}_{i=0}^n\)</span>, then <span
class="math inline">\(s(t)\)</span> and hence <span
class="math inline">\(p_T(t)\)</span> can be determined. Therefore, we
next study under what conditions <span
class="math inline">\(\{s_i\}_{i=0}^n\)</span> can be uniquely
determined. Since <span
class="math inline">\(\my{p}_T(t)-\my{p}_o(t)=g(t)r(t)\)</span>
according to <span
class="math inline">\(\eqref{eq_bearing_measure}\)</span> and <span
class="math inline">\(r(t)=\ell/\theta(t)\)</span> according to <span
class="math inline">\(\eqref{eq_theta_measure}\)</span>, we have <span
class="math display">\[s(t)=\my{p}_T(t)-\my{p}_o(t)=g(t)r(t)=\frac{g(t)}{\theta(t)}\ell.
\]</span> Substituting the above equation into <span
class="math inline">\(\eqref{eq_relative_motion}\)</span> yields <span
class="math display">\[\begin{align}\label{eq_st_tem}
\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t)=\frac{g(t)}{\theta(t)}\ell.
\end{align}\]</span> Here, <span class="math inline">\(\my{s}_0, \cdots,
\my{s}_n, \ell\)</span> are unknowns to be determined and <span
class="math inline">\(\my{g}(t),\theta(t),\my{h}(t)\)</span> are known.
Equation~<span class="math inline">\(\eqref{eq_st_tem}\)</span> can be
reorganized to a linear equation: <span
class="math display">\[\begin{align}\label{eq_linear_equations}
    \my{A}(t)\my{X} = \my{h}(t),
\end{align}\]</span> where <span class="math display">\[\begin{align*}
\my{X}&amp;=
\begin{bmatrix}
\my{s}_0^\mathrm{T}, \my{s}_1^\mathrm{T}, \cdots, \my{s}_n^\mathrm{T},
\ell
\end{bmatrix}^\mathrm{T}\in\mathbb{R}^{3n+4},
\end{align*}\]</span> and <span
class="math display">\[\begin{align}\label{eq_original_A}
\my{A}(t)&amp;=
\begin{bmatrix}
\my{I}_{3\times3}, t\my{I}_{3\times3}, \cdots, t^n\my{I}_{3\times3},
\rho(t)
\end{bmatrix}\in\mathbb{R}^{3\times(3n+4)},
\end{align}\]</span> where <span
class="math display">\[\begin{align}\label{eq_rho_denote}
\rho(t)&amp;\doteq-\dfrac{\my{g}(t)}{\theta(t)}\in\R^3.
\end{align}\]</span> Therefore, the problem that we aim to solve becomes
determining whether <span class="math inline">\(X\)</span> can be
uniquely solved from <span
class="math inline">\(\eqref{eq_linear_equations}\)</span>.</p>
<p>We next present a necessary and sufficient condition under which the
solution <span class="math inline">\(X\)</span> of <span
class="math inline">\(\eqref{eq_linear_equations}\)</span> is
unique.</p>
<p>Some important remarks about Theorem~<span
class="math inline">\(\ref{theorem_observability_confition}\)</span> are
given below.</p>
<ol type="1">
<li><p>The necessary and sufficient condition suggested by Theorem~<span
class="math inline">\(\ref{theorem_observability_confition}\)</span> is
that the observer should have higher-order motion than the target. For
example, when the target is stationary, the observer should move with a
nonzero velocity. When the target moves with a constant velocity, the
observer should move with a nonzero acceleration.</p></li>
<li><p>The necessary and sufficient condition given by Theorem~<span
class="math inline">\(\ref{theorem_observability_confition}\)</span> has
a from the bearing-only case that the higher-order motion in the
bearing-angle case is required to be orthogonal to the bearing vector,
making the bearing-angle approach more flexible than the bearing-only
one. For example, the bearing-angle approach can estimate the target's
motion even if the observer simply moves along the bearing
vector.</p></li>
<li><p>In the special case where the target moves with a constant
velocity, the condition in Theorem~<span
class="math inline">\(\ref{theorem_observability_confition}\)</span> is
consistent with the one obtained in Section~<span
class="math inline">\(\ref{sec_analysis_of_observability_matrix}\)</span>.
Although the condition in Theorem~<span
class="math inline">\(\ref{theorem_observability_confition}\)</span>
allows more general target motion, the analysis in Section~<span
class="math inline">\(\ref{sec_analysis_of_observability_matrix}\)</span>
is still meaningful since it is directly related to the dynamic model
used in the pseudo-linear Kalman filter.</p></li>
<li><p>In practice, we would not estimate the target's motion by using
the method of solving an equation like <span
class="math inline">\(\eqref{eq_new_linear_equtions}\)</span>. That is
because such a method involves calculating high-order derivatives, which
are challenging to obtain accurately in practice. The role of this
equation is to provide a fundamental perspective on whether there is
sufficient information to uniquely recover the target's motion.</p></li>
</ol>
<p>It is of practical importance to study how many discrete observations
are required to recover the target's motion. Although Theorem~<span
class="math inline">\(\ref{theorem_observability_confition}\)</span>
gives an observability condition, it does not answer this question
because it is based on the continuous time domain. We next answer this
question by exploring multiple discrete time steps.</p>
<p>Theorem~<span
class="math inline">\(\ref{theorem_observation_number}\)</span> suggests
that when the target is stationary and hence <span
class="math inline">\(n=0\)</span>, at least two discrete observations
are sufficient to localize the target. This is true even if the two
observations are acquired when the observer moves along the bearing
vector. When the target moves with a constant velocity and hence <span
class="math inline">\(n=1\)</span>, at least three discrete observations
are sufficient to localize the target, which is consistent with the
results in Section~<span
class="math inline">\(\ref{sec_analysis_of_observability_matrix}\)</span>.</p>
<p>This section presents a set of numerical simulation results to
demonstrate the effectiveness of the proposed bearing-angle
approach.</p>
<p>The values of the parameters in two estimators are selected as <span
class="math inline">\(\sigma_v=10^{-3}\)</span>, <span
class="math inline">\(\sigma_l=10^{-4}\)</span>, <span
class="math inline">\(\sigma_\mu=0.01\)</span>, and <span
class="math inline">\(\sigma_w=0.01\)</span>. The selection of these
values is inspired by the measurement noises obtained in the AirSim
simulation and real-world experiments as shown later. The initial
covariance matrix of the estimated states is set to <span
class="math inline">\(P(t_0)=0.1I\)</span>. The target is a circle whose
diameter is <span class="math inline">\(\ell=1\)</span>. The update rate
of the system is <span class="math inline">\(50\)</span>~Hz. In
addition, we use the same parameter values across all the simulation
examples to verify the robustness of the algorithm. Better performances
can be achieved if the parameters are well-tuned for specific scenarios.
We perform <span class="math inline">\(N_x=100\)</span> Monte Carlo
simulations for each scenario.</p>
<p>We use the normalized-estimation error squared (NEES) to analyze the
consistency of the estimation algorithms. In particular, the value of
the average NEES is</p>
<p><span class="math display">\[\begin{align}
    \bar{\epsilon}_{\text{NEES}}=\dfrac{1}{N_x}\sum_{i=1}^{N_x}(x-\hat{x}_i)^\mathrm{T}P_i^{-1}(x-\hat{x}_i),
    \label{eq_nees}
\end{align}\]</span> %where <span
class="math inline">\(n_x\in\mathbb{R}\)</span> is the dimension of the
estimated states (<span class="math inline">\(n_x=6\)</span> for
bearing-only, and <span class="math inline">\(n_x=7\)</span> for
bearing-angle). where <span class="math inline">\(\hat{x}_i\)</span> is
the estimated states in the <span class="math inline">\(i\)</span>th
simulation, and <span class="math inline">\(P_i\)</span> is the
covariance matrix obtained from the estimator in the <span
class="math inline">\(i\)</span>th simulation. %The expectation of the
average NEES value would be equal to the number of the estimated
states.</p>
<p>Finally, image acquisition and visual detection are not considered in
these numerical simulation scenarios. They will be considered in
Section~<span class="math inline">\(\ref{sec_airsim_simulation}\)</span>
and Section~<span
class="math inline">\(\ref{sec_real_world_experimental_validation}\)</span>.</p>
<p>In the first scenario, the target is stationary and located at <span
class="math inline">\(\my{p}_T=[0, 10]^\mathrm{T}\)</span>. The observer
moves on a circle centered at the target with the speed of <span
class="math inline">\(3\)</span>~m/s (see Fig.~<span
class="math inline">\(\ref{fig_matlab_1}\)</span>). The radius of the
circle is <span class="math inline">\(5\)</span>~m. The initial
estimates are <span class="math inline">\(\hat{p}_o(t_0) = [0,
13]^\mathrm{T}\)</span>, <span class="math inline">\(\hat{v_o}(t_0)=[0,
0]^\mathrm{T}\)</span>, <span
class="math inline">\(\hat{\ell}(t_0)=1.6\)</span>. During this process,
the bearing vector varies while the angle subtended by the target
remains constant. The angle measurement varies slightly due to the
measurement noise. This scenario is favorable to the conventional
bearing-only approach because its observability condition that the
target should be viewed from different angles is well satisfied .</p>
<p>Fig.~<span class="math inline">\(\ref{fig_matlab_1}\)</span> shows
the estimation results by the two approaches of bearing-only and
bearing-angle. As can be seen, both algorithms perform well. The
convergence of the bearing-angle approach is faster than the
bearing-only one, as shown in the middle and right subfigures of
Fig.~<span class="math inline">\(\ref{fig_matlab_1}\)</span>, due to the
additional angle measurement. The bearing-angle approach can
successfully estimate the size of the target as shown in the right
subfigure of Fig.~<span
class="math inline">\(\ref{fig_matlab_1}\)</span>.</p>
<p>In the second scenario, the target is also stationary but the
observer moves along a straight line towards and backwards the target
repeatedly (Fig.~<span
class="math inline">\(\ref{fig_matlab_2}\)</span>). During this process,
the bearing vector remains constant while the angle varies. This
scenario is most challenging for the bearing-only approach because its
observability condition is not fulfilled.</p>
<p>In this simulation scenario, the target is stationary and located at
<span class="math inline">\(\my{p}_T(t_0)=[0, 10]^\mathrm{T}\)</span>.
The observer moves along a straight line towards and backwards the
target with a constant acceleration of <span
class="math inline">\(-2\)</span>~<span
class="math inline">\(\text{m/s}^2\)</span>. The initial conditions are
<span class="math inline">\(v_o(t_0)=[0, 4]^\mathrm{T}\)</span> and
<span class="math inline">\(\my{p}_o (t_0)= [0,5]^\mathrm{T}\)</span>.
The initial estimates are <span class="math inline">\(\hat{p}_o(t_0) =
[0, 8]^\mathrm{T}\)</span>, <span
class="math inline">\(\hat{v_o}(t_0)=[0, 0]^\mathrm{T}\)</span>, <span
class="math inline">\(\hat{\ell}(t_0)=0.8\)</span>. In this scenario,
the true bearing of the target relative to the observer remains
unchanged though the bearing measurement may vary slightly due to the
measurement noise.</p>
<p>Fig.~<span class="math inline">\(\ref{fig_matlab_2}\)</span> shows
the estimation results of the bearing-only and bearing-angle approaches.
As can be seen, the bearing-only approach diverges since its
observability condition is not satisfied. By contrast, the proposed
bearing-angle approach converges, and is able to localize the target and
estimate its size, which demonstrates the strong observability of the
bearing-angle approach. One may notice that the estimated size and the
NEES value get worse first before converging. This is because the noise
level of the angle is set to be constant. Since the angle is small in
the beginning, the noise-angle ratio is large, causing a relatively
large NEES value.</p>
<p>The third scenario is more complex than the first two. Here, the
target moves with a constant velocity where the observer is controlled
by a proportional navigation guidance (PNG) law to approach the target
(Fig.~<span class="math inline">\(\ref{fig_matlab_3}\)</span>). During
this process, both the bearing and angle vary. This scenario is also
challenging for the bearing-only approach because its observability is
weak due to the fact that the lateral motion of the observer is small.
Many researchers have studied how to add extra control commands to the
PNG to enhance the observability based on the bearing-only approach
.</p>
<p>In this simulation scenario, the target moves along a straight line
with a constant velocity <span
class="math inline">\(\my{v}_T=[1/\sqrt{2},
1/\sqrt{2}]^\mathrm{T}\)</span>. The observer's velocity magnitude is
constantly <span class="math inline">\(3\)</span>~m/s while the velocity
direction is controlled by a PNG law. The navigation gain of the PNG law
is selected as one. The initial estimates of the target's states are the
same as Scenario~1. The simulation stops just before the observer
collides with the target.</p>
<p>Fig.~<span class="math inline">\(\ref{fig_matlab_3}\)</span> shows
the estimation results by the bearing-only and bearing-angle approaches.
As can be seen, the bearing-angle algorithm successfully converges
before the collision occurs, but the bearing-only algorithm fails to
estimate the target's states due to its weak observability. This
simulation example demonstrates that the bearing-angle algorithm can be
used directly in the guidance scenario without extra maneuvers required
by the bearing-only approach .</p>
<p>Although <span class="math inline">\(\ell\)</span> is assumed to be
invariant, it is meaningful to challenge the proposed bearing-angle
approach by considering time-varying <span
class="math inline">\(\ell\)</span>. We will see through simulation
examples that the bearing-angle approach is still effective when <span
class="math inline">\(\ell\)</span> varies slowly. It becomes unstable
when <span class="math inline">\(\ell\)</span> varies rapidly since the
assumption of invariant <span class="math inline">\(\ell\)</span> is
severely invalid.</p>
<p>Suppose that the target object has a square shape. Then, <span
class="math inline">\(\ell\)</span> varies when the object is observed
from different viewing angles or the object spins. Fig.~<span
class="math inline">\(\ref{fig_matlab_4}\)</span> shows a scenario where
the observer moves around the target, whose spinning speed is <span
class="math inline">\(2\pi\)</span>~rad/s. The red curve in the right
subfigure represents the true value of <span
class="math inline">\(\ell\)</span>, which varies rapidly. As can be
seen, the bearing-angle algorithm works effectively though there is a
small estimation bias. Fig.~<span
class="math inline">\(\ref{fig_matlab_pi_8}\)</span> shows a scenario
where the observer moves along the bearing vector. The spinning speed of
the target object is <span class="math inline">\(\pi/8\)</span>~rad/s.
As can be seen, the bearing-only approach diverges due to the lack of
observability. The bearing-angle algorithm can still converge since
<span class="math inline">\(\ell\)</span> varies slowly. When we further
increase the spinning speed of the target, the bearing-angle algorithm
will also diverge because the algorithm cannot distinguish whether the
change of <span class="math inline">\(\theta\)</span> is caused by the
change of <span class="math inline">\(\ell\)</span> or the change of
<span class="math inline">\(r\)</span>.</p>
<p>In this section, we show simulation results under a more realistic
setup. In particular, the simulation is based on AirSim, a simulator
that can provide high-quality visual simulation . Nonlinear MAV dynamics
and control are also considered.</p>
<p>Fig.~<span
class="math inline">\(\ref{fig_architecture_airsim}\)</span> shows an
AirSim simulation scenario. As can be seen, there are two flying
quadcopter MAVs. The observer MAV can capture images of the target MAV
using its simulated onboard camera. A simple gimbal camera controller is
implemented so that the target MAV is always located inside the field of
view of the camera. The visual environment used in the simulation is
called Landscape Mountains, which includes realistic mountains, lakes,
trees, and roads. Other environments can also be used if needed.</p>
<p>The bearing and angle measurements are obtained from the bounding
boxes generated by a Yolo-based detection algorithm. A tiny-YOLO v4
network is trained to detect the target MAV in the images. Although the
visual detector can be replaced by other state-of-the-art ones, the
tiny-YOLO v4 network is already sufficient to verify our proposed
approach. The architecture of the entire simulation system is shown in
Fig.~<span class="math inline">\(\ref{fig_box_airsim}\)</span>. The
system consists of the modules of automatic image dataset collection,
Yolo-based target detection, gimbal camera control, nonlinear quadcopter
dynamics, and quadcopter flight control. The quadcopter dynamics and
flight control used in the simulation are similar to and omitted here
due to space limitation. The quadcopter's physical size varies slightly
when viewed from different directions, although it is assumed to be
invariant. All of these factors make the Airsim simulation more
realistic and challenging.</p>
<p>To train the Yolo-based detector, we developed a module to
automatically collect an image dataset. This module has some advantages.
First, it is efficient. More than ten thousand labeled images can be
collected automatically in 24 hours. Second, it is flexible. It can
acquire images with random target's positions, random target's
attitudes, random camera's view angles, and random background scenes.
These images are beneficial to achieve a good generalization ability of
the detector. Third, the image labels are of high quality. Since the
ground truth of the target's image is known in the simulation, the
generated bounding box is tight. The collected dataset contains 17,000
labeled images (see Fig.~<span
class="math inline">\(\ref{fig_airsim_dataset}\)</span>). The resolution
of the images is <span class="math inline">\(1536\times 864\)</span>
pixels. The simulation system was deployed on a Dell Precision 7920
Tower Workstation with two NVIDIA Quadro GV100 graphic cards. Since the
dataset is sufficient and high-quality, the detection can achieve the
accuracy of mAP=99.5%.</p>
<p>We first consider the scenarios where the observer MAV approaches or
follows a target MAV. These scenarios widely exist in practical
applications such as aerial target pursuit.</p>
<p>We show two simulation examples in Fig.~<span
class="math inline">\(\ref{fig_airsim_1}\)</span> and Fig.~<span
class="math inline">\(\ref{fig_airsim_2}\)</span>, respectively. In both
examples, the observer is controlled by a controller so that it can
approach the target and maintain a desired separation. In particular,
the controller is <span class="math display">\[\begin{align}
\label{eq_tracking_control}
v_o^\text{cmd}(t)&amp;=v_T(t)+k^\text{track}\dfrac{r^2(t)-r_d^2}{r^2(t)}g(t),
\end{align}\]</span> where <span
class="math inline">\(v_o^\text{cmd}(t)\)</span> is the velocity command
of the observer MAV, <span
class="math inline">\(k^\text{track}=3\)</span> is the control gain, and
<span class="math inline">\(r_d=3\)</span> is the desired separation.
The magnitude of the observer's velocity is bounded from above by <span
class="math inline">\(3\)</span>~m/s. It should be noted that <span
class="math inline">\(\eqref{eq_tracking_control}\)</span> relies on the
true position and velocity of the target MAV in the simulation.
Therefore, the data is collected first and then processed offline so
that we can compare the performances of the bearing-only and
bearing-angle approaches.</p>
<p>In the first example, the target MAV hovers constantly at <span
class="math inline">\(p_T(t_0)=[0, 10, 10]^\mathrm{T}\)</span>. The
observer MAV moves along a straight line toward the target with a
decreasing velocity command. Since the bearing of the target MAV remains
the same, this example is challenging for the bearing-only approach. As
shown in Fig.~<span class="math inline">\(\ref{fig_airsim_1}\)</span>,
the bearing-only approach fails to converge while the bearing-angle
approach can successfully estimate the target's motion.</p>
<p>In the second example, the target MAV moves with a constant velocity
of <span class="math inline">\(v_T=[1/\sqrt{2}, 1/\sqrt{2},
0]^\mathrm{T}\)</span>. The trajectory of the observer MAV under the
control of <span
class="math inline">\(\eqref{eq_tracking_control}\)</span> is still
close to (though not strictly) a straight line. As a result, the
observability is weak by the bearing-only approach. As shown in
Fig.~<span class="math inline">\(\ref{fig_airsim_2}\)</span>, the
bearing-angle approach successfully converges while the bearing-only one
fails. It is notable that <span class="math inline">\(\ell\)</span> is
invariant in the first example and varies slowly in the second
example.</p>
<p>It is worth mentioning that the detection results used in the
estimation algorithms are obtained from the Yolo-based estimator. The
ground truth obtained from AirSim is only used to calculate the errors
of measurements, as shown in the right figures of Figs.~<span
class="math inline">\(\ref{fig_airsim_1}\)</span> and <span
class="math inline">\(\ref{fig_airsim_2}\)</span>. It is not surprising
that the measurement noises are not strictly Gaussian since the 2D
bounding box is generated by a deep learning vision algorithm. It is
noticed that the noises are inversely correlated to the observer-target
range. This is reasonable because, when the target is close to the
camera and hence its image is large, the center point and the size of
the bounding box usually vary for a few pixels.</p>
<p>The NEES values are also shown in Fig.~<span
class="math inline">\(\ref{fig_airsim}\)</span>. As can be seen, the
NEES value of the bearing-only approach diverges. The NEES value of the
bearing-angle approach oscillates and converges slowly. The reasons are
analyzed as follows. Compared to the Matlab-based numerical simulation,
the visual measurements here are generated by deep learning algorithms,
and the measurement noises are non-Gaussian. The non-Gaussian noises
propagate into <span class="math inline">\(P\)</span> in <span
class="math inline">\(\eqref{eq_nees}\)</span> since the calculation of
<span class="math inline">\(P\)</span> relies on noisy measurements. The
noises may also cause an estimation bias that can further aggravate the
NEES error. Moreover, although the system is observable in the two
simulation examples, the observability is relatively weak compared to
the case where the observer moves surrounding the target. As a result,
the matrix <span class="math inline">\(P\)</span> may not be able to
perfectly describe the estimation accuracy. These elements may jointly
cause the convergence behavior of the NEES values shown in Fig.~<span
class="math inline">\(\ref{fig_airsim}\)</span>.</p>
<p>We next examine a case where <span
class="math inline">\(\ell\)</span> is time-varying. In particular,
suppose a target quadcopter MAV hovers constantly at <span
class="math inline">\(p_T(t_0)=[0, 10, 10]^\mathrm{T}\)</span>. The
observer MAV moves on a circle centered at the target (Fig.~<span
class="math inline">\(\ref{fig_airsim_6_1}\)</span>). Since the target
quadcopter MAV has a square shape from the top view, its size <span
class="math inline">\(\ell\)</span> is time-varying when viewed from
side angles (see the red curves in the middle subfigure of Fig.~<span
class="math inline">\(\ref{fig_airsim_6_1}\)</span>).</p>
<p>We show two simulation examples in Fig.~<span
class="math inline">\(\ref{fig_airsim_6_1}\)</span> and Fig.~<span
class="math inline">\(\ref{fig_airsim_6_2}\)</span>, respectively. The
two simulation examples share the same measurement data but different
values of <span class="math inline">\(\sigma_\ell\)</span>. Moreover,
the other parameters are the same as those in Section~<span
class="math inline">\(\ref{sec_sim_res_for_tracking}\)</span>.</p>
<p>In the first simulation example, <span
class="math inline">\(\sigma_\ell\)</span> is set to be a small value:
<span class="math inline">\(\sigma_\ell=10^{-4}\)</span>. Its
interpretation is that <span class="math inline">\(\ell\)</span> is
treated as invariant during the process. In this case, the performance
of the bearing-angle approach is almost the same as the bearing-only one
as shown in Fig.~<span
class="math inline">\(\ref{fig_airsim_6_1}\)</span>. Since <span
class="math inline">\(\ell\)</span> is treated to be invariant, the
estimated value <span class="math inline">\(\hat{\ell}\)</span>
converges to a constant which is the mean value of the time-varying
<span class="math inline">\(\ell\)</span>.</p>
<p>In the second simulation example, the value of <span
class="math inline">\(\sigma_\ell\)</span> is larger than the first
example: <span class="math inline">\(\sigma_\ell = 0.01\)</span>. Its
interpretation is that <span class="math inline">\(\ell\)</span> is
believed to be time-varying during the process. In this case, the
performance of the bearing-angle approach is still almost the same as
the bearing-only one. Moreover, since <span
class="math inline">\(\sigma_\ell\)</span> is large, the bearing-angle
approach can successfully estimate the true time-varying value of <span
class="math inline">\(\ell\)</span>.</p>
<p>In summary, in the case where <span
class="math inline">\(\ell\)</span> varies slowly, the bearing-angle
approach would degenerate to the bearing-only one. The fundamental
reason is that the extra information embedded in the angle measurement
is used to estimate the time-varying <span
class="math inline">\(\ell\)</span> rather than improving the
observability of the target's motion.</p>
<p>In this section, two sets of real-world experiments are presented to
further verify the effectiveness of the approach. The first is based on
a hand-held camera and a ground robot. The second is based on two
quadcopter MAVs. The second experimental scenario is motivated by aerial
target pursuit tasks.</p>
<p>The experimental setup is shown in Fig.~<span
class="math inline">\(\ref{fig_architecture_indoor}\)</span>. The
observer is a hand-held camera (Hik Vision DS-E14S) connected to a
laptop. The camera's intrinsic parameters are calibrated beforehand. The
robot built on Mecanum wheels can move in any direction on the ground
under velocity control. The ground truth of the states of the camera and
the robot are provided by a Vicon indoor motion capture system. The key
experimental specifications are listed in Table~<span
class="math inline">\(\ref{table_indoor_hardware}\)</span>.</p>
<p>A dataset of 5,514 images was collected and used to train a tiny-YOLO
v4 network to detect the target robot (see Fig.~<span
class="math inline">\(\ref{fig_car_dataset}\)</span>). The detection
precision of the trained network is mAP=99.8%. In the experiment, the
target robot is commanded to move with a constant velocity. In the
meantime, a person holding the camera moves along some trajectories. Two
different cases are studied. In both of the cases, the target robot
moves with a constant velocity <span class="math inline">\(v_T=[-0.1,
0.1 ,0]^\mathrm{T}\)</span>. The noises of the measurements are
calculated based on the ground truth provided by the Vicon system. The
noises are shown in the right subfigures of Fig.~<span
class="math inline">\(\ref{fig_indoor_9}\)</span> and Fig.~<span
class="math inline">\(\ref{fig_indoor_6}\)</span>.</p>
<p>In the first case, the camera is held about 1.5 meters above the
ground and moves around the target robot. In this case, the bearing
vector varies sufficiently and hence the observability conditions for
the bearing-only and bearing-angle approaches are both well satisfied.
As shown in Fig.~<span
class="math inline">\(\ref{fig_indoor_9}\)</span>, both approaches
perform well in this case while the bearing-angle approach performs
slightly better than the bearing-only one.</p>
In the second case, the camera moves along the trajectory of the robot
by getting close or far from it periodically. In this case, the angle
varies significantly, but the bearing does not. Without surprise, the
bearing-only approach performs poorly in this case due to weak
observability (Fig.~<span
class="math inline">\(\ref{fig_indoor_6}\)</span>). By contrast, the
bearing-angle approach can perform stably due to its enhanced
observability.
<p>Two MAV platforms were developed based on DJI M300 quadcopters
(Fig.~<span class="math inline">\(\ref{fig_M300}\)</span>). The MAV
platforms are equipped with RTK GPS modules for accurate
self-localization, an H20 camera for visual detection, a Manifold 2G
onboard computer for onboard flight control, and a Zigbee module for
wireless communication. Some key specifications of the MAV platforms are
listed in Table~<span class="math inline">\(\ref{table_M300}\)</span>.
The structure of the hardware perception and communication system is
illustrated in Fig.~<span
class="math inline">\(\ref{fig_outdoor_hardware}\)</span>. The target
MAV is also equipped with an RTK GPS module, whose measurements are used
as the ground truth to calculate the noises of the visual measurements.
The noises are shown in the right subfigure of Fig.~<span
class="math inline">\(\ref{fig_outdoor_1}\)</span>.</p>
<p>The experiment consists of two stages: data acquisition and offline
data processing. In the data acquisition stage, the target MAV is
commanded to fly with a constant velocity, and the observer MAV is
automatically controlled to follow the target MAV to maintain a constant
distance from the target. More specifically, the procedure of the flight
experiment is as follows. Initially, the observer MAV is placed about 20
meters behind the target MAV on the ground. Then, the two MAVs take off
and fly to the same specified height automatically upon a takeoff
command sent from the ground control station. After they have reached
the desired height, all deployed algorithms are activated. Then, the
target MAV moves with a constant velocity of <span
class="math inline">\(v_T=[1/\sqrt{2}, 1/\sqrt{2},
0]^\mathrm{T}\)</span>. The observer MAV approaches the target by the
controller in <span
class="math inline">\(\eqref{eq_tracking_control}\)</span>. It takes the
observer MAV about eight seconds to reach the desired relative distance.
Then, the two MAVs fly with the same velocity and remain relatively
stationary for another 20 seconds. Finally, the ground station sends a
stop command and the two MAVs return and land automatically.</p>
<p>During the flight, the gimbal camera of the observer MAV is
automatically controlled so that the target MAV is maintained in the
field of view. It is noted that the control of the gimbal camera and the
observer MAV is not based on the visual detection results. Instead, the
control is based on the measurements provided by the RKT GPS and
inter-MAV wireless communication. In this way, we can analyze the image
and flight data offline and compare the performance of the two
approaches of bearing-angle and bearing-only. The acquired images and
flight data are saved on the onboard computer during the flight. A
dataset of 5,341 images was collected (Fig.~<span
class="math inline">\(\ref{fig_M300_dataset}\)</span>) and used to train
a tiny-YOLO v4 network. The detection precision of the trained network
reaches mAP=99.8%.</p>
<p>The experimental results are shown in Fig.~<span
class="math inline">\(\ref{fig_outdoor_1}\)</span>. As can be seen, the
bearing-angle approach performs well. By contrast, the bearing-only
approach only works well before the observer MAV reached the desired
position relative to the target MAV. That is because the bearing varies
significantly during this process due to the fluctuation of the
observer's motion caused by the flight control. However, the
bearing-only approach diverges quickly thereafter when the bearing stops
varying significantly.</p>
<p>Motivated by the limitation of the existing bearing-only approach,
this paper proposed and analyzed a novel bearing-angle approach for
vision-based target motion estimation. We showed that the observability
by the bearing-angle approach is significantly enhanced compared to the
bearing-only one. As a result, the requirement of the observer's extra
motion for observability enhancement can be significantly relaxed. As we
showed in various experiments, the bearing-angle approach can
successfully estimate the target's motion in many scenarios where the
bearing-only approach fails. The enhanced observability of the
bearing-angle approach comes with no additional cost since almost all
vision detection algorithms can generate bounding boxes. One assumption
adopted in the bearing-angle approach is that the target's physical size
is invariant to different viewing angles. Although this assumption is
approximately valid in many tasks as demonstrated in this paper, it is
meaningful to study how to relax or remove this assumption in the
future.</p>
%
<p>%The authors would like to thank the anonymous reviewers and the
editors for their helpful advice for improving this work.</p>
<p>The author(s) declared no potential conflicts of interest with
respect to the research, authorship, and/or publication of this
article.</p>
<p>The author(s) disclosed receipt of the following financial support
for the research, authorship, and/or publication of this artical: This
work was supported by the Hangzhou Key Technology Research and
Development Program (Grant 20212013B09), and the Research Center for
Industries of the Future at Westlake University (Grant WU2022C027).</p>
%
<p>\end{document}</p>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>论文阅读：一种基于目测的未知目标运动分析方位角方法</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://www.adunas.top/posts/20240223a.html">https://www.adunas.top/posts/20240223a.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>阿杜那斯🍀</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2024-02-23</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2024-02-23</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA/"><div class="tags-punctuation"><svg class="faa-tada icon" style="height:1.1em;width:1.1em;fill:currentColor;position:relative;top:2px;margin-right:3px" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg></div>视觉导航</a></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">投喂作者</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://picture.adunas.top/WeChatPaycodeAdunasA.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/WeChatPaycodeAdunasA.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://picture.adunas.top/AliPaycodeAdunasA.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/AliPaycodeAdunasA.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.36/audio/aowu.m4a"></audio><script defer="defer" src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/20240225b.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_23.webp" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">论文阅读：一种基于目测的未知目标运动分析方位角方法</div></div></a></div><div class="next-post pull-right"><a href="/posts/20240222b.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_15.webp" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">关于爱莉西亚局长的个人回忆</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/20240225b.html" title="论文阅读：一种基于目测的未知目标运动分析方位角方法"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_23.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-02-23</div><div class="title">论文阅读：一种基于目测的未知目标运动分析方位角方法</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:bold">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%98%85%E8%AF%BB%E5%AF%BC%E8%88%AA"><span class="toc-number">1.</span> <span class="toc-text">阅读导航</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#a-bearing-angle-approach-for-unknown-target-motion-analysis-based-on-visual-measurements"><span class="toc-number">2.</span> <span class="toc-text">A
Bearing-Angle Approach for Unknown Target Motion Analysis Based on
Visual Measurements</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-number">2.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#keywords"><span class="toc-number">2.2.</span> <span class="toc-text">Keywords</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">2.3.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#related-work"><span class="toc-number">2.4.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#algorithms-for-bearing-only-target-motion-estimation"><span class="toc-number">2.4.1.</span> <span class="toc-text">Algorithms
for bearing-only target motion estimation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#observability-analysis-of-bearing-only-target-motion-estimation"><span class="toc-number">2.4.2.</span> <span class="toc-text">Observability
analysis of bearing-only target motion estimation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#problem-formulation"><span class="toc-number">2.5.</span> <span class="toc-text">Problem Formulation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#states-transition-equation"><span class="toc-number">2.5.1.</span> <span class="toc-text">States transition equation</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-color: transparent;"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">格言🧬</p><div class="bg-ad"><div>&emsp;&emsp;其实爱情早就命中注定了，真正爱你的人会永远爱你，不爱你的人你也永远不会爱上✨</div></div></div><div class="t-t-r"><p class="ft-t t-l-t">猜你想看💡</p><ul class="ft-links"><li><a href="/posts/2013454d.html">格式指南</a><a href="/box/nav/">网址导航</a></li><li><a href="/social/link/">我的朋友</a><a href="/comments/">留点什么</a></li><li><a href="/personal/about/">关于作者</a><a href="/archives/">文章归档</a></li><li><a href="/categories/">文章分类</a><a href="/tags/">文章标签</a></li><li><a href="/box/Gallery/">我的画廊</a><a href="/personal/bb/">我的唠叨</a></li><li><a href="/site/time/">建设进程</a><a href="/site/census/">网站统计</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">推荐友链⌛</p><div class="ft-img-group"><div class="img-group-item"><a target="_blank" rel="noopener" href="https://wenderfeng.top/" title="皮皮丰"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/SteveFengA.webp" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" title="Hexo"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/Hexo-logo-avatar.png" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://butterfly.js.org/" title="Butterfly🦋"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://butterfly.js.org/img/avatar.png" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://www.fomal.cc/" title="Fomalhaut🥝"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.bitiful.net/img/avatar.webp" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://www.roydon.top/" title="roydon"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gcore.jsdelivr.net/gh/roydonGuo/CDN/avatar/ganyu.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div></div></div></div><div class="copyright"><span><b>&copy;2023-2024</b></span><span><b>&nbsp;&nbsp;By 阿杜那斯🍀</b></span></div><div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.3.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Frame-Hexo-blue.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.3.1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Theme-Butterfly-6513df.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站采用多线部署，主线路托管于Vercel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Hosted-Vercel-brightgreen.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://user.51.la/" style="margin-inline:5px" title="本站数据分析得益于51la技术支持"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Analytics-51la-3db1eb.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本网站源码由Github提供存储仓库"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Source-Github-d021d6.svg" alt=""/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fa fa-paper-plane"></i><span>随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:toggleWinbox();"><i class="fas fa-cog"></i><span>美化设置</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://comment.adunas.top/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://comment.adunas.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.staticfile.org/jquery/3.6.0/jquery.min.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script async src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="https://cdn1.tianli0.top/gh/nextapps-de/winbox/dist/winbox.bundle.min.js"></script><script async src="//at.alicdn.com/t/c/font_3586335_hsivh70x0fm.js"></script><script async src="//at.alicdn.com/t/c/font_3636804_gr02jmjr3y9.js"></script><script async src="//at.alicdn.com/t/c/font_3612150_kfv55xn3u2g.js"></script><script async src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><script defer src="/js/fomal.js"></script><script async src="//at.alicdn.com/t/c/font_4353813_47f1tj73u94.js"></script><script src="https://cdn.geogebra.org/apps/deployggb.js"></script><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdn1.tianli0.top/npm/js-heo@1.0.12/metingjs/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax","#bibi","body > title","#app","#tag-echarts","#posts-echart","#categories-echarts"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/文章导航/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📕 阿杜の文章导航&归档 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/数学/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍼 阿杜の数学笔记 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/英语/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍟 阿杜の英语笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/阅读/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎠 阿杜の阅读笔记 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/文学/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🧨 阿杜の文学作品 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/编程/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍡 阿杜の算法编程笔记 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/博客/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍿 阿杜の博客教程 (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/操作系统-软件/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎐 阿杜の操作系统&软件笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/日程表/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🚩 阿杜の日程表 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/运动健康/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🏀 阿杜の运动健康笔记 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/游戏/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍕 阿杜の游戏笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://www.adunas.top/categories/" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #e9e9e9;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--text-bg-hover)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240223a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_6.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-23</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240223a.html&quot;);" href="javascript:void(0);" alt="">论文阅读：一种基于目测的未知目标运动分析方位角方法</a><div class="blog-slider__text">🧵本文研究了使用移动单目相机估计移动目标物体运动的问题</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240223a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240225b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_23.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-23</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240225b.html&quot;);" href="javascript:void(0);" alt="">论文阅读：一种基于目测的未知目标运动分析方位角方法</a><div class="blog-slider__text">🧵本文研究了使用移动单目相机估计移动目标物体运动的问题</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240225b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_27.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224a.html&quot;);" href="javascript:void(0);" alt="">论文阅读方法</a><div class="blog-slider__text">🎗本文记录学习论文的资源和方法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240304a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_16.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240304a.html&quot;);" href="javascript:void(0);" alt="">离骚（节选）</a><div class="blog-slider__text">🥨本文为高中所学离骚（节选）的内容</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240304a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240225c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_7.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-25</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240225c.html&quot;);" href="javascript:void(0);" alt="">Latex</a><div class="blog-slider__text">🍙本文记录Latex语法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240225c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240225a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_22.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-25</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240225a.html&quot;);" href="javascript:void(0);" alt="">正则表达式</a><div class="blog-slider__text">🍤本文是正则表达式的教程</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240225a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231205a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_30.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-05</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231205a.html&quot;);" href="javascript:void(0);" alt="">卡尔曼滤波</a><div class="blog-slider__text">🥧本文推导卡尔曼滤波，并给出matlab仿真代码</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231205a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240304b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_31.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240304b.html&quot;);" href="javascript:void(0);" alt="">Pandoc</a><div class="blog-slider__text">🥯本文为 Pandoc 的使用教程</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240304b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240222a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_38.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240222a.html&quot;);" href="javascript:void(0);" alt="">日程表：2024年02月</a><div class="blog-slider__text">🥐本文记录 Adunas 2024年02月的日程安排和实施情况</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240222a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240222b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_15.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240222b.html&quot;);" href="javascript:void(0);" alt="">关于爱莉西亚局长的个人回忆</a><div class="blog-slider__text">🧶傻瓜，你还是跟过来了呀，我的小英雄</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240222b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_12.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224c.html&quot;);" href="javascript:void(0);" alt="">思考该不该吃完一颗难吃的苹果</a><div class="blog-slider__text">🍎每次难吃的苹果我都咽下去了，这次我决定不吃了</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231204a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_5.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231204a.html&quot;);" href="javascript:void(0);" alt="">协方差</a><div class="blog-slider__text">🥧本文讲解协方差，并给出matlab仿真代码</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231204a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231210b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_34.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-10</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231210b.html&quot;);" href="javascript:void(0);" alt="">GroGebra</a><div class="blog-slider__text">🥧本文介绍网页中使用动态数学软件GroGebra的方法。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231210b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231201b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_45.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231201b.html&quot;);" href="javascript:void(0);" alt="">Adunas的游戏账号昵称和ID</a><div class="blog-slider__text">🥧本文记录我的游戏账号昵称和ID，欢迎找我玩儿~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231201b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240221b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_8.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240221b.html&quot;);" href="javascript:void(0);" alt="">编程导航</a><div class="blog-slider__text">🥞本文是编程分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240221b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231205b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_14.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231205b.html&quot;);" href="javascript:void(0);" alt="">Markdown语法（三）：Butterfly外挂标签</a><div class="blog-slider__text">🥧本文汇总Markdown外挂标签在网页端的渲染效果，可作为文档进行查询</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231205b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_7.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224b.html&quot;);" href="javascript:void(0);" alt="">论文阅读</a><div class="blog-slider__text">🍜本文是阅读分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224d.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_46.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224d.html&quot;);" href="javascript:void(0);" alt="">文学导航</a><div class="blog-slider__text">🍛本文是文学分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224d.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240221a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_27.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240221a.html&quot;);" href="javascript:void(0);" alt="">文章导航</a><div class="blog-slider__text">🥞本文是文章分类导航的最顶层</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240221a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240210a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_9.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-10</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240210a.html&quot;);" href="javascript:void(0);" alt="">数学导航</a><div class="blog-slider__text">🥧本文是数学分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240210a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240221c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_8.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240221c.html&quot;);" href="javascript:void(0);" alt="">博客搭建导航</a><div class="blog-slider__text">🧈本文是博客搭建的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240221c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231201a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_3.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231201a.html&quot;);" href="javascript:void(0);" alt="">Markdown语法（一）：基础语法</a><div class="blog-slider__text">🥧本文汇总Markdown基础语法，可作为文档进行查询</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231201a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" id="gitcalendarBar" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 320px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/site/census/'|| '/site/census/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("/api?null",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'null')
    }
  </script><!-- hexo injector body_end end --></body></html>