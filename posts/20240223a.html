<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><div id="myscoll"></div><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>论文阅读：一种基于目测的未知目标运动分析方位角方法 | Adunas🍀の异世界</title><meta name="keywords" content="视觉导航"><meta name="author" content="阿杜那斯🍀"><meta name="copyright" content="阿杜那斯🍀"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="🧵本文研究了使用移动单目相机估计移动目标物体运动的问题">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：一种基于目测的未知目标运动分析方位角方法">
<meta property="og:url" content="https://www.adunas.top/posts/20240223a.html">
<meta property="og:site_name" content="Adunas🍀の异世界">
<meta property="og:description" content="🧵本文研究了使用移动单目相机估计移动目标物体运动的问题">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://source.fomal.cc/img/default_cover_4.webp">
<meta property="article:published_time" content="2024-02-23T14:30:12.000Z">
<meta property="article:modified_time" content="2024-02-23T14:30:12.000Z">
<meta property="article:author" content="阿杜那斯🍀">
<meta property="article:tag" content="视觉导航">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://source.fomal.cc/img/default_cover_4.webp"><link rel="shortcut icon" href="/"><link rel="canonical" href="https://www.adunas.top/posts/20240223a"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文阅读：一种基于目测的未知目标运动分析方位角方法',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-23 22:30:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/element-ui@2.15.6/packages/theme-chalk/lib/index.css"><style id="themeColor"></style><style id="rightSide"></style><style id="transPercent"></style><style id="blurNum"></style><style id="settingStyle"></style><span id="fps"></span><style id="defineBg"></style><style id="menu_shadow"></style><link rel="stylesheet" href="//at.alicdn.com/t/c/font_4353813_47f1tj73u94.css" media="defer" onload="this.media='all'"><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Adunas🍀の异世界" type="application/atom+xml">
</head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/AsitaA.jpg" onerror="onerror=null;src='/assets/r1.jpg'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">46</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pinweishenghuo"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-yinle">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying1">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-youxishoubing">                   </use></svg><span class="menu_word" style="font-size:17px"> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xiangzi"></use></svg><span class="menu_word" style="font-size:17px"> 八宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/gallery/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tubiaozhizuomoban">                   </use></svg><span class="menu_word" style="font-size:17px"> 画廊</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-nvwumao">                   </use></svg><span class="menu_word" style="font-size:17px"> 动画</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/nav/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-zhifengche">                   </use></svg><span class="menu_word" style="font-size:17px"> 网址导航</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/social/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-wangye"></use></svg><span class="menu_word" style="font-size:17px"> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/site/census/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--tongjibiao">                   </use></svg><span class="menu_word" style="font-size:17px"> 网站统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/echarts/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shujutongji1">                   </use></svg><span class="menu_word" style="font-size:17px"> 文章统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/time/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xianxingshalou">                   </use></svg><span class="menu_word" style="font-size:17px"> 旧时光</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 唠叨</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-love-sign">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Adunas🍀の异世界</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-home"></use></svg><span class="menu_word" style="font-size:17px"> 首页</span></a></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--article"></use></svg><span class="menu_word" style="font-size:17px"> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-guidang1">                   </use></svg><span class="menu_word" style="font-size:17px"> 归档</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-sekuaibiaoqian">                   </use></svg><span class="menu_word" style="font-size:17px"> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-fenlei">                   </use></svg><span class="menu_word" style="font-size:17px"> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pinweishenghuo"></use></svg><span class="menu_word" style="font-size:17px"> 休闲</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/life/music/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-yinle">                   </use></svg><span class="menu_word" style="font-size:17px"> 八音盒</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/movies/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-dianying1">                   </use></svg><span class="menu_word" style="font-size:17px"> 影院</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/life/games/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-youxishoubing">                   </use></svg><span class="menu_word" style="font-size:17px"> 游戏</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xiangzi"></use></svg><span class="menu_word" style="font-size:17px"> 八宝箱</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/box/gallery/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-tubiaozhizuomoban">                   </use></svg><span class="menu_word" style="font-size:17px"> 画廊</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/animation/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-nvwumao">                   </use></svg><span class="menu_word" style="font-size:17px"> 动画</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/box/nav/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-zhifengche">                   </use></svg><span class="menu_word" style="font-size:17px"> 网址导航</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shejiaoxinxi"></use></svg><span class="menu_word" style="font-size:17px"> 社交</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/social/fcircle/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-pengyouquan">                   </use></svg><span class="menu_word" style="font-size:17px"> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-liuyan">                   </use></svg><span class="menu_word" style="font-size:17px"> 留言板</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/social/link/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-lianjie">                   </use></svg><span class="menu_word" style="font-size:17px"> 友人帐</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-wangye"></use></svg><span class="menu_word" style="font-size:17px"> 网站</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/site/census/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon--tongjibiao">                   </use></svg><span class="menu_word" style="font-size:17px"> 网站统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/echarts/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-shujutongji1">                   </use></svg><span class="menu_word" style="font-size:17px"> 文章统计</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/site/time/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-xianxingshalou">                   </use></svg><span class="menu_word" style="font-size:17px"> 旧时光</span></a></li></ul></div><div class="menus_item"><a class="site-page group faa-parent animated-hover hide" href="javascript:void(0);"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-maoliang"></use></svg><span class="menu_word" style="font-size:17px"> 个人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/personal/bb/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-qunliaotian">                   </use></svg><span class="menu_word" style="font-size:17px"> 唠叨</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/love/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-love-sign">                   </use></svg><span class="menu_word" style="font-size:17px"> 恋爱小屋</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/personal/about/"><svg class="menu_icon faa-tada" aria-hidden="true" style="width:1.30em;height:1.30em;vertical-align:-0.15em;fill:currentColor;overflow:hidden;"><use xlink:href="#icon-paperplane">                   </use></svg><span class="menu_word" style="font-size:17px"> 关于</span></a></li></ul></div></div><center id="name-container"><a id="page-name" href="javascript:scrollToTop()">PAGE_NAME</a></center><div id="nav-right"><div id="search-button"><a class="search faa-parent animated-hover" title="检索站内任何你想要的信息"><svg class="faa-tada icon" style="height:24px;width:24px;fill:currentColor;position:relative;top:6px" aria-hidden="true"><use xlink:href="#icon-valentine_-search-love-find-heart"></use></svg><span> 搜索</span></a></div><a class="meihua faa-parent animated-hover" onclick="toggleWinbox()" title="美化设置-自定义你的风格" id="meihua-button"><svg class="faa-tada icon" style="height:26px;width:26px;fill:currentColor;position:relative;top:8px" aria-hidden="true"><use xlink:href="#icon-tupian1"></use></svg></a><a class="sun_moon faa-parent animated-hover" onclick="switchNightMode()" title="浅色和深色模式转换" id="nightmode-button"><svg class="faa-tada" style="height:25px;width:25px;fill:currentColor;position:relative;top:7px" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon">       </use></svg></a><div id="toggle-menu"><a><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-info"><h1 class="post-title">论文阅读：一种基于目测的未知目标运动分析方位角方法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><svg class="meta_icon post-meta-icon" style="width:30px;height:30px;position:relative;top:10px"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于 </span><time class="post-meta-date-created" datetime="2024-02-23T14:30:12.000Z" title="发表于 2024-02-23 22:30:12">2024-02-23</time><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-gengxin1"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-23T14:30:12.000Z" title="更新于 2024-02-23 22:30:12">2024-02-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:18px;height:18px;position:relative;top:5px"><use xlink:href="#icon-biaoqian"></use></svg><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB/">阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:8px"><use xlink:href="#icon-charuword"></use></svg><span class="post-meta-label">字数总计:</span><span class="word-count">1.5w</span><span class="post-meta-separator">|</span><svg class="meta_icon post-meta-icon" style="width:20px;height:20px;position:relative;top:5px"><use xlink:href="#icon-shizhong"></use></svg><span class="post-meta-label">阅读时长:</span><span>91分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文阅读：一种基于目测的未知目标运动分析方位角方法"><svg class="meta_icon post-meta-icon" style="width:25px;height:25px;position:relative;top:5px"><use xlink:href="#icon-eye"></use></svg><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="note blue no-icon flat"><ol>
<li>b站视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1EC411z7Lz/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">【【IJRR最新成果】利用被忽视的视觉信息大幅提升目标定位可观性】</a></li>
<li>论文资源：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.17117">A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements</a></li>
</ol>
</div>
<h1><a href="./20240224b.html#%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E7%9B%AE%E6%B5%8B%E7%9A%84%E6%9C%AA%E7%9F%A5%E7%9B%AE%E6%A0%87%E8%BF%90%E5%8A%A8%E5%88%86%E6%9E%90%E6%96%B9%E4%BD%8D%E8%A7%92%E6%96%B9%E6%B3%95">阅读导航</a></h1>
<h1>A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements</h1>
<h2 id="Abstract">Abstract</h2>
<p>  Vision-based estimation of the motion of a moving target is usually formulated as a <em>bearing-only</em> estimation problem where the visual measurement is modeled as a bearing vector. Although the bearing-only approach has been studied for decades, a <em>fundamental limitation</em> of this approach is that it requires extra lateral motion of the observer to enhance the target’s observability. Unfortunately, the extra lateral motion conflicts with the desired motion of the observer in many tasks.<br>
It is well-known that, once a target has been detected in an image, a bounding box that surrounds the target can be obtained.<br>
Surprisingly, this common visual measurement especially its size information has not been well explored up to now.<br>
In this paper, we propose a new <em>bearing-angle</em> approach to estimate the motion of a target by modeling its image bounding box as bearing-angle measurements.<br>
Both theoretical analysis and experimental results show that this approach can significantly enhance the observability <em>without</em> relying on additional lateral motion of the observer.<br>
The benefit of the bearing-angle approach comes with no additional cost because a bounding box is a standard output of object detection algorithms.<br>
The approach simply exploits the information that has not been fully exploited in the past.<br>
No additional sensing devices or special detection algorithms are required.</p>
<h2 id="Keywords">Keywords</h2>
<p>Bearing-only target motion estimation, Pseudo-linear Kalman filter, Observability enhancement</p>
<h2 id="Introduction">Introduction</h2>
<p>  This paper studies the problem of estimating the motion of a moving target object using a moving monocular camera. The target’s geometric information such as its physical size is <em>unknown</em> in advance. This problem is important in many fields<!--  \citep{Qiu2019, Griffin2021, Tekin2018} -->.<br>
Our present work is particularly motivated by the task of aerial target pursuit, where a micro aerial vehicle (MAV) uses its onboard camera to detect, localize, and then pursue another flying MAV.<br>
The task of aerial target pursuit, originally motivated by the interesting bird-catching-bird behaviors in nature<!--  \citep{Brighton2019} -->, potentially provides an effective approach to the defense of misused MAV<!--  \citep{Rothe2019, Dressel2019, Vrba2020} -->.</p>
<p><a id= "fig_architecture_outdoor"></a><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_outdoor.png" alt="Fig.1 An observer MAV observes a target MAV with a monocular camera. The bearing $g$ and angle $\theta$ can be obtained from the bounding box that surrounds the target in the image."></p>
<p>  When a target has been detected in an image by a vision detection algorithm, we usually obtain a <em>bounding box</em> that surrounds the target’s image (see <a href="#fig_architecture_outdoor">Fig.1</a>).<br>
The bounding box carries two types of useful information that can be used to estimate the target’s motion.</p>
<p>  The first type of useful information is the <em>center point</em> of the bounding box.<br>
The pixel coordinate of the center point can be used to calculate the spatial <em>bearing vector</em> pointing from the camera to the target based on the pin-hole camera model<!--  \citep{Ma2012} -->.<br>
Using the bearing vector to estimate the target’s motion is referred to as <em>bearing-only</em> target motion estimation<!--  \citep{Fogel1988, He2019, Li2022} -->.<br>
As a problem that has been studied for more than 40 years, bearing-only target motion estimation was originally studied to estimate the motion of ships on the ocean surface<!--  \citep{hoelzer1978modified} -->, and regained increasing research attention in recent years in vision-based target estimation tasks<!--  \citep{Ponda2009, Anjaly2018, He2019} -->.</p>
<p>  Bearing-only target motion estimation requires an <em>observability condition</em>: The observer must have higher-order motion than the target and, more importantly, the higher-order motion must contain components that are orthogonal to the target’s bearing vector<!--  \citep{Fogel1988} -->.<br>
Motivated by this observability condition, enormous works have studied how an observer should move to enhance the observability<!--  \citep{Hammel1989, Sabet2016, Anjaly2018, He2019} -->.<br>
For instance, in our recent work<!--  \citep{Li2022} -->, we proposed a helical guidance law so that a MAV moves along a helical curve to optimize the observability in the 3D space.</p>
<p>  A <em>limitation</em> of the observability condition of the classic bearing-only approach is that the observer must move in the lateral directions that are orthogonal to the bearing vector of the target.<br>
Such additional lateral motion is usually unfavorable because it may conflict with the desired motion of the observer in many tasks.<br>
For example, in an aerial target pursuit task, the pursuer is desired to approach the target as fast as possible and then keep stationary relative to the target. Then, the additional lateral motion would conflict with the desired motion.<br>
It is, therefore, important to study other ways that can enhance the observability while avoiding unfavorable lateral motion.</p>
<p>  The second type of useful information of a bounding box is its <em>size</em> (either width or height).<br>
The size of a bounding box is jointly determined by several factors such as the target’s distance, the target’s physical size, and the orientation of the camera.<br>
The target’s physical size is usually unknown in many tasks, especially in those antagonistic ones such as aerial pursuit of misused MAVs.<br>
As a result, the size of the bounding box cannot directly infer the target’s distance.<br>
Nevertheless, it carries valuable information for localizing the target.</p>
<p>  Surprisingly, the size information of the bounding box has not been well explored so far.<br>
The work that is closely relevant to ours is the state-of-the-art one in<!--  \citep{Griffin2021} -->, where the size of a bounding box is used to localize unknown target objects.<br>
Although the approach in<!--  \citep{Griffin2021} --> is inspiring, it relies on two assumptions: The target objects are stationary and the camera can only translate without rotating.<br>
It is still an open problem how to estimate a target’s motion when the two assumptions are not valid.<br>
Moreover, the theoretical role of the size of a bounding box in target motion estimation has not been fully understood so far.<br>
Although the work in<!--  \citep{Vrba2020} --> also utilizes the size of the bounding box to estimate the target’s position, it is assumed that the target’s physical size is known in advance.</p>
<p>  Estimating the motion of moving objects is also a fundamental problem in dynamic SLAM.<br>
For example, the works in<!--  \citep{Yang2019,Qiu2019} --> firstly estimate the camera’s pose and secondly estimate the target object’s pose subject to a scale factor, and finally estimate the scale factor from multi-view measurements.<br>
To estimate the target object’s pose subject to a scale factor,<!--  \citep{Yang2019} --> and<!--  \citep{Qiu2019} --> rely on detecting, respectively, a 3D bounding box and sufficient feature points inside the 2D bounding box.<br>
Different from<!--  \citep{Yang2019,Qiu2019} -->, our proposed approach merely utilizes a 2D image bounding box without further extracting feature points or a 3D bounding box inside the 2D bounding box.<br>
As a result, one benefit is that this approach is more computationally efficient.<br>
Moreover, this approach can handle the challenging small-target case where the target object is far and hence its image is small.<br>
In this case, it would be unreliable to extract sufficient stable features or conduct 3D detection.</p>
<p>  The aforementioned approaches in<!--  \citep{Griffin2021,Yang2019,Qiu2019} --> are all based on multiple views.<br>
It is also possible to estimate the target’s depth from a single view/image<!--  \citep{Tekin2018, Vrba2020} -->.<br>
The single-view approach however requires prior information of the objects.<br>
Moreover, it would be unable to successfully localize target objects with different sizes but similar appearances.<br>
In this paper, we focus on the multi-view case.</p>
<p>  In this paper, we propose a novel <em>bearing-angle</em> target motion estimation approach that models a bounding box as bearing-angle measurements.<br>
This approach can enhance the observability by fully exploiting the information in a bounding box rather than relying on the additional lateral motion of the observer.<br>
The benefit of the proposed bearing-angle approach comes with no additional cost since the bounding box is a standard output of object detection algorithms.<br>
The approach simply exploits the angle information that has not been fully exploited in the past.<br>
No additional sensing devices or special detection algorithms are required.</p>
<p>  The technical novelties of this approach are threefold.</p>
<ol>
<li>
<p>The proposed approach does not directly use the size of a bounding box because the size is variant to the orientation of the camera.<br>
That is, even if the target’s relative position is unchanged, the size of the bounding box still varies when the camera rotates.<br>
Motivated by this problem, we convert the size of the bounding box to an angle subtended by the target (see <a href="#fig_architecture_outdoor">Fig.1</a>).<br>
The merit of using the angle measurement is that it is <em>invariant</em> to the camera’s orientation change (see <a href="#fig_cam_rotate">Fig.2</a>) and hence can greatly facilitate the estimator design.<br>
In this way, the assumption in<!--  \citep{Griffin2021} --> that the camera can only translate but not rotate can be avoided.</p>
</li>
<li>
<p>Although the bearing-angle approach incorporates an additional angle measurement, it is nontrivial to see how to properly use this measurement because the angle does not directly infer the target’s distance given that the target’s size is unknown.<br>
We notice that the angle is a joint nonlinear function of the target’s physical size and relative distance.<br>
Hence, the state vector, which only consists of the target’s position and velocity in the conventional bearing-only approach, is augmented by the unknown target’s physical size.<br>
Since the bearing and angle measurements are all nonlinear functions of the target’s state, we establish a pseudo-linear Kalman filter to properly utilize the measurements to enhance estimation stability.<br>
Both simulation and real-world experiments verify the effectiveness of the proposed estimator.</p>
</li>
<li>
<p>Although an additional angle measurement is used, an additional unknown, the target’s physical size, is also introduced into the estimator.<br>
It is, therefore, nontrivial to see how the additional angle measurement can help improve the observability.<br>
Motivated by this problem, we prove the necessary and sufficient observability condition for bearing-angle target motion estimation.<br>
In particular, we show that the target’s motion can be recovered if and only if the observer has a higher-order motion than the target.<br>
Different from the bearing-only case, the higher-order motion is <em>not</em> required to be in the lateral directions that are orthogonal to the bearing vector.<br>
This is an important enhancement of the observability. As we show in various experiments, the bearing-angle approach can successfully recover the target’s motion in many scenarios where the bearing-only approach fails.</p>
</li>
</ol>
<h2 id="Related-Work">Related Work</h2>
<h3 id="Algorithms-for-bearing-only-target-motion-estimation">Algorithms for bearing-only target motion estimation</h3>
<p>  Bearing-only target motion analysis aims to estimate the target’s motion states, such as position and velocity, using bearing measurement only.<br>
It was originally motivated by ship localization and tracking in the ocean<!--  \citep{hoelzer1978modified} -->. With the rapid development of small-scale mobile robots equipped with cameras, the bearing-only approach regained increasing attention in recent years<!--  \citep{Ponda2009, Anjaly2018, He2019} -->.</p>
<p>  Kalman filter-based estimators are widely used in the bearing-only target motion.<br>
One challenge of applying the Kalman filter to the bearing-only estimation is the nonlinearity of the bearing measurement.<br>
The conventional extended Kalman filter (EKF) exhibits divergence problems when applied to bearing-only target motion estimation<!--  \citep{Aidala1979, Lin2002} -->.<br>
Several methods have been proposed to solve this problem.<br>
They can be divided into two types.<br>
The first type is the modified polar EKF, which was first proposed in<!--  \citep{hoelzer1978modified} -->.<br>
In this approach, three observable quantities are separated from the unobservable ones to prevent divergence.<br>
The work in<!--  \citep{Stallard1991} --> extends this approach to the case of spherical coordinates to track targets in 3D space.<br>
The second type is the pseudo-linear Kalman filter, which is first proposed in<!--  \citep{Lingren1978} --> to solve the instability problem by transforming the nonlinear measurement equation into a pseudo-linear one.<br>
However, this transformation makes the noise become non-Gaussian and highly correlated to the measurement matrix and then causes estimation bias.<br>
Nevertheless, the work in<!--  \citep{Aidala1982} --> theoretically proves that the velocity estimation has no bias, and the position estimation bias can be removed by the observer’s maneuvers.</p>
<p>  Recently, other estimation algorithms based on advanced but more complex filters have been proposed.<br>
The work in<!--  \citep{Farina1999} --> uses the maximum likelihood (MLE) algorithm to estimate the target’s motion using bearing-only measurements.<br>
The comparison with the Cramer-Rao lower bound indicates that the MLE-based estimator is effective against measurement errors.<br>
The work in<!--  \citep{Dogancay2005} --> proposes a constrained total least-squares algorithm, which can improve the estimation accuracy when the error of bearing measurement is large.<br>
Three different algorithms are used and compared in<!--  \citep{Lin2002} -->.<br>
The results show that the EKF, the pseudo-linear filter, and the particle filter have similar performances in most situations, while the EKF loses track when the initial estimate error is large.</p>
<p>  Another type of approach, called bearing-only trajectory triangulation<!--  \citep{Avidan2000} -->, estimates the target’s position from the perspective of trajectory fitting.<br>
It reconstructs the trajectory by intersecting parametric trajectory to a series of sight rays obtained from bearing measurement.<br>
Once the trajectory is successfully fitted, the target’s position at each time instant can be estimated by the intersection of the bearing and the trajectory.<br>
The trajectory fitting relies on the assumption of the trajectory’s shape.<br>
However, in many applications, the target’s trajectory is complex and unknown in advance.<br>
Many consecutive studies aim to relax this assumption in various ways based on hypersurfaces<!--  \citep{Kaminski2004} -->, parametric temporal polynomials<!--  \citep{Yu2009} -->, or compact basis vectors<!--  \citep{Park2015} -->.</p>
<h3 id="Observability-analysis-of-bearing-only-target-motion-estimation">Observability analysis of bearing-only target motion estimation</h3>
<p>  Observability is a fundamental problem in bearing-only target motion estimation.<br>
Early works mainly focus on whether the system is observable or not.<br>
For example, the work in<!--  \citep{Lingren1978} --> uses the rank of observation matrix to determine the observability.<br>
The work in<!--  \citep{Fogel1988} --> extends the observability criterion in<!--  \citep{Nardone1981} --> to the Nth-order target dynamics and inspires us for the observability analysis in Section<!--  \ref{sec_observability_criteria} --> <a href="#sec_observability_criteria">Observability Analysis by Solving Linear Equations</a>.<br>
All these conditions indicate that the observer must have extra high-order motion in the lateral direction.<br>
The observability condition can be significantly relaxed in our approach.</p>
<p>  Unlike the works on determining whether the system is observable or not, some studies focus on quantifying the observability degree.<br>
The work in<!--  \citep{Hammel1989} --> first introduces the Fisher information matrix (FIM) into the observability analysis.<br>
The works in<!--  \citep{Sabet2016} --> and<!--  \citep{Anjaly2018} --> use FIM-based objective functions to maximize observability.<br>
We also use the FIM in our former work<!--  \citep{Li2022} --> to optimize the 3D helical guidance law for better observability.<br>
Another method called the geometric method uses the geometric relationship between the target and the observer in two consecutive time instants to derive the measure of observability<!--  \citep{He2019, Woffinden2009} -->, and the results are consistent with those derived using FIM.<br>
Compared to the bearing-only approach, the observability degree of our bearing-angle method is sufficient to estimate the target’s motion in many common scenarios such as tracking and guidance (see experiment results in Figs.~\ref{fig_matlab_3} and~\ref{fig_outdoor_1}).</p>
<h2 id="Problem-Formulation">Problem Formulation</h2>
<p><a id= "fig_cam_rotate"></a><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_cam_rotate.png" alt="Fig.2 The size of the bounding box varies when the camera rotates. By contrast, the angle subtended by the target object is invariant to the camera's orientation change."></p>
<p>  Consider a target object moving in the 3D space. Its position and velocity at time $t_k$ are denoted as $p_T(t_k) \in \mathbb{R}^3$ and $v_T(t_k) \in \mathbb{R}^3$, respectively.<br>
Suppose there is an observer carrying a monocular camera to observe the target.<br>
The position of the observer is denoted as $p_o(t_k) \in \mathbb{R}^3$.<br>
Here, we assume that the observer/camera’s pose including its position and orientation can be obtained in other ways.<br>
For example, it can be measured directly by RTK GPS<!--  \citep{Li2022} --> or estimated by visual inertial odometry<!--  \citep{Qiu2019} -->.<br>
In the rest of the paper, the dependence of a variable on $t_k$ is dropped when the context is clear.</p>
<p>  If the target object can be detected by a vision algorithm, we can obtain a bounding box surrounding the target object in the image.<br>
Two types of information carried by the bounding box can be used to estimate the motion of the target.</p>
<p>  First, the center point of the bounding box can be used to calculate the <em>bearing</em> vector of the target.<br>
In particular, denote $g \in \mathbb{R}^3$ as the unit bearing vector pointing from $p_o $ to $p_T $.<br>
Suppose $P_\text{cam}\in \mathbb{R}^{3\times3}$ is the intrinsic parameter matrix of the camera<!--  \citep[Section~\ref{section_bearing-angle-target-motion-estimator}]{Ma2012} -->, and $R_\text{c}^\text{w} \in \mathbb{R}^{3\times 3}$ is the rotation from the camera frame to the world frame.<br>
Then, the bearing vector $g$ can be calculated as</p>
<p>$$<br>
\begin{align*}<br>
g =<br>
\dfrac{<br>
R_\text{c}^\text{w}<br>
P_\text{cam}^{-1}<br>
q_{\rm pix}<br>
}{<br>
|R_\text{c}^\text{w}<br>
P_\text{cam}^{-1}<br>
q_{\rm pix}<br>
|<br>
},<br>
\end{align*}%\label{eq_bearing_information}<br>
$$</p>
<p>where $q_{\rm pix} =[x_{\rm pix} , y_{\rm pix} , 1]^\mathrm{T} \in \mathbb{R}^3$.<br>
Here, $(x_{\rm pix} ,y_{\rm pix})$ is the pixel coordinate of the center point of the bounding box.</p>
<p>  Second, the size of the bounding box can be used to calculate the <em>angle</em> subtended by the target in the camera’s field of view.<br>
The reason that we convert the bounding box’s size to the angle is that the angle is invariant to the camera’s orientation change (see <a href="#fig_cam_rotate">Fig.2</a>).<br>
In particular, let $s_{\rm pix} $ denote the size of the bounding box.<br>
It can be either the width or the height.<br>
Let $\theta \in (0,\pi/2)$ be the angle.<br>
According to the pin-hole camera model<!--  \citep[Section~\ref{section_bearing-angle-target-motion-estimator}]{Ma2012} --> and the law of cosine (see <a href="#fig_cam_rotate">Fig.2</a>), the angle can be calculated as<br>
\begin{align*}<br>
\theta = \arccos\left(\dfrac{l_\mathrm{left}^2 + l_\mathrm{right}^2 - s_\mathrm{pix}^2}{2l_\mathrm{left}l_\mathrm{right}}\right),<br>
\end{align*}%\label{eq_angle_information}<br>
where $l_\mathrm{left}=\sqrt{(f/\alpha)^2+(\delta x-s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}$ and $l_\mathrm{right}=\sqrt{(f/\alpha)^2+(\delta x+s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}$ are the distances in pixel from the camera center to the middle points of the left and right sides of the bounding box, respectively (Fig.~\ref{fig_architecture_outdoor}).<br>
Moreover, $f$ and $\alpha$ denote the camera’s focal length and single pixel size, respectively.<br>
$i_{\text{width}}$ and $i_{\text{height}}$ represent the width and the height of the whole image in pixels, respectively. $\delta x=|x_\text{pix}-i_\text{width}/2|\in\mathbb{R}$ and $\delta y = |y_\text{pix}-i_\text{height}/2|\in\mathbb{R}$ are the distances between the center of the bounding box and the center of the image.</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\includegraphics[width=1\linewidth]{fig_architecture_algorithm}<br>
\caption{The architecture of the proposed approach. All the simulation and real-world experiments in this paper follow this architecture.}<br>
\label{fig_architecture_algorithm}<br>
\end{figure*}</p>
<p>  Our goal is to estimate the target’s position and velocity, $p_T$ and $v_T$, based on the noisy measurements of the bearing vector $g$ and the angle $\theta$ together with the observer’s own position $p_o$.<br>
To achieve this goal, we propose a new bearing-angle target motion estimator (Fig.~\ref{fig_architecture_algorithm}).<br>
The estimator is introduced in detail in Section~\ref{section_bearing-angle-target-motion-estimator}.<br>
The observability of this estimator is analyzed based on Kalman’s observability criterion in Section~\ref{sec_analysis_of_observability_matrix}.<br>
We further prove a necessary and sufficient observability condition of the observer in Section~\ref{sec_observability_criteria}.<br>
Numerical simulation results are given in Section~\ref{sec_matlab_simulation}.<br>
More realistic AirSim simulation results are given in Section~\ref{sec_airsim_simulation}.<br>
Finally, real-world experiments are given in Section~\ref{sec_real_world_experimental_validation}.</p>
<p>\section{Bearing-Angle Target Motion Estimator}<br>
\label{section_bearing-angle-target-motion-estimator}</p>
<p>This section designs a bearing-angle target motion estimator based on the framework of pseudo-linear Kalman filtering. The key here is to establish appropriate measurement and state transition equations.</p>
<h3 id="States-transition-equation">States transition equation</h3>
<p>\label{sec_states_transition_equation}<br>
The state vector of the target is designed as<br>
\begin{align*}<br>
x=<br>
\left[<br>
\begin{array}{c}<br>
p_T \<br>
v_T \<br>
\ell \<br>
\end{array}<br>
\right]\in \mathbb{R}^7,<br>
\end{align*}%\label{eq_states_target}<br>
where $p_T $ and $v_T $ are target’s global position and velocity, respectively.<br>
Here, $\ell&gt;0$ is a scalar that represents the physical size of the target object in the dimension that is orthogonal to the bearing vector (see <a href="#fig_cam_rotate">Fig.2</a>). In this paper, $\ell$ is assumed to be constant or varying slowly, which means that the physical size of the target object should be approximately invariant from different viewing angles. Here, $\ell$ corresponds to $\theta$, which further corresponds to either the width or height of the bounding box. Whether $\ell$ should correspond to the width or height depends on in which dimension the physical size of the target object is invariant when viewed from different angles.<br>
More explanation is given in Section~\ref{sec_dynamical_model_of_size}.</p>
<p>  Different from the bearing-only case where the state merely consists of the position and velocity, the state here is augmented by the target’s physical size. This is due to the fact that the angle measurement is a function of the target’s physical size, which should be estimated as well. One may wonder whether the state vector can also incorporate the target’s acceleration. To estimate high-order motion (e.g., acceleration) of the target, the observer must have higher-order motion (e.g., nonzero jerk) according to the observability condition presented in Section~\ref{sec_observability_criteria}. Otherwise, the estimation would diverge. Therefore, it is preferred to exclude the acceleration and merely estimate the position and velocity.</p>
<p>  If no information of the target’s motion is available, it is common to model the target’s motion as a discrete-time noise-driven double integrator:</p>
<p>$$<br>
\begin{align}<br>
x(t_{k+1})=Fx(t_k) +q(t_k) ,<br>
\end{align}<br>
$$\label{eq_state_transition}</p>
<p>where</p>
<p>$$<br>
\begin{align}<br>
F=<br>
\begin{bmatrix}<br>
I_{3\times3} &amp; \delta tI_{3\times3} &amp; 0_{3\times1}  \<br>
0_{3\times3} &amp; I_{3\times3}  &amp; 0_{3\times1}   \<br>
0_{1\times 3} &amp; 0_{1\times 3} &amp; 1<br>
\end{bmatrix}\in\mathbb{R}^{7\times 7},<br>
\end{align}<br>
$$\label{eq_matrix_A}</p>
<p>with $\delta t$ as the sampling time, and $I$ and $0$ as the identity and zero matrices, respectively.<br>
Here, $q \in\mathbb{R}^7$ is a zero-mean process noise satisfying $q \sim \mathcal{N}(0,{\Sigma}_q)$, where the covariance matrix is</p>
<p>$$<br>
\begin{align}<br>
{\Sigma}<em>q=\text{diag}(0, 0, 0, \sigma_v^2, \sigma_v^2, \sigma_v^2, \sigma</em>\ell^2)\in\mathbb{R}^{7\times7}.<br>
\end{align}%\label{eq_covariance_q}<br>
$$</p>
<p>Here, $\sigma_v\in\mathbb{R}$ and $\sigma_\ell\in\mathbb{R}$ are the standard deviations of the target’s velocity and size, respectively.<br>
When the target’s shape is irregular, $\ell$ may vary when viewed from different angles.<br>
By letting $\sigma_\ell\ne0$, we can handle the case where $\ell$ varies slowly.<br>
The dynamic modeling of $\ell$ is discussed in the following subsection.</p>
<p>\subsection{Dynamic modeling of target’s physical size}<br>
\label{sec_dynamical_model_of_size}</p>
<p>  Since the target’s physical size $\ell$ is a state variable to be estimated, it is important to discuss its dynamic model. In fact, the dynamic model of $\ell$ in \eqref{eq_state_transition} assumes that $\ell$ varies slowly. We next justify this modeling and provide more discussion.</p>
<p>First of all, $\ell$ corresponds to the physical size of the target object in the dimension that is orthogonal to the bearing vector. Its dynamics can be categorized into three cases.</p>
<p><em>1) $\ell$ is invariant.</em><br>
In theory, when $\ell$ is invariant, a change of $\theta$ implies a change of $r$.<br>
As a result, the measurement of $\theta$ can help improve the system’s observability, as proven in Section~\ref{sec_observability_criteria}.<br>
An ideal case where $\ell$ is invariant is that the target object is a sphere or cylinder so that $\ell$ corresponds to its diameter<!--  \citep{Vrba2020} -->.<br>
In practice, the target object does not have to be the ideal case. For example, consider an autonomous driving scenario where a focal vehicle uses a camera to localize its surrounding vehicles in the 2D plane.<br>
Although the physical size of a surrounding vehicle changes greatly when viewed from behind or side, the height of the vehicle is <em>invariant</em> from different side-view angles.<br>
In this case, $\ell$ corresponds to the height of the vehicle, and we need to use the height of the image bounding box to calculate $\theta$.</p>
<p><em>2) $\ell$ varies slowly.</em><br>
If there does not exist any dimension in which the physical size of the target remains invariant, $\ell$ may vary slowly when the target is viewed from different angles. For example, in the tasks of aerial target pursuit, if the target is a quadcopter or hexacopter, then $\ell$ is approximately equal to the wheelbase but may vary slightly when viewed from different angles since the MAV is not a perfect cylinder.<br>
In this case, $\ell$ corresponds to the wheelbase of the MAV, and we need to use the width of the image bounding box to calculate $\theta$.</p>
<p>If $\ell$ varies slowly, it can still be treated as invariant within short time intervals.<br>
As long as the observability condition (Section~\ref{sec_observability_criteria}) is satisfied, the motion of the target as well as $\ell$ can be successfully estimated.<br>
This fact is supported by the experimental results in Section~\ref{sec_sim_res_circular_scenario}.<br>
It is however worth nothing that the performance of the proposed bearing-angle approach would degenerate to the conventional bearing-only one because the additional information brought by $\theta$ is used to estimate the time-varying $\ell$ rather than helping improve the system’s observability.</p>
<p><em>3) $\ell$ varies rapidly.</em><br>
If $\ell$ varies rapidly due to certain reasons, it would be difficult to distinguish whether the change of $\theta$ is caused by the change of $\ell$ or the change of $r$.<br>
For example, when a MAV is used to track a ground vehicle, $\ell$ in any dimension may vary rapidly when the relative motion between the MAV and the ground vehicle is highly dynamic.<br>
In such scenarios, the additional information brought by $\theta$ is no longer sufficient to estimate the rapidly varying $\ell$ in this case. Additional visual information such as a 3D bounding box that indicates the target’s 3D attitude is required. This is an important topic for future research but out of the scope of the present paper.</p>
<p>\subsection{Nonlinear measurement equations}</p>
<p>The bearing vector $g$ and the subtended angle $\theta $ are both nonlinear functions of the target’s position. In particular,</p>
<p>$$<br>
\begin{align}<br>
g &amp;=\dfrac{p_T -p_o }{r },<br>
\theta &amp;=2\arctan\left(\dfrac{\ell}{2r }\right)\approx \dfrac{\ell}{r },<br>
\end{align}<br>
$$\label{eq_information}	\label{eq_bearing_measure} \\label{eq_theta_measure}</p>
<p>where<br>
$$r =|\my{p}_T -\my{p}_o |$$<br>
is the distance between the target and the observer.<br>
It is notable that there is an approximation in \eqref{eq_theta_measure}. This approximation is accurate.<br>
Specifically, when $r&gt;3\ell$, which is common in practice, it can be verified that the approximation error is less than $0.08%$. The approximation error further decreases as $r$ increases.</p>
<p>In practice, measurements always contain noises.<br>
First, denote $\hat{\my{g}} \in\mathbb{R}^3$ as the noise-corrupted bearing measurement. Then, we have<br>
\begin{align}<br>
\label{eq_noised_g_mear}<br>
\hat{\my{g}}  = \my{R}\left(\my{\eta} , \epsilon \right) \my{g} ,<br>
\end{align}<br>
where $\my{R}\left(\my{\eta} , \epsilon \right) \in \mathbb{R}^{3\times 3}$ is a rotation matrix that perturbs $\my{g}$.<br>
Here, $\my{\eta} \in\mathbb{R}^3$ is a unit vector representing a random rotation axis, and $\epsilon \in \mathbb{R}$ is a random rotation angle.<br>
This rotation matrix would rotate the vector $\my{g} $ by an angle $\epsilon $ around the axis $\my{\eta} $.<br>
The productive noise in \eqref{eq_noised_g_mear} can be transformed into an additive one:<br>
\begin{align}\label{eq_noised_g_mear_add}<br>
\hat{\my{g}}  = \my{g}  + \my{\mu} ,<br>
\end{align}<br>
where $\my{\mu} =(\my{R}\left(\my{\eta} , \epsilon \right) - \my{I}<em>{3\times3})\my{g} \in\mathbb{R}^3$ is the measurement noise of the bearing vector.<br>
The covariance of $\mu$ is derived in our previous work<!--  \citep{Li2022} -->. Since the covariance is complex and involves unknown true values, we can approximately treat it as a Gaussian noise: $\mu\sim\mathcal{N}(0, \sigma</em>\mu^2 I_{3\times 3})$<!--  \citep{Li2022} -->.</p>
<p>Substituting \eqref{eq_bearing_measure} into \eqref{eq_noised_g_mear_add} gives the <em>nonlinear bearing measurement equation:</em><br>
\begin{align}\label{eq_bearing_measure_noise}<br>
\hat{\my{g}} &amp;=\dfrac{\my{p}_T -\my{p}_o }{r } + \my{\mu} .<br>
\end{align}</p>
<p>Second, denote $\hat{\theta} \in\mathbb{R}$ as the noise-corrupted measurement of the subtended angle. Then, we have<br>
\begin{align}\label{eq_noise_theta}<br>
\hat{\theta} =\theta  + w ,<br>
\end{align}<br>
where $w \sim \mathcal{N}(0, \sigma^2_w)$ is the measurement noise.<br>
Substituting \eqref{eq_theta_measure} into \eqref{eq_noise_theta} yields the <em>nonlinear angle measurement equation:</em><br>
\begin{align}\label{eq_theta_measure_noise}<br>
\hat{\theta} &amp;=\dfrac{\ell}{r } + w.<br>
\end{align}</p>
<p>\subsection{Pseudo-linear measurement equations}</p>
<p>The measurement equations \eqref{eq_bearing_measure_noise} and \eqref{eq_theta_measure_noise} are nonlinear in the target’s state. In the following, we convert the two equations to be pseudo-linear and then apply pseudo-linear Kalman filtering to achieve better estimation stability<!--  \citep{Lin2002} -->.</p>
<p>First, to convert the 3D bearing measurement to pseudo-linear, we introduce a useful orthogonal projection matrix:<br>
\begin{align*}<br>
\my{P}<em>{\hat{\my{g}} }\doteq\my{I}</em>{3\times 3}-\hat{\my{g}} \hat{\my{g}}^\mathrm{T}  \in \mathbb{R}^{3\times 3}.<br>
\end{align*}%\label{eq_projMatrix}<br>
This matrix plays an important role in the analysis of bearing-related estimation and control problems<!--  \citep{Zhao2019} -->. It has an important property: $$\my{P}<em>{\hat{\my{g}} }\hat{\my{g}} =\my{0}</em>{3\times 1}.$$<br>
As a result, multiplying $r\my{P}<em>{\hat{\my{g}} }$ on both side of \eqref{eq_bearing_measure_noise} yields<br>
\begin{align*}<br>
\my{0}</em>{3\times 1}=\my{P}<em>{\hat{\my{g}} }(\my{p}<em>T -\my{p}<em>o) + r\my{P}</em>{\hat{\my{g}} }\my{\mu}<br>
\end{align*}<br>
and consequently<br>
\begin{align*}<br>
\my{P}</em>{\hat{\my{g}} }\my{p}<em>o =\my{P}</em>{\hat{\my{g}} }\my{p}<em>T  + r\my{P}</em>{\hat{\my{g}} }\my{\mu}.<br>
\end{align*}%\label{eq_g_pseudo_linear_measurement}<br>
Rewriting this equation in terms of the target’s state variables yields the <em>pseudo-linear bearing measurement equation:</em><br>
\begin{align}\label{eq_pseudo_linear_measurement_g_equation}<br>
\my{P}</em>{\hat{\my{g}} }\my{p}<em>o =<br>
\begin{bmatrix}<br>
\my{P}</em>{\hat{\my{g}} } &amp;<br>
\my{0}<em>{3\times4}<br>
\end{bmatrix}<br>
\left[<br>
\begin{array}{c}<br>
p_T \<br>
v_T \<br>
\ell \<br>
\end{array}<br>
\right]  +  r\my{P}</em>{\hat{\my{g}} }\my{\mu} .<br>
\end{align}<br>
Here, $\my{P}_{\hat{\my{g}} }\my{p}_o $ on the left-hand side is the new measurement, which is pseudo-linear in the target’s state variables.<br>
The reason that it is called “pseudo” is because the measurements also appear on the right-hand side of the equation, especially in the measurement matrix.</p>
<p>Second, we convert the nonlinear angle measurement in \eqref{eq_theta_measure_noise} to be pseudo-linear.<br>
To that end, multiplying $r \my{\hat{g}} $ on both side of \eqref{eq_theta_measure_noise} yields<br>
\begin{align}\label{eq_theta_pseudo_tem}<br>
\hat{\theta} r\hat{\my{g}}  = \ell\hat{\my{g}} +wr\hat{\my{g}} .<br>
\end{align}<br>
It follows from \eqref{eq_bearing_measure_noise} that $r\my{\hat{g}}=\my{p}_T -\my{p}_o+r\mu$, substituting which into the left-hand side of \eqref{eq_theta_pseudo_tem} gives<br>
\begin{align*}<br>
\hat{\theta} (\my{p}_T -\my{p}_o+r\mu)  = \ell\hat{\my{g}} +wr\hat{\my{g}}.<br>
\end{align*}<br>
Reorganizing the above equation gives<br>
\begin{align*}<br>
\hat{\theta} \my{p}_o  = &amp;\hat{\theta} \my{p}<em>T  - \ell\hat{\my{g}} + r(\hat{\theta}  \my{\mu}  - w \hat{\my{g}}).<br>
\end{align*}<br>
Rewriting this equation in terms of the target’s state variables yields the <em>pseudo-linear angle measurement equation:</em><br>
\begin{align}\label{eq_pseudo_linear_measurement_theta_equation}<br>
\begin{aligned}<br>
\hat{\theta} \my{p}<em>o  =&amp;<br>
\begin{bmatrix}<br>
\hat{\theta} \my{I}</em>{3\times 3} &amp; \my{0}</em>{3\times 3}  &amp; -\hat{\my{g}}<br>
\end{bmatrix}<br>
\left[<br>
\begin{array}{c}<br>
p_T \<br>
v_T \<br>
\ell \<br>
\end{array}<br>
\right]</p>
<ul>
<li>r(\hat{\theta}  \my{\mu}  - w \hat{\my{g}} ),<br>
\end{aligned}<br>
\end{align}<br>
where $\hat{\theta} \my{p}_o $ is the new measurement that is pseudo-linear in the target’s state variables.</li>
</ul>
<p>\subsection{Bearing-angle estimation algorithm}</p>
<p>Combining  \eqref{eq_pseudo_linear_measurement_g_equation} and \eqref{eq_pseudo_linear_measurement_theta_equation} gives the compact form of the measurement equation:<br>
\begin{align}\label{eq_pseudo_linear_measurement_equations}<br>
\my{z} = \my{H} \my{x}  + \my{\nu} ,<br>
\end{align}<br>
where<br>
\begin{subequations}<br>
\begin{align}<br>
\my{z} &amp;=<br>
\begin{bmatrix}<br>
\my{P}<em>{\hat{g}} \my{p}<em>o   \<br>
\hat{\theta} \my{p}<em>o<br>
\end{bmatrix}\in\mathbb{R}^6, \<br>
\my{H}&amp; =<br>
\begin{bmatrix}<br>
\my{P}</em>{\hat{g}}  &amp; \my{0}</em>{3\times 3} &amp; \my{0}</em>{3\times 1} \<br>
\hat{\theta} \my{I}<em>{3\times 3} &amp; \my{0}</em>{3\times 3}  &amp; -\hat{\my{g}}<br>
\end{bmatrix}\in\mathbb{R}^{6\times7},<br>
\label{eq_matrix_H}	\<br>
\my{\nu}  &amp;=<br>
\begin{bmatrix}<br>
r \my{P}<em>{\hat{g}} \my{\mu}  \<br>
r (\hat{\theta}  \my{\mu}  - w \hat{\my{g}} )<br>
\end{bmatrix}<br>
\in\mathbb{R}^6.<br>
\label{eq_final_measurement_noise}<br>
\end{align}<br>
\end{subequations}<br>
Here, $\nu$ can be rewritten as a matrix form<br>
\begin{align*}<br>
\nu=E<br>
\begin{bmatrix}<br>
\mu \ w<br>
\end{bmatrix},<br>
\end{align*}<br>
where<br>
\begin{align}\label{eq_E_mat}<br>
E=r<br>
\begin{bmatrix}<br>
P</em>{\hat{g}} &amp; 0_{3\times 1}\<br>
\hat{\theta}I_{3\times 3} &amp; -\hat{g}<br>
\end{bmatrix}\in\mathbb{R}^{6\times 4}.<br>
\end{align}<br>
As a result, $\nu$ can be approximately treated as a linear transformation of Gaussian noises.<br>
Its covariance matrix can be calculated as<br>
\begin{align*}%\label{eq_final_measurement_noise_covariance}<br>
\my{\Sigma}<em>{\my{\nu}}  = E<br>
\begin{bmatrix}<br>
\sigma</em>\mu^2 I_{3\times 3} &amp; 0_{3\times1}\<br>
0_{1\times 3} &amp; \sigma_w^2<br>
\end{bmatrix}<br>
E^\mathrm{T}\in\mathbb{R}^{6\times6}.<br>
\end{align*}<br>
Although the quantities in $E$ such as $\hat{g}$ and $\hat{\theta}$ contain measurement noises, it is a common practice to treat them as deterministic quantities. Otherwise, if, for example, $\hat{g}$ is split to $\hat{g}=g+\mu$ and we consider the noise separately, the expression of $\nu$ would be a complex function of the true values and the noises. Since the true values are unknown, the covariance cannot be calculated.<br>
Moreover, $r $ in \eqref{eq_E_mat} is the true target range, which is unknown. We can use the estimated value $\hat{r} =|\hat{\my{p}}_T -\my{p}_o |$ to replace it in implementation. Here, $\hat{p}_T\in\mathbb{R}^3$ is the estimated value of the target’s position. This technique has been used in bearing-only target estimation \citep{He2018, Li2022}.</p>
<p>With the state transition equation \eqref{eq_state_transition} and the measurement equation \eqref{eq_pseudo_linear_measurement_equations}, the bearing-angle estimator can be realized by the Kalman filter.<br>
For a quick reference, we list the steps below.<br>
The prediction steps are<br>
\begin{align*}<br>
\hat{\my{x}}^{-}(t_k) &amp;= \my{F}\hat{\my{x}}(t_{k-1}), \<br>
\my{P}^{-}(t_k) &amp;= \my{F}\my{P}(t_{k-1})\my{F}^\mathrm{T} + \my{\Sigma}<em>q,<br>
\end{align*}<br>
where $\hat{\my{x}}^{-}(t_k)\in\mathbb{R}^7$ and $\my{P}^{-}(t_k)\in\mathbb{R}^{7\times7}$ are the prior estimated state and covariance matrix, respectively.<br>
The correction steps are<br>
\begin{align*}<br>
\my{K}(t_k) &amp;= \my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)\left[\my{H}(t_k)\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)+\my{\Sigma}</em>\nu\right]^{\dagger}, \<br>
\hat{\my{x}}(t_k) &amp;= \hat{\my{x}}^{-}(t_k) + \my{K}(t_k)\left[\my{z}(t_k)-\my{H}(t_k)\hat{\my{x}}^{-}(t_k)\right], \<br>
\my{P}(t_k) &amp;=\left[\my{I}<em>{7\times 7} -\my{K}(t_k)\my{H}(t_k) \right]\my{P}^{-}(t_k),<br>
\end{align*}<br>
where $\my{K}(t_k)\in\mathbb{R}^{7\times6}$ is the Kalman gain matrix, $\hat{\my{x}}(t_k) $  and $\my{P}(t_k)$ are posterior estimated state and covariance matrix, and symbol $\dagger$ denotes the pseudoinverse.<br>
The usage of pseudoinverse in the Kalman filter is a common practice to prevent the situation that $\my{H}(t_k)\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)+\my{\Sigma}</em>\nu$ is rank deficient \citep{YOSHIKAWA1972,Kulikov2018}.</p>
<p>\section{Observability Analysis by Kalman’s Criterion}\label{sec_analysis_of_observability_matrix}</p>
<p>Although an additional angle measurement is adopted in the bearing-angle estimator, it is nontrivial to see whether this additional measurement can improve the system’s observability because an additional unknown variable, the target’s physical size, is also required to estimate. It is therefore necessary to study the observability conditions under which the target’s motion can be successfully estimated.</p>
<p>In this and the next sections, we present two methods to analyze the observability conditions. The first method, as presented in this section, relies on Kalman’s observability criterion, which is to check the rank of the observability matrix of a linear system. The second method, as presented in the next section, relies on solving a set of linear equations.<br>
Both methods have been adopted in the literature to analyze the observability of estimators \citep{Zhao2015, Fogel1988}.<br>
For the bearing-angle estimator, the first method considers the specific dynamics of the filter but is not able to handle the case when the target’s motion has a higher order.<br>
The second method can handle the high-order motion of the target but does not consider the dynamics of the filter. We will show that the conclusions given by the two methods are consistent.<br>
In both of the methods, we consider the case where $\ell$ is invariant.</p>
<p>\subsection{The observability matrix}</p>
<p>Consider a time horizon of $k\geq 3$ consecutive steps.<br>
The observability matrix of the system of \eqref{eq_matrix_H} and \eqref{eq_matrix_A} can be calculated as<br>
\begin{align}\label{eq_Qo}<br>
\my{Q}=<br>
\begin{bmatrix}<br>
\my{H}(t_1) \<br>
\my{H}(t_2)\my{F} \<br>
\my{H}(t_3)\my{F}^2 \<br>
\cdots \<br>
\my{H}(t_k)\my{F}^{k-1} \<br>
\end{bmatrix}\in\mathbb{R}^{6k\times7}.<br>
\end{align}<br>
Substituting the expressions of $F$ and $H$ in \eqref{eq_matrix_A} and \eqref{eq_matrix_H} into \eqref{eq_Qo} yields<br>
\begin{align*}<br>
\my{Q}=<br>
\left[<br>
\begin{array}{ccc}<br>
\my{P}<em>g(t_1) &amp; \my{0}</em>{3\times 3} &amp; \my{0}<em>{3\times 1} \<br>
\theta(t_1)\my{I}</em>{3\times 3} &amp; \my{0}<em>{3\times 3}  &amp; -\my{g}(t_1) \<br>
\hdashline<br>
\my{P}<em>g(t_2) &amp; \delta t\my{P}</em>{g}(t_2) &amp; \my{0}</em>{3\times 1} \<br>
\theta(t_2)\my{I}<em>{3\times 3} &amp; \delta t\theta(t_2)\my{I}</em>{3\times 3}  &amp; -\my{g}(t_2) \<br>
\hdashline<br>
\vdots &amp; \vdots &amp; \vdots \<br>
\hdashline<br>
\my{P}<em>g(t_k) &amp; (k-1)\delta t\my{P}</em>{g}(t_k) &amp; \my{0}<em>{3\times 1} \<br>
\theta(t_k)\my{I}</em>{3\times 3} &amp; (k-1)\delta t\theta(t_k)\my{I}<em>{3\times 3}  &amp; -\my{g}(t_k)\<br>
\end{array}<br>
\right].<br>
\end{align*}<br>
Note that the noises in the bearing and angle measurements are neglected when we analyze the fundamental observability property.<br>
After a series of elementary row transformations in $\my{Q}$, we can obtain<br>
\begin{align}\label{eq_Qo_2}<br>
\my{Q}<br>
\rightarrow<br>
\begin{bmatrix}<br>
\my{I}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; -\my{g}(t_1)/\theta(t_1) \<br>
\my{0}</em>{3\times 3} &amp; \my{I}<em>{3\times 3} &amp; -\delta\my{v}(t_2)/\ell \<br>
\vdots &amp; \vdots &amp; \vdots \<br>
\my{0}</em>{3\times 3} &amp; \my{I}<em>{3\times 3} &amp; -\delta\my{v}(t_k)/\ell \<br>
\hdashline<br>
\my{0}</em>{3k\times 3} &amp; \my{0}<em>{3k\times 3} &amp; \my{0}</em>{3k\times 1}<br>
\end{bmatrix},<br>
\end{align}<br>
where<br>
\begin{align*}<br>
\delta\my{v}(t_k) \doteq \my{v}_T(t_k) - \my{v}_o(t_k)<br>
\end{align*}%\label{eq_delta_vel}<br>
is the relative velocity.</p>
<p>In the following two subsections, we analyze the rank of the observability matrix in two scenarios where the observer moves with zero and nonzero acceleration, respectively. In the two scenarios, the target is always assumed to move with a constant velocity:<br>
\begin{align*}<br>
\my{v}_T(t_k) = \my{v}_T^\text{const}.<br>
\end{align*}</p>
<h1>\subsection{Case 1: the observer’s velocity is constant}<br>
Denoted $\my{v}<em>o\in \mathbb{R}^3$ as the velocity of the observer.<br>
Consider the case where the observer has a constant velocity $\my{v}<em>o^\text{case1}(t_i)=\my{v}<em>o^\text{const}$ for any $i\in{1,\dots,k}$.<br>
Then, the relative velocity is also constant:<br>
\begin{align}\label{eq_delta_vel_case1}<br>
\delta \my{v}^\text{case1}(t_i) = \my{v}<em>T^\text{const} - \my{v}<em>o^\text{const} = \delta\my{v}^\text{const}.<br>
\end{align}<br>
Substituting \eqref{eq_delta_vel_case1} into \eqref{eq_Qo_2} and conducting elementary row transformation yields<br>
\begin{align}\label{eq_Qo_3}<br>
\my{Q}^\text{case1}<br>
\rightarrow<br>
\left[<br>
\begin{array}{cc:c}<br>
\my{I}</em>{3\times 3} &amp; \my{0}</em>{3\times 3} &amp; -\my{g}(t_1)/\theta(t_1) \<br>
\my{0}</em>{3\times 3} &amp; \my{I}</em>{3\times 3} &amp; -\delta\my{v}^\text{const}/\ell \<br>
\hdashline<br>
\my{0}</em>{6(k-1)\times 3} &amp; \my{0}<em>{6(k-1)\times 3} &amp; \my{0}</em>{6(k-1)\times 1}<br>
\end{array}\right].<br>
\end{align}<br>
Since the upper $6\times7$ block of \eqref{eq_Qo_3} has full row rank and the lower block is zero, the rank of $\my{Q}^\text{case1}$ is<br>
\begin{align*}<br>
\text{rank}\left(\my{Q}^\text{case1}\right) = 6.<br>
\end{align*}<br>
Since the number of states is seven and the rank is six, we know there is \emph{one unobservable mode}.<br>
To identify this unobservable mode, we calculate the unobservable subspace, which is the null space of $\my{Q}$:<br>
\begin{align}\label{eq_unobservable_subspace}<br>
\text{Null}\left(\my{Q}^\text{case1}\right) = \text{span}\left{<br>
\begin{bmatrix}<br>
\my{g}(t_1)/\theta(t_1)  \<br>
\delta\my{v}^\text{const}/\ell \<br>
1<br>
\end{bmatrix}\right}.<br>
\end{align}<br>
According to \eqref{eq_unobservable_subspace}, the unobservable mode is<br>
\begin{align}<br>
x^T<br>
\left[<br>
\begin{array}{c}<br>
\my{g}(t_1)/\theta(t_1)  \<br>
\delta\my{v}^\text{const}/\ell \<br>
1<br>
\end{array}<br>
\right]</h1>
<p>\my{p}_T^\mathrm{T}\dfrac{\my{g}(t_1)}{\theta(t_1)}+<br>
\my{v}_T^\mathrm{T}\dfrac{\delta\my{v}^\text{const}}{\ell} + \ell.<br>
\label{eq_unobservable_mode}<br>
\end{align}%<br>
Although there is only one unobservable mode, this mode given in \eqref{eq_unobservable_mode} involves all the states including the target’s position, velocity, and physical size. It suggests that the estimation of the three quantities is coupled. In conclusion, we know that, if the target moves with a constant velocity, its states are unobservable when the observer moves with a constant velocity.</p>
<p>\subsection{Case 2: the observer’s velocity is time-varying}</p>
<p>We now consider the case where the observer has nonzero acceleration so that its velocity is time-varying across the time horizon from $t_1$ to $t_k$.</p>
<p>Denote $\my{a}<em>o(t_i)\in\mathbb{R}$ as the observer’s acceleration, which can be approximated as<br>
\begin{align}\label{eq_acc}<br>
\my{a}<em>o(t_i) &amp;\approx<br>
\dfrac{\my{v}<em>o(t_i) - \my{v}<em>o(t</em>{i-1})}{\delta t} \nonumber\<br>
&amp;=-\dfrac{\left[\my{v}<em>T^\text{const} - \my{v}<em>o(t_i)\right] - \left[\my{v}<em>T^\text{const} - \my{v}<em>o(t</em>{i-1})\right]}{\delta t} \nonumber\<br>
&amp;=-\dfrac{\delta \my{v}(t_i) - \delta \my{v}(t</em>{i-1})}{\delta t}.<br>
\end{align}<br>
Substituting \eqref{eq_acc} into \eqref{eq_Qo_2} and performing elementary row transformation yields<br>
\begin{align}\label{eq_Q_case2_final}<br>
\my{Q}^\text{case2}<br>
\rightarrow<br>
\left[\begin{array}{ccc}<br>
\my{I}</em>{3\times 3} &amp; \my{0}</em>{3\times 3} &amp; -\my{g}(t_1)/\theta(t_1) \<br>
\my{0}</em>{3\times 3} &amp; \my{I}</em>{3\times 3} &amp; -\delta\my{v}(t_2)/\ell \<br>
\my{0}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; \delta t \my{a}<em>o(t_3)/\ell \<br>
\hdashline<br>
\vdots &amp; \vdots &amp;\vdots \<br>
\my{0}</em>{3\times 3} &amp; \my{0}</em>{3\times 3} &amp; \delta t \my{a}<em>o(t_k)/\ell \<br>
\my{0}</em>{3k\times 3} &amp; \my{0}<em>{3k\times 3} &amp; \my{0}</em>{3k\times 1}<br>
\end{array}\right].<br>
\end{align}<br>
The upper $6\times7$ block in \eqref{eq_Q_case2_final} has full column rank.<br>
Therefore, if $a_o(t_i)\ne0$ for any $i\geq3$, then<br>
\begin{align*}<br>
\text{rank}\left(\my{Q}^\text{case2}\right) = 7,<br>
\end{align*}<br>
Which is the same as the number of estimated states.<br>
Therefore, the target’s state is observable when the observer moves with nonzero acceleration.</p>
<p>\subsection{Summary of this section}</p>
<p>From the above analysis, we know that when the target has a constant velocity, its states including its position, velocity, and physical size are observable if and only if the observer has non-zero accelerations.</p>
<p>The critical difference of this condition from the bearing-only case is that the target’s states are still observable \emph{even if the observer moves along the bearing vector} towards or backward the target.<br>
By contrast, for a bearing-only estimator, moving along the bearing vector is insufficient to recover the target’s motion. Therefore, the additional lateral motion of the observer required in the bearing-only case is \emph{not} required in the bearing-angle case anymore, which provides better flexibility for designing the observer’s motion.</p>
<p>\section{Observability Analysis by Solving Linear Equations}\label{sec_observability_criteria}</p>
<p>This section extends the observability condition obtained in the last section to more general cases where the target’s velocity does not have to be constant.</p>
<p>\subsection{Problem formulation}</p>
<p>The observability problem that we aim to solve is to determine whether $\my{p}_T(t)$ can be recovered from $\my{p}_o(t)$ and $g(t),\theta(t)$.</p>
<p>Suppose the target’s motion can be described by an $n$th-order polynomial during a time interval:<br>
\begin{align}\label{eq_target_nth_Order}<br>
\my{p}_T(t)=\my{b}_0+\my{b}_1t+\cdots+\my{b}_nt^n,<br>
\end{align}<br>
where $\my{b}_0, \my{b}_1, \cdots, \my{b}<em>n\in\mathbb{R}^3$ are unknown constant vectors.<br>
If we can determine the values of ${b_i}</em>{i=0}^n$, then we can determine the target’s motion and hence it is observable.<br>
Although polynomials cannot represent all trajectories, they can effectively approximate a majority of them according to the method of Taylor expansion. This is especially true if we consider a short time horizon. This kind of technique has been adopted in the observability analysis of bearing-only target motion estimation tasks~\citep{Nardone1981, Lee2010}.</p>
<p>Suppose the observer’s motion is described by<br>
\begin{align*}<br>
\my{p}_o(t)=\my{c}_0+\my{c}_1t+\cdots+\my{c}_nt^n+\my{h}(t),<br>
\end{align*}%\label{eq_c_nth_Order}<br>
where $\my{c}_0, \my{c}_1, \cdots, \my{c}_n\in\mathbb{R}^3$ are constant parameters, and<br>
\begin{align}\label{eq_definition_h}<br>
\my{h}(t) = \my{d}_1 t^{n+1}+\my{d}_2t^{n+2}+\cdots<br>
\end{align}<br>
represents \emph{higher-order} motion with $\my{d}_1, \my{d}<em>2, \cdots\in\mathbb{R}^3$.<br>
It can be verified that the derivatives of $\my{h}(t)$ satisfy $\my{h}^{(i)}(0)=\my{0}</em>{3\times 1}$ for $i=0,1,\cdots, n$.<br>
%<br>
Let $\my{s}(t)\in\mathbb{R}^3$ be the relative motion between the target and the observer:<br>
\begin{align}\label{eq_relative_motion}<br>
\my{s}(t)&amp;\doteq\my{p}_T(t)-\my{p}_o(t)  \nonumber\<br>
&amp;\doteq\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t),<br>
\end{align}<br>
where $\my{s}_i = \my{d}_i - \my{c}_i\in\R^3$ for $i = 0,1,\cdots, n$.</p>
<p>If we can determine ${s_i}<em>{i=0}^n$, then $s(t)$ and hence $p_T(t)$ can be determined.<br>
Therefore, we next study under what conditions ${s_i}</em>{i=0}^n$ can be uniquely determined.<br>
Since $\my{p}_T(t)-\my{p}_o(t)=g(t)r(t)$ according to \eqref{eq_bearing_measure} and $r(t)=\ell/\theta(t)$ according to \eqref{eq_theta_measure}, we have<br>
$$s(t)=\my{p}_T(t)-\my{p}_o(t)=g(t)r(t)=\frac{g(t)}{\theta(t)}\ell. $$<br>
Substituting the above equation into \eqref{eq_relative_motion} yields<br>
\begin{align}\label{eq_st_tem}<br>
\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t)=\frac{g(t)}{\theta(t)}\ell.<br>
\end{align}<br>
Here, $\my{s}_0, \cdots, \my{s}_n, \ell$ are unknowns to be determined and $\my{g}(t),\theta(t),\my{h}(t)$ are known.<br>
Equation~\eqref{eq_st_tem} can be reorganized to a linear equation:<br>
\begin{align}\label{eq_linear_equations}<br>
\my{A}(t)\my{X} = \my{h}(t),<br>
\end{align}<br>
where<br>
\begin{align*}<br>
\my{X}&amp;=<br>
\begin{bmatrix}<br>
\my{s}<em>0^\mathrm{T}, \my{s}<em>1^\mathrm{T}, \cdots, \my{s}<em>n^\mathrm{T}, \ell<br>
\end{bmatrix}^\mathrm{T}\in\mathbb{R}^{3n+4},<br>
\end{align*}<br>
and<br>
\begin{align}\label{eq_original_A}<br>
\my{A}(t)&amp;=<br>
\begin{bmatrix}<br>
\my{I}</em>{3\times3}, t\my{I}</em>{3\times3}, \cdots, t^n\my{I}</em>{3\times3}, \rho(t)<br>
\end{bmatrix}\in\mathbb{R}^{3\times(3n+4)},<br>
\end{align}<br>
where<br>
\begin{align}\label{eq_rho_denote}<br>
\rho(t)&amp;\doteq-\dfrac{\my{g}(t)}{\theta(t)}\in\R^3.<br>
\end{align}<br>
Therefore, the problem that we aim to solve becomes determining whether $X$ can be uniquely solved from \eqref{eq_linear_equations}.</p>
<p>\subsection{Necessary and sufficient observability condition}</p>
<p>We next present a necessary and sufficient condition under which the solution $X$ of \eqref{eq_linear_equations} is unique.</p>
<p>\begin{theorem}[(Necessary and sufficient observability condition)]<br>
\label{theorem_observability_confition}<br>
The target’s motion $p_T(t)$ can be uniquely determined by the observer’s motion $p_o(t)$, the bearing $g(t)$, and the angle $\theta(t)$ if and only if<br>
\begin{align*}<br>
\my{h}(t)\neq\my{0}_{3\times1},<br>
\end{align*}<br>
which means that the order of the observer’s motion must be greater than the target.<br>
\end{theorem}<br>
\begin{proof}<br>
Since the row number of $\my{A}(t)$ is less than its column number, \eqref{eq_linear_equations} is an under-determined system whose solution cannot be uniquely determined.<br>
However, in the continuous time domain, we can use additional higher derivatives of this equation to uniquely determine $X$.</p>
<p>In particular, taking the $i$th-order derivative on both sides of \eqref{eq_linear_equations} gives $A^{(i)}(t)X=h^{(i)}(t)$. Consider any integer $N$ satisfying $N\ge n+1$. Combining the equations with $i\in{0,1,\dots,N}$  gives<br>
\begin{align}\label{eq_new_linear_equtions}<br>
\bar{\my{A}}(t)\my{X} = \bar{\my{h}}(t),<br>
\end{align}<br>
where<br>
\begin{align}\label{eq_new_A}<br>
\bar{\my{A}}(t) =<br>
\left[<br>
\begin{array}{c}<br>
\my{A}(t) \<br>
\my{A}^{‘}(t) \<br>
\vdots \<br>
\my{A}^{(N)}(t)<br>
\end{array}<br>
\right],\qquad<br>
\bar{\my{h}}(t)\left[<br>
\begin{array}{c}<br>
\my{h}(t)\<br>
\my{h}^{’}(t)\<br>
\vdots\<br>
\my{h}^{(N)}(t)\<br>
\end{array}<br>
\right].<br>
\end{align}<br>
Here, $\bar{\my{A}}(t)\in\mathbb{R}^{(3N+3)\times (3n+4)}$ and $\bar{\my{h}}(t)\in\mathbb{R}^{3N+3}$.<br>
Since $N\ge n+1$, $\bar{A}(t)$ is a tall matrix and \eqref{eq_new_linear_equtions} is an over-determined system.</p>
<p>We next examine when $\bar{A}(t)$ has full column rank.<br>
Substituting \eqref{eq_original_A} into $\bar{A}(t)$ yields<br>
\begin{align*}<br>
\bar{\my{A}}(t)=<br>
\left[\begin{array}{cccc:c}<br>
\my{I}<em>{3\times3}&amp; t\my{I}</em>{3\times3}&amp; \cdots&amp; t^n\my{I}<em>{3\times3}&amp; \rho(t) \<br>
\my{0}</em>{3\times3}&amp; \my{I}<em>{3\times3}&amp; \cdots&amp; nt^{n-1}\my{I}</em>{3\times3}&amp; \rho^{'}(t) \<br>
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \<br>
\my{0}<em>{3\times3}&amp; \my{0}</em>{3\times3}&amp; \cdots&amp; n!\my{I}<em>{3\times3}&amp; \rho^{(n)}(t) \<br>
\hdashline<br>
\my{0}</em>{3\times3}&amp; \my{0}<em>{3\times3}&amp; \cdots&amp; \my{0}</em>{3\times3}&amp; \rho^{(n+1)}(t) \<br>
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \<br>
\my{0}<em>{3\times3}&amp; \my{0}</em>{3\times3}&amp; \cdots&amp; \my{0}<em>{3\times3}&amp; \rho^{(N)}(t) \<br>
%\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \<br>
\end{array}\right].<br>
\end{align*}%\label{eq_expanded_tilde_A}<br>
Since the top-left block of $\bar{A}(t)$ is a full-rank square matrix, $\bar{\my{A}}(t)$ has full column rank if and only if there exists $i\in{n+1,\dots,N}$ such that<br>
\begin{align}\label{eq_observability_criteria_2}<br>
\rho^{(i)}(t)\neq \my{0}</em>{3\times1}.<br>
\end{align}<br>
Since $\rho(t)=-g(t)/\theta(t)$ as shown in \eqref{eq_rho_denote} and $g(t)/\theta(t)=(\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t))/\ell$ as shown in \eqref{eq_st_tem}, we can rewrite \eqref{eq_observability_criteria_2} to<br>
\begin{align}\label{eq_critia_2}<br>
-\dfrac{1}{\ell}(\my{s}<em>0+\my{s}<em>1t+\cdots+\my{s}<em>nt^n+\my{h}(t))^{(i)}\neq \my{0}</em>{3\times1}.<br>
\end{align}<br>
Since $i\ge n+1$, \eqref{eq_critia_2} is equivalent to<br>
\begin{align}\label{eq_observability_criteria_final}<br>
\my{h}^{(i)} (t) \neq \my{0}</em>{3\times1}.<br>
\end{align}<br>
According to the definition of $\my{h}(t)$ in \eqref{eq_definition_h}, the condition in \eqref{eq_observability_criteria_final} is equivalent to<br>
\begin{align*}<br>
\my{h}(t)\neq \my{0}</em>{3\times1}.<br>
\end{align*}<br>
The proof is complete.<br>
\end{proof}</p>
<p>Some important remarks about Theorem~\ref{theorem_observability_confition} are given below.</p>
<ol>
<li>
<p>The necessary and sufficient condition suggested by Theorem~\ref{theorem_observability_confition} is that the observer should have higher-order motion than the target.<br>
For example, when the target is stationary, the observer should move with a nonzero velocity. When the target moves with a constant velocity, the observer should move with a nonzero acceleration.</p>
</li>
<li>
<p>The necessary and sufficient condition given by Theorem~\ref{theorem_observability_confition} has a \emph{key difference} from the bearing-only case that the higher-order motion in the bearing-angle case is \emph{not} required to be orthogonal to the bearing vector, making the bearing-angle approach more flexible than the bearing-only one.<br>
For example, the bearing-angle approach can estimate the target’s motion even if the observer simply moves along the bearing vector.</p>
</li>
<li>
<p>In the special case where the target moves with a constant velocity, the condition in Theorem~\ref{theorem_observability_confition} is consistent with the one obtained in Section~\ref{sec_analysis_of_observability_matrix}. Although the condition in Theorem~\ref{theorem_observability_confition} allows more general target motion, the analysis in Section~\ref{sec_analysis_of_observability_matrix} is still meaningful since it is directly related to the dynamic model used in the pseudo-linear Kalman filter.</p>
</li>
<li>
<p>In practice, we would not estimate the target’s motion by using the method of solving an equation like \eqref{eq_new_linear_equtions}. That is because such a method involves calculating high-order derivatives, which are challenging to obtain accurately in practice. The role of this equation is to provide a fundamental perspective on whether there is sufficient information to uniquely recover the target’s motion.</p>
</li>
</ol>
<p>\subsection{Number of observations required}</p>
<p>\begin{figure*}[!ht]<br>
\normalsize<br>
\begin{align}<br>
\label{eq_A_22}<br>
\tilde{A}<br>
\rightarrow<br>
\left[\begin{array}{ccccc:c}<br>
\my{I} &amp; t_1\my{I} &amp; \cdots &amp; t_1^{n-1}\my{I} &amp; t_1^n\my{I} &amp; \rho(t_1) \<br>
\my{0} &amp; \my{I} &amp; \cdots &amp; {\Delta(t_2^{n-1}, t_1^{n-1})}\my{I} &amp; {\Delta(t_2^n, t_1^n)}{}\my{I} &amp; {\Delta(\rho(t_2),\rho(t_1) )}{} \<br>
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots \<br>
\my{0} &amp; \my{0} &amp; \cdots &amp; (n-1)!\my{I} &amp; {\Delta^{n-1}(t_n^n, \cdots , t_1^n)}{} &amp; {\Delta^{n-1}(\rho(t_n),\cdots,\rho(t_1) )}{} \<br>
\my{0} &amp; \my{0} &amp; \cdots &amp; \my{0} &amp; n!\my{I} &amp;  {\Delta^{n}(\rho(t_{n+1}),\cdots,\rho(t_1) )}{} \<br>
\hdashline<br>
\my{0} &amp; \my{0} &amp; \cdots &amp; \my{0} &amp; \my{0} &amp; {\Delta^{n+1}(\rho(t_{n+2}),\cdots,\rho(t_1) )}{} \<br>
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \<br>
\my{0} &amp; \my{0} &amp; \cdots &amp; \my{0} &amp; \my{0} &amp; {\Delta^{N-1}(\rho(t_N),\cdots,\rho(t_1) )}{} \<br>
\end{array}<br>
\right]<br>
\end{align}<br>
\hrulefill<br>
\vspace*{4pt}<br>
\end{figure*}</p>
<p>It is of practical importance to study how many discrete observations are required to recover the target’s motion. Although Theorem~\ref{theorem_observability_confition} gives an observability condition, it does not answer this question because it is based on the continuous time domain. We next answer this question by exploring multiple discrete time steps.</p>
<p>\begin{theorem}[(Number of discrete observations)]\label{theorem_observation_number}<br>
If the observer’s motion satisfies the observability condition in Theorem~\ref{theorem_observability_confition}, it is necessary and sufficient to use at least $n+2$ observations to recover the target’s motion. Here, $n$ is the order of the target’s polynomial motion as shown in \eqref{eq_target_nth_Order}.<br>
\end{theorem}<br>
\begin{proof}<br>
Consider $t_1,\dots,t_N$ time instances. Each time instance corresponds to an equation like \eqref{eq_linear_equations}: $\my{A}(t_i)\my{X} = \my{h}(t_i)$ for $i=1,\dots,N$.<br>
Combining these equations gives<br>
\begin{align}\label{eq_convergence_linear_eqs}<br>
\tilde{\my{A}}\my{X}=\tilde{\my{h}},<br>
\end{align}<br>
where<br>
\begin{align}\label{eq_new_A_2}<br>
\tilde{\my{A}} =<br>
\left[<br>
\begin{array}{c}<br>
\my{A}(t_1) \<br>
\vdots \<br>
\my{A}(t_N)<br>
\end{array}<br>
\right],\qquad<br>
\tilde{\my{h}}\left[<br>
\begin{array}{c}<br>
\my{h}(t_1)\<br>
\vdots\<br>
\my{h}(t_N)\<br>
\end{array}<br>
\right].<br>
\end{align}<br>
Here, $\tilde{\my{A}}\in\mathbb{R}^{(3N) \times (3n+4)}$ and $\tilde{\my{h}}\in\mathbb{R}^{3N}$.</p>
<p>(\emph{Necessity}) Since $X\in\R^{3n+4}$, we need at least $N\ge n+2$ observations so that $\tilde{\my{A}}$ is a tall matrix and hence \eqref{eq_convergence_linear_eqs} is an over-determined system.</p>
<p>(\emph{Sufficiency})<br>
Suppose we have $N\ge n+2$ discrete observations.<br>
Substituting \eqref{eq_original_A} into \eqref{eq_new_A_2} yields<br>
\begin{align*}<br>
\tilde{A} =<br>
\begin{bmatrix}<br>
\my{I}<em>{3\times 3} &amp; t_1\my{I}</em>{3\times 3} &amp; \cdots &amp; t_1^n\my{I}<em>{3\times 3} &amp; \rho(t_1) \<br>
\my{I}</em>{3\times 3} &amp; t_2\my{I}<em>{3\times 3} &amp; \cdots &amp; t_2^n\my{I}</em>{3\times 3} &amp; \rho(t_2)  \<br>
\vdots &amp; \vdots &amp;&amp; \vdots &amp; \vdots  \<br>
\my{I}<em>{3\times 3} &amp; t</em>{n+1}\my{I}<em>{3\times 3} &amp; \cdots &amp; t</em>{n+1}^n\my{I}<em>{3\times 3} &amp; \rho(t</em>{n+1}) \<br>
\my{I}<em>{3\times 3} &amp; t</em>{n+2}\my{I}<em>{3\times 3} &amp; \cdots &amp; t</em>{n+2}^n\my{I}<em>{3\times 3} &amp; \rho(t</em>{n+2})\<br>
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\<br>
\my{I}<em>{3\times 3} &amp; t</em>{N}\my{I}<em>{3\times 3} &amp; \cdots &amp; t</em>{N}^n\my{I}<em>{3\times 3} &amp; \rho(t</em>{N})\<br>
\end{bmatrix}.<br>
\end{align*}<br>
Starting from the last line in $\tilde{A}$, subtract the previous line from each subsequent line, and repeat this process.<br>
Finally, we can obtain \eqref{eq_A_22} (the equation is too long and located at the top of another page).<br>
Here, $\Delta^n$ represents the $n$th-order time difference \citep{MilneThomson2000}.<br>
For example, $\Delta (a_2, a_1)=(a_2-a_1)/\delta t$, $\Delta^2 (a_3, a_2, a_1) = \Delta (\Delta(a_3, a_2), \Delta(a_2, a_1))=[(a_3-a_2)/\delta t-(a_2-a_1)/\delta t]/\delta t$.<br>
When $\delta t$ is sufficiently small, the time difference is an approximation of the derivative.<br>
When the observability condition in Theorem~\ref{theorem_observability_confition} is satisfied, there exists $i\ge n+1$ such that $\rho^{(i)}(t)\neq 0$ as shown in \eqref{eq_observability_criteria_2}. As a result, there exists $i\ge n+1$ such that<br>
\begin{align*}<br>
\Delta^{i}(\rho(t_{i+1}),\cdots,\rho(t_1))\neq \my{0}.<br>
\end{align*}<br>
The above implication is valid because $\Delta^{i}$ is an approximation of the $i$th-order derivative when $\delta t$ is sufficiently small.<br>
Then, $\tilde{A}$ in \eqref{eq_A_22} has full column rank and hence \eqref{eq_convergence_linear_eqs} has a unique solution.<br>
\end{proof}</p>
<p>Theorem~\ref{theorem_observation_number} suggests that when the target is stationary and hence $n=0$, at least two discrete observations are sufficient to localize the target. This is true even if the two observations are acquired when the observer moves along the bearing vector.<br>
When the target moves with a constant velocity and hence $n=1$, at least three discrete observations are sufficient to localize the target, which is consistent with the results in Section~\ref{sec_analysis_of_observability_matrix}.</p>
<p>\section{Numerical Simulation Results}\label{sec_matlab_simulation}<br>
\begin{figure*}[!t]<br>
\centering<br>
\subfloat[Scenario 1: Circular motion around the target. Both the bearing-only and bearing-angle approaches work well, but the bearing-angle one converges faster.]{<br>
\includegraphics[width=1 \linewidth]{fig_matlab_1}<br>
\label{fig_matlab_1}<br>
}<br>
\hfill<br>
\subfloat[Scenario 2: Straight motion towards and backwards the target. The bearing-only approach fails, but the bearing-angle approach works effectively.]{<br>
\includegraphics[width=1 \linewidth]{fig_matlab_2}<br>
\label{fig_matlab_2}<br>
}<br>
\hfill<br>
\subfloat[<br>
Scenario 3: Approaching the target by a guidance law. The bearing-only approach works unstably, but the bearing-angle approach works effectively.]{<br>
\includegraphics[width=1 \linewidth]{fig_matlab_3}<br>
\label{fig_matlab_3}<br>
}<br>
\caption{Numerical simulation results based on 100 Monte Carlo runs in three scenarios.}<br>
\end{figure*}</p>
<p>\begin{figure*}[!t]<br>
\label{fig_matlab_varying_ell}<br>
\centering<br>
\subfloat[<br>
The observer moves around the square-shaped target. The target spins rapidly at $2\pi$~rad/s.]{<br>
\includegraphics[width=1 \linewidth]{fig_matlab_4}<br>
\label{fig_matlab_4}<br>
}<br>
\hfill<br>
\subfloat[<br>
The observer moves along the bearing vector. The target’s spinning speed is $\pi/8$~rad/s.]{<br>
\includegraphics[width=1 \linewidth]{fig_matlab_pi_8}<br>
\label{fig_matlab_pi_8}<br>
}<br>
\caption{Numerical simulation results for time-varying $\ell$.}<br>
\end{figure*}<br>
This section presents a set of numerical simulation results to demonstrate the effectiveness of the proposed bearing-angle approach.</p>
<p>The values of the parameters in two estimators are selected as $\sigma_v=10^{-3}$, $\sigma_l=10^{-4}$, $\sigma_\mu=0.01$, and $\sigma_w=0.01$.<br>
The selection of these values is inspired by the measurement noises obtained in the AirSim simulation and real-world experiments as shown later.<br>
The initial covariance matrix of the estimated states is set to $P(t_0)=0.1I$.<br>
The target is a circle whose diameter is $\ell=1$.<br>
The update rate of the system is $50$~Hz.<br>
In addition, we use the same parameter values across all the simulation examples to verify the robustness of the algorithm.<br>
Better performances can be achieved if the parameters are well-tuned for specific scenarios.<br>
We perform $N_x=100$ Monte Carlo simulations for each scenario.</p>
<p>We use the normalized-estimation error squared (NEES) \citep{bar1998estimation} to analyze the consistency of the estimation algorithms.<br>
In particular, the value of the average NEES is</p>
<p>\begin{align}<br>
\bar{\epsilon}<em>{\text{NEES}}=\dfrac{1}{N_x}\sum</em>{i=1}^{N_x}(x-\hat{x}_i)^\mathrm{T}P_i^{-1}(x-\hat{x}_i),<br>
\label{eq_nees}<br>
\end{align}<br>
%where $n_x\in\mathbb{R}$ is the dimension of the estimated states ($n_x=6$ for bearing-only, and $n_x=7$ for bearing-angle).<br>
where $\hat{x}_i$ is the estimated states in the $i$th simulation, and $P_i$ is the covariance matrix obtained from the estimator in the $i$th simulation.<br>
%The expectation of the average NEES value would be equal to the number of the estimated states.</p>
<p>Finally, image acquisition and visual detection are not considered in these numerical simulation scenarios. They will be considered in Section~\ref{sec_airsim_simulation} and Section~\ref{sec_real_world_experimental_validation}.</p>
<p>\subsection{Scenario 1: Circular motion around the target}<br>
In the first scenario, the target is stationary and located at $\my{p}_T=[0, 10]^\mathrm{T}$.<br>
The observer moves on a circle centered at the target with the speed of $3$~m/s (see Fig.~\ref{fig_matlab_1}).<br>
The radius of the circle is $5$~m.<br>
The initial estimates are $\hat{p}_o(t_0) = [0, 13]^\mathrm{T}$, $\hat{v_o}(t_0)=[0, 0]^\mathrm{T}$, $\hat{\ell}(t_0)=1.6$.<br>
During this process, the bearing vector varies while the angle subtended by the target remains constant.<br>
The angle measurement varies slightly due to the measurement noise.<br>
This scenario is favorable to the conventional bearing-only approach because its observability condition that the target should be viewed from different angles is well satisfied \citep{Li2022}.</p>
<p>Fig.~\ref{fig_matlab_1} shows the estimation results by the two approaches of bearing-only and bearing-angle.<br>
As can be seen, both algorithms perform well.<br>
The convergence of the bearing-angle approach is faster than the bearing-only one, as shown in the middle and right subfigures of Fig.~\ref{fig_matlab_1}, due to the additional angle measurement.<br>
The bearing-angle approach can successfully estimate the size of the target as shown in the right subfigure of Fig.~\ref{fig_matlab_1}.</p>
<p>\subsection{Scenario 2: Straight motion towards and backwards the target repeatedly}<br>
In the second scenario, the target is also stationary but the observer moves along a straight line towards and backwards the target repeatedly (Fig.~\ref{fig_matlab_2}).<br>
During this process, the bearing vector remains constant while the angle varies.<br>
This scenario is most challenging for the bearing-only approach because its observability condition is not fulfilled.</p>
<p>In this simulation scenario, the target is stationary and located at $\my{p}_T(t_0)=[0, 10]^\mathrm{T}$.<br>
The observer moves along a straight line towards and backwards the target with a constant acceleration of $-2$~$\text{m/s}^2$. The initial conditions are $v_o(t_0)=[0, 4]^\mathrm{T}$ and $\my{p}_o (t_0)= [0,5]^\mathrm{T}$.<br>
The initial estimates are $\hat{p}_o(t_0) = [0, 8]^\mathrm{T}$, $\hat{v_o}(t_0)=[0, 0]^\mathrm{T}$, $\hat{\ell}(t_0)=0.8$.<br>
In this scenario, the true bearing of the target relative to the observer remains unchanged though the bearing measurement may vary slightly due to the measurement noise.</p>
<p>Fig.~\ref{fig_matlab_2} shows the estimation results of the bearing-only and bearing-angle approaches.<br>
As can be seen, the bearing-only approach diverges since its observability condition is not satisfied.<br>
By contrast, the proposed bearing-angle approach converges, and is able to localize the target and estimate its size, which demonstrates the strong observability of the bearing-angle approach.<br>
One may notice that the estimated size and the NEES value get worse first before converging.<br>
This is because the noise level of the angle is set to be constant. Since the angle is small in the beginning, the noise-angle ratio is large, causing a relatively large NEES value.</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\subfloat[An AirSim simulation experimental scenario.]{<br>
\includegraphics[width=0.5 \linewidth]{fig_architecture_airsim}<br>
\label{fig_architecture_airsim}<br>
}<br>
\subfloat[Samples of the dataset collected automatically in AirSim.]{<br>
\includegraphics[width=0.5 \linewidth]{fig_airsim_dataset}<br>
\label{fig_airsim_dataset}<br>
}<br>
\caption{The setup of the AirSim simulation experiments.}<br>
\end{figure*}</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\includegraphics[width=1\linewidth]{fig_box_airsim}<br>
\caption{The software architecture of the AirSim simulation system. AirSim is a plugin for Unreal Engine. Three programmed modules (Offline training, Online estimation, and MAV control) communicate with the AirSim plugin through APIs.}<br>
\label{fig_box_airsim}<br>
\end{figure*}</p>
<p>\subsection{Scenario 3: Approaching the target by a guidance law}<br>
The third scenario is more complex than the first two. Here, the target moves with a constant velocity where the observer is controlled by a proportional navigation guidance (PNG) law to approach the target (Fig.~\ref{fig_matlab_3}).<br>
During this process, both the bearing and angle vary.<br>
This scenario is also challenging for the bearing-only approach because its observability is weak due to the fact that the lateral motion of the observer is small.<br>
Many researchers have studied how to add extra control commands to the PNG to enhance the observability based on the bearing-only approach \citep{Song1996, Seo2015, Lee2015}.</p>
<p>In this simulation scenario, the target moves along a straight line with a constant velocity $\my{v}_T=[1/\sqrt{2}, 1/\sqrt{2}]^\mathrm{T}$.<br>
The observer’s velocity magnitude is constantly $3$~m/s while the velocity direction is controlled by a PNG law.<br>
The navigation gain of the PNG law is selected as one.<br>
The initial estimates of the target’s states are the same as Scenario~1.<br>
The simulation stops just before the observer collides with the target.</p>
<p>Fig.~\ref{fig_matlab_3} shows the estimation results by the bearing-only and bearing-angle approaches. As can be seen, the bearing-angle algorithm successfully converges before the collision occurs, but the bearing-only algorithm fails to estimate the target’s states due to its weak observability.<br>
This simulation example demonstrates that the bearing-angle algorithm can be used directly in the guidance scenario without extra maneuvers required by the bearing-only approach \citep{Song1996, Seo2015, Lee2015}.</p>
<p>\subsection{Simulation results for time-varying $\ell$}<br>
\label{sec_matlab_varying_ell}<br>
Although $\ell$ is assumed to be invariant, it is meaningful to challenge the proposed bearing-angle approach by considering time-varying $\ell$.<br>
We will see through simulation examples that the bearing-angle approach is still effective when $\ell$ varies slowly. It becomes unstable when $\ell$ varies rapidly since the assumption of invariant $\ell$ is severely invalid.</p>
<p>Suppose that the target object has a square shape. Then, $\ell$ varies when the object is observed from different viewing angles or the object spins.<br>
Fig.~\ref{fig_matlab_4} shows a scenario where the observer moves around the target, whose spinning speed is $2\pi$~rad/s.<br>
The red curve in the right subfigure represents the true value of $\ell$, which varies rapidly.<br>
As can be seen, the bearing-angle algorithm works effectively though there is a small estimation bias.<br>
Fig.~\ref{fig_matlab_pi_8} shows a scenario where the observer moves along the bearing vector. The spinning speed of the target object is $\pi/8$~rad/s.<br>
As can be seen, the bearing-only approach diverges due to the lack of observability. The bearing-angle algorithm can still converge since $\ell$ varies slowly.<br>
When we further increase the spinning speed of the target, the bearing-angle algorithm will also diverge because the algorithm cannot distinguish whether the change of $\theta$ is caused by the change of $\ell$ or the change of $r$.</p>
<p>\section{AirSim Simulation Results}\label{sec_airsim_simulation}<br>
In this section, we show simulation results under a more realistic setup. In particular, the simulation is based on AirSim, a simulator that can provide high-quality visual simulation \citep{Shah2017}. Nonlinear MAV dynamics and control are also considered.</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\subfloat[The target MAV hovers stationarily, while the observer MAV approaches the target MAV under the control of \eqref{eq_tracking_control}.]{<br>
\includegraphics[width=1 \linewidth]{fig_airsim_1}<br>
\label{fig_airsim_1}<br>
}<br>
\hfill<br>
\subfloat[The target MAV moves with a constant velocity, while the observer MAV follows the target MAV under the control of \eqref{eq_tracking_control}.]{<br>
\includegraphics[width=1 \linewidth]{fig_airsim_2}<br>
\label{fig_airsim_2}<br>
}<br>
\caption{AirSim simulation results in the approaching and following scenarios.}<br>
\label{fig_airsim}<br>
\end{figure*}</p>
<p>\subsection{Simulation setup}</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\subfloat[Estimation results when $\sigma_l=10^{-4}$ and the other parameters are the same as those in Section~\ref{sec_sim_res_for_tracking}.]{<br>
\includegraphics[width=1 \linewidth]{fig_airsim_6_1}<br>
\label{fig_airsim_6_1}<br>
}<br>
\hfill<br>
\subfloat[Estimation results when $\sigma_l=0.01$ and the other parameters are the same as those in Section~\ref{sec_sim_res_for_tracking}.]{<br>
\includegraphics[width=1 \linewidth]{fig_airsim_6_2}<br>
\label{fig_airsim_6_2}<br>
}<br>
\caption{AirSim simulation results in the circular motion scenario where $\ell$ varies.}<br>
\label{fig_airsim_6}<br>
\end{figure*}</p>
<p>Fig.~\ref{fig_architecture_airsim} shows an AirSim simulation scenario.<br>
As can be seen, there are two flying quadcopter MAVs. The observer MAV can capture images of the target MAV using its simulated onboard camera.<br>
A simple gimbal camera controller is implemented so that the target MAV is always located inside the field of view of the camera.<br>
The visual environment used in the simulation is called Landscape Mountains, which includes realistic mountains, lakes, trees, and roads. Other environments can also be used if needed.</p>
<p>The bearing and angle measurements are obtained from the bounding boxes generated by a Yolo-based detection algorithm.<br>
A tiny-YOLO v4 network \citep{Bochkovskiy2020} is trained to detect the target MAV in the images. Although the visual detector can be replaced by other state-of-the-art ones, the tiny-YOLO v4 network is already sufficient to verify our proposed approach.<br>
The architecture of the entire simulation system is shown in Fig.~\ref{fig_box_airsim}.<br>
The system consists of the modules of automatic image dataset collection, Yolo-based target detection, gimbal camera control, nonlinear quadcopter dynamics, and quadcopter flight control.<br>
The quadcopter dynamics and flight control used in the simulation are similar to \citep{Meier2011, Shah2017} and omitted here due to space limitation.<br>
The quadcopter’s physical size varies slightly when viewed from different directions, although it is assumed to be invariant.<br>
All of these factors make the Airsim simulation more realistic and challenging.</p>
<p>\subsection{Automatic dataset collection}<br>
To train the Yolo-based detector, we developed a module to automatically collect an image dataset.<br>
This module has some advantages.<br>
First, it is efficient. More than ten thousand labeled images can be collected automatically in 24 hours.<br>
Second, it is flexible.<br>
It can acquire images with random target’s positions, random target’s attitudes, random camera’s view angles, and random background scenes.<br>
These images are beneficial to achieve a good generalization ability of the detector.<br>
Third, the image labels are of high quality. Since the ground truth of the target’s image is known in the simulation, the generated bounding box is tight.<br>
The collected dataset contains 17,000 labeled images (see Fig.~\ref{fig_airsim_dataset}).<br>
The resolution of the images is $1536\times 864$ pixels.<br>
The simulation system was deployed on a Dell Precision 7920 Tower Workstation with two NVIDIA Quadro GV100 graphic cards.<br>
Since the dataset is sufficient and high-quality, the detection can achieve the accuracy of mAP=99.5%.</p>
<p>\subsection{Scenario 1: Approaching and following the target}<br>
\label{sec_sim_res_for_tracking}<br>
We first consider the scenarios where the observer MAV approaches or follows a target MAV.<br>
These scenarios widely exist in practical applications such as aerial target pursuit.</p>
<p>We show two simulation examples in Fig.~\ref{fig_airsim_1} and Fig.~\ref{fig_airsim_2}, respectively.<br>
In both examples, the observer is controlled by a controller so that it can approach the target and maintain a desired separation. In particular, the controller is<br>
\begin{align}<br>
\label{eq_tracking_control}<br>
v_o^\text{cmd}(t)&amp;=v_T(t)+k^\text{track}\dfrac{r^2(t)-r_d^2}{r^2(t)}g(t),<br>
\end{align}<br>
where $v_o^\text{cmd}(t)$ is the velocity command of the observer MAV, $k^\text{track}=3$ is the control gain, and $r_d=3$ is the desired separation.<br>
The magnitude of the observer’s velocity is bounded from above by $3$~m/s.<br>
It should be noted that \eqref{eq_tracking_control} relies on the true position and velocity of the target MAV in the simulation. Therefore, the data is collected first and then processed offline so that we can compare the performances of the bearing-only and bearing-angle approaches.</p>
<p>In the first example, the target MAV hovers constantly at $p_T(t_0)=[0, 10, 10]^\mathrm{T}$.<br>
The observer MAV moves along a straight line toward the target with a decreasing velocity command.<br>
Since the bearing of the target MAV remains the same, this example is challenging for the bearing-only approach.<br>
As shown in Fig.~\ref{fig_airsim_1}, the bearing-only approach fails to converge while the bearing-angle approach can successfully estimate the target’s motion.</p>
<p>In the second example, the target MAV moves with a constant velocity of $v_T=[1/\sqrt{2}, 1/\sqrt{2}, 0]^\mathrm{T}$.<br>
The trajectory of the observer MAV under the control of \eqref{eq_tracking_control} is still close to (though not strictly) a straight line. As a result, the observability is weak by the bearing-only approach.<br>
As shown in Fig.~\ref{fig_airsim_2}, the bearing-angle approach successfully converges while the bearing-only one fails.<br>
It is notable that $\ell$ is invariant in the first example and varies slowly in the second example.</p>
<p>It is worth mentioning that the detection results used in the estimation algorithms are obtained from the Yolo-based estimator.<br>
The ground truth obtained from AirSim is only used to calculate the errors of measurements, as shown in the right figures of Figs.~\ref{fig_airsim_1} and \ref{fig_airsim_2}.<br>
It is not surprising that the measurement noises are not strictly Gaussian since the 2D bounding box is generated by a deep learning vision algorithm. It is noticed that the noises are inversely correlated to the observer-target range.<br>
This is reasonable because, when the target is close to the camera and hence its image is large, the center point and the size of the bounding box usually vary for a few pixels.</p>
<p>The NEES values are also shown in Fig.~\ref{fig_airsim}.<br>
As can be seen, the NEES value of the bearing-only approach diverges. The NEES value of the bearing-angle approach oscillates and converges slowly. The reasons are analyzed as follows. Compared to the Matlab-based numerical simulation, the visual measurements here are generated by deep learning algorithms, and the measurement noises are non-Gaussian. The non-Gaussian noises propagate into $P$ in \eqref{eq_nees} since the calculation of $P$ relies on noisy measurements. The noises may also cause an estimation bias that can further aggravate the NEES error. Moreover, although the system is observable in the two simulation examples, the observability is relatively weak compared to the case where the observer moves surrounding the target. As a result, the matrix $P$ may not be able to perfectly describe the estimation accuracy. These elements may jointly cause the convergence behavior of the NEES values shown in Fig.~\ref{fig_airsim}.</p>
<p>\subsection{Scenario 2: Circular motion and varying $\ell$}<br>
\label{sec_sim_res_circular_scenario}</p>
<p>We next examine a case where $\ell$ is time-varying.<br>
In particular, suppose a target quadcopter MAV hovers constantly at $p_T(t_0)=[0, 10, 10]^\mathrm{T}$.<br>
The observer MAV moves on a circle centered at the target (Fig.~\ref{fig_airsim_6_1}).<br>
Since the target quadcopter MAV has a square shape from the top view, its size $\ell$ is time-varying when viewed from side angles (see the red curves in the middle subfigure of Fig.~\ref{fig_airsim_6_1}).</p>
<p>We show two simulation examples in Fig.~\ref{fig_airsim_6_1} and Fig.~\ref{fig_airsim_6_2}, respectively.<br>
The two simulation examples share the same measurement data but different values of $\sigma_\ell$.<br>
Moreover, the other parameters are the same as those in Section~\ref{sec_sim_res_for_tracking}.</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\subfloat[Experimental setup]{<br>
\includegraphics[width=0.48 \linewidth]{fig_architecture_indoor}<br>
\label{fig_architecture_indoor}<br>
}<br>
\subfloat[Samples in the dataset]{<br>
\includegraphics[width=0.48 \linewidth]{fig_car_dataset1}<br>
\label{fig_car_dataset}<br>
}<br>
\caption{The setup of the experiments based on a hand-held camera.}<br>
\end{figure*}</p>
<p>In the first simulation example, $\sigma_\ell$ is set to be a small value: $\sigma_\ell=10^{-4}$.<br>
Its interpretation is that $\ell$ is treated as invariant during the process.<br>
In this case, the performance of the bearing-angle approach is almost the same as the bearing-only one as shown in Fig.~\ref{fig_airsim_6_1}.<br>
Since $\ell$ is treated to be invariant, the estimated value $\hat{\ell}$ converges to a constant which is the mean value of the time-varying $\ell$.</p>
<p>In the second simulation example, the value of $\sigma_\ell$ is larger than the first example: $\sigma_\ell = 0.01$.<br>
Its interpretation is that $\ell$ is believed to be time-varying during the process.<br>
In this case, the performance of the bearing-angle approach is still almost the same as the bearing-only one.<br>
Moreover, since $\sigma_\ell$ is large, the bearing-angle approach can successfully estimate the true time-varying value of $\ell$.</p>
<p>In summary, in the case where $\ell$ varies slowly, the bearing-angle approach would degenerate to the bearing-only one.<br>
The fundamental reason is that the extra information embedded in the angle measurement is used to estimate the time-varying $\ell$ rather than improving the observability of the target’s motion.</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\subfloat[Case 1: The observer moves around the target. Both the bearing-only and bearing-angle approaches work well.]{<br>
\includegraphics[width=1 \linewidth]{fig_indoor_9}<br>
\label{fig_indoor_9}<br>
}<br>
\hfill<br>
\subfloat[Case 2: The observer moves close or far from the target periodically. The bearing-angle approach performs effectively, but the bearing-only approach works unstably.]{<br>
\includegraphics[width=1 \linewidth]{fig_indoor_6}<br>
\label{fig_indoor_6}<br>
}<br>
\caption{Experimental results based on a hand-held camera.}<br>
\end{figure*}</p>
<p>\section{Real-World Experimental Results}\label{sec_real_world_experimental_validation}</p>
<p>In this section, two sets of real-world experiments are presented to further verify the effectiveness of the approach. The first is based on a hand-held camera and a ground robot.<br>
The second is based on two quadcopter MAVs. The second experimental scenario is motivated by aerial target pursuit tasks.</p>
<p>\subsection{Experiment 1: Hand-held camera}</p>
<p>The experimental setup is shown in Fig.~\ref{fig_architecture_indoor}.<br>
The observer is a hand-held camera (Hik Vision DS-E14S) connected to a laptop. The camera’s intrinsic parameters are calibrated beforehand.<br>
The robot built on Mecanum wheels can move in any direction on the ground under velocity control.<br>
The ground truth of the states of the camera and the robot are provided by a Vicon indoor motion capture system.<br>
The key experimental specifications are listed in Table~\ref{table_indoor_hardware}.</p>
<p>A dataset of 5,514 images was collected and used to train a tiny-YOLO v4 network to detect the target robot (see Fig.~\ref{fig_car_dataset}).<br>
The detection precision of the trained network is mAP=99.8%.<br>
In the experiment, the target robot is commanded to move with a constant velocity.<br>
In the meantime, a person holding the camera moves along some trajectories.<br>
Two different cases are studied. In both of the cases, the target robot moves with a constant velocity $v_T=[-0.1, 0.1 ,0]^\mathrm{T}$.<br>
The noises of the measurements are calculated based on the ground truth provided by the Vicon system. The noises are shown in the right subfigures of Fig.~\ref{fig_indoor_9} and Fig.~\ref{fig_indoor_6}.</p>
<p>In the first case, the camera is held about 1.5 meters above the ground and moves around the target robot. In this case, the bearing vector varies sufficiently and hence the observability conditions for the bearing-only and bearing-angle approaches are both well satisfied. As shown in Fig.~\ref{fig_indoor_9}, both approaches perform well in this case while the bearing-angle approach performs slightly better than the bearing-only one.</p>
<p>In the second case, the camera moves along the trajectory of the robot by getting close or far from it periodically.<br>
In this case, the angle varies significantly, but the bearing does not.<br>
Without surprise, the bearing-only approach performs poorly in this case due to weak observability  (Fig.~\ref{fig_indoor_6}).<br>
By contrast, the bearing-angle approach can perform stably due to its enhanced observability.<br>
\begin{table}<br>
\begin{center}<br>
\caption{Key specifications of the \emph{indoor} hardware system.}<br>
\label{table_indoor_hardware}<br>
\begin{tabular}{l|lll}<br>
\hline<br>
&amp; Parameter &amp; Value &amp; Unit \<br>
\hline<br>
\multirow{2}<em>{Camera} &amp; Resolution &amp; 640$\times$ 480 &amp; pixel\<br>
~ &amp; Max frequency &amp; 30 &amp;fps\<br>
\hline<br>
\multirow{2}</em>{Robot} &amp; Max speed &amp; 1&amp; m/s \<br>
~ &amp; Diameter size &amp; 295 &amp; mm\<br>
\hline<br>
\multirow{2}*{Vicon} &amp; Localization accuracy &amp; 1 &amp; mm \<br>
~ &amp; Max frequency &amp; 100 &amp; Hz\<br>
\hline<br>
\end{tabular}<br>
\end{center}<br>
\end{table}</p>
<p>\subsection{Experiment 2: MAV-following-MAV}<br>
\label{sec_mav_following_mav}</p>
<p>\begin{table}<br>
\begin{center}<br>
\caption{Key specifications of the \emph{outdoor} hardware system.}<br>
\label{table_M300}<br>
\begin{tabular}{c|lll}<br>
\hline<br>
&amp; Parameter &amp; Value &amp; Unit \<br>
\hline<br>
\multirow{5}{<em>}{\makecell[c]{M300 \quadcopter}} &amp; Diagonal size &amp; 895 &amp; mm\<br>
~&amp;Total mass &amp; 7.4 &amp; kg \<br>
~&amp;Max pitch/roll &amp; 30 &amp; degree \<br>
~&amp;Max flight time &amp; 30 &amp; minutes\<br>
\hline<br>
\multirow{2}{</em>}{RTK} &amp; Accuracy &amp; 1 &amp; cm \<br>
~&amp; Max frequency &amp; 10 &amp; Hz\<br>
\hline<br>
\multirow{3}{*}{\makecell[c]{H20 \ gimbal &amp; \ camera} } &amp; Resolution &amp;1920$\times$1080  &amp; pixel\<br>
~&amp; Frequency &amp; 15 &amp; Hz \<br>
~ &amp; Max angular rate &amp; 180 &amp; deg/s\<br>
\hline<br>
\end{tabular}<br>
\end{center}<br>
\end{table}</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\subfloat[Hardware platforms]{<br>
\includegraphics[width=0.48 \linewidth]{fig_M300}<br>
\label{fig_M300}<br>
}<br>
\subfloat[Samples of the images in the dataset]{<br>
\includegraphics[width=0.48\linewidth]{fig_M300_dataset1}<br>
\label{fig_M300_dataset}<br>
}<br>
\hfill<br>
\subfloat[System architecture]{<br>
\includegraphics[width=0.48 \linewidth]{fig_outdoor_hardware}<br>
\label{fig_outdoor_hardware}<br>
}<br>
\caption{The setup of the MAV-following-MAV experiment.}<br>
\end{figure*}</p>
<p>\begin{figure*}[!t]<br>
\centering<br>
\includegraphics[width=1\linewidth]{fig_outdoor_1}<br>
\caption{The results of the MAV-following-MAV experiments. The bearing-angle approach performs effectively, but the bearing-only approach works unstably.}<br>
\label{fig_outdoor_1}<br>
\end{figure*}</p>
<p>Two MAV platforms were developed based on DJI M300 quadcopters (Fig.~\ref{fig_M300}).<br>
The MAV platforms are equipped with RTK GPS modules for accurate self-localization, an H20 camera for visual detection, a Manifold 2G onboard computer for onboard flight control, and a Zigbee module for wireless communication.<br>
Some key specifications of the MAV platforms are listed in Table~\ref{table_M300}.<br>
The structure of the hardware perception and communication system is illustrated in Fig.~\ref{fig_outdoor_hardware}.<br>
The target MAV is also equipped with an RTK GPS module, whose measurements are used as the ground truth to calculate the noises of the visual measurements. The noises are shown in the right subfigure of Fig.~\ref{fig_outdoor_1}.</p>
<p>The experiment consists of two stages: data acquisition and offline data processing.<br>
In the data acquisition stage, the target MAV is commanded to fly with a constant velocity, and the observer MAV is automatically controlled to follow the target MAV to maintain a constant distance from the target.<br>
More specifically, the procedure of the flight experiment is as follows. Initially, the observer MAV is placed about 20 meters behind the target MAV on the ground. Then, the two MAVs take off and fly to the same specified height automatically upon a takeoff command sent from the ground control station.<br>
After they have reached the desired height, all deployed algorithms are activated.<br>
Then, the target MAV moves with a constant velocity of $v_T=[1/\sqrt{2}, 1/\sqrt{2}, 0]^\mathrm{T}$. The observer MAV approaches the target by the controller in \eqref{eq_tracking_control}. It takes the observer MAV about eight seconds to reach the desired relative distance.<br>
Then, the two MAVs fly with the same velocity and remain relatively stationary for another 20 seconds.<br>
Finally, the ground station sends a stop command and the two MAVs return and land automatically.</p>
<p>During the flight, the gimbal camera of the observer MAV is automatically controlled so that the target MAV is maintained in the field of view.<br>
It is noted that the control of the gimbal camera and the observer MAV is not based on the visual detection results. Instead, the control is based on the measurements provided by the RKT GPS and inter-MAV wireless communication. In this way, we can analyze the image and flight data offline and compare the performance of the two approaches of bearing-angle and bearing-only.<br>
The acquired images and flight data are saved on the onboard computer during the flight. A dataset of 5,341 images was collected (Fig.~\ref{fig_M300_dataset}) and used to train a tiny-YOLO v4 network.<br>
The detection precision of the trained network reaches mAP=99.8%.</p>
<p>The experimental results are shown in Fig.~\ref{fig_outdoor_1}.<br>
As can be seen, the bearing-angle approach performs well. By contrast, the bearing-only approach only works well before the observer MAV reached the desired position relative to the target MAV. That is because the bearing varies significantly during this process due to the fluctuation of the observer’s motion caused by the flight control. However, the bearing-only approach diverges quickly thereafter when the bearing stops varying significantly.</p>
<p>\section{Conclusion}\label{section_conclusion}<br>
Motivated by the limitation of the existing bearing-only approach, this paper proposed and analyzed a novel bearing-angle approach for vision-based target motion estimation. We showed that the observability by the bearing-angle approach is significantly enhanced compared to the bearing-only one.<br>
As a result, the requirement of the observer’s extra motion for observability enhancement can be significantly relaxed.<br>
As we showed in various experiments, the bearing-angle approach can successfully estimate the target’s motion in many scenarios where the bearing-only approach fails.<br>
The enhanced observability of the bearing-angle approach comes with no additional cost since almost all vision detection algorithms can generate bounding boxes.<br>
One assumption adopted in the bearing-angle approach is that the target’s physical size is invariant to different viewing angles. Although this assumption is approximately valid in many tasks as demonstrated in this paper, it is meaningful to study how to relax or remove this assumption in the future.</p>
<p>%\section*{Acknowledgements}<br>
%The authors would like to thank the anonymous reviewers and the editors for their helpful advice for improving this work.</p>
<p>\section*{Declaration of conflicting interests}<br>
The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
<p>\section*{Funding}<br>
The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this artical: This work was supported by the Hangzhou Key Technology Research and Development Program (Grant 20212013B09), and the Research Center for Industries of the Future at Westlake University (Grant WU2022C027).</p>
<p>\bibliographystyle{SageH}<br>
%\bibliographystyle{SageV}<br>
\bibliography{paper}</p>
<p>\end{document}</p>
</article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info"><h>论文阅读：一种基于目测的未知目标运动分析方位角方法</h></span></div><div class="post-copyright__type"><span class="post-copyright-info"><a href="https://www.adunas.top/posts/20240223a.html">https://www.adunas.top/posts/20240223a.html</a></span></div><div class="post-copyright-m"><div class="post-copyright-m-info"><div class="post-copyright-a"><h>作者</h><div class="post-copyright-cc-info"><h>阿杜那斯🍀</h></div></div><div class="post-copyright-c"><h>发布于</h><div class="post-copyright-cc-info"><h>2024-02-23</h></div></div><div class="post-copyright-u"><h>更新于</h><div class="post-copyright-cc-info"><h>2024-02-23</h></div></div><div class="post-copyright-c"><h>许可协议</h><div class="post-copyright-cc-info"><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a rel="noopener" target="_blank" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></div></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA/"><div class="tags-punctuation"><svg class="faa-tada icon" style="height:1.1em;width:1.1em;fill:currentColor;position:relative;top:2px;margin-right:3px" aria-hidden="true"><use xlink:href="#icon-sekuaibiaoqian"></use></svg></div>视觉导航</a></div></div><link rel="stylesheet" href="/css/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">投喂作者</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://picture.adunas.top/WeChatPaycodeAdunasA.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/WeChatPaycodeAdunasA.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://picture.adunas.top/AliPaycodeAdunasA.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/AliPaycodeAdunasA.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.36/audio/aowu.m4a"></audio><script defer="defer" src="/js/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/20240224a.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_1.webp" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">论文阅读方法</div></div></a></div><div class="next-post pull-right"><a href="/posts/20240225b.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_5.webp" onerror="onerror=null;src='/assets/r2.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">论文阅读：一种基于目测的未知目标运动分析方位角方法</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/20240225b.html" title="论文阅读：一种基于目测的未知目标运动分析方位角方法"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_5.webp" alt="cover"><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-02-23</div><div class="title">论文阅读：一种基于目测的未知目标运动分析方位角方法</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><svg class="meta_icon" style="width:22px;height:22px;position:relative;top:5px"><use xlink:href="#icon-mulu1"></use></svg><span style="font-weight:bold">目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">阅读导航</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">2.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Keywords"><span class="toc-number">2.2.</span> <span class="toc-text">Keywords</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">2.3.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">2.4.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Algorithms-for-bearing-only-target-motion-estimation"><span class="toc-number">2.4.1.</span> <span class="toc-text">Algorithms for bearing-only target motion estimation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Observability-analysis-of-bearing-only-target-motion-estimation"><span class="toc-number">2.4.2.</span> <span class="toc-text">Observability analysis of bearing-only target motion estimation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Problem-Formulation"><span class="toc-number">2.5.</span> <span class="toc-text">Problem Formulation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#States-transition-equation"><span class="toc-number">2.5.1.</span> <span class="toc-text">States transition equation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">\subsection{Case 1: the observer’s velocity is constant}
Denoted $\my{v}o\in \mathbb{R}^3$ as the velocity of the observer.
Consider the case where the observer has a constant velocity $\my{v}o^\text{case1}(t_i)&#x3D;\my{v}o^\text{const}$ for any $i\in{1,\dots,k}$.
Then, the relative velocity is also constant:
\begin{align}\label{eq_delta_vel_case1}
\delta \my{v}^\text{case1}(t_i) &#x3D; \my{v}T^\text{const} - \my{v}o^\text{const} &#x3D; \delta\my{v}^\text{const}.
\end{align}
Substituting \eqref{eq_delta_vel_case1} into \eqref{eq_Qo_2} and conducting elementary row transformation yields
\begin{align}\label{eq_Qo_3}
\my{Q}^\text{case1}
\rightarrow
\left[
\begin{array}{cc:c}
\my{I}{3\times 3} &amp; \my{0}{3\times 3} &amp; -\my{g}(t_1)&#x2F;\theta(t_1) \
\my{0}{3\times 3} &amp; \my{I}{3\times 3} &amp; -\delta\my{v}^\text{const}&#x2F;\ell \
\hdashline
\my{0}{6(k-1)\times 3} &amp; \my{0}{6(k-1)\times 3} &amp; \my{0}{6(k-1)\times 1}
\end{array}\right].
\end{align}
Since the upper $6\times7$ block of \eqref{eq_Qo_3} has full row rank and the lower block is zero, the rank of $\my{Q}^\text{case1}$ is
\begin{align*}
\text{rank}\left(\my{Q}^\text{case1}\right) &#x3D; 6.
\end{align*}
Since the number of states is seven and the rank is six, we know there is \emph{one unobservable mode}.
To identify this unobservable mode, we calculate the unobservable subspace, which is the null space of $\my{Q}$:
\begin{align}\label{eq_unobservable_subspace}
\text{Null}\left(\my{Q}^\text{case1}\right) &#x3D; \text{span}\left{
\begin{bmatrix}
\my{g}(t_1)&#x2F;\theta(t_1)  \
\delta\my{v}^\text{const}&#x2F;\ell \
1
\end{bmatrix}\right}.
\end{align}
According to \eqref{eq_unobservable_subspace}, the unobservable mode is
\begin{align}
x^T
\left[
\begin{array}{c}
\my{g}(t_1)&#x2F;\theta(t_1)  \
\delta\my{v}^\text{const}&#x2F;\ell \
1
\end{array}
\right]</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-color: transparent;"><div id="footer-wrap"><div id="ft"><div class="ft-item-1"><div class="t-top"><div class="t-t-l"><p class="ft-t t-l-t">格言🧬</p><div class="bg-ad"><div>&emsp;&emsp;其实爱情早就命中注定了，真正爱你的人会永远爱你，不爱你的人你也永远不会爱上✨</div></div></div><div class="t-t-r"><p class="ft-t t-l-t">猜你想看💡</p><ul class="ft-links"><li><a href="/posts/2013454d.html">格式指南</a><a href="/box/nav/">网址导航</a></li><li><a href="/social/link/">我的朋友</a><a href="/comments/">留点什么</a></li><li><a href="/personal/about/">关于作者</a><a href="/archives/">文章归档</a></li><li><a href="/categories/">文章分类</a><a href="/tags/">文章标签</a></li><li><a href="/box/Gallery/">我的画廊</a><a href="/personal/bb/">我的唠叨</a></li><li><a href="/site/time/">建设进程</a><a href="/site/census/">网站统计</a></li></ul></div></div></div><div class="ft-item-2"><p class="ft-t">推荐友链⌛</p><div class="ft-img-group"><div class="img-group-item"><a target="_blank" rel="noopener" href="https://wenderfeng.top/" title="皮皮丰"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/SteveFengA.webp" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" title="Hexo"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picture.adunas.top/Hexo-logo-avatar.png" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://butterfly.js.org/" title="Butterfly🦋"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://butterfly.js.org/img/avatar.png" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://www.fomal.cc/" title="Fomalhaut🥝"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.bitiful.net/img/avatar.webp" alt=""/></a></div><div class="img-group-item"><a target="_blank" rel="noopener" href="https://www.roydon.top/" title="roydon"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gcore.jsdelivr.net/gh/roydonGuo/CDN/avatar/ganyu.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div><div class="img-group-item"><a href="javascript:void(0)" title="广告位招租"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://lskypro.acozycotage.net/LightPicture/2022/12/65307a5828af6790.webp" alt=""/></a></div></div></div></div><div class="copyright"><span><b>&copy;2023-2024</b></span><span><b>&nbsp;&nbsp;By 阿杜那斯🍀</b></span></div><div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.3.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Frame-Hexo-blue.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.3.1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Theme-Butterfly-6513df.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站采用多线部署，主线路托管于Vercel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Hosted-Vercel-brightgreen.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://user.51.la/" style="margin-inline:5px" title="本站数据分析得益于51la技术支持"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://sourcebucket.s3.ladydaily.com/badge/Analytics-51la-3db1eb.svg" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本网站源码由Github提供存储仓库"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src=" https://sourcebucket.s3.ladydaily.com/badge/Source-Github-d021d6.svg" alt=""/></a></p></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="浅色和深色模式转换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="share" type="button" title="右键模式" onclick="changeMouseMode()"><i class="fas fa-mouse"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog right_side"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button class="share" type="button" title="分享链接" onclick="share()"><i class="fas fa-share-nodes"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i><span id="percent">0<span>%</span></span></button><button id="go-down" type="button" title="直达底部" onclick="btf.scrollToDest(document.body.scrollHeight, 500)"><i class="fas fa-arrow-down"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="fa fa-search"></i><span>百度搜索</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:randomPost()"><i class="fa fa-paper-plane"></i><span>随便逛逛</span></a><a class="rightMenu-item" href="javascript:switchNightMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="/personal/about/"><i class="fa fa-info-circle"></i><span>关于博客</span></a><a class="rightMenu-item" href="javascript:toggleWinbox();"><i class="fas fa-cog"></i><span>美化设置</span></a><a class="rightMenu-item" href="javascript:rmf.fullScreen();"><i class="fas fa-expand"></i><span>切换全屏</span></a><a class="rightMenu-item" href="javascript:window.print();"><i class="fa-solid fa-print"></i><span>打印页面</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.staticfile.org/fancyapps-ui/4.0.31/fancybox.umd.min.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/instant.page/5.1.0/instantpage.min.js" type="module"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/vanilla-lazyload/17.3.1/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script async="async">var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())
setTimeout(function(){preloader.endLoading();}, 5000);
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://comment.adunas.top/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://comment.adunas.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.staticfile.org/twikoo/1.6.8/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.staticfile.org/jquery/3.6.0/jquery.min.js"></script><script async src="https://cdn1.tianli0.top/npm/vue@2.6.14/dist/vue.min.js"></script><script async src="https://cdn1.tianli0.top/npm/element-ui@2.15.6/lib/index.js"></script><script async src="https://cdn.bootcdn.net/ajax/libs/clipboard.js/2.0.11/clipboard.min.js"></script><script defer type="text/javascript" src="https://cdn1.tianli0.top/npm/sweetalert2@8.19.0/dist/sweetalert2.all.js"></script><script async src="//npm.elemecdn.com/pace-js@1.2.4/pace.min.js"></script><script defer src="https://cdn1.tianli0.top/gh/nextapps-de/winbox/dist/winbox.bundle.min.js"></script><script async src="//at.alicdn.com/t/c/font_3586335_hsivh70x0fm.js"></script><script async src="//at.alicdn.com/t/c/font_3636804_gr02jmjr3y9.js"></script><script async src="//at.alicdn.com/t/c/font_3612150_kfv55xn3u2g.js"></script><script async src="https://cdn.wpon.cn/2022-sucai/Gold-ingot.js"></script><canvas id="universe"></canvas><canvas id="snow"></canvas><script defer src="/js/fomal.js"></script><script async src="//at.alicdn.com/t/c/font_4353813_47f1tj73u94.js"></script><script defer src="/js/aplayerExample.js"></script><script defer src="/js/aplayerWord.js"></script><script src="https://cdn.geogebra.org/apps/deployggb.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/metingjs/dist/Meting.min.js"></script><script src="https://lib.baomitu.com/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#web_bg",".js-pjax","#bibi","body > title","#app","#tag-echarts","#posts-echart","#categories-echarts"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/文章导航/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📕 阿杜の文章导航&归档 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/数学/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍼 阿杜の数学笔记 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/英语/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍟 阿杜の英语笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/阅读/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎠 阿杜の阅读笔记 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/文学/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🧨 阿杜の文学作品 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/编程/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍡 阿杜の算法编程笔记 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/博客/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍿 阿杜の博客教程 (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/操作系统-软件/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎐 阿杜の操作系统&软件笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/日程表/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🚩 阿杜の日程表 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/运动健康/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🏀 阿杜の运动健康笔记 (2)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.adunas.top/categories/游戏/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🍕 阿杜の游戏笔记 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://www.adunas.top/categories/" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #e9e9e9;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: var(--text-bg-hover)}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240225b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_5.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-23</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240225b.html&quot;);" href="javascript:void(0);" alt="">论文阅读：一种基于目测的未知目标运动分析方位角方法</a><div class="blog-slider__text">🧵本文研究了使用移动单目相机估计移动目标物体运动的问题</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240225b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231210b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_1.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-10</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231210b.html&quot;);" href="javascript:void(0);" alt="">GroGebra</a><div class="blog-slider__text">🥧本文介绍网页中使用动态数学软件GroGebra的方法。</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231210b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240223a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_4.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-23</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240223a.html&quot;);" href="javascript:void(0);" alt="">论文阅读：一种基于目测的未知目标运动分析方位角方法</a><div class="blog-slider__text">🧵本文研究了使用移动单目相机估计移动目标物体运动的问题</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240223a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_1.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224a.html&quot;);" href="javascript:void(0);" alt="">论文阅读方法</a><div class="blog-slider__text">🎗本文记录学习论文的资源和方法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240304a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_5.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240304a.html&quot;);" href="javascript:void(0);" alt="">离骚（节选）</a><div class="blog-slider__text">🥨本文为高中所学离骚（节选）的内容</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240304a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240225a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_46.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-25</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240225a.html&quot;);" href="javascript:void(0);" alt="">正则表达式</a><div class="blog-slider__text">🍤本文是正则表达式的教程</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240225a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240222a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_7.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240222a.html&quot;);" href="javascript:void(0);" alt="">日程表：2024年02月</a><div class="blog-slider__text">🥐本文记录 Adunas 2024年02月的日程安排和实施情况</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240222a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240304b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_10.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-03-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240304b.html&quot;);" href="javascript:void(0);" alt="">Pandoc</a><div class="blog-slider__text">🥯本文为 Pandoc 的使用教程</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240304b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240222b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_11.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240222b.html&quot;);" href="javascript:void(0);" alt="">关于爱莉西亚局长的个人回忆</a><div class="blog-slider__text">🧶傻瓜，你还是跟过来了呀，我的小英雄</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240222b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240225c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_4.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-25</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240225c.html&quot;);" href="javascript:void(0);" alt="">Latex</a><div class="blog-slider__text">🍙本文记录Latex语法</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240225c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_8.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224c.html&quot;);" href="javascript:void(0);" alt="">思考该不该吃完一颗难吃的苹果</a><div class="blog-slider__text">🍎每次难吃的苹果我都咽下去了，这次我决定不吃了</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231204a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_49.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-04</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231204a.html&quot;);" href="javascript:void(0);" alt="">协方差</a><div class="blog-slider__text">🥧本文讲解协方差，并给出matlab仿真代码</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231204a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231205a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_12.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-05</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231205a.html&quot;);" href="javascript:void(0);" alt="">卡尔曼滤波</a><div class="blog-slider__text">🥧本文推导卡尔曼滤波，并给出matlab仿真代码</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231205a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240221b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_15.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240221b.html&quot;);" href="javascript:void(0);" alt="">编程导航</a><div class="blog-slider__text">🥞本文是编程分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240221b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_13.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224b.html&quot;);" href="javascript:void(0);" alt="">论文阅读</a><div class="blog-slider__text">🍜本文是阅读分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231201b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_18.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231201b.html&quot;);" href="javascript:void(0);" alt="">Adunas的游戏账号昵称和ID</a><div class="blog-slider__text">🥧本文记录我的游戏账号昵称和ID，欢迎找我玩儿~</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231201b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240224d.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_43.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240224d.html&quot;);" href="javascript:void(0);" alt="">文学导航</a><div class="blog-slider__text">🍛本文是文学分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240224d.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240210a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_11.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-10</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240210a.html&quot;);" href="javascript:void(0);" alt="">数学导航</a><div class="blog-slider__text">🥧本文是数学分类的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240210a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240221a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_25.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240221a.html&quot;);" href="javascript:void(0);" alt="">文章导航</a><div class="blog-slider__text">🥞本文是文章分类导航的最顶层</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240221a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231201a.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_29.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231201a.html&quot;);" href="javascript:void(0);" alt="">Markdown语法（一）：基础语法</a><div class="blog-slider__text">🥧本文汇总Markdown基础语法，可作为文档进行查询</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231201a.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20240221c.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_35.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-02-21</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20240221c.html&quot;);" href="javascript:void(0);" alt="">博客搭建导航</a><div class="blog-slider__text">🧈本文是博客搭建的导航</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20240221c.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/20231205b.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://source.fomal.cc/img/default_cover_9.webp" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-01</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/20231205b.html&quot;);" href="javascript:void(0);" alt="">Markdown语法（三）：Butterfly外挂标签</a><div class="blog-slider__text">🥧本文汇总Markdown外挂标签在网页端的渲染效果，可作为文档进行查询</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/20231205b.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('gitZone');
      var item_html = '<div class="recent-post-item" id="gitcalendarBar" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 320px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('gitZone') && (location.pathname ==='/site/census/'|| '/site/census/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("/api?null",['#d9e0df', '#c6e0dc', '#a8dcd4', '#9adcd2', '#89ded1', '#77e0d0', '#5fdecb', '#47dcc6', '#39dcc3', '#1fdabe', '#00dab9'],'null')
    }
  </script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '2s');
    arr[i].setAttribute('data-wow-delay', '200ms');
    arr[i].setAttribute('data-wow-offset', '30');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script></div><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><!-- hexo injector body_end end --></body></html>