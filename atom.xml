<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AdunasğŸ€ã®å¼‚ä¸–ç•Œ</title>
  
  
  <link href="https://www.adunas.top/atom.xml" rel="self"/>
  
  <link href="https://www.adunas.top/"/>
  <updated>2024-03-04T02:09:14.000Z</updated>
  <id>https://www.adunas.top/</id>
  
  <author>
    <name>é˜¿æœé‚£æ–¯ğŸ€</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pandoc</title>
    <link href="https://www.adunas.top/posts/20240304b.html"/>
    <id>https://www.adunas.top/posts/20240304b.html</id>
    <published>2024-03-04T02:09:14.000Z</published>
    <updated>2024-03-04T02:09:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><a href="./20240221b.html#Pandoc">ç¼–ç¨‹å¯¼èˆª</a></h1><p>â€ƒâ€ƒPandoc æ˜¯ä¸€ä¸ªå¼€æºçš„æ–‡æœ¬è½¬æ¢å·¥å…·ã€‚</p>]]></content>
    
    
    <summary type="html">ğŸ¥¯æœ¬æ–‡ä¸º Pandoc çš„ä½¿ç”¨æ•™ç¨‹</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="Pandoc" scheme="https://www.adunas.top/tags/Pandoc/"/>
    
  </entry>
  
  <entry>
    <title>ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰</title>
    <link href="https://www.adunas.top/posts/20240304a.html"/>
    <id>https://www.adunas.top/posts/20240304a.html</id>
    <published>2024-03-04T00:55:25.000Z</published>
    <updated>2024-03-04T00:55:25.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="é˜…è¯»å¯¼èˆª"><ahref="./20240224b.html#ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰">é˜…è¯»å¯¼èˆª</a></h1><div class='poem'><div class='poem-title'>ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰</div><div class='poem-author'>å±ˆåŸ</div><p>é•¿å¤ªæ¯ä»¥æ©æ¶•å…®ï¼Œå“€æ°‘ç”Ÿä¹‹å¤šè‰°ã€‚ä½™è™½å¥½ä¿®å§±ä»¥é¿ç¾å…®ï¼Œè¬‡æœè°‡è€Œå¤•æ›¿ã€‚</p><p>æ—¢æ›¿ä½™ä»¥è•™çº•å…®ï¼Œåˆç”³ä¹‹ä»¥æ½èŒã€‚äº¦ä½™å¿ƒä¹‹æ‰€å–„å…®ï¼Œè™½ä¹æ­»å…¶çŠ¹æœªæ‚”ã€‚</p><p>æ€¨çµä¿®ä¹‹æµ©è¡å…®ï¼Œç»ˆä¸å¯Ÿå¤«æ°‘å¿ƒã€‚ä¼—å¥³å«‰ä½™ä¹‹è›¾çœ‰å…®ï¼Œè°£è¯¼è°“ä½™ä»¥å–„æ·«ã€‚</p><p>å›ºæ—¶ä¿—ä¹‹å·¥å·§å…®ï¼Œå­è§„çŸ©è€Œæ”¹é”™ã€‚èƒŒç»³å¢¨ä»¥è¿½æ›²å…®ï¼Œç«å‘¨å®¹ä»¥ä¸ºåº¦ã€‚</p><p>å¿³éƒé‚‘ä½™ä¾˜å‚ºå…®ï¼Œå¾ç‹¬ç©·å›°ä¹æ­¤æ—¶ä¹Ÿã€‚å®æº˜æ­»ä»¥æµäº¡å…®ï¼Œä½™ä¸å¿ä¸ºæ­¤æ€ä¹Ÿã€‚</p><p>é¸·é¸Ÿä¹‹ä¸ç¾¤å…®ï¼Œè‡ªå‰ä¸–è€Œå›ºç„¶ã€‚ä½•æ–¹åœœä¹‹èƒ½å‘¨å…®ï¼Œå¤«å­°å¼‚é“è€Œç›¸å®‰ï¼Ÿ</p><p>å±ˆå¿ƒè€ŒæŠ‘å¿—å…®ï¼Œå¿å°¤è€Œæ”˜è¯Ÿã€‚ä¼æ¸…ç™½ä»¥æ­»ç›´å…®ï¼Œå›ºå‰åœ£ä¹‹æ‰€åšã€‚</p><p>æ‚”ç›¸é“ä¹‹ä¸å¯Ÿå…®ï¼Œå»¶ä¼«ä¹å¾å°†åã€‚å›æœ•è½¦ä»¥å¤è·¯å…®ï¼ŒåŠè¡Œè¿·ä¹‹æœªè¿œã€‚</p><p>æ­¥ä½™é©¬äºå…°çš‹å…®ï¼Œé©°æ¤’ä¸˜ä¸”ç„‰æ­¢æ¯ã€‚è¿›ä¸å…¥ä»¥ç¦»å°¤å…®ï¼Œé€€å°†å¤ä¿®å¾åˆæœã€‚</p><p>åˆ¶èŠ°è·ä»¥ä¸ºè¡£å…®ï¼Œé›†èŠ™è“‰ä»¥ä¸ºè£³ã€‚ä¸å¾çŸ¥å…¶äº¦å·²å…®ï¼Œè‹Ÿä½™æƒ…å…¶ä¿¡èŠ³ã€‚</p><p>é«˜ä½™å† ä¹‹å²Œå²Œå…®ï¼Œé•¿ä½™ä½©ä¹‹é™†ç¦»ã€‚èŠ³ä¸æ³½å…¶æ‚ç³…å…®ï¼Œå”¯æ˜­è´¨å…¶çŠ¹æœªäºã€‚</p><p>å¿½åé¡¾ä»¥æ¸¸ç›®å…®ï¼Œå°†å¾€è§‚ä¹å››è’ã€‚ä½©ç¼¤çº·å…¶ç¹é¥°å…®ï¼ŒèŠ³è²è²å…¶å¼¥ç« ã€‚</p><p>æ°‘ç”Ÿå„æœ‰æ‰€ä¹å…®ï¼Œä½™ç‹¬å¥½ä¿®ä»¥ä¸ºå¸¸ã€‚è™½ä½“è§£å¾çŠ¹æœªå˜å…®ï¼Œå²‚ä½™å¿ƒä¹‹å¯æƒ©ã€‚</p></div><p>æƒ…æ„Ÿè¿‡å¤´ï¼š</p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/Read/LiSaoAdunasA.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><p>æœ—è¯»å‹˜è¯¯ï¼šèƒŒç»³å¢¨ä»¥è¿½æ›²å…®ï¼Œå…¶ä¸­ â€œæ›²â€ ä¸ºäºŒå£°ï¼Œå’Œç›´ç›¸å¯¹ã€‚</p><p>æƒ…æ„Ÿä¸è¶³ï¼Œæ”¹æ­£è¯»éŸ³é”™è¯¯ï¼Œè¡¥å…¨æœ€åä¸€å¥ï¼š</p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/Read/LiSaoAdunasB.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div>]]></content>
    
    
    <summary type="html">ğŸ¥¨æœ¬æ–‡ä¸ºé«˜ä¸­æ‰€å­¦ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰çš„å†…å®¹</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="é˜…è¯»æ–¹æ³•" scheme="https://www.adunas.top/tags/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Latex</title>
    <link href="https://www.adunas.top/posts/20240225c.html"/>
    <id>https://www.adunas.top/posts/20240225c.html</id>
    <published>2024-02-25T03:38:02.000Z</published>
    <updated>2024-03-04T02:09:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><a href="./20240221b.html#Latex">ç¼–ç¨‹å¯¼èˆª</a></h1><p>â€ƒâ€ƒæ˜“ç”¨éš¾ç²¾ã€‚<ahref="https://youtu.be/HPSK7q13-40?si=-mt3QWOA63NQ4pvm">How to Convert aWord Document to Markdown for Free using Pandoc</a></p><h1 id="è¯­æ³•">è¯­æ³•</h1><p>\documentclass</p>]]></content>
    
    
    <summary type="html">ğŸ™æœ¬æ–‡è®°å½•Latexè¯­æ³•</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="Latex" scheme="https://www.adunas.top/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>æ­£åˆ™è¡¨è¾¾å¼</title>
    <link href="https://www.adunas.top/posts/20240225a.html"/>
    <id>https://www.adunas.top/posts/20240225a.html</id>
    <published>2024-02-25T01:43:26.000Z</published>
    <updated>2024-02-25T01:43:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><ahref="./20240221b.html#æ­£åˆ™è¡¨è¾¾å¼">ç¼–ç¨‹å¯¼èˆª</a></h1>]]></content>
    
    
    <summary type="html">ğŸ¤æœ¬æ–‡æ˜¯æ­£åˆ™è¡¨è¾¾å¼çš„æ•™ç¨‹</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="æ­£åˆ™è¡¨è¾¾å¼" scheme="https://www.adunas.top/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ</title>
    <link href="https://www.adunas.top/posts/20240224c.html"/>
    <id>https://www.adunas.top/posts/20240224c.html</id>
    <published>2024-02-24T07:51:08.000Z</published>
    <updated>2024-02-24T07:51:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡å­¦å¯¼èˆª"><ahref="./20240224d.html#æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ">æ–‡å­¦å¯¼èˆª</a></h1><p>â€ƒâ€ƒæ¯æ¬¡éš¾åƒçš„è‹¹æœæˆ‘éƒ½å’½ä¸‹å»äº†ï¼Œä½†æ˜¯è¿™æ¬¡æˆ‘å†³å®šä¸åƒäº†ã€‚ï¼ˆæœªå®Œå¾…ç»­ï¼‰</p>]]></content>
    
    
    <summary type="html">ğŸæ¯æ¬¡éš¾åƒçš„è‹¹æœæˆ‘éƒ½å’½ä¸‹å»äº†ï¼Œè¿™æ¬¡æˆ‘å†³å®šä¸åƒäº†</summary>
    
    
    
    <category term="æ–‡å­¦" scheme="https://www.adunas.top/categories/%E6%96%87%E5%AD%A6/"/>
    
    
    <category term="æ€è€ƒ" scheme="https://www.adunas.top/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>æ–‡å­¦å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240224d.html"/>
    <id>https://www.adunas.top/posts/20240224d.html</id>
    <published>2024-02-24T07:42:23.000Z</published>
    <updated>2024-02-24T07:42:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#æ–‡å­¦">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="åŸåˆ›">åŸåˆ›</h1><h2 id="æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ"><ahref="./20240224c.html">æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ</a></h2><h1 id="æˆæƒå‘è¡¨">æˆæƒå‘è¡¨</h1><h2 id="å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†"><ahref="./20240222b.html">å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†</a></h2>]]></content>
    
    
    <summary type="html">ğŸ›æœ¬æ–‡æ˜¯æ–‡å­¦åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>é˜…è¯»å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240224b.html"/>
    <id>https://www.adunas.top/posts/20240224b.html</id>
    <published>2024-02-23T17:17:02.000Z</published>
    <updated>2024-02-23T17:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#é˜…è¯»">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="è®ºæ–‡">è®ºæ–‡</h1><h2 id="è®ºæ–‡é˜…è¯»æ–¹æ³•"><a href="./20240224a.html">è®ºæ–‡é˜…è¯»æ–¹æ³•</a></h2><h2 id="ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•"><ahref="./20240223a.html">ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•</a></h2><h1 id="åè‘—">åè‘—</h1><h2 id="ç¦»éªšèŠ‚é€‰"><a href="./20240304a.html">ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰</a></h2>]]></content>
    
    
    <summary type="html">ğŸœæœ¬æ–‡æ˜¯é˜…è¯»åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡é˜…è¯»æ–¹æ³•</title>
    <link href="https://www.adunas.top/posts/20240224a.html"/>
    <id>https://www.adunas.top/posts/20240224a.html</id>
    <published>2024-02-23T17:17:02.000Z</published>
    <updated>2024-02-23T17:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="é˜…è¯»å¯¼èˆª"><ahref="./20240224b.html#è®ºæ–‡é˜…è¯»æ–¹æ³•">é˜…è¯»å¯¼èˆª</a></h1><h1 id="èµ„æºä¸‹è½½">èµ„æºä¸‹è½½</h1><h2 id="arxiv">arXiv</h2><ol type="1"><li>å®˜ç½‘ï¼š<a href="https://arxiv.org/">arXiv</a>ã€‚</li><li>è§†é¢‘ä»‹ç»ï¼š<ahref="https://www.bilibili.com/video/BV1pT4y1m7AF/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€æ¨å€’è®ºæ–‡ä»˜è´¹å¢™ï¼Œæ•‘äººæ–°å† ç–«æƒ…é‡Œï¼Œè¿™æ˜¯â€œåå‘çŸ¥ç½‘â€arXivçš„30å¹´ã€‘</a>ã€‚</li></ol><p>â€ƒâ€ƒarXivæ˜¯å…è´¹çš„ã€å¯ä¾›ä¸‹è½½çš„è®ºæ–‡åº“ã€‚æ˜¯ä¸€ä¸ªè®ºæ–‡é¢„å°ç‰ˆç½‘ç«™ã€‚é¢„å°æœ¬ï¼ˆPreprintï¼‰æ˜¯æŒ‡ç§‘ç ”å·¥ä½œè€…çš„ç ”ç©¶æˆæœè¿˜æœªåœ¨æ­£å¼å‡ºç‰ˆç‰©ä¸Šå‘è¡¨ï¼Œè€Œå‡ºäºå’ŒåŒè¡Œäº¤æµç›®çš„è‡ªæ„¿å…ˆåœ¨å­¦æœ¯ä¼šè®®ä¸Šæˆ–é€šè¿‡äº’è”ç½‘å‘å¸ƒçš„ç§‘ç ”è®ºæ–‡ã€ç§‘æŠ€æŠ¥å‘Šç­‰æ–‡ç« ã€‚è€Œå¦ä¸€æ–¹é¢ï¼ŒarXivæœ‰ç‹¬ç‰¹çš„ä½œç”¨ï¼šä¸ºäº†é˜²æ­¢è‡ªå·±çš„idea åœ¨è®ºæ–‡è¢«æ”¶å½•å‰è¢«åˆ«äººå‰½çªƒï¼Œå¯ä»¥å°†é¢„ç¨¿ä¸Šä¼ åˆ° arXivä½œä¸ºé¢„æ”¶å½•ï¼Œå› æ­¤è¿™å°±æ˜¯ä¸ªå¯ä»¥è¯æ˜è®ºæ–‡åŸåˆ›æ€§ï¼ˆä¸Šä¼ æ—¶é—´æˆ³ï¼‰çš„æ–‡æ¡£æ”¶å½•ç½‘ç«™ã€‚</p>]]></content>
    
    
    <summary type="html">ğŸ—æœ¬æ–‡è®°å½•å­¦ä¹ è®ºæ–‡çš„èµ„æºå’Œæ–¹æ³•</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="é˜…è¯»æ–¹æ³•" scheme="https://www.adunas.top/tags/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡é˜…è¯»ï¼šä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•</title>
    <link href="https://www.adunas.top/posts/20240223a.html"/>
    <id>https://www.adunas.top/posts/20240223a.html</id>
    <published>2024-02-23T14:30:12.000Z</published>
    <updated>2024-02-23T14:30:12.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note blue no-icon flat"><ol type="1"><li>bç«™è§†é¢‘ï¼š<ahref="https://www.bilibili.com/video/BV1EC411z7Lz/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€ã€IJRRæœ€æ–°æˆæœã€‘åˆ©ç”¨è¢«å¿½è§†çš„è§†è§‰ä¿¡æ¯å¤§å¹…æå‡ç›®æ ‡å®šä½å¯è§‚æ€§ã€‘</a></li><li>è®ºæ–‡èµ„æºï¼š<a href="https://arxiv.org/abs/2401.17117">A Bearing-AngleApproach for Unknown Target Motion Analysis Based on VisualMeasurements</a></li></ol></div><h1 id="é˜…è¯»å¯¼èˆª"><ahref="./20240224b.html#ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•">é˜…è¯»å¯¼èˆª</a></h1><h1 id="abstract">Abstract</h1><p>â€ƒâ€ƒVision-based estimation of the motion of a moving target is usuallyformulated as a <em>bearing-only</em> estimation problem where thevisual measurement is modeled as a bearing vector. Although thebearing-only approach has been studied for decades, a <em>fundamentallimitation</em> of this approach is that it requires extra lateralmotion of the observer to enhance the target's observability.Unfortunately, the extra lateral motion conflicts with the desiredmotion of the observer in many tasks. It is well-known that, once atarget has been detected in an image, a bounding box that surrounds thetarget can be obtained. Surprisingly, this common visual measurementespecially its size information has not been well explored up to now. Inthis paper, we propose a new <em>bearing-angle</em> approach to estimatethe motion of a target by modeling its image bounding box asbearing-angle measurements. Both theoretical analysis and experimentalresults show that this approach can significantly enhance theobservability <em>without</em> relying on additional lateral motion ofthe observer. The benefit of the bearing-angle approach comes with noadditional cost because a bounding box is a standard output of objectdetection algorithms. The approach simply exploits the information thathas not been fully exploited in the past. No additional sensing devicesor special detection algorithms are required.</p><details class="folding-tag" blue><summary> æ³¨è§£ </summary>              <div class='content'>              <div id="åˆ†æ " class="tabs"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#åˆ†æ -1">éŸ³é¢‘</button></li><li class="tab"><button type="button" data-href="#åˆ†æ -2">æ¦‚æ‹¬</button></li></ul><div class="tab-contents"><div id="åˆ†æ -1" class="tab-item-content active"><div id="aplayer20240223a"></div><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div id="åˆ†æ -2" class="tab-item-content"><p>è¿™äº›æ–‡å­—å¾ˆå¤šåºŸè¯ã€‚æ€»ç»“å°±æ˜¯ï¼šæ²¡æœ‰åˆ©ç”¨å¤šä½™çš„ä¼ æ„Ÿå™¨ï¼Œè€Œæ˜¯ç”¨è§†è§‰æ–°çš„ä¿¡æ¯ï¼šç‰©ä½“æ¡†ä½œä¸ºæ–°çš„è§‚æµ‹å€¼ï¼Œæé«˜äº†æ–¹ä½è§’çš„ç²¾åº¦ã€‚åŒæ—¶ä¸éœ€è¦è¿åŠ¨ç‰©ä½“åšé¢å¤–çš„æ¨ªå‘è¿åŠ¨ã€‚</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>              </div>            </details><h1 id="keywords">Keywords</h1><p>Bearing-only target motion estimation, Pseudo-linear Kalman filter,Observability enhancement</p><h1 id="introduction">Introduction</h1><p>â€ƒâ€ƒThis paper studies the problem of estimating the motion of a movingtarget object using a moving monocular camera. The target's geometricinformation such as its physical size is <em>unknown</em> in advance.This problem is important in many fields . Our present work isparticularly motivated by the task of aerial target pursuit, where amicro aerial vehicle (MAV) uses its onboard camera to detect, localize,and then pursue another flying MAV. The task of aerial target pursuit,originally motivated by the interesting bird-catching-bird behaviors innature , potentially provides an effective approach to the defense ofmisused MAV.</p><figure id="fig_architecture_outdoor"></figure><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_outdoor.png" /><figcaption><b>Figure 1.</b> An observer MAV observes a target MAV with a monocular camera. The bearing $g$ and angle $\theta$ can be obtained from the bounding box that surrounds the target in the image.</figcaption><p>â€ƒâ€ƒWhen a target has been detected in an image by a vision detectionalgorithm, we usually obtain a <em>bounding box</em> that surrounds thetarget's image (see Fig.Â <a href="#fig_architecture_outdoor"data-reference-type="ref"data-reference="fig_architecture_outdoor">1</a>). The bounding boxcarries two types of useful information that can be used to estimate thetarget's motion.</p><p>â€ƒâ€ƒThe first type of useful information is the <em>center point</em>of the bounding box. The pixel coordinate of the center point can beused to calculate the spatial <em>bearing vector</em> pointing from thecamera to the target based on the pin-hole camera model <spanclass="citation" data-cites="Ma2012">[@Ma2012]</span>. Using the bearingvector to estimate the target's motion is referred to as<em>bearing-only</em> target motion estimation <span class="citation"data-cites="Fogel1988 He2019 Li2022">[@Fogel1988; @He2019;@Li2022]</span>. As a problem that has been studied for more than 40years, bearing-only target motion estimation was originally studied toestimate the motion of ships on the ocean surface <span class="citation"data-cites="hoelzer1978modified">[@hoelzer1978modified]</span>, andregained increasing research attention in recent years in vision-basedtarget estimation tasks <span class="citation"data-cites="Ponda2009 Anjaly2018 He2019">[@Ponda2009; @Anjaly2018;@He2019]</span>.</p><p>â€ƒâ€ƒBearing-only target motion estimation requires an <em>observabilitycondition</em>: The observer must have higher-order motion than thetarget and, more importantly, the higher-order motion must containcomponents that are orthogonal to the target's bearing vector <spanclass="citation" data-cites="Fogel1988">[@Fogel1988]</span>. Motivatedby this observability condition, enormous works have studied how anobserver should move to enhance the observability <span class="citation"data-cites="Hammel1989 Sabet2016 Anjaly2018 He2019">[@Hammel1989;@Sabet2016; @Anjaly2018; @He2019]</span>. For instance, in our recentwork <span class="citation" data-cites="Li2022">[@Li2022]</span>, weproposed a helical guidance law so that a MAV moves along a helicalcurve to optimize the observability in the 3D space.</p><p>â€ƒâ€ƒA <em>limitation</em> of the observability condition of the classicbearing-only approach is that the observer must move in the lateraldirections that are orthogonal to the bearing vector of the target. Suchadditional lateral motion is usually unfavorable because it may conflictwith the desired motion of the observer in many tasks. For example, inan aerial target pursuit task, the pursuer is desired to approach thetarget as fast as possible and then keep stationary relative to thetarget. Then, the additional lateral motion would conflict with thedesired motion. It is, therefore, important to study other ways that canenhance the observability while avoiding unfavorable lateral motion.</p><p>â€ƒâ€ƒThe second type of useful information of a bounding box is its<em>size</em> (either width or height). The size of a bounding box isjointly determined by several factors such as the target's distance, thetarget's physical size, and the orientation of the camera. The target'sphysical size is usually unknown in many tasks, especially in thoseantagonistic ones such as aerial pursuit of misused MAVs. As a result,the size of the bounding box cannot directly infer the target'sdistance. Nevertheless, it carries valuable information for localizingthe target.</p><p>â€ƒâ€ƒSurprisingly, the size information of the bounding box has not beenwell explored so far. The work that is closely relevant to ours is thestate-of-the-art one in <span class="citation"data-cites="Griffin2021">[@Griffin2021]</span>, where the size of abounding box is used to localize unknown target objects. Although theapproach in <span class="citation"data-cites="Griffin2021">[@Griffin2021]</span> is inspiring, it relieson two assumptions: The target objects are stationary and the camera canonly translate without rotating. It is still an open problem how toestimate a target's motion when the two assumptions are not valid.Moreover, the theoretical role of the size of a bounding box in targetmotion estimation has not been fully understood so far. Although thework in <span class="citation" data-cites="Vrba2020">[@Vrba2020]</span>also utilizes the size of the bounding box to estimate the target'sposition, it is assumed that the target's physical size is known inadvance.</p><p>â€ƒâ€ƒEstimating the motion of moving objects is also a fundamentalproblem in dynamic SLAM. For example, the works in <spanclass="citation" data-cites="Yang2019 Qiu2019">[@Yang2019;@Qiu2019]</span> firstly estimate the camera's pose and secondlyestimate the target object's pose subject to a scale factor, and finallyestimate the scale factor from multi-view measurements. To estimate thetarget object's pose subject to a scale factor, <span class="citation"data-cites="Yang2019">[@Yang2019]</span> and <span class="citation"data-cites="Qiu2019">[@Qiu2019]</span> rely on detecting, respectively,a 3D bounding box and sufficient feature points inside the 2D boundingbox. Different from <span class="citation"data-cites="Yang2019 Qiu2019">[@Yang2019; @Qiu2019]</span>, our proposedapproach merely utilizes a 2D image bounding box without furtherextracting feature points or a 3D bounding box inside the 2D boundingbox. As a result, one benefit is that this approach is morecomputationally efficient. Moreover, this approach can handle thechallenging small-target case where the target object is far and henceits image is small. In this case, it would be unreliable to extractsufficient stable features or conduct 3D detection.</p><p>â€ƒâ€ƒThe aforementioned approaches in <span class="citation"data-cites="Griffin2021 Yang2019 Qiu2019">[@Griffin2021; @Yang2019;@Qiu2019]</span> are all based on multiple views. It is also possible toestimate the target's depth from a single view/image <spanclass="citation" data-cites="Tekin2018 Vrba2020">[@Tekin2018;@Vrba2020]</span>. The single-view approach however requires priorinformation of the objects. Moreover, it would be unable to successfullylocalize target objects with different sizes but similar appearances. Inthis paper, we focus on the multi-view case.</p><p>â€ƒâ€ƒIn this paper, we propose a novel <em>bearing-angle</em> targetmotion estimation approach that models a bounding box as bearing-anglemeasurements. This approach can enhance the observability by fullyexploiting the information in a bounding box rather than relying on theadditional lateral motion of the observer. The benefit of the proposedbearing-angle approach comes with no additional cost since the boundingbox is a standard output of object detection algorithms. The approachsimply exploits the angle information that has not been fully exploitedin the past. No additional sensing devices or special detectionalgorithms are required.</p><p>â€ƒâ€ƒThe technical novelties of this approach are threefold.</p><p>1) The proposed approach does not directly use the size of a boundingbox because the size is variant to the orientation of the camera. Thatis, even if the target's relative position is unchanged, the size of thebounding box still varies when the camera rotates. Motivated by thisproblem, we convert the size of the bounding box to an angle subtendedby the target (see Fig.Â <a href="#fig_architecture_outdoor"data-reference-type="ref"data-reference="fig_architecture_outdoor">1</a>). The merit of using theangle measurement is that it is <em>invariant</em> to the camera'sorientation change (see Fig.Â <a href="#fig_cam_rotate"data-reference-type="ref" data-reference="fig_cam_rotate">2</a>) andhence can greatly facilitate the estimator design. In this way, theassumption in <span class="citation"data-cites="Griffin2021">[@Griffin2021]</span> that the camera can onlytranslate but not rotate can be avoided.</p><p>2) Although the bearing-angle approach incorporates an additionalangle measurement, it is nontrivial to see how to properly use thismeasurement because the angle does not directly infer the target'sdistance given that the target's size is unknown. We notice that theangle is a joint nonlinear function of the target's physical size andrelative distance. Hence, the state vector, which only consists of thetarget's position and velocity in the conventional bearing-onlyapproach, is augmented by the unknown target's physical size. Since thebearing and angle measurements are all nonlinear functions of thetarget's state, we establish a pseudo-linear Kalman filter to properlyutilize the measurements to enhance estimation stability. Bothsimulation and real-world experiments verify the effectiveness of theproposed estimator.</p><p>3) Although an additional angle measurement is used, an additionalunknown, the target's physical size, is also introduced into theestimator. It is, therefore, nontrivial to see how the additional anglemeasurement can help improve the observability. Motivated by thisproblem, we prove the necessary and sufficient observability conditionfor bearing-angle target motion estimation. In particular, we show thatthe target's motion can be recovered if and only if the observer has ahigher-order motion than the target. Different from the bearing-onlycase, the higher-order motion is <em>not</em> required to be in thelateral directions that are orthogonal to the bearing vector. This is animportant enhancement of the observability. As we show in variousexperiments, the bearing-angle approach can successfully recover thetarget's motion in many scenarios where the bearing-only approachfails.</p><h1 id="related-work">Related Work</h1><h2 id="algorithms-for-bearing-only-target-motion-estimation">Algorithmsfor bearing-only target motion estimation</h2><p>â€ƒâ€ƒBearing-only target motion analysis aims to estimate the target'smotion states, such as position and velocity, using bearing measurementonly. It was originally motivated by ship localization and tracking inthe ocean <span class="citation"data-cites="hoelzer1978modified">[@hoelzer1978modified]</span>. With therapid development of small-scale mobile robots equipped with cameras,the bearing-only approach regained increasing attention in recent years<span class="citation"data-cites="Ponda2009 Anjaly2018 He2019">[@Ponda2009; @Anjaly2018;@He2019]</span>.</p><p>â€ƒâ€ƒKalman filter-based estimators are widely used in the bearing-onlytarget motion. One challenge of applying the Kalman filter to thebearing-only estimation is the nonlinearity of the bearing measurement.The conventional extended Kalman filter (EKF) exhibits divergenceproblems when applied to bearing-only target motion estimation <spanclass="citation" data-cites="Aidala1979 Lin2002">[@Aidala1979;@Lin2002]</span>. Several methods have been proposed to solve thisproblem. They can be divided into two types. The first type is themodified polar EKF, which was first proposed in <span class="citation"data-cites="hoelzer1978modified">[@hoelzer1978modified]</span>. In thisapproach, three observable quantities are separated from theunobservable ones to prevent divergence. The work in <spanclass="citation" data-cites="Stallard1991">[@Stallard1991]</span>extends this approach to the case of spherical coordinates to tracktargets in 3D space. The second type is the pseudo-linear Kalman filter,which is first proposed in <span class="citation"data-cites="Lingren1978">[@Lingren1978]</span> to solve the instabilityproblem by transforming the nonlinear measurement equation into apseudo-linear one. However, this transformation makes the noise becomenon-Gaussian and highly correlated to the measurement matrix and thencauses estimation bias. Nevertheless, the work in <span class="citation"data-cites="Aidala1982">[@Aidala1982]</span> theoretically proves thatthe velocity estimation has no bias, and the position estimation biascan be removed by the observer's maneuvers.</p><p>â€ƒâ€ƒRecently, other estimation algorithms based on advanced but morecomplex filters have been proposed. The work in <span class="citation"data-cites="Farina1999">[@Farina1999]</span> uses the maximum likelihood(MLE) algorithm to estimate the target's motion using bearing-onlymeasurements. The comparison with the Cramer-Rao lower bound indicatesthat the MLE-based estimator is effective against measurement errors.The work in <span class="citation"data-cites="Dogancay2005">[@Dogancay2005]</span> proposes a constrainedtotal least-squares algorithm, which can improve the estimation accuracywhen the error of bearing measurement is large. Three differentalgorithms are used and compared in <span class="citation"data-cites="Lin2002">[@Lin2002]</span>. The results show that the EKF,the pseudo-linear filter, and the particle filter have similarperformances in most situations, while the EKF loses track when theinitial estimate error is large.</p><p>â€ƒâ€ƒAnother type of approach, called bearing-only trajectorytriangulation <span class="citation"data-cites="Avidan2000">[@Avidan2000]</span>, estimates the target'sposition from the perspective of trajectory fitting. It reconstructs thetrajectory by intersecting parametric trajectory to a series of sightrays obtained from bearing measurement. Once the trajectory issuccessfully fitted, the target's position at each time instant can beestimated by the intersection of the bearing and the trajectory. Thetrajectory fitting relies on the assumption of the trajectory's shape.However, in many applications, the target's trajectory is complex andunknown in advance. Many consecutive studies aim to relax thisassumption in various ways based on hypersurfaces <span class="citation"data-cites="Kaminski2004">[@Kaminski2004]</span>, parametric temporalpolynomials <span class="citation" data-cites="Yu2009">[@Yu2009]</span>,or compact basis vectors <span class="citation"data-cites="Park2015">[@Park2015]</span>.</p><h2id="observability-analysis-of-bearing-only-target-motion-estimation">Observabilityanalysis of bearing-only target motion estimation</h2><p>â€ƒâ€ƒObservability is a fundamental problem in bearing-only targetmotion estimation. Early works mainly focus on whether the system isobservable or not. For example, the work in <span class="citation"data-cites="Lingren1978">[@Lingren1978]</span> uses the rank ofobservation matrix to determine the observability. The work in <spanclass="citation" data-cites="Fogel1988">[@Fogel1988]</span> extends theobservability criterion in <span class="citation"data-cites="Nardone1981">[@Nardone1981]</span> to the Nth-order targetdynamics and inspires us for the observability analysis in SectionÂ <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.All these conditions indicate that the observer must have extrahigh-order motion in the lateral direction. The observability conditioncan be significantly relaxed in our approach.</p><p>â€ƒâ€ƒUnlike the works on determining whether the system is observable ornot, some studies focus on quantifying the observability degree. Thework in <span class="citation"data-cites="Hammel1989">[@Hammel1989]</span> first introduces the Fisherinformation matrix (FIM) into the observability analysis. The works in<span class="citation" data-cites="Sabet2016">[@Sabet2016]</span> and<span class="citation" data-cites="Anjaly2018">[@Anjaly2018]</span> useFIM-based objective functions to maximize observability. We also use theFIM in our former work <span class="citation"data-cites="Li2022">[@Li2022]</span> to optimize the 3D helical guidancelaw for better observability. Another method called the geometric methoduses the geometric relationship between the target and the observer intwo consecutive time instants to derive the measure of observability<span class="citation" data-cites="He2019 Woffinden2009">[@He2019;@Woffinden2009]</span>, and the results are consistent with thosederived using FIM. Compared to the bearing-only approach, theobservability degree of our bearing-angle method is sufficient toestimate the target's motion in many common scenarios such as trackingand guidance (see experiment results in Figs.Â <a href="#fig_matlab_3"data-reference-type="ref"data-reference="fig_matlab_3">[fig_matlab_3]</a> andÂ <ahref="#fig_outdoor_1" data-reference-type="ref"data-reference="fig_outdoor_1">[fig_outdoor_1]</a>).</p><h1 id="problem-formulation">Problem Formulation</h1><figure id="fig_cam_rotate"></figure><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_cam_rotate.png" /><figcaption><b>Figure 2.</b> The size of the bounding box varies when the camera rotates. By contrast, the angle subtended by the target object is invariant to the camera's orientation change.</figcaption><p>â€ƒâ€ƒConsider a target object moving in the 3D space. Its position andvelocity at time <span class="math inline">\(t_k\)</span> are denoted as<span class="math inline">\(p_T(t_k) \in\mathbb{R}^3\)</span> and <spanclass="math inline">\(v_T(t_k) \in\mathbb{R}^3\)</span>, respectively.Suppose there is an observer carrying a monocular camera to observe thetarget. The position of the observer is denoted as <spanclass="math inline">\(p_o(t_k) \in\mathbb{R}^3\)</span>. Here, we assumethat the observer/camera's pose including its position and orientationcan be obtained in other ways. For example, it can be measured directlyby RTK GPSÂ <span class="citation" data-cites="Li2022">[@Li2022]</span>or estimated by visual inertial odometryÂ <span class="citation"data-cites="Qiu2019">[@Qiu2019]</span>. In the rest of the paper, thedependence of a variable on <span class="math inline">\(t_k\)</span> isdropped when the context is clear.</p><p>â€ƒâ€ƒIf the target object can be detected by a vision algorithm, we canobtain a bounding box surrounding the target object in the image. Twotypes of information carried by the bounding box can be used to estimatethe motion of the target.</p><p>â€ƒâ€ƒFirst, the center point of the bounding box can be used tocalculate the <em>bearing</em> vector of the target. In particular,denote <span class="math inline">\(g \in \mathbb{R}^3\)</span> as theunit bearing vector pointing from <spanclass="math inline">\(p_o\)</span> to <spanclass="math inline">\(p_T\)</span>. Suppose <spanclass="math inline">\(p_\text{cam}\in\mathbb{R}^{3\times3}\)</span> isthe intrinsic parameter matrix of the camera (<span class="citation"data-cites="Ma2012">@Ma2012</span> SectionÂ <ahref="#bearing-angle-target-motion-estimator">4</a>), and <spanclass="math inline">\({R}_\text{c}^\text{w} \in\mathbb{R}^{3\times3}\)</span> is the rotation from the camera frame to the worldframe.</p><p>Then, the bearing vector <span class="math inline">\(g\)</span> canbe calculated as</p><p><span class="math display">\[\begin{aligned}g =\dfrac{{R}_\text{c}^\text{w}p_\text{cam}^{-1}{q}_{\rm pix}}{\|{R}_\text{c}^\text{w}p_\text{cam}^{-1}{q}_{\rm pix}\|},\end{aligned}\]</span></p><p>where <span class="math inline">\({q}_{\rm pix} =[x_{\rm pix} ,y_{\rm pix} , 1]^\mathrm{T} \in \mathbb{R}^3\)</span>. Here, <spanclass="math inline">\((x_{\rm pix} ,y_{\rm pix})\)</span> is the pixelcoordinate of the center point of the bounding box.</p><p>â€ƒâ€ƒSecond, the size of the bounding box can be used to calculate the<em>angle</em> subtended by the target in the camera's field of view.The reason that we convert the bounding box's size to the angle is thatthe angle is invariant to the camera's orientation change (see Fig.Â <ahref="#fig_cam_rotate" data-reference-type="ref"data-reference="fig_cam_rotate">2</a>). In particular, let <spanclass="math inline">\(s_{\rm pix}\)</span> denote the size of thebounding box. It can be either the width or the height. Let <spanclass="math inline">\(\theta \in (0,\pi/2)\)</span> be the angle.According to the pin-hole camera model <span class="citation"data-cites="Ma2012">[@Ma2012SectionÂ [4](#bearing-angle-target-motion-estimator)]</span> and the lawof cosine (see Fig.Â <a href="#fig_cam_rotate" data-reference-type="ref"data-reference="fig_cam_rotate">2</a>), the angle can be calculated as<span class="math display">\[\begin{aligned}\theta = \arccos\left(\dfrac{l_\mathrm{left}^2 + l_\mathrm{right}^2 -s_\mathrm{pix}^2}{2l_\mathrm{left}l_\mathrm{right}}\right),\end{aligned}\]</span> where <spanclass="math inline">\(l_\mathrm{left}=\sqrt{(f/\alpha)^2+(\deltax-s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}\)</span> and <spanclass="math inline">\(l_\mathrm{right}=\sqrt{(f/\alpha)^2+(\deltax+s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}\)</span> are thedistances in pixel from the camera center to the middle points of theleft and right sides of the bounding box, respectively (Fig.Â <ahref="#fig_architecture_outdoor" data-reference-type="ref"data-reference="fig_architecture_outdoor">1</a>). Moreover, <spanclass="math inline">\(f\)</span> and <spanclass="math inline">\(\alpha\)</span> denote the camera's focal lengthand single pixel size, respectively. <spanclass="math inline">\(i_{\text{width}}\)</span> and <spanclass="math inline">\(i_{\text{height}}\)</span> represent the width andthe height of the whole image in pixels, respectively. <spanclass="math inline">\(\deltax=\|x_\text{pix}-i_\text{width}/2\|\in\mathbb{R}\)</span> and <spanclass="math inline">\(\delta y =\|y_\text{pix}-i_\text{height}/2\|\in\mathbb{R}\)</span> are thedistances between the center of the bounding box and the center of theimage.</p><figure id="fig_architecture_algorithm"></figure><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_algorithm.png" /><figcaption><b>Figure 3.</b> The architecture of the proposed approach. All the simulation and real-world experiments in this paper follow this architecture.</figcaption><p>Our goal is to estimate the target's position and velocity, <spanclass="math inline">\(p_T\)</span> and <spanclass="math inline">\(v_T\)</span>, based on the noisy measurements ofthe bearing vector <span class="math inline">\(g\)</span> and the angle<span class="math inline">\(\theta\)</span> together with the observer'sown position <span class="math inline">\(p_o\)</span>. To achieve thisgoal, we propose a new bearing-angle target motion estimator (Fig.Â <ahref="#fig_architecture_algorithm">3</a>). The estimator is introducedin detail in SectionÂ <ahref="#bearing-angle-target-motion-estimator">4</a>. The observabilityof this estimator is analyzed based on Kalman's observability criterionin SectionÂ <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>.We further prove a necessary and sufficient observability condition ofthe observer in SectionÂ <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.Numerical simulation results are given in SectionÂ <ahref="#Numerical%20Simulation%20Results" data-reference-type="ref"data-reference="Numerical Simulation Results">7</a>. More realisticAirSim simulation results are given in SectionÂ <ahref="#AirSim%20Simulation%20Results" data-reference-type="ref"data-reference="AirSim Simulation Results">8</a>. Finally, real-worldexperiments are given in SectionÂ <ahref="#Real-World%20Experimental%20Results" data-reference-type="ref"data-reference="Real-World Experimental Results">9</a>.</p><p><a id="bearing-angle-target-motion-estimator"></a></p><h1 id="bearing-angle-target-motion-estimator">Bearing-Angle TargetMotion Estimator</h1><p>This section designs a bearing-angle target motion estimator based onthe framework of pseudo-linear Kalman filtering. The key here is toestablish appropriate measurement and state transition equations.</p><h2 id="states-transition-equation">States transition equation</h2><p>â€ƒâ€ƒThe state vector of the target is designed as</p><p><span class="math display">\[\begin{aligned}{x}=\left[  \begin{array}{c}    p_T \\    v_T \\    \ell \\  \end{array}\right]\in \mathbb{R}^7,\end{aligned}\]</span> where <span class="math inline">\(p_T\)</span>and <span class="math inline">\(v_T\)</span> are target's globalposition and velocity, respectively. Here, <spanclass="math inline">\(\ell&gt;0\)</span> is a scalar that represents thephysical size of the target object in the dimension that is orthogonalto the bearing vector (Fig.Â <a href="#fig_cam_rotate"data-reference-type="ref" data-reference="fig_cam_rotate">2</a>). Inthis paper, <span class="math inline">\(\ell\)</span> is assumed to beconstant or varying slowly, which means that the physical size of thetarget object should be approximately invariant from different viewingangles. Here, <span class="math inline">\(\ell\)</span> corresponds to<span class="math inline">\(\theta\)</span>, which further correspondsto either the width or height of the bounding box. Whether <spanclass="math inline">\(\ell\)</span> should correspond to the width orheight depends on in which dimension the physical size of the targetobject is invariant when viewed from different angles. More explanationis given in SectionÂ <ahref="#Dynamic%20modeling%20of%20target&#39;s%20physical%20size"data-reference-type="ref"data-reference="Dynamic modeling of target&#39;s physical size">4.2</a>.</p><p>Different from the bearing-only case where the state merely consistsof the position and velocity, the state here is augmented by thetarget's physical size. This is due to the fact that the anglemeasurement is a function of the target's physical size, which should beestimated as well. One may wonder whether the state vector can alsoincorporate the target's acceleration. To estimate high-order motion(e.g., acceleration) of the target, the observer must have higher-ordermotion (e.g., nonzero jerk) according to the observability conditionpresented in SectionÂ <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.Otherwise, the estimation would diverge. Therefore, it is preferred toexclude the acceleration and merely estimate the position andvelocity.</p><p>If no information of the target's motion is available, it is commonto model the target's motion as a discrete-time noise-driven doubleintegrator: <span class="math display">\[\begin{aligned}\label{eq_state_transition}    {x}(t_{k+1})={F}{x}(t_k) +{q}(t_k) ,\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_matrix_A}{F}=\begin{bmatrix}{I}_{3\times3} &amp; \delta t{I}_{3\times3} &amp; {0}_{3\times1}  \\{0}_{3\times3} &amp; {I}_{3\times3}  &amp; {0}_{3\times1}   \\{0}_{1\times 3} &amp; {0}_{1\times 3} &amp; 1\end{bmatrix}\in\mathbb{R}^{7\times 7},\end{aligned}\]</span> with <span class="math inline">\(\deltat\)</span> as the sampling time, and <spanclass="math inline">\({I}\)</span> and <spanclass="math inline">\({0}\)</span> as the identity and zero matrices,respectively. Here, <span class="math inline">\({q}\in\mathbb{R}^7\)</span> is a zero-mean process noise satisfying <spanclass="math inline">\({q} \sim \mathcal{N}(0,{\Sigma}_q)\)</span>, wherethe covariance matrix is <span class="math display">\[\begin{aligned}{\Sigma}_q=\text{diag}(0, 0, 0, \sigma_v^2, \sigma_v^2, \sigma_v^2,\sigma_\ell^2)\in\mathbb{R}^{7\times7}.\end{aligned}\]</span> Here, <spanclass="math inline">\(\sigma_v\in\mathbb{R}\)</span> and <spanclass="math inline">\(\sigma_\ell\in\mathbb{R}\)</span> are the standarddeviations of the target's velocity and size, respectively. When thetarget's shape is irregular, <span class="math inline">\(\ell\)</span>may vary when viewed from different angles. By letting <spanclass="math inline">\(\sigma_\ell\ne0\)</span>, we can handle the casewhere <span class="math inline">\(\ell\)</span> varies slowly. Thedynamic modeling of <span class="math inline">\(\ell\)</span> isdiscussed in the following subsection.</p><h2 id="dynamic-modeling-of-targets-physical-size">Dynamic modeling oftarget's physical size</h2><p>â€ƒâ€ƒSince the target's physical size <spanclass="math inline">\(\ell\)</span> is a state variable to be estimated,it is important to discuss its dynamic model. In fact, the dynamic modelof <span class="math inline">\(\ell\)</span> in <ahref="#eq_state_transition" data-reference-type="eqref"data-reference="eq_state_transition">[eq_state_transition]</a> assumesthat <span class="math inline">\(\ell\)</span> varies slowly. We nextjustify this modeling and provide more discussion.</p><p>First of all, <span class="math inline">\(\ell\)</span> correspondsto the physical size of the target object in the dimension that isorthogonal to the bearing vector. Its dynamics can be categorized intothree cases.</p><p><em>1) <span class="math inline">\(\ell\)</span> is invariant.</em>In theory, when <span class="math inline">\(\ell\)</span> is invariant,a change of <span class="math inline">\(\theta\)</span> implies a changeof <span class="math inline">\(r\)</span>. As a result, the measurementof <span class="math inline">\(\theta\)</span> can help improve thesystem's observability, as proven in SectionÂ <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.An ideal case where <span class="math inline">\(\ell\)</span> isinvariant is that the target object is a sphere or cylinder so that<span class="math inline">\(\ell\)</span> corresponds to its diameter<span class="citation" data-cites="Vrba2020">[@Vrba2020]</span>. Inpractice, the target object does not have to be the ideal case. Forexample, consider an autonomous driving scenario where a focal vehicleuses a camera to localize its surrounding vehicles in the 2D plane.Although the physical size of a surrounding vehicle changes greatly whenviewed from behind or side, the height of the vehicle is<em>invariant</em> from different side-view angles. In this case, <spanclass="math inline">\(\ell\)</span> corresponds to the height of thevehicle, and we need to use the height of the image bounding box tocalculate <span class="math inline">\(\theta\)</span>.</p><p><em>2) <span class="math inline">\(\ell\)</span> varies slowly.</em>If there does not exist any dimension in which the physical size of thetarget remains invariant, <span class="math inline">\(\ell\)</span> mayvary slowly when the target is viewed from different angles. Forexample, in the tasks of aerial target pursuit, if the target is aquadcopter or hexacopter, then <span class="math inline">\(\ell\)</span>is approximately equal to the wheelbase but may vary slightly whenviewed from different angles since the MAV is not a perfect cylinder. Inthis case, <span class="math inline">\(\ell\)</span> corresponds to thewheelbase of the MAV, and we need to use the width of the image boundingbox to calculate <span class="math inline">\(\theta\)</span>.</p><p>If <span class="math inline">\(\ell\)</span> varies slowly, it canstill be treated as invariant within short time intervals. As long asthe observability condition (SectionÂ <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>)is satisfied, the motion of the target as well as <spanclass="math inline">\(\ell\)</span> can be successfully estimated. Thisfact is supported by the experimental results in SectionÂ <ahref="#Scenario%202:%20Circular%20motion%20and%20varying%20$\ell$"data-reference-type="ref"data-reference="Scenario 2: Circular motion and varying $\ell$">8.4</a>.It is however worth nothing that the performance of the proposedbearing-angle approach would degenerate to the conventional bearing-onlyone because the additional information brought by <spanclass="math inline">\(\theta\)</span> is used to estimate thetime-varying <span class="math inline">\(\ell\)</span> rather thanhelping improve the system's observability.</p><p><em>3) <span class="math inline">\(\ell\)</span> varies rapidly.</em>If <span class="math inline">\(\ell\)</span> varies rapidly due tocertain reasons, it would be difficult to distinguish whether the changeof <span class="math inline">\(\theta\)</span> is caused by the changeof <span class="math inline">\(\ell\)</span> or the change of <spanclass="math inline">\(r\)</span>. For example, when a MAV is used totrack a ground vehicle, <span class="math inline">\(\ell\)</span> in anydimension may vary rapidly when the relative motion between the MAV andthe ground vehicle is highly dynamic. In such scenarios, the additionalinformation brought by <span class="math inline">\(\theta\)</span> is nolonger sufficient to estimate the rapidly varying <spanclass="math inline">\(\ell\)</span> in this case. Additional visualinformation such as a 3D bounding box that indicates the target's 3Dattitude is required. This is an important topic for future research butout of the scope of the present paper.</p><h2 id="nonlinear-measurement-equations">Nonlinear measurementequations</h2><p>The bearing vector <span class="math inline">\(g\)</span> and thesubtended angle <span class="math inline">\(\theta\)</span> are bothnonlinear functions of the target's position. In particular, <spanclass="math display">\[\label{eq_information}\begin{align}    g &amp;=\dfrac{p_T -p_o }{r },    \label{eq_bearing_measure} \\    \theta &amp;=2\arctan\left(\dfrac{\ell}{2r }\right)\approx\dfrac{\ell}{r },    \label{eq_theta_measure}\end{align}\]</span> where <span class="math display">\[r =\|p_T -p_o\|\]</span> is the distance between the target and the observer. It isnotable that there is an approximation in <a href="#eq_theta_measure"data-reference-type="eqref"data-reference="eq_theta_measure">[eq_theta_measure]</a>. Thisapproximation is accurate. Specifically, when <spanclass="math inline">\(r&gt;3\ell\)</span>, which is common in practice,it can be verified that the approximation error is less than <spanclass="math inline">\(0.08\%\)</span>. The approximation error furtherdecreases as <span class="math inline">\(r\)</span> increases.</p><p>In practice, measurements always contain noises. First, denote <spanclass="math inline">\(\hat{g} \in\mathbb{R}^3\)</span> as thenoise-corrupted bearing measurement. Then, we have <spanclass="math display">\[\begin{aligned}\label{eq_noised_g_mear}\hat{g}  = {R}\left({\eta} , \epsilon \right) g ,\end{aligned}\]</span> where <span class="math inline">\({R}\left({\eta}, \epsilon \right) \in \mathbb{R}^{3\times 3}\)</span> is a rotationmatrix that perturbs <span class="math inline">\(g\)</span>. Here, <spanclass="math inline">\({\eta} \in\mathbb{R}^3\)</span> is a unit vectorrepresenting a random rotation axis, and <spanclass="math inline">\(\epsilon \in \mathbb{R}\)</span> is a randomrotation angle. This rotation matrix would rotate the vector <spanclass="math inline">\(g\)</span> by an angle <spanclass="math inline">\(\epsilon\)</span> around the axis <spanclass="math inline">\({\eta}\)</span>. The productive noise in <ahref="#eq_noised_g_mear" data-reference-type="eqref"data-reference="eq_noised_g_mear">[eq_noised_g_mear]</a> can betransformed into an additive one: <spanclass="math display">\[\begin{aligned}\label{eq_noised_g_mear_add}    \hat{g}  = g  + {\mu} ,\end{aligned}\]</span> where <span class="math inline">\({\mu}=({R}\left({\eta} , \epsilon \right) - {I}_{3\times3})g\in\mathbb{R}^3\)</span> is the measurement noise of the bearing vector.The covariance of <span class="math inline">\(\mu\)</span> is derived inour previous workÂ <span class="citation"data-cites="Li2022">[@Li2022]</span>. Since the covariance is complexand involves unknown true values, we can approximately treat it as aGaussian noise: <span class="math inline">\(\mu\sim\mathcal{N}(0,\sigma_\mu^2 I_{3\times 3})\)</span> <span class="citation"data-cites="Li2022">[@Li2022]</span>.</p><p>Substituting <a href="#eq_bearing_measure"data-reference-type="eqref"data-reference="eq_bearing_measure">[eq_bearing_measure]</a> into <ahref="#eq_noised_g_mear_add" data-reference-type="eqref"data-reference="eq_noised_g_mear_add">[eq_noised_g_mear_add]</a> givesthe <em>nonlinear bearing measurement equation:</em> <spanclass="math display">\[\begin{aligned}\label{eq_bearing_measure_noise}    \hat{g} &amp;=\dfrac{p_T -p_o }{r } + {\mu} .\end{aligned}\]</span></p><p>Second, denote <span class="math inline">\(\hat{\theta}\in\mathbb{R}\)</span> as the noise-corrupted measurement of thesubtended angle. Then, we have <spanclass="math display">\[\begin{aligned}\label{eq_noise_theta}    \hat{\theta} =\theta  + w ,\end{aligned}\]</span> where <span class="math inline">\(w \sim\mathcal{N}(0, \sigma^2_w)\)</span> is the measurement noise.Substituting <a href="#eq_theta_measure" data-reference-type="eqref"data-reference="eq_theta_measure">[eq_theta_measure]</a> into <ahref="#eq_noise_theta" data-reference-type="eqref"data-reference="eq_noise_theta">[eq_noise_theta]</a> yields the<em>nonlinear angle measurement equation:</em> <spanclass="math display">\[\begin{aligned}\label{eq_theta_measure_noise}    \hat{\theta} &amp;=\dfrac{\ell}{r } + w.\end{aligned}\]</span></p><h2 id="pseudo-linear-measurement-equations">Pseudo-linear measurementequations</h2><p>The measurement equations <a href="#eq_bearing_measure_noise"data-reference-type="eqref"data-reference="eq_bearing_measure_noise">[eq_bearing_measure_noise]</a>and <a href="#eq_theta_measure_noise" data-reference-type="eqref"data-reference="eq_theta_measure_noise">[eq_theta_measure_noise]</a> arenonlinear in the target's state. In the following, we convert the twoequations to be pseudo-linear and then apply pseudo-linear Kalmanfiltering to achieve better estimation stability <span class="citation"data-cites="Lin2002">[@Lin2002]</span>.</p><p>First, to convert the 3D bearing measurement to pseudo-linear, weintroduce a useful orthogonal projection matrix: <spanclass="math display">\[\begin{aligned}    p_{\hat{g} }\doteq{I}_{3\times 3}-\hat{g} \hat{g}^\mathrm{T}  \in\mathbb{R}^{3\times 3}.\end{aligned}\]</span> This matrix plays an important role in theanalysis of bearing-related estimation and control problems <spanclass="citation" data-cites="Zhao2019">[@Zhao2019]</span>. It has animportant property: <span class="math display">\[p_{\hat{g} }\hat{g}={0}_{3\times 1}.\]</span> As a result, multiplying <spanclass="math inline">\(rp_{\hat{g} }\)</span> on both side of <ahref="#eq_bearing_measure_noise" data-reference-type="eqref"data-reference="eq_bearing_measure_noise">[eq_bearing_measure_noise]</a>yields <span class="math display">\[\begin{aligned}{0}_{3\times 1}=p_{\hat{g} }(p_T -p_o) + rp_{\hat{g} }{\mu}\end{aligned}\]</span> and consequently <spanclass="math display">\[\begin{aligned}p_{\hat{g} }p_o =p_{\hat{g} }p_T  + rp_{\hat{g} }{\mu}.\end{aligned}\]</span> Rewriting this equation in terms of the target'sstate variables yields the <em>pseudo-linear bearing measurementequation:</em> <span class="math display">\[\begin{aligned}\label{eq_pseudo_linear_measurement_g_equation}p_{\hat{g} }p_o =\begin{bmatrix}p_{\hat{g} } &amp;{0}_{3\times4}\end{bmatrix}\left[  \begin{array}{c}    p_T \\    v_T \\    \ell \\  \end{array}\right]  +  rp_{\hat{g} }{\mu} .\end{aligned}\]</span> Here, <span class="math inline">\(p_{\hat{g}}p_o\)</span> on the left-hand side is the new measurement, which ispseudo-linear in the target's state variables. The reason that it iscalled "pseudo" is because the measurements also appear on theright-hand side of the equation, especially in the measurementmatrix.</p><p>Second, we convert the nonlinear angle measurement in <ahref="#eq_theta_measure_noise" data-reference-type="eqref"data-reference="eq_theta_measure_noise">[eq_theta_measure_noise]</a> tobe pseudo-linear. To that end, multiplying <span class="math inline">\(r{\hatg}\)</span> on both side of <a href="#eq_theta_measure_noise"data-reference-type="eqref"data-reference="eq_theta_measure_noise">[eq_theta_measure_noise]</a>yields <span class="math display">\[\begin{aligned}\label{eq_theta_pseudo_tem}\hat{\theta} r\hat{g}  = \ell\hat{g} +wr\hat{g} .\end{aligned}\]</span> It follows from <ahref="#eq_bearing_measure_noise" data-reference-type="eqref"data-reference="eq_bearing_measure_noise">[eq_bearing_measure_noise]</a>that <span class="math inline">\(r{\hatg}=p_T -p_o+r\mu\)</span>,substituting which into the left-hand side of <ahref="#eq_theta_pseudo_tem" data-reference-type="eqref"data-reference="eq_theta_pseudo_tem">[eq_theta_pseudo_tem]</a> gives<span class="math display">\[\begin{aligned}\hat{\theta} (p_T -p_o+r\mu)  = \ell\hat{g} +wr\hat{g}.\end{aligned}\]</span> Reorganizing the above equation gives <spanclass="math display">\[\begin{aligned}\hat{\theta} p_o  = &amp;\hat{\theta} p_T  - \ell\hat{g} +r(\hat{\theta}  {\mu}  - w \hat{g}).\end{aligned}\]</span> Rewriting this equation in terms of the target'sstate variables yields the <em>pseudo-linear angle measurementequation:</em> <span class="math display">\[\begin{aligned}\label{eq_pseudo_linear_measurement_theta_equation}\begin{aligned}\hat{\theta} p_o  =&amp;\begin{bmatrix}\hat{\theta} {I}_{3\times 3} &amp; {0}_{3\times 3}  &amp; -\hat{g}\end{bmatrix}\left[  \begin{array}{c}    p_T \\    v_T \\    \ell \\  \end{array}\right]+ r(\hat{\theta}  {\mu}  - w \hat{g} ),\end{aligned}\end{aligned}\]</span> where <span class="math inline">\(\hat{\theta}p_o\)</span> is the new measurement that is pseudo-linear in thetarget's state variables.</p><h2 id="bearing-angle-estimation-algorithm">Bearing-angle estimationalgorithm</h2><p>Combining <a href="#eq_pseudo_linear_measurement_g_equation"data-reference-type="eqref"data-reference="eq_pseudo_linear_measurement_g_equation">[eq_pseudo_linear_measurement_g_equation]</a>and <a href="#eq_pseudo_linear_measurement_theta_equation"data-reference-type="eqref"data-reference="eq_pseudo_linear_measurement_theta_equation">[eq_pseudo_linear_measurement_theta_equation]</a>gives the compact form of the measurement equation: <spanclass="math display">\[\begin{aligned}\label{eq_pseudo_linear_measurement_equations}{z} = {H} {x}  + {\nu} ,\end{aligned}\]</span> where <span class="math display">\[\begin{align}{z} &amp;=    \begin{bmatrix}    p_{\hatg} p_o   \\    \hat{\theta} p_o    \end{bmatrix}\in\mathbb{R}^6, \\{H}&amp; =    \begin{bmatrix}    p_{\hatg}  &amp; {0}_{3\times 3} &amp; {0}_{3\times 1} \\    \hat{\theta} {I}_{3\times 3} &amp; {0}_{3\times 3}  &amp; -\hat{g}    \end{bmatrix}\in\mathbb{R}^{6\times7},    \label{eq_matrix_H} \\{\nu}  &amp;=    \begin{bmatrix}    r p_{\hatg} {\mu}  \\    r (\hat{\theta}  {\mu}  - w \hat{g} )    \end{bmatrix}    \in\mathbb{R}^6.    \label{eq_final_measurement_noise}\end{align}\]</span> Here, <span class="math inline">\(\nu\)</span> canbe rewritten as a matrix form <spanclass="math display">\[\begin{aligned}    \nu=E    \begin{bmatrix}        \mu \\ w    \end{bmatrix},\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_E_mat}    E=r    \begin{bmatrix}        P_{\hatg} &amp; 0_{3\times 1}\\        \hat{\theta}I_{3\times 3} &amp; -\hatg    \end{bmatrix}\in\mathbb{R}^{6\times 4}.\end{aligned}\]</span> As a result, <spanclass="math inline">\(\nu\)</span> can be approximately treated as alinear transformation of Gaussian noises. Its covariance matrix can becalculated as <span class="math display">\[\begin{aligned}%\label{eq_final_measurement_noise_covariance}{\Sigma}_  = E\begin{bmatrix}\sigma_\mu^2 I_{3\times 3} &amp; 0_{3\times1}\\0_{1\times 3} &amp; \sigma_w^2\end{bmatrix}E^\mathrm{T}\in\mathbb{R}^{6\times6}.\end{aligned}\]</span> Although the quantities in <spanclass="math inline">\(E\)</span> such as <spanclass="math inline">\(\hatg\)</span> and <spanclass="math inline">\(\hat{\theta}\)</span> contain measurement noises,it is a common practice to treat them as deterministic quantities.Otherwise, if, for example, <span class="math inline">\(\hatg\)</span>is split to <span class="math inline">\(\hatg=g+\mu\)</span> and weconsider the noise separately, the expression of <spanclass="math inline">\(\nu\)</span> would be a complex function of thetrue values and the noises. Since the true values are unknown, thecovariance cannot be calculated. Moreover, <spanclass="math inline">\(r\)</span> in <a href="#eq_E_mat"data-reference-type="eqref" data-reference="eq_E_mat">[eq_E_mat]</a> isthe true target range, which is unknown. We can use the estimated value<span class="math inline">\(\hat{r} =\|\hat{p}_T -p_o \|\)</span> toreplace it in implementation. Here, <spanclass="math inline">\(\hatp_T\in\mathbb{R}^3\)</span> is the estimatedvalue of the target's position. This technique has been used inbearing-only target estimation <span class="citation"data-cites="He2018 Li2022">[@He2018; @Li2022]</span>.</p><p>With the state transition equation <a href="#eq_state_transition"data-reference-type="eqref"data-reference="eq_state_transition">[eq_state_transition]</a> and themeasurement equation <a href="#eq_pseudo_linear_measurement_equations"data-reference-type="eqref"data-reference="eq_pseudo_linear_measurement_equations">[eq_pseudo_linear_measurement_equations]</a>,the bearing-angle estimator can be realized by the Kalman filter. For aquick reference, we list the steps below. The prediction steps are <spanclass="math display">\[\begin{aligned}\hat^{-}(t_k) &amp;={F}\hat(t_{k-1}), \\p^{-}(t_k) &amp;= {F}p(t_{k-1}){F}^\mathrm{T} + {\Sigma}_q,\end{aligned}\]</span> where <spanclass="math inline">\(\hat^{-}(t_k)\in\mathbb{R}^7\)</span>and <spanclass="math inline">\(p^{-}(t_k)\in\mathbb{R}^{7\times7}\)</span> arethe prior estimated state and covariance matrix, respectively. Thecorrection steps are <span class="math display">\[\begin{aligned}{K}(t_k) &amp;=p^{-}(t_k){H}^\mathrm{T}(t_k)\left[{H}(t_k)p^{-}(t_k){H}^\mathrm{T}(t_k)+{\Sigma}_\nu\right]^{\dagger},\\\hat(t_k) &amp;= \hat^{-}(t_k) +{K}(t_k)\left[{z}(t_k)-{H}(t_k)\hat^{-}(t_k)\right],\\p(t_k) &amp;=\left[{I}_{7\times 7} -{K}(t_k){H}(t_k) \right]p^{-}(t_k),\end{aligned}\]</span> where <spanclass="math inline">\({K}(t_k)\in\mathbb{R}^{7\times6}\)</span> is theKalman gain matrix, <spanclass="math inline">\(\hat(t_k)\)</span> and <spanclass="math inline">\(p(t_k)\)</span> are posterior estimated state andcovariance matrix, and symbol <spanclass="math inline">\(\dagger\)</span> denotes the pseudoinverse. Theusage of pseudoinverse in the Kalman filter is a common practice toprevent the situation that <spanclass="math inline">\({H}(t_k)p^{-}(t_k){H}^\mathrm{T}(t_k)+{\Sigma}_\nu\)</span>is rank deficient <span class="citation"data-cites="YOSHIKAWA1972 Kulikov2018">[@YOSHIKAWA1972;@Kulikov2018]</span>.</p><h1 id="observability-analysis-by-kalmans-criterion">ObservabilityAnalysis by Kalman's Criterion</h1><p>Although an additional angle measurement is adopted in thebearing-angle estimator, it is nontrivial to see whether this additionalmeasurement can improve the system's observability because an additionalunknown variable, the target's physical size, is also required toestimate. It is therefore necessary to study the observabilityconditions under which the target's motion can be successfullyestimated.</p><p>In this and the next sections, we present two methods to analyze theobservability conditions. The first method, as presented in thissection, relies on Kalman's observability criterion, which is to checkthe rank of the observability matrix of a linear system. The secondmethod, as presented in the next section, relies on solving a set oflinear equations. Both methods have been adopted in the literature toanalyze the observability of estimators <span class="citation"data-cites="Zhao2015 Fogel1988">[@Zhao2015; @Fogel1988]</span>. For thebearing-angle estimator, the first method considers the specificdynamics of the filter but is not able to handle the case when thetarget's motion has a higher order. The second method can handle thehigh-order motion of the target but does not consider the dynamics ofthe filter. We will show that the conclusions given by the two methodsare consistent. In both of the methods, we consider the case where <spanclass="math inline">\(\ell\)</span> is invariant.</p><h2 id="the-observability-matrix">The observability matrix</h2><p>Consider a time horizon of <span class="math inline">\(k\geq3\)</span> consecutive steps. The observability matrix of the system of<a href="#eq_matrix_H" data-reference-type="eqref"data-reference="eq_matrix_H">[eq_matrix_H]</a> and <ahref="#eq_matrix_A" data-reference-type="eqref"data-reference="eq_matrix_A">[eq_matrix_A]</a> can be calculated as<span class="math display">\[\begin{aligned}\label{eq_Qo}    {Q}=    \begin{bmatrix}    {H}(t_1) \\    {H}(t_2){F} \\    {H}(t_3){F}^2 \\    \cdots \\    {H}(t_k){F}^{k-1} \\    \end{bmatrix}\in\mathbb{R}^{6k\times7}.\end{aligned}\]</span> Substituting the expressions of <spanclass="math inline">\(F\)</span> and <spanclass="math inline">\(H\)</span> in <a href="#eq_matrix_A"data-reference-type="eqref"data-reference="eq_matrix_A">[eq_matrix_A]</a> and <ahref="#eq_matrix_H" data-reference-type="eqref"data-reference="eq_matrix_H">[eq_matrix_H]</a> into <a href="#eq_Qo"data-reference-type="eqref" data-reference="eq_Qo">[eq_Qo]</a> yields<span class="math display">\[\begin{aligned}{Q}=\left[\begin{array}{ccc}p_g(t_1) &amp; {0}_{3\times 3} &amp; {0}_{3\times 1} \\\theta(t_1){I}_{3\times 3} &amp; {0}_{3\times 3}  &amp; -g(t_1) \\\hdashlinep_g(t_2) &amp; \delta tp_g(t_2) &amp; {0}_{3\times 1} \\\theta(t_2){I}_{3\times 3} &amp; \delta t\theta(t_2){I}_{3\times3}  &amp; -g(t_2) \\\hdashline\vdots &amp; \vdots &amp; \vdots \\\hdashlinep_g(t_k) &amp; (k-1)\delta tp_g(t_k) &amp; {0}_{3\times 1} \\\theta(t_k){I}_{3\times 3} &amp; (k-1)\delta t\theta(t_k){I}_{3\times3}  &amp; -g(t_k)\\\end{array}\right].\end{aligned}\]</span> Note that the noises in the bearing and anglemeasurements are neglected when we analyze the fundamental observabilityproperty. After a series of elementary row transformations in <spanclass="math inline">\({Q}\)</span>, we can obtain <spanclass="math display">\[\begin{aligned}\label{eq_Qo_2}{Q}\rightarrow\begin{bmatrix}{I}_{3\times 3} &amp; {0}_{3\times 3} &amp; -g(t_1)/\theta(t_1) \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav(t_2)/\ell \\\vdots &amp; \vdots &amp; \vdots \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav(t_k)/\ell \\\hdashline{0}_{3k\times 3} &amp; {0}_{3k\times 3} &amp; {0}_{3k\times 1}\end{bmatrix},\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\deltav(t_k) \doteq v_T(t_k) - v_o(t_k)\end{aligned}\]</span> is the relative velocity.</p><p>In the following two subsections, we analyze the rank of theobservability matrix in two scenarios where the observer moves with zeroand nonzero acceleration, respectively. In the two scenarios, the targetis always assumed to move with a constant velocity: <spanclass="math display">\[\begin{aligned}v_T(t_k) = v_T^\text{const}.\end{aligned}\]</span></p><h2 id="case-1-the-observers-velocity-is-constant">Case 1: theobserver's velocity is constant</h2><p>Denoted <span class="math inline">\(v_o\in \mathbb{R}^3\)</span> asthe velocity of the observer. Consider the case where the observer has aconstant velocity <spanclass="math inline">\(v_o^\text{case1}(t_i)=v_o^\text{const}\)</span>for any <span class="math inline">\(i\in\{1,\dots,k\}\)</span>. Then,the relative velocity is also constant: <spanclass="math display">\[\begin{aligned}\label{eq_delta_vel_case1}\delta v^\text{case1}(t_i) = v_T^\text{const} - v_o^\text{const} =\deltav^\text{const}.\end{aligned}\]</span> Substituting <a href="#eq_delta_vel_case1"data-reference-type="eqref"data-reference="eq_delta_vel_case1">[eq_delta_vel_case1]</a> into <ahref="#eq_Qo_2" data-reference-type="eqref"data-reference="eq_Qo_2">[eq_Qo_2]</a> and conducting elementary rowtransformation yields <span class="math display">\[\begin{aligned}\label{eq_Qo_3}{Q}^\text{case1}\rightarrow\left[\begin{array}{cc:c}{I}_{3\times 3} &amp; {0}_{3\times 3} &amp; -g(t_1)/\theta(t_1) \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav^\text{const}/\ell\\\hdashline{0}_{6(k-1)\times 3} &amp; {0}_{6(k-1)\times 3} &amp; {0}_{6(k-1)\times1}\end{array}\right].\end{aligned}\]</span> Since the upper <spanclass="math inline">\(6\times7\)</span> block of <a href="#eq_Qo_3"data-reference-type="eqref" data-reference="eq_Qo_3">[eq_Qo_3]</a> hasfull row rank and the lower block is zero, the rank of <spanclass="math inline">\({Q}^\text{case1}\)</span> is <spanclass="math display">\[\begin{aligned}\text{rank}\left({Q}^\text{case1}\right) = 6.\end{aligned}\]</span> Since the number of states is seven and the rankis six, we know there is <em>one unobservable mode</em>. To identifythis unobservable mode, we calculate the unobservable subspace, which isthe null space of <span class="math inline">\({Q}\)</span>: <spanclass="math display">\[\begin{aligned}\label{eq_unobservable_subspace}\text{Null}\left({Q}^\text{case1}\right) = \text{span}\left\{\begin{bmatrix}g(t_1)/\theta(t_1)  \\\deltav^\text{const}/\ell \\1\end{bmatrix}\right\}.\end{aligned}\]</span> According to <a href="#eq_unobservable_subspace"data-reference-type="eqref"data-reference="eq_unobservable_subspace">[eq_unobservable_subspace]</a>,the unobservable mode is <span class="math display">\[\begin{aligned}x^T\left[\begin{array}{c}g(t_1)/\theta(t_1)  \\\deltav^\text{const}/\ell \\1\end{array}\right]=p_T^\mathrm{T}\dfrac{g(t_1)}{\theta(t_1)}+v_T^\mathrm{T}\dfrac{\deltav^\text{const}}{\ell} + \ell.\label{eq_unobservable_mode}\end{aligned}\]</span> Although there is only one unobservable mode,this mode given in <a href="#eq_unobservable_mode"data-reference-type="eqref"data-reference="eq_unobservable_mode">[eq_unobservable_mode]</a>involves all the states including the target's position, velocity, andphysical size. It suggests that the estimation of the three quantitiesis coupled. In conclusion, we know that, if the target moves with aconstant velocity, its states are unobservable when the observer moveswith a constant velocity.</p><h2 id="case-2-the-observers-velocity-is-time-varying">Case 2: theobserver's velocity is time-varying</h2><p>We now consider the case where the observer has nonzero accelerationso that its velocity is time-varying across the time horizon from <spanclass="math inline">\(t_1\)</span> to <spanclass="math inline">\(t_k\)</span>.</p><p>Denote <span class="math inline">\({a}_o(t_i)\in\mathbb{R}\)</span>as the observer's acceleration, which can be approximated as <spanclass="math display">\[\begin{aligned}\label{eq_acc}{a}_o(t_i) &amp;\approx\dfrac{v_o(t_i) - v_o(t_{i-1})}{\delta t} \nonumber\\&amp;=-\dfrac{\left[v_T^\text{const} - v_o(t_i)\right] -\left[v_T^\text{const} - v_o(t_{i-1})\right]}{\delta t} \nonumber\\&amp;=-\dfrac{\delta v(t_i) - \delta v(t_{i-1})}{\delta t}.\end{aligned}\]</span> Substituting <a href="#eq_acc"data-reference-type="eqref" data-reference="eq_acc">[eq_acc]</a> into <ahref="#eq_Qo_2" data-reference-type="eqref"data-reference="eq_Qo_2">[eq_Qo_2]</a> and performing elementary rowtransformation yields <span class="math display">\[\begin{aligned}\label{eq_Q_case2_final}{Q}^\text{case2}\rightarrow\left[\begin{array}{ccc}{I}_{3\times 3} &amp; {0}_{3\times 3} &amp; -g(t_1)/\theta(t_1) \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav(t_2)/\ell \\{0}_{3\times 3} &amp; {0}_{3\times 3} &amp; \delta t {a}_o(t_3)/\ell \\\hdashline\vdots &amp; \vdots &amp;\vdots \\{0}_{3\times 3} &amp; {0}_{3\times 3} &amp; \delta t {a}_o(t_k)/\ell \\{0}_{3k\times 3} &amp; {0}_{3k\times 3} &amp; {0}_{3k\times 1}\end{array}\right].\end{aligned}\]</span> The upper <spanclass="math inline">\(6\times7\)</span> block in <ahref="#eq_Q_case2_final" data-reference-type="eqref"data-reference="eq_Q_case2_final">[eq_Q_case2_final]</a> has full columnrank. Therefore, if <span class="math inline">\(a_o(t_i)\ne0\)</span>for any <span class="math inline">\(i\geq3\)</span>, then <spanclass="math display">\[\begin{aligned}\text{rank}\left({Q}^\text{case2}\right) = 7,\end{aligned}\]</span> Which is the same as the number of estimatedstates. Therefore, the target's state is observable when the observermoves with nonzero acceleration.</p><h2 id="summary-of-this-section">Summary of this section</h2><p>From the above analysis, we know that when the target has a constantvelocity, its states including its position, velocity, and physical sizeare observable if and only if the observer has non-zeroaccelerations.</p><p>The critical difference of this condition from the bearing-only caseis that the target's states are still observable <em>even if theobserver moves along the bearing vector</em> towards or backward thetarget. By contrast, for a bearing-only estimator, moving along thebearing vector is insufficient to recover the target's motion.Therefore, the additional lateral motion of the observer required in thebearing-only case is <em>not</em> required in the bearing-angle caseanymore, which provides better flexibility for designing the observer'smotion.</p><h1id="observability-analysis-by-solving-linear-equations">ObservabilityAnalysis by Solving Linear Equations</h1><p>This section extends the observability condition obtained in the lastsection to more general cases where the target's velocity does not haveto be constant.</p><h2 id="problem-formulation-1">Problem formulation</h2><p>The observability problem that we aim to solve is to determinewhether <span class="math inline">\(p_T(t)\)</span> can be recoveredfrom <span class="math inline">\(p_o(t)\)</span> and <spanclass="math inline">\(g(t),\theta(t)\)</span>.</p><p>Suppose the target's motion can be described by an <spanclass="math inline">\(n\)</span>th-order polynomial during a timeinterval: <span class="math display">\[\begin{aligned}\label{eq_target_nth_Order}    p_T(t)={b}_0+{b}_1t+\cdots+{b}_nt^n,\end{aligned}\]</span> where <span class="math inline">\({b}_0, {b}_1,\cdots, {b}_n\in\mathbb{R}^3\)</span> are unknown constant vectors. Ifwe can determine the values of <spanclass="math inline">\(\{b_i\}_{i=0}^n\)</span>, then we can determinethe target's motion and hence it is observable. Although polynomialscannot represent all trajectories, they can effectively approximate amajority of them according to the method of Taylor expansion. This isespecially true if we consider a short time horizon. This kind oftechnique has been adopted in the observability analysis of bearing-onlytarget motion estimation tasksÂ <span class="citation"data-cites="Nardone1981 Lee2010">[@Nardone1981; @Lee2010]</span>.</p><p>Suppose the observer's motion is described by <spanclass="math display">\[\begin{aligned}    p_o(t)={c}_0+{c}_1t+\cdots+{c}_nt^n+{h}(t),\end{aligned}\]</span> where <span class="math inline">\({c}_0, {c}_1,\cdots, {c}_n\in\mathbb{R}^3\)</span> are constant parameters, and <spanclass="math display">\[\begin{aligned}\label{eq_definition_h}{h}(t) = {d}_1 t^{n+1}+{d}_2t^{n+2}+\cdots\end{aligned}\]</span> represents <em>higher-order</em> motion with<span class="math inline">\({d}_1, {d}_2,\cdots\in\mathbb{R}^3\)</span>. It can be verified that the derivativesof <span class="math inline">\({h}(t)\)</span> satisfy <spanclass="math inline">\({h}^{(i)}(0)={0}_{3\times 1}\)</span> for <spanclass="math inline">\(i=0,1,\cdots, n\)</span>. Let <spanclass="math inline">\({s}(t)\in\mathbb{R}^3\)</span> be the relativemotion between the target and the observer: <spanclass="math display">\[\begin{aligned}\label{eq_relative_motion}    {s}(t)&amp;\doteqp_T(t)-p_o(t)  \nonumber\\    &amp;\doteq{s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t),\end{aligned}\]</span> where <span class="math inline">\({s}_i = {d}_i -{c}_i\in\mathbb{R}^3\)</span> for <span class="math inline">\(i =0,1,\cdots, n\)</span>.</p><p>If we can determine <spanclass="math inline">\(\{s_i\}_{i=0}^n\)</span>, then <spanclass="math inline">\(s(t)\)</span> and hence <spanclass="math inline">\(p_T(t)\)</span> can be determined. Therefore, wenext study under what conditions <spanclass="math inline">\(\{s_i\}_{i=0}^n\)</span> can be uniquelydetermined. Since <spanclass="math inline">\(p_T(t)-p_o(t)=g(t)r(t)\)</span> according to <ahref="#eq_bearing_measure" data-reference-type="eqref"data-reference="eq_bearing_measure">[eq_bearing_measure]</a> and <spanclass="math inline">\(r(t)=\ell/\theta(t)\)</span> according to <ahref="#eq_theta_measure" data-reference-type="eqref"data-reference="eq_theta_measure">[eq_theta_measure]</a>, we have <spanclass="math display">\[s(t)=p_T(t)-p_o(t)=g(t)r(t)=\frac{g(t)}{\theta(t)}\ell.\]</span>Substituting the above equation into <a href="#eq_relative_motion"data-reference-type="eqref"data-reference="eq_relative_motion">[eq_relative_motion]</a> yields<span class="math display">\[\begin{aligned}\label{eq_st_tem}{s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t)=\frac{g(t)}{\theta(t)}\ell.\end{aligned}\]</span> Here, <span class="math inline">\({s}_0, \cdots,{s}_n, \ell\)</span> are unknowns to be determined and <spanclass="math inline">\(g(t),\theta(t),{h}(t)\)</span> are known.EquationÂ <a href="#eq_st_tem" data-reference-type="eqref"data-reference="eq_st_tem">[eq_st_tem]</a> can be reorganized to alinear equation: <span class="math display">\[\begin{aligned}\label{eq_linear_equations}    {A}(t){X} = {h}(t),\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}{X}&amp;=\begin{bmatrix}{s}_0^\mathrm{T}, {s}_1^\mathrm{T}, \cdots, {s}_n^\mathrm{T}, \ell\end{bmatrix}^\mathrm{T}\in\mathbb{R}^{3n+4},\end{aligned}\]</span> and <span class="math display">\[\begin{aligned}\label{eq_original_A}{A}(t)&amp;=\begin{bmatrix}{I}_{3\times3}, t{I}_{3\times3}, \cdots, t^n{I}_{3\times3}, \rho(t)\end{bmatrix}\in\mathbb{R}^{3\times(3n+4)},\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_rho_denote}\rho(t)&amp;\doteq-\dfrac{g(t)}{\theta(t)}\in\mathbb{R}^3.\end{aligned}\]</span> Therefore, the problem that we aim to solvebecomes determining whether <span class="math inline">\(X\)</span> canbe uniquely solved from <a href="#eq_linear_equations"data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a>.</p><h2 id="necessary-and-sufficient-observability-condition">Necessary andsufficient observability condition</h2><p>We next present a necessary and sufficient condition under which thesolution <span class="math inline">\(X\)</span> of <ahref="#eq_linear_equations" data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a> isunique.</p><p><Theorem id="theorem_observability_confition "></Theorem><strong>Theorem 1.</strong> ((Necessary and sufficient observabilitycondition)). <em>The target's motion <spanclass="math inline">\(p_T(t)\)</span> can be uniquely determined by theobserver's motion <span class="math inline">\(p_o(t)\)</span>, thebearing <span class="math inline">\(g(t)\)</span>, and the angle <spanclass="math inline">\(\theta(t)\)</span> if and only if <spanclass="math display">\[\begin{aligned}{h}(t)\neq{0}_{3\times1},\end{aligned}\]</span> which means that the order of the observer'smotion must be greater than the target.</em></p><p>Since the row number of <span class="math inline">\({A}(t)\)</span>is less than its column number, <a href="#eq_linear_equations"data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a> is anunder-determined system whose solution cannot be uniquely determined.However, in the continuous time domain, we can use additional higherderivatives of this equation to uniquely determine <spanclass="math inline">\(X\)</span>.</p><p>In particular, taking the <spanclass="math inline">\(i\)</span>th-order derivative on both sides of <ahref="#eq_linear_equations" data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a> gives<span class="math inline">\(A^{(i)}(t)X=h^{(i)}(t)\)</span>. Considerany integer <span class="math inline">\(N\)</span> satisfying <spanclass="math inline">\(N\ge n+1\)</span>. Combining the equations with<span class="math inline">\(i\in\{0,1,\dots,N\}\)</span> gives <spanclass="math display">\[\begin{aligned}\label{eq_new_linear_equtions}    \bar(t){X} = \bar(t),\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_new_A}    \bar(t) =\left[  \begin{array}{c}    {A}(t) \\    {A}^{&#39;}(t) \\    \vdots \\    {A}^{(N)}(t)  \end{array}\right],\qquad\bar(t)\left[  \begin{array}{c}    {h}(t)\\    {h}^{&#39;}(t)\\    \vdots\\    {h}^{(N)}(t)\\  \end{array}\right].\end{aligned}\]</span> Here, <spanclass="math inline">\(\bar(t)\in\mathbb{R}^{(3N+3)\times(3n+4)}\)</span> and <spanclass="math inline">\(\bar(t)\in\mathbb{R}^{3N+3}\)</span>.Since <span class="math inline">\(N\ge n+1\)</span>, <spanclass="math inline">\(\bar{A}(t)\)</span> is a tall matrix and <ahref="#eq_new_linear_equtions" data-reference-type="eqref"data-reference="eq_new_linear_equtions">[eq_new_linear_equtions]</a> isan over-determined system.</p><p>We next examine when <span class="math inline">\(\bar{A}(t)\)</span>has full column rank. Substituting <a href="#eq_original_A"data-reference-type="eqref"data-reference="eq_original_A">[eq_original_A]</a> into <spanclass="math inline">\(\bar{A}(t)\)</span> yields <spanclass="math display">\[\begin{aligned}\bar(t)=    \left[\begin{array}{cccc:c}    {I}_{3\times3}&amp; t{I}_{3\times3}&amp; \cdots&amp;t^n{I}_{3\times3}&amp; \rho(t) \\    {0}_{3\times3}&amp; {I}_{3\times3}&amp; \cdots&amp;nt^{n-1}{I}_{3\times3}&amp; \rho^{&#39;}(t) \\    \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\    {0}_{3\times3}&amp; {0}_{3\times3}&amp; \cdots&amp;n!{I}_{3\times3}&amp; \rho^{(n)}(t) \\    \hdashline    {0}_{3\times3}&amp; {0}_{3\times3}&amp; \cdots&amp;{0}_{3\times3}&amp; \rho^{(n+1)}(t) \\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \\{0}_{3\times3}&amp; {0}_{3\times3}&amp; \cdots&amp; {0}_{3\times3}&amp;\rho^{(N)}(t) \\%\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \\    \end{array}\right].\end{aligned}\]</span> Since the top-left block of <spanclass="math inline">\(\bar{A}(t)\)</span> is a full-rank square matrix,<span class="math inline">\(\bar(t)\)</span> hasfull column rank if and only if there exists <spanclass="math inline">\(i\in\{n+1,\dots,N\}\)</span> such that <spanclass="math display">\[\begin{aligned}\label{eq_observability_criteria_2}    \rho^{(i)}(t)\neq {0}_{3\times1}.\end{aligned}\]</span> Since <spanclass="math inline">\(\rho(t)=-g(t)/\theta(t)\)</span> as shown in <ahref="#eq_rho_denote" data-reference-type="eqref"data-reference="eq_rho_denote">[eq_rho_denote]</a> and <spanclass="math inline">\(g(t)/\theta(t)=({s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t))/\ell\)</span>as shown in <a href="#eq_st_tem" data-reference-type="eqref"data-reference="eq_st_tem">[eq_st_tem]</a>, we can rewrite <ahref="#eq_observability_criteria_2" data-reference-type="eqref"data-reference="eq_observability_criteria_2">[eq_observability_criteria_2]</a>to <span class="math display">\[\begin{aligned}\label{eq_critia_2}-\dfrac{1}{\ell}({s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t))^{(i)}\neq{0}_{3\times1}.\end{aligned}\]</span> Since <span class="math inline">\(i\gen+1\)</span>, <a href="#eq_critia_2" data-reference-type="eqref"data-reference="eq_critia_2">[eq_critia_2]</a> is equivalent to <spanclass="math display">\[\begin{aligned}\label{eq_observability_criteria_final}{h}^{(i)} (t) \neq {0}_{3\times1}.\end{aligned}\]</span> According to the definition of <spanclass="math inline">\({h}(t)\)</span> in <a href="#eq_definition_h"data-reference-type="eqref"data-reference="eq_definition_h">[eq_definition_h]</a>, the condition in<a href="#eq_observability_criteria_final" data-reference-type="eqref"data-reference="eq_observability_criteria_final">[eq_observability_criteria_final]</a>is equivalent to <span class="math display">\[\begin{aligned}{h}(t)\neq {0}_{3\times1}.\end{aligned}\]</span> The proof is complete.</p><p>Some important remarks about TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> are givenbelow.</p><p>1) The necessary and sufficient condition suggested by TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> is that theobserver should have higher-order motion than the target. For example,when the target is stationary, the observer should move with a nonzerovelocity. When the target moves with a constant velocity, the observershould move with a nonzero acceleration.</p><p>2) The necessary and sufficient condition given by TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> has a <em>keydifference</em> from the bearing-only case that the higher-order motionin the bearing-angle case is <em>not</em> required to be orthogonal tothe bearing vector, making the bearing-angle approach more flexible thanthe bearing-only one. For example, the bearing-angle approach canestimate the target's motion even if the observer simply moves along thebearing vector.</p><p>3) In the special case where the target moves with a constantvelocity, the condition in TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> is consistentwith the one obtained in SectionÂ <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>.Although the condition in TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> allows moregeneral target motion, the analysis in SectionÂ <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>is still meaningful since it is directly related to the dynamic modelused in the pseudo-linear Kalman filter.</p><p>4) In practice, we would not estimate the target's motion by usingthe method of solving an equation like <a href="#eq_new_linear_equtions"data-reference-type="eqref"data-reference="eq_new_linear_equtions">[eq_new_linear_equtions]</a>.That is because such a method involves calculating high-orderderivatives, which are challenging to obtain accurately in practice. Therole of this equation is to provide a fundamental perspective on whetherthere is sufficient information to uniquely recover the target'smotion.</p><h2 id="number-of-observations-required">Number of observationsrequired</h2><div class="figure*"><p><span class="math display">\[\begin{aligned}\label{eq_A_22}\tilde{A}\rightarrow\left[\begin{array}{ccccc:c}{I} &amp; t_1{I} &amp; \cdots &amp; t_1^{n-1}{I} &amp; t_1^n{I} &amp;\rho(t_1) \\{0} &amp; {I} &amp; \cdots &amp; {\Delta(t_2^{n-1}, t_1^{n-1})}{I} &amp;{\Delta(t_2^n, t_1^n)}{}{I} &amp; {\Delta(\rho(t_2),\rho(t_1) )}{} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots\\{0} &amp; {0} &amp; \cdots &amp; (n-1)!{I} &amp; {\Delta^{n-1}(t_n^n,\cdots , t_1^n)}{} &amp; {\Delta^{n-1}(\rho(t_n),\cdots,\rho(t_1) )}{}\\{0} &amp; {0} &amp; \cdots &amp; {0} &amp; n!{I}&amp;  {\Delta^{n}(\rho(t_{n+1}),\cdots,\rho(t_1) )}{} \\\hdashline{0} &amp; {0} &amp; \cdots &amp; {0} &amp; {0} &amp;{\Delta^{n+1}(\rho(t_{n+2}),\cdots,\rho(t_1) )}{} \\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp;\vdots  \\{0} &amp; {0} &amp; \cdots &amp; {0} &amp; {0} &amp;{\Delta^{N-1}(\rho(t_N),\cdots,\rho(t_1) )}{} \\\end{array}\right]\end{aligned}\]</span></p></div><p>It is of practical importance to study how many discrete observationsare required to recover the target's motion. Although TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> gives anobservability condition, it does not answer this question because it isbased on the continuous time domain. We next answer this question byexploring multiple discrete time steps.</p><p><Theorem id="theorem_observation_number"></Theorem> <strong>Theorem2.</strong> ((Number of discrete observations)). <em>If the observer'smotion satisfies the observability condition in TheoremÂ <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a>, it is necessaryand sufficient to use at least <span class="math inline">\(n+2\)</span>observations to recover the target's motion. Here, <spanclass="math inline">\(n\)</span> is the order of the target's polynomialmotion as shown in <a href="#eq_target_nth_Order"data-reference-type="eqref"data-reference="eq_target_nth_Order">[eq_target_nth_Order]</a>.</em></p><p>Consider <span class="math inline">\(t_1,\dots,t_N\)</span> timeinstances. Each time instance corresponds to an equation like <ahref="#eq_linear_equations" data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a>: <spanclass="math inline">\({A}(t_i){X} = {h}(t_i)\)</span> for <spanclass="math inline">\(i=1,\dots,N\)</span>. Combining these equationsgives <span class="math display">\[\begin{aligned}\label{eq_convergence_linear_eqs}\tilde{X}=\tilde,\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_new_A_2}    \tilde =\left[  \begin{array}{c}    {A}(t_1) \\    \vdots \\    {A}(t_N)  \end{array}\right],\qquad\tilde\left[  \begin{array}{c}    {h}(t_1)\\    \vdots\\    {h}(t_N)\\  \end{array}\right].\end{aligned}\]</span> Here, <spanclass="math inline">\(\tilde\in\mathbb{R}^{(3N)\times (3n+4)}\)</span> and <spanclass="math inline">\(\tilde\in\mathbb{R}^{3N}\)</span>.</p><p>(<em>Necessity</em>) Since <spanclass="math inline">\(X\in\mathbb{R}^{3n+4}\)</span>, we need at least<span class="math inline">\(N\ge n+2\)</span> observations so that <spanclass="math inline">\(\tilde\)</span> is a tallmatrix and hence <a href="#eq_convergence_linear_eqs"data-reference-type="eqref"data-reference="eq_convergence_linear_eqs">[eq_convergence_linear_eqs]</a>is an over-determined system.</p><p>(<em>Sufficiency</em>) Suppose we have <spanclass="math inline">\(N\ge n+2\)</span> discrete observations.Substituting <a href="#eq_original_A" data-reference-type="eqref"data-reference="eq_original_A">[eq_original_A]</a> into <ahref="#eq_new_A_2" data-reference-type="eqref"data-reference="eq_new_A_2">[eq_new_A_2]</a> yields <spanclass="math display">\[\begin{aligned}\tilde{A} =\begin{bmatrix}{I}_{3\times 3} &amp; t_1{I}_{3\times 3} &amp; \cdots &amp;t_1^n{I}_{3\times 3} &amp; \rho(t_1) \\{I}_{3\times 3} &amp; t_2{I}_{3\times 3} &amp; \cdots &amp;t_2^n{I}_{3\times 3} &amp; \rho(t_2)  \\\vdots &amp; \vdots &amp;&amp; \vdots &amp; \vdots  \\{I}_{3\times 3} &amp; t_{n+1}{I}_{3\times 3} &amp; \cdots &amp;t_{n+1}^n{I}_{3\times 3} &amp; \rho(t_{n+1}) \\{I}_{3\times 3} &amp; t_{n+2}{I}_{3\times 3} &amp; \cdots &amp;t_{n+2}^n{I}_{3\times 3} &amp; \rho(t_{n+2})\\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\{I}_{3\times 3} &amp; t_{N}{I}_{3\times 3} &amp; \cdots &amp;t_{N}^n{I}_{3\times 3} &amp; \rho(t_{N})\\\end{bmatrix}.\end{aligned}\]</span> Starting from the last line in <spanclass="math inline">\(\tilde{A}\)</span>, subtract the previous linefrom each subsequent line, and repeat this process. Finally, we canobtain <a href="#eq_A_22" data-reference-type="eqref"data-reference="eq_A_22">[eq_A_22]</a> (the equation is too long andlocated at the top of another page). Here, <spanclass="math inline">\(\Delta^n\)</span> represents the <spanclass="math inline">\(n\)</span>th-order time difference <spanclass="citation"data-cites="MilneThomson2000">[@MilneThomson2000]</span>. For example,<span class="math inline">\(\Delta (a_2, a_1)=(a_2-a_1)/\deltat\)</span>, <span class="math inline">\(\Delta^2 (a_3, a_2, a_1) =\Delta (\Delta(a_3, a_2), \Delta(a_2, a_1))=[(a_3-a_2)/\deltat-(a_2-a_1)/\delta t]/\delta t\)</span>. When <spanclass="math inline">\(\delta t\)</span> is sufficiently small, the timedifference is an approximation of the derivative. When the observabilitycondition in TheoremÂ <a href="#theorem_observability_confition"data-reference-type="ref"data-reference="theorem_observability_confition">1</a> is satisfied,there exists <span class="math inline">\(i\ge n+1\)</span> such that<span class="math inline">\(\rho^{(i)}(t)\neq 0\)</span> as shown in <ahref="#eq_observability_criteria_2" data-reference-type="eqref"data-reference="eq_observability_criteria_2">[eq_observability_criteria_2]</a>.As a result, there exists <span class="math inline">\(i\ge n+1\)</span>such that <span class="math display">\[\begin{aligned}\Delta^{i}(\rho(t_{i+1}),\cdots,\rho(t_1))\neq {0}.\end{aligned}\]</span> The above implication is valid because <spanclass="math inline">\(\Delta^{i}\)</span> is an approximation of the<span class="math inline">\(i\)</span>th-order derivative when <spanclass="math inline">\(\delta t\)</span> is sufficiently small. Then,<span class="math inline">\(\tilde{A}\)</span> in <a href="#eq_A_22"data-reference-type="eqref" data-reference="eq_A_22">[eq_A_22]</a> hasfull column rank and hence <a href="#eq_convergence_linear_eqs"data-reference-type="eqref"data-reference="eq_convergence_linear_eqs">[eq_convergence_linear_eqs]</a>has a unique solution.</p><p>TheoremÂ <a href="#theorem_observation_number"data-reference-type="ref"data-reference="theorem_observation_number">2</a> suggests that when thetarget is stationary and hence <span class="math inline">\(n=0\)</span>,at least two discrete observations are sufficient to localize thetarget. This is true even if the two observations are acquired when theobserver moves along the bearing vector. When the target moves with aconstant velocity and hence <span class="math inline">\(n=1\)</span>, atleast three discrete observations are sufficient to localize the target,which is consistent with the results in SectionÂ <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>.</p><h1 id="numerical-simulation-results">Numerical Simulation Results</h1><figure id="sec_matlab_simulation">  <figure id="fig_matlab_1"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_1.png" />  <figcaption><b>(a)</b> Scenario 1: Circular motion around the target. Both the bearing-only and bearing-angle approaches work well, but the bearing-angle one converges faster.</figcaption>  <figure id="fig_matlab_2"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_2.png" />  <figcaption><b>(b)</b> Scenario 2: Straight motion towards and backwards the target. The bearing-only approach fails, but the bearing-angle approach works effectively.</figcaption>  <figure id="fig_matlab_3"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_3.png" />  <figcaption><b>(c)</b> Scenario 3: Approaching the target by a guidance law. The bearing-only approach works unstably, but the bearing-angle approach works effectively.</figcaption><figcaption><b>Figure 4.</b> Numerical simulation results based on 100 Monte Carlo runs in three scenarios.</figcaption></figure><figure id="fig_matlab_varying_ell">  <figure id="fig_cam_rotate"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_4.png" />  <figcaption><b>(a)</b> The observer moves around the square-shaped target. The target spins rapidly at $2\pi$~rad/s.</figcaption>  <figure id="fig_matlab_pi_8"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_pi_8.png" />  <figcaption><b>(c)</b>The observer moves along the bearing vector. The target's spinning speed is $\pi/8$~rad/s.</figcaption><figcaption><b>Figure 5.</b> Numerical simulation results for time-varying $\ell$.</figcaption></figure><p>This section presents a set of numerical simulation results todemonstrate the effectiveness of the proposed bearing-angleapproach.</p><p>The values of the parameters in two estimators are selected as <spanclass="math inline">\(\sigma_v=10^{-3}\)</span>, <spanclass="math inline">\(\sigma_l=10^{-4}\)</span>, <spanclass="math inline">\(\sigma_\mu=0.01\)</span>, and <spanclass="math inline">\(\sigma_w=0.01\)</span>. The selection of thesevalues is inspired by the measurement noises obtained in the AirSimsimulation and real-world experiments as shown later. The initialcovariance matrix of the estimated states is set to <spanclass="math inline">\(P(t_0)=0.1I\)</span>. The target is a circle whosediameter is <span class="math inline">\(\ell=1\)</span>. The update rateof the system is <span class="math inline">\(50\)</span>Â Hz. Inaddition, we use the same parameter values across all the simulationexamples to verify the robustness of the algorithm. Better performancescan be achieved if the parameters are well-tuned for specific scenarios.We perform <span class="math inline">\(N_x=100\)</span> Monte Carlosimulations for each scenario.</p><p>We use the normalized-estimation error squared (NEES) <spanclass="citation"data-cites="bar1998estimation">[@bar1998estimation]</span> to analyzethe consistency of the estimation algorithms. In particular, the valueof the average NEES is</p><p><span class="math display">\[\begin{aligned}    \bar{\epsilon}_{\text{NEES}}=\dfrac{1}{N_x}\sum_{i=1}^{N_x}(x-\hat{x}_i)^\mathrm{T}P_i^{-1}(x-\hat{x}_i),    \label{eq_nees}\end{aligned}\]</span> where <spanclass="math inline">\(\hat{x}_i\)</span> is the estimated states in the<span class="math inline">\(i\)</span>th simulation, and <spanclass="math inline">\(P_i\)</span> is the covariance matrix obtainedfrom the estimator in the <span class="math inline">\(i\)</span>thsimulation.</p><p>Finally, image acquisition and visual detection are not considered inthese numerical simulation scenarios. They will be considered inSectionÂ <a href="#AirSim%20Simulation%20Results"data-reference-type="ref"data-reference="AirSim Simulation Results">8</a> and SectionÂ <ahref="#Real-World%20Experimental%20Results" data-reference-type="ref"data-reference="Real-World Experimental Results">9</a>.</p><h2 id="scenario-1-circular-motion-around-the-target">Scenario 1:Circular motion around the target</h2><p>In the first scenario, the target is stationary and located at <spanclass="math inline">\(p_T=[0, 10]^\mathrm{T}\)</span>. The observermoves on a circle centered at the target with the speed of <spanclass="math inline">\(3\)</span>Â m/s (see Fig.Â <a href="#fig_matlab_1"data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a>). The radius of thecircle is <span class="math inline">\(5\)</span>Â m. The initialestimates are <span class="math inline">\(\hatp_o(t_0) = [0,13]^\mathrm{T}\)</span>, <span class="math inline">\(\hat{v_o}(t_0)=[0,0]^\mathrm{T}\)</span>, <spanclass="math inline">\(\hat{\ell}(t_0)=1.6\)</span>. During this process,the bearing vector varies while the angle subtended by the targetremains constant. The angle measurement varies slightly due to themeasurement noise. This scenario is favorable to the conventionalbearing-only approach because its observability condition that thetarget should be viewed from different angles is well satisfied <spanclass="citation" data-cites="Li2022">[@Li2022]</span>.</p><p>Fig.Â <a href="#fig_matlab_1" data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a> shows the estimationresults by the two approaches of bearing-only and bearing-angle. As canbe seen, both algorithms perform well. The convergence of thebearing-angle approach is faster than the bearing-only one, as shown inthe middle and right subfigures of Fig.Â <a href="#fig_matlab_1"data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a>, due to the additionalangle measurement. The bearing-angle approach can successfully estimatethe size of the target as shown in the right subfigure of Fig.Â <ahref="#fig_matlab_1" data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a>.</p><h2id="scenario-2-straight-motion-towards-and-backwards-the-target-repeatedly">Scenario2: Straight motion towards and backwards the target repeatedly</h2><p>In the second scenario, the target is also stationary but theobserver moves along a straight line towards and backwards the targetrepeatedly (Fig.Â <a href="#fig_matlab_2" data-reference-type="ref"data-reference="fig_matlab_2">[fig_matlab_2]</a>). During this process,the bearing vector remains constant while the angle varies. Thisscenario is most challenging for the bearing-only approach because itsobservability condition is not fulfilled.</p><p>In this simulation scenario, the target is stationary and located at<span class="math inline">\(p_T(t_0)=[0, 10]^\mathrm{T}\)</span>. Theobserver moves along a straight line towards and backwards the targetwith a constant acceleration of <spanclass="math inline">\(-2\)</span>Â <spanclass="math inline">\(\text{m/s}^2\)</span>. The initial conditions are<span class="math inline">\(v_o(t_0)=[0, 4]^\mathrm{T}\)</span> and<span class="math inline">\(p_o (t_0)= [0,5]^\mathrm{T}\)</span>. Theinitial estimates are <span class="math inline">\(\hatp_o(t_0) = [0,8]^\mathrm{T}\)</span>, <span class="math inline">\(\hat{v_o}(t_0)=[0,0]^\mathrm{T}\)</span>, <spanclass="math inline">\(\hat{\ell}(t_0)=0.8\)</span>. In this scenario,the true bearing of the target relative to the observer remainsunchanged though the bearing measurement may vary slightly due to themeasurement noise.</p><p>Fig.Â <a href="#fig_matlab_2" data-reference-type="ref"data-reference="fig_matlab_2">[fig_matlab_2]</a> shows the estimationresults of the bearing-only and bearing-angle approaches. As can beseen, the bearing-only approach diverges since its observabilitycondition is not satisfied. By contrast, the proposed bearing-angleapproach converges, and is able to localize the target and estimate itssize, which demonstrates the strong observability of the bearing-angleapproach. One may notice that the estimated size and the NEES value getworse first before converging. This is because the noise level of theangle is set to be constant. Since the angle is small in the beginning,the noise-angle ratio is large, causing a relatively large NEESvalue.</p><div class="figure*"></div><div class="figure*"><figure><img src="fig_box_airsim" alt="image" /><figcaption aria-hidden="true">image</figcaption></figure></div><h2 id="scenario-3-approaching-the-target-by-a-guidance-law">Scenario 3:Approaching the target by a guidance law</h2><p>The third scenario is more complex than the first two. Here, thetarget moves with a constant velocity where the observer is controlledby a proportional navigation guidance (PNG) law to approach the target(Fig.Â <a href="#fig_matlab_3" data-reference-type="ref"data-reference="fig_matlab_3">[fig_matlab_3]</a>). During this process,both the bearing and angle vary. This scenario is also challenging forthe bearing-only approach because its observability is weak due to thefact that the lateral motion of the observer is small. Many researchershave studied how to add extra control commands to the PNG to enhance theobservability based on the bearing-only approach <span class="citation"data-cites="Song1996 Seo2015 Lee2015">[@Song1996; @Seo2015;@Lee2015]</span>.</p><p>In this simulation scenario, the target moves along a straight linewith a constant velocity <span class="math inline">\(v_T=[1/\sqrt{2},1/\sqrt{2}]^\mathrm{T}\)</span>. The observer's velocity magnitude isconstantly <span class="math inline">\(3\)</span>Â m/s while the velocitydirection is controlled by a PNG law. The navigation gain of the PNG lawis selected as one. The initial estimates of the target's states are thesame as ScenarioÂ 1. The simulation stops just before the observercollides with the target.</p><p>Fig.Â <a href="#fig_matlab_3" data-reference-type="ref"data-reference="fig_matlab_3">[fig_matlab_3]</a> shows the estimationresults by the bearing-only and bearing-angle approaches. As can beseen, the bearing-angle algorithm successfully converges before thecollision occurs, but the bearing-only algorithm fails to estimate thetarget's states due to its weak observability. This simulation exampledemonstrates that the bearing-angle algorithm can be used directly inthe guidance scenario without extra maneuvers required by thebearing-only approach <span class="citation"data-cites="Song1996 Seo2015 Lee2015">[@Song1996; @Seo2015;@Lee2015]</span>.</p><h2 id="simulation-results-for-time-varying-ell">Simulation results fortime-varying <span class="math inline">\(\ell\)</span></h2><p>Although <span class="math inline">\(\ell\)</span> is assumed to beinvariant, it is meaningful to challenge the proposed bearing-angleapproach by considering time-varying <spanclass="math inline">\(\ell\)</span>. We will see through simulationexamples that the bearing-angle approach is still effective when <spanclass="math inline">\(\ell\)</span> varies slowly. It becomes unstablewhen <span class="math inline">\(\ell\)</span> varies rapidly since theassumption of invariant <span class="math inline">\(\ell\)</span> isseverely invalid.</p><p>Suppose that the target object has a square shape. Then, <spanclass="math inline">\(\ell\)</span> varies when the object is observedfrom different viewing angles or the object spins. Fig.Â <ahref="#fig_matlab_4" data-reference-type="ref"data-reference="fig_matlab_4">[fig_matlab_4]</a> shows a scenario wherethe observer moves around the target, whose spinning speed is <spanclass="math inline">\(2\pi\)</span>Â rad/s. The red curve in the rightsubfigure represents the true value of <spanclass="math inline">\(\ell\)</span>, which varies rapidly. As can beseen, the bearing-angle algorithm works effectively though there is asmall estimation bias. Fig.Â <a href="#fig_matlab_pi_8"data-reference-type="ref"data-reference="fig_matlab_pi_8">[fig_matlab_pi_8]</a> shows a scenariowhere the observer moves along the bearing vector. The spinning speed ofthe target object is <span class="math inline">\(\pi/8\)</span>Â rad/s.As can be seen, the bearing-only approach diverges due to the lack ofobservability. The bearing-angle algorithm can still converge since<span class="math inline">\(\ell\)</span> varies slowly. When we furtherincrease the spinning speed of the target, the bearing-angle algorithmwill also diverge because the algorithm cannot distinguish whether thechange of <span class="math inline">\(\theta\)</span> is caused by thechange of <span class="math inline">\(\ell\)</span> or the change of<span class="math inline">\(r\)</span>.</p><h1 id="airsim-simulation-results">AirSim Simulation Results</h1><p>In this section, we show simulation results under a more realisticsetup. In particular, the simulation is based on AirSim, a simulatorthat can provide high-quality visual simulation <span class="citation"data-cites="Shah2017">[@Shah2017]</span>. Nonlinear MAV dynamics andcontrol are also considered.</p><div class="figure*"></div><h2 id="simulation-setup">Simulation setup</h2><div class="figure*"></div><p>Fig.Â <a href="#fig_architecture_airsim" data-reference-type="ref"data-reference="fig_architecture_airsim">[fig_architecture_airsim]</a>shows an AirSim simulation scenario. As can be seen, there are twoflying quadcopter MAVs. The observer MAV can capture images of thetarget MAV using its simulated onboard camera. A simple gimbal cameracontroller is implemented so that the target MAV is always locatedinside the field of view of the camera. The visual environment used inthe simulation is called Landscape Mountains, which includes realisticmountains, lakes, trees, and roads. Other environments can also be usedif needed.</p><p>The bearing and angle measurements are obtained from the boundingboxes generated by a Yolo-based detection algorithm. A tiny-YOLO v4network <span class="citation"data-cites="Bochkovskiy2020">[@Bochkovskiy2020]</span> is trained todetect the target MAV in the images. Although the visual detector can bereplaced by other state-of-the-art ones, the tiny-YOLO v4 network isalready sufficient to verify our proposed approach. The architecture ofthe entire simulation system is shown in Fig.Â <a href="#fig_box_airsim"data-reference-type="ref"data-reference="fig_box_airsim">[fig_box_airsim]</a>. The systemconsists of the modules of automatic image dataset collection,Yolo-based target detection, gimbal camera control, nonlinear quadcopterdynamics, and quadcopter flight control. The quadcopter dynamics andflight control used in the simulation are similar to <spanclass="citation" data-cites="Meier2011 Shah2017">[@Meier2011;@Shah2017]</span> and omitted here due to space limitation. Thequadcopter's physical size varies slightly when viewed from differentdirections, although it is assumed to be invariant. All of these factorsmake the Airsim simulation more realistic and challenging.</p><h2 id="automatic-dataset-collection">Automatic dataset collection</h2><p>To train the Yolo-based detector, we developed a module toautomatically collect an image dataset. This module has some advantages.First, it is efficient. More than ten thousand labeled images can becollected automatically in 24 hours. Second, it is flexible. It canacquire images with random target's positions, random target'sattitudes, random camera's view angles, and random background scenes.These images are beneficial to achieve a good generalization ability ofthe detector. Third, the image labels are of high quality. Since theground truth of the target's image is known in the simulation, thegenerated bounding box is tight. The collected dataset contains 17,000labeled images (see Fig.Â <a href="#fig_airsim_dataset"data-reference-type="ref"data-reference="fig_airsim_dataset">[fig_airsim_dataset]</a>). Theresolution of the images is <span class="math inline">\(1536\times864\)</span> pixels. The simulation system was deployed on a DellPrecision 7920 Tower Workstation with two NVIDIA Quadro GV100 graphiccards. Since the dataset is sufficient and high-quality, the detectioncan achieve the accuracy of mAP=99.5%.</p><h2 id="scenario-1-approaching-and-following-the-target">Scenario 1:Approaching and following the target</h2><p>We first consider the scenarios where the observer MAV approaches orfollows a target MAV. These scenarios widely exist in practicalapplications such as aerial target pursuit.</p><p>We show two simulation examples in Fig.Â <a href="#fig_airsim_1"data-reference-type="ref"data-reference="fig_airsim_1">[fig_airsim_1]</a> and Fig.Â <ahref="#fig_airsim_2" data-reference-type="ref"data-reference="fig_airsim_2">[fig_airsim_2]</a>, respectively. In bothexamples, the observer is controlled by a controller so that it canapproach the target and maintain a desired separation. In particular,the controller is <span class="math display">\[\begin{aligned}\label{eq_tracking_control}v_o^\text{cmd}(t)&amp;=v_T(t)+k^\text{track}\dfrac{r^2(t)-r_d^2}{r^2(t)}g(t),\end{aligned}\]</span> where <spanclass="math inline">\(v_o^\text{cmd}(t)\)</span> is the velocity commandof the observer MAV, <spanclass="math inline">\(k^\text{track}=3\)</span> is the control gain, and<span class="math inline">\(r_d=3\)</span> is the desired separation.The magnitude of the observer's velocity is bounded from above by <spanclass="math inline">\(3\)</span>Â m/s. It should be noted that <ahref="#eq_tracking_control" data-reference-type="eqref"data-reference="eq_tracking_control">[eq_tracking_control]</a> relies onthe true position and velocity of the target MAV in the simulation.Therefore, the data is collected first and then processed offline sothat we can compare the performances of the bearing-only andbearing-angle approaches.</p><p>In the first example, the target MAV hovers constantly at <spanclass="math inline">\(p_T(t_0)=[0, 10, 10]^\mathrm{T}\)</span>. Theobserver MAV moves along a straight line toward the target with adecreasing velocity command. Since the bearing of the target MAV remainsthe same, this example is challenging for the bearing-only approach. Asshown in Fig.Â <a href="#fig_airsim_1" data-reference-type="ref"data-reference="fig_airsim_1">[fig_airsim_1]</a>, the bearing-onlyapproach fails to converge while the bearing-angle approach cansuccessfully estimate the target's motion.</p><p>In the second example, the target MAV moves with a constant velocityof <span class="math inline">\(v_T=[1/\sqrt{2}, 1/\sqrt{2},0]^\mathrm{T}\)</span>. The trajectory of the observer MAV under thecontrol of <a href="#eq_tracking_control" data-reference-type="eqref"data-reference="eq_tracking_control">[eq_tracking_control]</a> is stillclose to (though not strictly) a straight line. As a result, theobservability is weak by the bearing-only approach. As shown in Fig.Â <ahref="#fig_airsim_2" data-reference-type="ref"data-reference="fig_airsim_2">[fig_airsim_2]</a>, the bearing-angleapproach successfully converges while the bearing-only one fails. It isnotable that <span class="math inline">\(\ell\)</span> is invariant inthe first example and varies slowly in the second example.</p><p>It is worth mentioning that the detection results used in theestimation algorithms are obtained from the Yolo-based estimator. Theground truth obtained from AirSim is only used to calculate the errorsof measurements, as shown in the right figures of Figs.Â <ahref="#fig_airsim_1" data-reference-type="ref"data-reference="fig_airsim_1">[fig_airsim_1]</a> and <ahref="#fig_airsim_2" data-reference-type="ref"data-reference="fig_airsim_2">[fig_airsim_2]</a>. It is not surprisingthat the measurement noises are not strictly Gaussian since the 2Dbounding box is generated by a deep learning vision algorithm. It isnoticed that the noises are inversely correlated to the observer-targetrange. This is reasonable because, when the target is close to thecamera and hence its image is large, the center point and the size ofthe bounding box usually vary for a few pixels.</p><p>The NEES values are also shown in Fig.Â <a href="#fig_airsim"data-reference-type="ref" data-reference="fig_airsim">[fig_airsim]</a>.As can be seen, the NEES value of the bearing-only approach diverges.The NEES value of the bearing-angle approach oscillates and convergesslowly. The reasons are analyzed as follows. Compared to theMatlab-based numerical simulation, the visual measurements here aregenerated by deep learning algorithms, and the measurement noises arenon-Gaussian. The non-Gaussian noises propagate into <spanclass="math inline">\(P\)</span> in <a href="#eq_nees"data-reference-type="eqref" data-reference="eq_nees">[eq_nees]</a> sincethe calculation of <span class="math inline">\(P\)</span> relies onnoisy measurements. The noises may also cause an estimation bias thatcan further aggravate the NEES error. Moreover, although the system isobservable in the two simulation examples, the observability isrelatively weak compared to the case where the observer movessurrounding the target. As a result, the matrix <spanclass="math inline">\(P\)</span> may not be able to perfectly describethe estimation accuracy. These elements may jointly cause theconvergence behavior of the NEES values shown in Fig.Â <ahref="#fig_airsim" data-reference-type="ref"data-reference="fig_airsim">[fig_airsim]</a>.</p><h2 id="scenario-2-circular-motion-and-varying-ell">Scenario 2: Circularmotion and varying <span class="math inline">\(\ell\)</span></h2><p>We next examine a case where <spanclass="math inline">\(\ell\)</span> is time-varying. In particular,suppose a target quadcopter MAV hovers constantly at <spanclass="math inline">\(p_T(t_0)=[0, 10, 10]^\mathrm{T}\)</span>. Theobserver MAV moves on a circle centered at the target (Fig.Â <ahref="#fig_airsim_6_1" data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a>). Since the targetquadcopter MAV has a square shape from the top view, its size <spanclass="math inline">\(\ell\)</span> is time-varying when viewed fromside angles (see the red curves in the middle subfigure of Fig.Â <ahref="#fig_airsim_6_1" data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a>).</p><p>We show two simulation examples in Fig.Â <a href="#fig_airsim_6_1"data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a> and Fig.Â <ahref="#fig_airsim_6_2" data-reference-type="ref"data-reference="fig_airsim_6_2">[fig_airsim_6_2]</a>, respectively. Thetwo simulation examples share the same measurement data but differentvalues of <span class="math inline">\(\sigma_\ell\)</span>. Moreover,the other parameters are the same as those in SectionÂ <ahref="#Scenario%201:%20Approaching%20and%20following%20the%20target"data-reference-type="ref"data-reference="Scenario 1: Approaching and following the target">8.3</a>.</p><div class="figure*"></div><p>In the first simulation example, <spanclass="math inline">\(\sigma_\ell\)</span> is set to be a small value:<span class="math inline">\(\sigma_\ell=10^{-4}\)</span>. Itsinterpretation is that <span class="math inline">\(\ell\)</span> istreated as invariant during the process. In this case, the performanceof the bearing-angle approach is almost the same as the bearing-only oneas shown in Fig.Â <a href="#fig_airsim_6_1" data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a>. Since <spanclass="math inline">\(\ell\)</span> is treated to be invariant, theestimated value <span class="math inline">\(\hat{\ell}\)</span>converges to a constant which is the mean value of the time-varying<span class="math inline">\(\ell\)</span>.</p><p>In the second simulation example, the value of <spanclass="math inline">\(\sigma_\ell\)</span> is larger than the firstexample: <span class="math inline">\(\sigma_\ell = 0.01\)</span>. Itsinterpretation is that <span class="math inline">\(\ell\)</span> isbelieved to be time-varying during the process. In this case, theperformance of the bearing-angle approach is still almost the same asthe bearing-only one. Moreover, since <spanclass="math inline">\(\sigma_\ell\)</span> is large, the bearing-angleapproach can successfully estimate the true time-varying value of <spanclass="math inline">\(\ell\)</span>.</p><p>In summary, in the case where <spanclass="math inline">\(\ell\)</span> varies slowly, the bearing-angleapproach would degenerate to the bearing-only one. The fundamentalreason is that the extra information embedded in the angle measurementis used to estimate the time-varying <spanclass="math inline">\(\ell\)</span> rather than improving theobservability of the target's motion.</p><div class="figure*"></div><h1 id="real-world-experimental-results">Real-World ExperimentalResults</h1><p>In this section, two sets of real-world experiments are presented tofurther verify the effectiveness of the approach. The first is based ona hand-held camera and a ground robot. The second is based on twoquadcopter MAVs. The second experimental scenario is motivated by aerialtarget pursuit tasks.</p><h2 id="experiment-1-hand-held-camera">Experiment 1: Hand-heldcamera</h2><p>The experimental setup is shown in Fig.Â <ahref="#fig_architecture_indoor" data-reference-type="ref"data-reference="fig_architecture_indoor">[fig_architecture_indoor]</a>.The observer is a hand-held camera (Hik Vision DS-E14S) connected to alaptop. The camera's intrinsic parameters are calibrated beforehand. Therobot built on Mecanum wheels can move in any direction on the groundunder velocity control. The ground truth of the states of the camera andthe robot are provided by a Vicon indoor motion capture system. The keyexperimental specifications are listed in TableÂ <ahref="#table_indoor_hardware" data-reference-type="ref"data-reference="table_indoor_hardware">[table_indoor_hardware]</a>.</p><p>A dataset of 5,514 images was collected and used to train a tiny-YOLOv4 network to detect the target robot (see Fig.Â <ahref="#fig_car_dataset" data-reference-type="ref"data-reference="fig_car_dataset">[fig_car_dataset]</a>). The detectionprecision of the trained network is mAP=99.8%. In the experiment, thetarget robot is commanded to move with a constant velocity. In themeantime, a person holding the camera moves along some trajectories. Twodifferent cases are studied. In both of the cases, the target robotmoves with a constant velocity <span class="math inline">\(v_T=[-0.1,0.1 ,0]^\mathrm{T}\)</span>. The noises of the measurements arecalculated based on the ground truth provided by the Vicon system. Thenoises are shown in the right subfigures of Fig.Â <a href="#fig_indoor_9"data-reference-type="ref"data-reference="fig_indoor_9">[fig_indoor_9]</a> and Fig.Â <ahref="#fig_indoor_6" data-reference-type="ref"data-reference="fig_indoor_6">[fig_indoor_6]</a>.</p><p>In the first case, the camera is held about 1.5 meters above theground and moves around the target robot. In this case, the bearingvector varies sufficiently and hence the observability conditions forthe bearing-only and bearing-angle approaches are both well satisfied.As shown in Fig.Â <a href="#fig_indoor_9" data-reference-type="ref"data-reference="fig_indoor_9">[fig_indoor_9]</a>, both approachesperform well in this case while the bearing-angle approach performsslightly better than the bearing-only one.</p><p>In the second case, the camera moves along the trajectory of therobot by getting close or far from it periodically. In this case, theangle varies significantly, but the bearing does not. Without surprise,the bearing-only approach performs poorly in this case due to weakobservability (Fig.Â <a href="#fig_indoor_6" data-reference-type="ref"data-reference="fig_indoor_6">[fig_indoor_6]</a>). By contrast, thebearing-angle approach can perform stably due to its enhancedobservability.</p><div class="center"><div class="tabular"><p>l|lll &amp; Parameter &amp; Value &amp; Unit<br />*Camera &amp; Resolution &amp; 640<spanclass="math inline">\(\times\)</span> 480 &amp; pixel<br />Â  &amp; Max frequency &amp; 30 &amp;fps<br />*Robot &amp; Max speed &amp; 1&amp; m/s<br />Â  &amp; Diameter size &amp; 295 &amp; mm<br />*Vicon &amp; Localization accuracy &amp; 1 &amp; mm<br />Â  &amp; Max frequency &amp; 100 &amp; Hz<br /></p></div></div><h2 id="experiment-2-mav-following-mav">Experiment 2:MAV-following-MAV</h2><div class="center"><div class="tabular"><p>c|lll &amp; Parameter &amp; Value &amp; Unit<br />&amp; Diagonal size &amp; 895 &amp; mm<br />Â &amp;Total mass &amp; 7.4 &amp; kg<br />Â &amp;Max pitch/roll &amp; 30 &amp; degree<br />Â &amp;Max flight time &amp; 30 &amp; minutes<br />&amp; Accuracy &amp; 1 &amp; cm<br />Â &amp; Max frequency &amp; 10 &amp; Hz<br />&amp; Resolution &amp;1920<spanclass="math inline">\(\times\)</span><!-- -->1080 &amp; pixel<br />Â &amp; Frequency &amp; 15 &amp; Hz<br />Â  &amp; Max angular rate &amp; 180 &amp; deg/s<br /></p></div></div><div class="figure*"></div><div class="figure*"><figure><img src="fig_outdoor_1" alt="image" /><figcaption aria-hidden="true">image</figcaption></figure></div><p>Two MAV platforms were developed based on DJI M300 quadcopters(Fig.Â <a href="#fig_M300" data-reference-type="ref"data-reference="fig_M300">[fig_M300]</a>). The MAV platforms areequipped with RTK GPS modules for accurate self-localization, an H20camera for visual detection, a Manifold 2G onboard computer for onboardflight control, and a Zigbee module for wireless communication. Some keyspecifications of the MAV platforms are listed in TableÂ <ahref="#table_M300" data-reference-type="ref"data-reference="table_M300">[table_M300]</a>. The structure of thehardware perception and communication system is illustrated in Fig.Â <ahref="#fig_outdoor_hardware" data-reference-type="ref"data-reference="fig_outdoor_hardware">[fig_outdoor_hardware]</a>. Thetarget MAV is also equipped with an RTK GPS module, whose measurementsare used as the ground truth to calculate the noises of the visualmeasurements. The noises are shown in the right subfigure of Fig.Â <ahref="#fig_outdoor_1" data-reference-type="ref"data-reference="fig_outdoor_1">[fig_outdoor_1]</a>.</p><p>The experiment consists of two stages: data acquisition and offlinedata processing. In the data acquisition stage, the target MAV iscommanded to fly with a constant velocity, and the observer MAV isautomatically controlled to follow the target MAV to maintain a constantdistance from the target. More specifically, the procedure of the flightexperiment is as follows. Initially, the observer MAV is placed about 20meters behind the target MAV on the ground. Then, the two MAVs take offand fly to the same specified height automatically upon a takeoffcommand sent from the ground control station. After they have reachedthe desired height, all deployed algorithms are activated. Then, thetarget MAV moves with a constant velocity of <spanclass="math inline">\(v_T=[1/\sqrt{2}, 1/\sqrt{2},0]^\mathrm{T}\)</span>. The observer MAV approaches the target by thecontroller in <a href="#eq_tracking_control" data-reference-type="eqref"data-reference="eq_tracking_control">[eq_tracking_control]</a>. It takesthe observer MAV about eight seconds to reach the desired relativedistance. Then, the two MAVs fly with the same velocity and remainrelatively stationary for another 20 seconds. Finally, the groundstation sends a stop command and the two MAVs return and landautomatically.</p><p>During the flight, the gimbal camera of the observer MAV isautomatically controlled so that the target MAV is maintained in thefield of view. It is noted that the control of the gimbal camera and theobserver MAV is not based on the visual detection results. Instead, thecontrol is based on the measurements provided by the RKT GPS andinter-MAV wireless communication. In this way, we can analyze the imageand flight data offline and compare the performance of the twoapproaches of bearing-angle and bearing-only. The acquired images andflight data are saved on the onboard computer during the flight. Adataset of 5,341 images was collected (Fig.Â <a href="#fig_M300_dataset"data-reference-type="ref"data-reference="fig_M300_dataset">[fig_M300_dataset]</a>) and used totrain a tiny-YOLO v4 network. The detection precision of the trainednetwork reaches mAP=99.8%.</p><p>The experimental results are shown in Fig.Â <a href="#fig_outdoor_1"data-reference-type="ref"data-reference="fig_outdoor_1">[fig_outdoor_1]</a>. As can be seen, thebearing-angle approach performs well. By contrast, the bearing-onlyapproach only works well before the observer MAV reached the desiredposition relative to the target MAV. That is because the bearing variessignificantly during this process due to the fluctuation of theobserver's motion caused by the flight control. However, thebearing-only approach diverges quickly thereafter when the bearing stopsvarying significantly.</p><h1 id="conclusion">Conclusion</h1><p>Motivated by the limitation of the existing bearing-only approach,this paper proposed and analyzed a novel bearing-angle approach forvision-based target motion estimation. We showed that the observabilityby the bearing-angle approach is significantly enhanced compared to thebearing-only one. As a result, the requirement of the observer's extramotion for observability enhancement can be significantly relaxed. As weshowed in various experiments, the bearing-angle approach cansuccessfully estimate the target's motion in many scenarios where thebearing-only approach fails. The enhanced observability of thebearing-angle approach comes with no additional cost since almost allvision detection algorithms can generate bounding boxes. One assumptionadopted in the bearing-angle approach is that the target's physical sizeis invariant to different viewing angles. Although this assumption isapproximately valid in many tasks as demonstrated in this paper, it ismeaningful to study how to relax or remove this assumption in thefuture.</p><h1 id="declaration-of-conflicting-interests">Declaration of conflictinginterests</h1><p>The author(s) declared no potential conflicts of interest withrespect to the research, authorship, and/or publication of thisarticle.</p><h1 id="funding">Funding</h1><p>The author(s) disclosed receipt of the following financial supportfor the research, authorship, and/or publication of this artical: Thiswork was supported by the Hangzhou Key Technology Research andDevelopment Program (Grant 20212013B09), and the Research Center forIndustries of the Future at Westlake University (Grant WU2022C027).</p>]]></content>
    
    
    <summary type="html">ğŸ§µæœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨ç§»åŠ¨å•ç›®ç›¸æœºä¼°è®¡ç§»åŠ¨ç›®æ ‡ç‰©ä½“è¿åŠ¨çš„é—®é¢˜</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="è§†è§‰å¯¼èˆª" scheme="https://www.adunas.top/tags/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†</title>
    <link href="https://www.adunas.top/posts/20240222b.html"/>
    <id>https://www.adunas.top/posts/20240222b.html</id>
    <published>2024-02-22T11:12:03.000Z</published>
    <updated>2024-02-22T13:46:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡å­¦å¯¼èˆª"><ahref="./20240224d.html#å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†">æ–‡å­¦å¯¼èˆª</a></h1><blockquote><p>è­¦å¯Ÿå±€æ¡£æ¡ˆç¼–å·ï¼š2024-01-11-001</p><p>æ¡£æ¡ˆåç§°ï¼šå…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†</p><p>æ¡£æ¡ˆä½œè€…ï¼šè‹±ä»™åº§ï¼Œè­¦å¯Ÿå±€å‰¯å±€é•¿</p></blockquote><p>â€ƒâ€ƒæˆ‘ä¸çˆ±è‰è¥¿äºšå±€é•¿çš„ç›¸è¯†ï¼Œè¦è¿½æº¯åˆ°ä¸‰å¹´å‰çš„ä¸€èµ·å¥‡æ€ªçš„æ¡ˆä»¶ã€‚å½“æ—¶ï¼Œæˆ‘è¿˜æ˜¯ä¸€ä¸ªé“¶è¡ŒåŠ«åŒªï¼Œå’Œæˆ‘çš„åŒä¼™ä¸€èµ·ç­–åˆ’äº†ä¸€æ¬¡å¤§è§„æ¨¡çš„æŠ¢åŠ«ã€‚æˆ‘ä»¬æ‰“ç®—åœ¨æ°æ‹‰å¾·Â·å¼—é›·æ³½çš„é“¶è¡Œé‡Œè£…ä¸Šç‚¸å¼¹ï¼Œç„¶åè¶ç€æ··ä¹±ï¼ŒæŠ¢èµ°æ‰€æœ‰çš„é’±ã€‚æˆ‘ä»¬ä»¥ä¸ºæˆ‘ä»¬çš„è®¡åˆ’ååˆ†å®Œç¾ï¼Œæ²¡æƒ³åˆ°ï¼Œé‡åˆ°äº†çˆ±è‰è¥¿äºšï¼Œä¹Ÿå› æ­¤è®¤è¯†äº†é“¶è¡Œå®¶ã€‚</p><p>â€ƒâ€ƒå¥¹å½“æ—¶è¿˜ä¸æ˜¯å±€é•¿ï¼Œåªæ˜¯ä¸€ä¸ªåˆšåˆšè°ƒæ¥çš„åˆ‘è­¦ï¼Œè´Ÿè´£è°ƒæŸ¥ä¸€èµ·æ¶‰åŠé»‘ç¤¾ä¼šçš„æªå‡»æ¡ˆã€‚å¥¹æ°å·§åœ¨é‚£å®¶é“¶è¡Œé‡Œï¼Œå‘ç°äº†æˆ‘ä»¬çš„ç‚¸å¼¹ï¼Œå°±ç«‹åˆ»é€šçŸ¥äº†è­¦æ–¹ï¼Œç„¶åå†²è¿›äº†æˆ‘ä»¬çš„è—èº«å¤„ï¼Œä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æŠŠæˆ‘ä»¬åˆ¶æœäº†ã€‚å¥¹çš„åŠ¨ä½œååˆ†è¿…é€Ÿï¼Œå‡ ä¹æ²¡æœ‰ç»™æˆ‘ä»¬ååº”çš„æœºä¼šã€‚æˆ‘æ˜¯æœ€åä¸€ä¸ªè¢«å¥¹æŠ“ä½çš„ï¼Œå¥¹ç”¨æªæŒ‡ç€æˆ‘çš„å¤´ï¼Œè¯´ï¼šâ€œä½ ä»¬è¿™äº›æ— è€»çš„å®¶ä¼™ï¼Œç«Ÿæ•¢å¨èƒæ— è¾œçš„äººæ°‘ï¼Œåº”è¯¥å—åˆ°æƒ©ç½šã€‚â€å¥¹çš„çœ¼ç¥ååˆ†å†·é…·ï¼Œè®©æˆ‘æ„Ÿåˆ°ä¸€é˜µå¯’æ„ã€‚</p><p>â€ƒâ€ƒä½†æ˜¯ï¼Œå°±åœ¨å¥¹å‡†å¤‡æ‰£åŠ¨æ‰³æœºçš„æ—¶å€™ï¼Œå¥¹çªç„¶åœä½äº†ï¼Œå¥¹çš„çœ¼ç¥å˜å¾—æŸ”å’Œï¼Œå¥¹è¯´ï¼šâ€œä¸è¿‡ï¼Œä½ è¿˜æœ‰æ•‘èµçš„æœºä¼šï¼Œä½ å¯ä»¥é€‰æ‹©è·Ÿæˆ‘èµ°ï¼Œæˆ–è€…ç•™åœ¨è¿™é‡Œç­‰æ­»ã€‚â€æˆ‘ä¸çŸ¥é“å¥¹ä¸ºä»€ä¹ˆä¼šçªç„¶æ”¹å˜ä¸»æ„ï¼Œä¹Ÿä¸çŸ¥é“å¥¹è¦å¸¦æˆ‘å»å“ªé‡Œï¼Œä½†æ˜¯æˆ‘è§‰å¾—æˆ‘æ²¡æœ‰åˆ«çš„é€‰æ‹©ï¼Œå°±è·Ÿç€å¥¹èµ°äº†ã€‚</p><p>â€ƒâ€ƒä»é‚£ä»¥åï¼Œæˆ‘å°±æˆäº†çˆ±è‰è¥¿äºšå±€é•¿çš„å¾—åŠ›åŠ©æ‰‹ï¼Œä¹Ÿæ˜¯å¥¹å”¯ä¸€çš„æœ‹å‹ã€‚å¥¹å¯¹æˆ‘å¾ˆå¥½ï¼Œæ€»æ˜¯ç»™æˆ‘è®²ä¸€äº›æœ‰è¶£çš„æ•…äº‹ï¼Œè¿˜æ•™æˆ‘ä¸€äº›å¥‡æ€ªçš„çŸ¥è¯†ã€‚å¥¹è¯´å¥¹æ˜¯ä»ä¸€ä¸ªå«åšâ€œé€ç«ä¹‹è›¾â€ çš„ç»„ç»‡æ¥çš„ï¼Œé‚£é‡Œæœ‰å¾ˆå¤šå¥‡å¦™çš„äº‹ç‰©ï¼Œè¿˜æœ‰ä¸€äº›å¥¹çš„æˆ˜å‹ã€‚</p><p>â€ƒâ€ƒæˆ‘ä¸çŸ¥é“å¥¹è¯´çš„è¿™äº›æ˜¯çœŸæ˜¯å‡ï¼Œä½†æˆ‘è§‰å¾—å¥¹å¾ˆå¯ä¿¡ï¼Œä¹Ÿå¾ˆæœ‰é­…åŠ›ã€‚å¥¹åœ¨å·¥ä½œä¸Šå¾ˆæœ‰èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¿…é€Ÿè§£å†³å„ç§æ£˜æ‰‹çš„æ¡ˆä»¶ï¼Œè¿˜èƒ½å’Œå„æ–¹æ‰“å¥½å…³ç³»ã€‚å¥¹åœ¨ç”Ÿæ´»ä¸Šå¾ˆæœ‰è¶£ï¼Œç»å¸¸æ‹‰ç€æˆ‘å»é€›è¡—ï¼Œè®©æˆ‘å¸®å¥¹æŒ‘é€‰è¡£æœå’ŒåŒ–å¦†å“ï¼Œæœ‰æ—¶å€™æˆ‘å¿ƒä¸åœ¨ç„‰ï¼Œå¥¹åˆä¼šæ‹‰ç€æˆ‘çš„æ‰‹å¯¹æˆ‘è¯´ï¼šâ€œä½ å¿«å¯¹æˆ‘è¯´ï¼Œè‰¾è‰è¥¿äºšç©¿ä»€ä¹ˆéƒ½å¥½çœ‹ï¼Œå¥½ä¸å¥½å˜›ï¼Ÿâ€æœ‰æ—¶å€™å¥¹ä¹Ÿä¼šæ‹‰ç€æˆ‘å»çœ‹ææ€–ç”µå½±ï¼Œæ¼”åˆ°å“äººçš„åœºæ™¯æ—¶å¥¹ä¹Ÿä¼šå®³æ€•çš„ç¼©æˆä¸€å›¢ï¼Œå’Œä¹‹å‰å‹‡æ•¢æ— ç•çš„å±€é•¿åˆ¤è‹¥ä¸¤äººã€‚è™½ç„¶æˆ‘ä¹Ÿå¾ˆå®³æ€•ï¼Œä½†è¿˜æ˜¯ä¼šæ‘¸æ‘¸å¥¹çš„å¤´ï¼Œå¯¹å¥¹è¯´ï¼šâ€œæˆ‘ä¼šæ°¸è¿œä¿æŠ¤ä½ çš„ã€‚â€è€Œå¥¹ä¼šè¶æœºé åœ¨æˆ‘çš„è‚©è†€ä¸Šè¯´ï¼šâ€œä½ å¯çœŸæ˜¯æˆ‘çš„å°è‹±é›„ï¼â€</p><p><img src="https://picture.adunas.top/Article/ElysiaA.png" /></p><p>â€ƒâ€ƒæœ‰ä¸€æ¬¡æˆ‘ä»¬è§£å†³äº†å“ˆå±±çš„æ¡ˆå­ï¼Œä¸­é—´å’Œå¥¹åˆ†å¼€äº†ä¸€æ®µæ—¶é—´ï¼Œç»“æœå¬åˆ°å¥¹çš„ä¸€å£°æƒ¨å«ï¼Œä½†æ˜¯å½“æˆ‘è¿‡æ¥ä¹‹åå¥¹åªæ˜¯ä¸€è„¸ç¬‘æ„çš„çœ‹ç€æˆ‘ï¼Œæ‰‹ä¸Šæ‹¿ç€ä¸€ä¸ªå¥‡æ€ªçš„æ€€è¡¨ã€‚ä¹‹åçš„æ—¥å­é‡Œå¥¹æœ‰æ—¶å€™ä¼šçªç„¶æ¶ˆå¤±ä¸€æ®µæ—¶é—´ï¼Œç„¶ååˆçªç„¶å‡ºç°åœ¨æˆ‘çš„é¢å‰ï¼Œå¥¹ä»ä¸å‘Šè¯‰æˆ‘å¥¹å»äº†å“ªé‡Œï¼Œåšäº†ä»€ä¹ˆï¼Œåªæ˜¯ç¬‘ç€è¯´ï¼šâ€œä½ ä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘åªæ˜¯æœ‰äº›ç§äº‹è¦åŠã€‚â€æˆ‘æ€»æ˜¯è§‰å¾—å¥¹åœ¨éšç’ä»€ä¹ˆï¼Œä½†æˆ‘ä¸æ•¢å¤šé—®ï¼Œåªæ˜¯é»˜é»˜åœ°ç­‰å¾…å¥¹çš„å½’æ¥ï¼Œåªè§‰å¾—å¥¹æœ‰ä¸€ç§ç¥å¥‡çš„åŠ›é‡ã€‚</p><p>â€ƒâ€ƒå¥¹ç»å¸¸è®©æˆ‘é™ªå¥¹å»ä¸€äº›å±é™©çš„åœ°æ–¹ï¼Œè¯´æ˜¯ä¸ºäº†è°ƒæŸ¥ä¸€äº›æ¡ˆä»¶ï¼Œå…¶å®æ˜¯ä¸ºäº†å¯»æ‰¾å¥¹çš„ç§˜å¯†ã€‚å¥¹æ€»æ˜¯è®©æˆ‘é‡åˆ°å„ç§éº»çƒ¦ï¼Œæ¯”å¦‚è¢«é»‘ç¤¾ä¼šè¿½æ€ï¼Œè¢«é‚ªæ¶çš„åŠ›é‡æ„ŸæŸ“ï¼Œç­‰ç­‰ã€‚å¥¹æ¯æ¬¡éƒ½ä¼šåœ¨æœ€åä¸€åˆ»å‡ºç°ï¼Œæ•‘æˆ‘ä¸€å‘½ï¼Œç„¶åå¯¹æˆ‘è¯´ï¼šâ€œä½ çœŸæ˜¯ä¸ªç¬¨è›‹ï¼Œæ€ä¹ˆæ€»æ˜¯è®©è‡ªå·±é™·å…¥å±é™©ï¼Œä½ ä¸çŸ¥é“æˆ‘æœ‰å¤šæ‹…å¿ƒä½ å—ï¼Ÿâ€å¥¹çš„è¯­æ°”æ€»æ˜¯å¸¦ç€ä¸€ç§å˜²è®½ï¼Œè®©æˆ‘è§‰å¾—å¥¹æ˜¯åœ¨æ•…æ„æ‰å¼„æˆ‘ï¼Œä½†æ˜¯å¥¹çš„çœ¼ç¥å´åˆå……æ»¡äº†å…³åˆ‡ï¼Œè®©æˆ‘è§‰å¾—å¥¹æ˜¯åœ¨çœŸå¿ƒä¿æŠ¤æˆ‘ã€‚æˆ‘ä¸çŸ¥é“å¥¹åˆ°åº•æ˜¯æ€ä¹ˆæƒ³çš„ï¼Œä½†æ˜¯æˆ‘æ€»æ˜¯æ„Ÿæ¿€å¥¹ï¼Œä¹Ÿæ€»æ˜¯åŸè°…å¥¹ã€‚</p><p>â€ƒâ€ƒç›´åˆ°é‚£ä¸€å¤©ï¼Œä¸€åˆ‡éƒ½æ”¹å˜äº†ã€‚é‚£æ˜¯ä¸€å¤©æ™šä¸Šï¼Œæˆ‘ä»¬åœ¨ç°åœºå‘ç°äº†ä¸€ä¸ªå°å¥³å­©ï¼Œçˆ±è‰è¥¿äºšçœ‹åˆ°å¥¹ï¼Œå°±æƒŠå‘¼äº†ä¸€å£°ï¼Œè¯´ï¼šâ€œæ˜¯ä½ ï¼â€ç„¶åï¼Œå¥¹å°±å†²ä¸Šå»ï¼ŒæŠ±ä½äº†é‚£ä¸ªå¥³å­©ã€‚æ¥ä¸‹æ¥çš„äº‹æƒ…ï¼Œæˆ‘å°±è®°ä¸å¤ªæ¸…æ¥šäº†ã€‚æˆ‘åªè®°å¾—çˆ±è‰è¥¿äºšå±€é•¿å’Œé‚£ä¸ªå¥³å­©è¯´äº†ä¸€äº›è¯ï¼Œç„¶åå¥¹å°±å¯¹æˆ‘è¯´ï¼šâ€œå¯¹ä¸èµ·ï¼Œæˆ‘è¦èµ°äº†ï¼Œæˆ‘æœ‰å¾ˆé‡è¦çš„äº‹æƒ…è¦åšï¼Œå’Œå¥¹æœ‰å…³ã€‚â€æˆ‘é—®å¥¹è¦å»å“ªé‡Œï¼Œå¥¹è¯´ï¼šâ€œå»ä¸€ä¸ªä½ æ— æ³•è·Ÿéšçš„åœ°æ–¹ï¼Œå»å®Œæˆæˆ‘çš„ä½¿å‘½ã€‚â€è€Œæˆ‘æ— æ³•æŠ›ä¸‹å¥¹ä¸ç®¡ï¼Œè¿˜æ˜¯å·å·è·Ÿäº†è¿‡å»ã€‚</p><p>â€ƒâ€ƒä¸­é—´æ’•æ‰äº†å¾ˆå¤šé¡µï¼ˆï¼‰</p><p>â€ƒâ€ƒé‚£ä¸€å¤©çš„åœºæ™¯ä»ç„¶æ— æ•°æ¬¡çš„å‡ºç°åœ¨æˆ‘çš„æ¢¦é‡Œï¼Œæˆ‘ä»¿ä½›ç½®èº«å……æ»¡äº†ææ€–å’Œç»æœ›çš„åœ°æ–¹ï¼Œè®©äººåªèƒ½æ„Ÿå—åˆ°ç–¯ç‹‚å’Œæ­»äº¡ã€‚é‚£é‡Œæœ‰æ— æ•°çš„é»‘æš—ï¼Œæ— æ•°çš„æ€ªç‰©ï¼Œæ— æ•°çš„å°–å«ï¼Œæ— æ•°çš„è¡€è‚‰ã€‚é‚£é‡Œæ²¡æœ‰å…‰æ˜ï¼Œæ²¡æœ‰ç”Ÿå‘½ï¼Œæ²¡æœ‰å¸Œæœ›ï¼Œæ²¡æœ‰æ„ä¹‰ï¼Œæ²¡æœ‰è§„åˆ™ã€‚é‚£é‡Œåªæœ‰ä¸€ä¸ªæ— å°½çš„æ··æ²Œï¼Œä¸€ä¸ªæ— è¾¹çš„ç–¯ç‹‚ï¼Œä¸€ä¸ªæ— åçš„ææƒ§ï¼Œä¸€ä¸ªæ— æ³•çš„å´©åã€‚</p><p>â€ƒâ€ƒæˆ‘åªè®°å¾—æœ€åï¼Œè‰¾è‰è¥¿äºšå¯¹æˆ‘è¯´ï¼šâ€œå‚»ç“œï¼Œä½ è¿˜æ˜¯è·Ÿè¿‡æ¥äº†å‘€ï¼Œæˆ‘çš„å°è‹±é›„ã€‚â€</p><details class="folding-tag" orange><summary> ç‚¹å‡»æŸ¥çœ‹è¯­å½• </summary>              <div class='content'>              <span class="p green">&gt;</span>ç²‰è‰²å¤´å‘çš„è¿·äººå¥³å­©æ˜¯è°å‘€ï¼Œå“¦ï¼ŒåŸæ¥æ˜¯æˆ‘å‘€ï¼<spanclass="p green">&lt;</span><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E7%88%B1%E8%8E%89%E5%B8%8C%E9%9B%85-%E8%AF%B4%E8%B5%B7%E7%B2%89%E8%89%B2%E5%A4%B4%E5%8F%91%E7%9A%84%E5%8F%AF%E7%88%B1%E5%A5%B3%E5%AD%A9%EF%BC%8C%E4%BD%A0%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BC%9A%E6%83%B3%E5%88%B0%E8%B0%81%EF%BC%9F%E4%B8%89%E4%BA%8C%E4%B8%80%E5%9B%9E%E7%AD%94%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><span class="p green">&gt;</span> å¤šå¤¸å¤¸æˆ‘å˜›ï¼Œæˆ‘ä¼šå¾ˆå¼€å¿ƒçš„~<spanclass="p green">&lt;</span><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E7%88%B1%E8%8E%89%E5%B8%8C%E9%9B%85-%E5%97%A8%EF%BC%8C%E6%88%91%E5%8F%88%E6%9D%A5%E5%95%A6%E3%80%82%E5%A4%9A%E5%A4%B8%E5%A4%B8%E6%88%91%E5%A5%BD%E5%90%97%EF%BC%9F%E6%88%91%E4%BC%9A%E5%BE%88%E2%80%94%E2%80%94%E5%BC%80%E5%BF%83%E7%9A%84%E5%93%A6%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><span class="p green">&gt;</span> å¯çˆ±çš„å°‘å¥³å¿ƒï¼Œå¯æ˜¯æ— æ‰€ä¸èƒ½çš„å“¦ï¼<spanclass="p green">&lt;</span><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E4%BA%BA%E4%B9%8B%E5%BE%8B%E8%80%85-%E5%91%B5...%E7%9C%8B%EF%BC%8C%E5%8F%AF%E7%88%B1%E7%9A%84%E5%B0%91%E5%A5%B3%E5%BF%83%E5%8F%AF%E6%98%AF%E6%97%A0%E6%89%80%E4%B8%8D%E8%83%BD%E7%9A%84%E5%93%A6%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div>              </div>            </details>]]></content>
    
    
    <summary type="html">ğŸ§¶å‚»ç“œï¼Œä½ è¿˜æ˜¯è·Ÿè¿‡æ¥äº†å‘€ï¼Œæˆ‘çš„å°è‹±é›„</summary>
    
    
    
    <category term="æ–‡å­¦" scheme="https://www.adunas.top/categories/%E6%96%87%E5%AD%A6/"/>
    
    
    <category term="å°è¯´" scheme="https://www.adunas.top/tags/%E5%B0%8F%E8%AF%B4/"/>
    
    <category term="äººç‰©æ¡£æ¡ˆ" scheme="https://www.adunas.top/tags/%E4%BA%BA%E7%89%A9%E6%A1%A3%E6%A1%88/"/>
    
    <category term="è·‘å›¢" scheme="https://www.adunas.top/tags/%E8%B7%91%E5%9B%A2/"/>
    
  </entry>
  
  <entry>
    <title>æ—¥ç¨‹è¡¨ï¼š2024å¹´02æœˆ</title>
    <link href="https://www.adunas.top/posts/20240222a.html"/>
    <id>https://www.adunas.top/posts/20240222a.html</id>
    <published>2024-02-22T08:36:32.000Z</published>
    <updated>2024-02-22T08:36:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#2024å¹´2æœˆ">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="å¹´2æœˆ23æ—¥">2024å¹´2æœˆ23æ—¥</h1><div class='checkbox red checked'><input type="checkbox" checked="checked"/>            <p>è¿åŠ¨1å°æ—¶</p>            </div><ul class="task-list"><li><label><input type="checkbox" checked="" />ç¾½æ¯›çƒ</label></li></ul><div class='checkbox red'><input type="checkbox" />            <p>å†™ä¸€ç¯‡é˜…è¯»è®ºæ–‡çš„åšå®¢</p>            </div><details class="folding-tag" blue><summary> æ—¥ç¨‹è¡¨ </summary>              <div class='content'>              <div class="timeline blue"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>æ—¶é—´è½´</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>17ç‚¹46åˆ†</p></div></div><div class="timeline-item-content"><ol type="1"><li>åƒæ™šé¥­</li></ol></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>18ç‚¹10åˆ†</p></div></div><div class="timeline-item-content"><ol type="1"><li>é˜…è¯»è®ºæ–‡</li></ol></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>18ç‚¹40åˆ†-20ç‚¹40åˆ†</p></div></div><div class="timeline-item-content"><ol type="1"><li>ç¾½æ¯›çƒ</li></ol></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>21ç‚¹56åˆ†</p></div></div><div class="timeline-item-content"><ol type="1"><li>é˜…è¯»è®ºæ–‡</li></ol></div></div></div>              </div>            </details>]]></content>
    
    
    <summary type="html">ğŸ¥æœ¬æ–‡è®°å½• Adunas 2024å¹´02æœˆçš„æ—¥ç¨‹å®‰æ’å’Œå®æ–½æƒ…å†µ</summary>
    
    
    
    <category term="æ—¥ç¨‹è¡¨" scheme="https://www.adunas.top/categories/%E6%97%A5%E7%A8%8B%E8%A1%A8/"/>
    
    
    <category term="æ—¥ç¨‹è¡¨" scheme="https://www.adunas.top/tags/%E6%97%A5%E7%A8%8B%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>åšå®¢æ­å»ºå¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240221c.html"/>
    <id>https://www.adunas.top/posts/20240221c.html</id>
    <published>2024-02-21T11:26:31.000Z</published>
    <updated>2024-02-21T11:26:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#åšå®¢æ­å»º">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="åšå®¢æ–‡ç« è¯­æ³•ç¬”è®°å¯¼èˆª">åšå®¢æ–‡ç« è¯­æ³•ç¬”è®°å¯¼èˆª</h1><h2 id="markdownåŸºç¡€è¯­æ³•"><ahref="./20231201a.html">MarkdownåŸºç¡€è¯­æ³•</a></h2><h2 id="markdownå†…ç½®htmlè¯­æ³•"><ahref="./20231206b.html">Markdownå†…ç½®Htmlè¯­æ³•</a></h2><h2 id="butterflyå¤–æŒ‚æ ‡ç­¾"><ahref="./20231205b.html">Butterflyå¤–æŒ‚æ ‡ç­¾</a></h2><h1 id="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª">åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª</h1><h2 id="åŸºç¡€æ•™ç¨‹"><a href="./20231205d.html">åŸºç¡€æ•™ç¨‹</a></h2><h2 id="bugæ±‡æ€»"><a href="./20231204c.html">bugæ±‡æ€»</a></h2><h2 id="æœªæ¥å¯æœŸ"><a href="./20231205c.html">æœªæ¥å¯æœŸ</a></h2><h2 id="éŸ³é¢‘æ•™ç¨‹"><a href="./20231207a.html">éŸ³é¢‘æ•™ç¨‹</a></h2><h2 id="æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½"><ahref="./20240201a.html">æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½</a></h2><h2 id="é¦–é¡µç¾åŒ–"><a href="./20240202a.html">é¦–é¡µç¾åŒ–</a></h2>]]></content>
    
    
    <summary type="html">ğŸ§ˆæœ¬æ–‡æ˜¯åšå®¢æ­å»ºçš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>ç¼–ç¨‹å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240221b.html"/>
    <id>https://www.adunas.top/posts/20240221b.html</id>
    <published>2024-02-21T10:48:39.000Z</published>
    <updated>2024-02-21T10:49:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#ç¼–ç¨‹">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="c">C++</h1><h2 id="æ‰“å°"><a href="./20240116a.html">æ‰“å°</a></h2><h1 id="å‘½ä»¤è¡Œ">å‘½ä»¤è¡Œ</h1><h2 id="git"><a href="./20231206a.html">Git</a></h2><h1 id="java">Java</h1><h2 id="å‰ç«¯"><a href="./20231211a.html">å‰ç«¯</a></h2><h1 id="æœç´¢">æœç´¢</h1><h2 id="æ­£åˆ™è¡¨è¾¾å¼"><a href="./20240225a.html">æ­£åˆ™è¡¨è¾¾å¼</a></h2><h1 id="latex"><a href="./20240225c.html">Latex</a></h1><h1 id="pandoc"><a href="./20240304b.html">Pandoc</a></h1>]]></content>
    
    
    <summary type="html">ğŸ¥æœ¬æ–‡æ˜¯ç¼–ç¨‹åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>æ–‡ç« å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240221a.html"/>
    <id>https://www.adunas.top/posts/20240221a.html</id>
    <published>2024-02-21T10:41:36.000Z</published>
    <updated>2024-02-21T10:41:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ•°å­¦"><a href="./20240210a.html">æ•°å­¦</a></h1><h1 id="è‹±è¯­">è‹±è¯­</h1><h2 id="å•è¯"><a href="./20231208a.html">å•è¯</a></h2><h1 id="é˜…è¯»"><a href="./20240224b.html">é˜…è¯»</a></h1><h1 id="æ–‡å­¦"><a href="./20240224d.html">æ–‡å­¦</a></h1><h1 id="ç¼–ç¨‹"><a href="./20240221b.html">ç¼–ç¨‹</a></h1><h1 id="åšå®¢æ­å»º"><a href="./20240221c.html">åšå®¢æ­å»º</a></h1><h1 id="æ—¥ç¨‹è¡¨">æ—¥ç¨‹è¡¨</h1><h2 id="å¹´2æœˆ"><a href="./20240222a.html">2024å¹´2æœˆ</a></h2><h1 id="è¿åŠ¨å¥åº·">è¿åŠ¨å¥åº·</h1><h2 id="æ—¥å¸¸åŸºç¡€ç¯‡"><a href="./20240131a.html">æ—¥å¸¸åŸºç¡€ç¯‡</a></h2><h2 id="çŠ¶æ€è°ƒæ•´ç¯‡"><a href="./20240203a.html">çŠ¶æ€è°ƒæ•´ç¯‡</a></h2><h1 id="æ“ä½œç³»ç»Ÿ">æ“ä½œç³»ç»Ÿ</h1><h1 id="ios">IOS</h1><h2 id="ipa"><a href="./20240115a.html">ipa</a></h2><h1 id="æ¸¸æˆ">æ¸¸æˆ</h1><h2 id="adunasçš„æ¸¸æˆè´¦å·æ˜µç§°å’Œid"><ahref="./20231201b.html">Adunasçš„æ¸¸æˆè´¦å·æ˜µç§°å’ŒID</a></h2>]]></content>
    
    
    <summary type="html">ğŸ¥æœ¬æ–‡æ˜¯æ–‡ç« åˆ†ç±»å¯¼èˆªçš„æœ€é¡¶å±‚</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>æ•°å­¦å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240210a.html"/>
    <id>https://www.adunas.top/posts/20240210a.html</id>
    <published>2024-02-10T06:57:53.000Z</published>
    <updated>2024-02-21T10:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#æ•°å­¦">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="çŸ©é˜µ">çŸ©é˜µ</h1><h2 id="è¿¹"><a href="./20231210a.html">è¿¹</a></h2><h2 id="åæ–¹å·®"><a href="./20231204a.html">åæ–¹å·®</a></h2><h1 id="æ»¤æ³¢">æ»¤æ³¢</h1><h2 id="å¡å°”æ›¼æ»¤æ³¢"><a href="./20231205a.html">å¡å°”æ›¼æ»¤æ³¢</a></h2><h1 id="ç»˜å›¾å·¥å…·">ç»˜å›¾å·¥å…·</h1><h2 id="åŠ¨æ€æ•°å­¦è½¯ä»¶"><a href="./20231210b.html">åŠ¨æ€æ•°å­¦è½¯ä»¶</a></h2><p>â€ƒâ€ƒåŠ¨æ€æ•°å­¦è½¯ä»¶GroGebraã€‚</p>]]></content>
    
    
    <summary type="html">ğŸ¥§æœ¬æ–‡æ˜¯æ•°å­¦åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</title>
    <link href="https://www.adunas.top/posts/20240203a.html"/>
    <id>https://www.adunas.top/posts/20240203a.html</id>
    <published>2024-02-03T04:32:11.000Z</published>
    <updated>2024-02-03T04:32:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#çŠ¶æ€è°ƒæ•´ç¯‡">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª">è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol type="1"><li><a href="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a></li><li><ahref="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li></ol></blockquote><div class="note info flat"></div><h1 id="ç‹¬ç«‹è‡ªä¸»">ç‹¬ç«‹è‡ªä¸»</h1><p>â€ƒâ€ƒå­¦ä¼šè‡ªå°Šè‡ªçˆ±ï¼Œä»»ä½•æ—¶å€™ä¸èƒ½æŠŠè‡ªå·±çš„æœªæ¥æ‰˜ä»˜ç»™åˆ«äººã€‚ä½ æœ€äº²çš„çˆ¶æ¯ä¸å¯ä»¥ï¼Œæœ€å¥½çš„æœ‹å‹ä¸å¯ä»¥ï¼Œæœ€çˆ±çš„å¥³æœ‹å‹ä¸å¯ä»¥ï¼Œæœ€çŸ¥å¿ƒçš„è€å¸ˆä¹Ÿä¸å¯ä»¥ã€‚ä½ å”¯ä¸€è¦å€¼å¾—æ‰˜ä»˜çš„äººåªæœ‰è‡ªå·±ï¼Œä¹Ÿåªèƒ½æ˜¯è‡ªå·±ã€‚è‡ªå·±æ˜¯è‡ªå·±çš„çˆ¶æ¯ï¼Œç…§é¡¾è‡ªå·±è¡£é£Ÿèµ·å±…ã€‚è‡ªå·±æ˜¯è‡ªå·±çš„å­©å­ï¼Œçº¯çœŸã€ç†æƒ³ã€çœŸå¿ƒéƒ½åœ¨æ­¤ã€‚</p><h1 id="å‹åŠ›åˆ«äºº">å‹åŠ›åˆ«äºº</h1><p>â€ƒâ€ƒå¶å°”è¿˜æ˜¯æœ‰è¿™ä¸ªåä¹ æƒ¯ã€‚å‹åŠ›åˆ«äººå…¸å‹æ˜¯è‡ªå‘çš„è¡¨ç°ï¼Œæƒ³é€šè¿‡æ‰“å‹åˆ«äººæ¥ä½“ç°è‡ªèº«çš„ä»·å€¼ï¼Œè¿™åªæ˜¯å«‰å¦’ï¼Œæ˜¯å¾ˆä¸å¥åº·çš„ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸¤æ€§å…³ç³»ä¸Šã€‚ç”Ÿæ´»å·²ç»å¾ˆç´¯å•¦ï¼Œå¥¹è¦çš„æ˜¯æƒ…ç»ªä»·å€¼ï¼Œè€Œä¸æ˜¯åˆå¤šä¸€ä¸ªå‹åŠ›çš„è€å¸ˆã€‚å¤šç«™åœ¨åˆ«äººçš„è§’åº¦å»æƒ³æƒ³ã€å»å…³å¿ƒã€å»çˆ±å§ã€‚å­¦ä¼š<ahref="#èµç¾">èµç¾</a>åˆ«äººã€‚</p><h1 id="æ²‰é»˜ä¸æ¿€æƒ…">æ²‰é»˜ä¸æ¿€æƒ…</h1><p>â€ƒâ€ƒä¸æ±‚æ— åŠŸï¼Œä½†æ±‚æ— è¿‡ã€‚è¿™å¥è¯è¯´å¾—çœŸå·®ï¼æˆ‘æ¥æ”¹æ”¹ï¼šä¸æ±‚æ— åŠŸï¼Œä¸æ€•çŠ¯é”™ï¼è¿™æ®µæ—¶é—´å…å»äº†å¾ˆå¤šæ— ç”¨çš„ç¤¾äº¤ã€æ— ç”¨çš„ç„¦è™‘ã€‚æ²‰å¿ƒé™æ°”åœ°æå­¦ä¹ å’Œç ”ç©¶ï¼Œå¹¶ä¸è§‰å¾—å­¤ç‹¬ï¼Œåè€Œè§‰å¾—æ— æ¯”è¸å®ã€èˆ’å¿ƒã€‚åˆé€‚çš„ç¤¾äº¤ï¼Œæˆ‘ä¼šæ‰“ç ´æ²‰é»˜ï¼Œæˆ‘è¦ä»æ¿€æƒ…åœ°å­¦ä¹ è½¬å˜æˆçƒ­æƒ…åœ°äº¤æµï¼ŒçœŸè¯šé¢å¯¹æ¯ä¸€ä¸ªäººï¼Œå’Œä¸åŒçš„äººã€åˆé€‚çš„äººäº¤æµæ‰èƒ½è®©è‡ªå·±èƒ½å¤Ÿä¸è®©è‡ªå·±çš„æ€æƒ³å’Œè§†é‡å˜å¾—ç‹­éš˜å’Œåé¢‡ã€‚çƒ­æƒ…ä¼šè¢«æ‰“å‡»ï¼Œä½†æ˜¯é‚£ç®€ç›´æ˜¯æŒ ç—’ç—’ï¼Œå› ä¸ºæˆ‘ä»¬æ ¹æœ¬<ahref="#ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ">ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ</a>å‘€ã€‚</p><h1 id="ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ">ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ</h1><p>â€ƒâ€ƒä½ è¦å§‹ç»ˆæ˜ç™½è‡ªå·±åœ¨ä¹ä»€ä¹ˆï¼Œä»€ä¹ˆæ˜¯å¯¹ä½ é‡è¦çš„ã€‚ä¸è®ºç”·å¥³ï¼Œæœ€é‡è¦çš„æ˜¯åšå¥½è‡ªå·±è¯¥åšçš„äº‹æƒ…ã€‚å¯¹äºæˆ‘ï¼Œç”·ç”Ÿæ¥è¯´ï¼Œæœ€é‡è¦çš„æ˜¯äº‹ä¸šï¼Œäº‹ä¸šåšå¥½äº†ï¼Œå¥¹æœ‰å¯èƒ½è·Ÿä½ ï¼Œäº‹ä¸šåšä¸å¥½ï¼Œå¥¹ä¸€å®šä¸ä¼šè·Ÿä½ ã€‚æ‰€ä»¥ä½ æƒ³æƒ³ï¼ŒçœŸçš„æ˜¯åˆ«äººè®©ä½ å¿ƒæƒ…ä¸å¥½äº†å˜›ï¼Ÿç­”æ¡ˆæ˜¯å¦å®šçš„ï¼Œè€Œæ˜¯è‡ªå·±æŠŠè‡ªå·±å¿ƒæƒ…å˜å¾—ä¸å¥½äº†ã€‚</p><p>â€ƒâ€ƒæˆ‘è·Ÿè€å¸ˆèŠè¿‡ã€‚æˆ‘è·ŸåŒå­¦èŠè¿‡ã€‚æˆ‘è·Ÿå®¶äººèŠè¿‡ã€‚æˆ‘è·Ÿæœ‹å‹èŠè¿‡ã€‚æˆ‘ä¹Ÿè·Ÿè‡ªå·±èŠè¿‡ã€‚å¦‚æœæˆ‘èƒ½è·Ÿå¥¹å†èŠä¸€èŠå°±æ›´å¥½äº†ã€‚å¼€å¿ƒåœ°ã€åŠªåŠ›åœ°ã€è‡ªä¿¡åœ°åšæ‰‹å¤´ä¸Šçš„äº‹æƒ…ï¼Œå°±æ˜¯æœ€æ£’äº†ã€‚æœ‰å¥½èº«ä½“ã€å¥½å·¥ä½œã€å¥½å¿ƒæ€å°±å·²ç»å®Œèƒœå•¦ã€‚</p><h1 id="èµç¾">èµç¾</h1><p>â€ƒâ€ƒä»¥å‰æˆ‘å¾ˆè®¨åŒé˜¿è°€å¥‰æ‰¿ï¼Œç„¶è€Œè¿™ç§è®¨åŒè¢«æ— å½¢åœ°æ‰©å¤§äº†ã€‚æ‰©å¤§åˆ°ä¸ä¼šç”±è¡·åœ°æ¬£èµèµç¾åˆ«äººã€‚è€Œä¸”é˜¿è°€å¥‰æ‰¿æˆ‘ç°åœ¨æ ¹æœ¬ä¸è®¨åŒäº†ï¼Œä½†æˆ‘ä¸ä¼šå»é˜¿è°€å¥‰æ‰¿ã€‚å¦‚æœæˆ‘éœ€è¦å¸®åŠ©ï¼Œæˆ‘ä¼šçœŸè¯šåœ°è¡¨è¾¾ã€å¯»æ±‚å¸®åŠ©ã€‚æˆ‘çš„èµç¾ä¹Ÿä¸ä¼šæ˜¯é˜¿è°€å¥‰æ‰¿ï¼Œè€Œæ˜¯è¦é€šè¿‡è§‚å¯Ÿåï¼ŒçœŸçš„èƒ½å‘ç°è¿™ä»¶äº‹å¸¦ç»™æˆ‘ä»¬çš„ç¾ï¼Œä»¥åŠé‚£èƒŒåçš„æ•…äº‹~</p><p>â€ƒâ€ƒä¸ºä»€ä¹ˆæˆ‘ä¸è®¨åŒé˜¿è°€å¥‰æ‰¿ã€‚å› ä¸ºæˆ‘çŸ¥é“äººçš„ç”Ÿæ´»æ˜¯è‰°éš¾çš„ï¼Œä»–åªä¸è¿‡åœ¨è‰°éš¾åœ°åœ¨å¤¹ç¼ä¸­ç”Ÿå­˜ç€ï¼Œä»–é˜¿è°€å¥‰æ‰¿å‡ å¥ï¼Œå¹¶ä¸æ˜¯å‡ºäºæ¶æ„ï¼Œè€Œæ˜¯å¯ä»¥ä¿ä½è‡ªå·±çš„å·¥ä½œï¼Œä¿ä½è‡ªå·±çš„é¥­ç¢—ï¼Œæœ‰ä¸ªæ›´å¥½çš„æœºä¼šè€Œå·²ã€‚è¯´å‡ å¥è¯èƒ½è®©å¤§å®¶éƒ½å¼€å¿ƒï¼Œè¿™æœ‰ä»€ä¹ˆä¸å¯¹å—ï¼Ÿè¿™æ ·åœ¨å·¥ä½œä¸­å¤§å®¶éƒ½å¾ˆèˆ’æœï¼Œè¿™æ˜¯æå…¶æ­£ç¡®çš„ã€‚</p><p>â€ƒâ€ƒæ¨èç”¨æ›´å¥½çš„ â€œé˜¿è°€å¥‰æ‰¿â€çš„æ–¹æ³•ï¼Œé‚£ä¾¿æ˜¯èµç¾ã€‚å­¦ä¼šè®¤å¯åˆ«äººçš„å·¥ä½œï¼Œå­¦ä¼šæ¬£èµï¼Œå­¦ä¼šèµç¾ã€‚æ¯”å¦‚å¥¹ç”»äº†ä¸€ä¸ªå¦†ï¼Œç”·ç”Ÿå¯èƒ½çœ‹äº†å¹¶æ²¡æœ‰ä»€ä¹ˆå’Œä¹‹å‰æ„Ÿè§‰ä¸ä¸€æ ·ï¼Œä½†æ˜¯ä½ ä¸çŸ¥é“çš„æ˜¯ï¼Œå¥¹ä¸ºäº†ä½ åŒ–å¦†å‡†å¤‡äº†å¤šä¹…ã€‚å¥¹å¹³æ—¶ä¸€ä¸ªäººçš„æ—¶å€™å¯æ˜¯æ‡’å¾—æ‰“æ‰®å‘€ï¼Œè¿™æ—¶å€™ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªå¥³ç”Ÿæ˜¯çœŸçš„å¾ˆç¾ï¼Œå¾ˆå¯çˆ±å‘€ã€‚æˆ‘ä¼šä»”ç»†åœ°çœ‹çœ‹å¥¹åœ°çœ¼ç›ã€è…®çº¢ï¼Œè™½ç„¶æˆ‘å¯¹åŒ–å¦†ä¸€çªä¸é€šï¼Œä½†æ˜¯å¥½åƒçœŸçš„æœ‰äº›ä¸ä¸€æ ·ï¼Œæˆ‘ä¸€å®šä¼šå¼€å¿ƒå¾—çœ‹ç€å¥¹è¯´ï¼šä½ ä»Šå¤©çœŸç¾ï¼</p><p>æ‰€ä»¥ä½ åœ¨å’Œåˆ«äººäº¤æµçš„æ—¶å€™ï¼Œæ€»æœ‰äº›ä¸œè¥¿ä½ ä¸å¤ªæ‡‚ï¼Œä½†æ˜¯å¯¹æ–¹æåŠ›è®²çš„æ—¶å€™ï¼Œä¸€å®šæ˜¯å¯¹ä»–éå¸¸é‡è¦çš„ä¸œè¥¿å§ï¼ä»–ä¸€å®šä¸ºè¿™ä»¶äº‹ä»˜å‡ºäº†å¾ˆå¤šå®å®åœ¨åœ¨çš„åŠªåŠ›ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä¼šå¤§æ–¹åœ°èµç¾ï¼Œå› ä¸ºæˆ‘ç¡®å®èƒ½è¢«æ„ŸæŸ“åˆ°ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä¸è®¤ä¸ºæ˜¯ä»€ä¹ˆé˜¿è°€å¥‰æ‰¿ã€‚</p><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª-1">è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol type="1"><li><a href="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a></li><li><ahref="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li></ol></blockquote>]]></content>
    
    
    <summary type="html">ğŸ«æœ¬æ–‡æ€»ç»“çŠ¶æ€è°ƒæ•´çš„æ–¹æ³•</summary>
    
    
    
    <category term="è¿åŠ¨å¥åº·" scheme="https://www.adunas.top/categories/%E8%BF%90%E5%8A%A8%E5%81%A5%E5%BA%B7/"/>
    
    
    <category term="å¥åº·" scheme="https://www.adunas.top/tags/%E5%81%A5%E5%BA%B7/"/>
    
    <category term="å¿ƒæ€" scheme="https://www.adunas.top/tags/%E5%BF%83%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>åšå®¢æ­å»ºæ•™ç¨‹ï¼šé¦–é¡µç¾åŒ–</title>
    <link href="https://www.adunas.top/posts/20240202a.html"/>
    <id>https://www.adunas.top/posts/20240202a.html</id>
    <published>2024-02-02T15:36:47.000Z</published>
    <updated>2024-02-21T12:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"><ahref="./20240221c.html#é¦–é¡µç¾åŒ–">åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª</a></h1><h1 id="æ ¼è¨€">æ ¼è¨€</h1><p>â€ƒâ€ƒåœ¨[é¡µè„šé…ç½®æ–‡ä»¶]./themes/butterfly/layout/includes/footer.pugä¸­ï¼Œä¿®æ”¹å¦‚ä¸‹ä»£ç ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.t-t-l</span><br><span class="line">          p.ft-t.t-l-t æ ¼è¨€ğŸ§¬</span><br><span class="line">          .bg-ad</span><br><span class="line">            div</span><br><span class="line">              | å†çœ‹çœ‹é‚£ä¸ªå…‰ç‚¹ï¼Œå®ƒå°±åœ¨è¿™é‡Œï¼Œè¿™æ˜¯å®¶å›­ï¼Œè¿™æ˜¯æˆ‘ä»¬ â€”â€” ä½ æ‰€çˆ±çš„æ¯ä¸€ä¸ªäººï¼Œä½ è®¤è¯†çš„ä¸€ä¸ªäººï¼Œä½ å¬è¯´è¿‡çš„æ¯ä¸€ä¸ªäººï¼Œæ›¾ç»æœ‰è¿‡çš„æ¯ä¸€ä¸ªäººï¼Œéƒ½åœ¨å®ƒä¸Šé¢åº¦è¿‡ä»–ä»¬çš„ä¸€ç”Ÿâœ¨</span><br><span class="line">            .btn-xz-box</span><br><span class="line">              a.btn-xz(href=&#x27;https://stellarium.org/&#x27;) ç‚¹å‡»å¼€å¯æ˜Ÿè¾°ä¹‹æ—…</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">ğŸŸæœ¬æ–‡è®°å½•åšå®¢é¦–é¡µç¾åŒ–çš„æ–¹æ³•</summary>
    
    
    
    <category term="åšå®¢" scheme="https://www.adunas.top/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
    <category term="hexo" scheme="https://www.adunas.top/tags/hexo/"/>
    
    <category term="html" scheme="https://www.adunas.top/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>åšå®¢æ­å»ºæ•™ç¨‹ï¼šæ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½</title>
    <link href="https://www.adunas.top/posts/20240201a.html"/>
    <id>https://www.adunas.top/posts/20240201a.html</id>
    <published>2024-02-01T03:30:06.000Z</published>
    <updated>2024-02-21T12:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"><ahref="./20240221c.html#æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½">åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª</a></h1><h1 id="æ–‡ç« é¡µhtmlæ ‡ç­¾">æ–‡ç« é¡µHtmlæ ‡ç­¾</h1><p>â€ƒâ€ƒæœ‰æ—¶å€™æˆ‘ä»¬æƒ³åœ¨åšå®¢æ–‡ç« é‡Œæ·»åŠ ä¸€äº› hexo ä¸å…·æœ‰çš„ç‰¹æ€§æ—¶ï¼Œå°±å¯ä»¥åœ¨markdown æ–‡ä»¶ä¸­æ·»åŠ  Html æ ‡ç­¾ã€‚</p><p>â€ƒâ€ƒhtmlã€CSS å’Œ js å¯ä»¥åˆ†å¼€å†™ï¼Œä¹Ÿåˆ†ä¸‰ä¸ªæ–‡ä»¶å†™ï¼Œhtmlå§‹ç»ˆæ”¾åœ¨markdownæ–‡ä»¶é‡Œã€‚åˆ†å¼€å†™çš„è¯ï¼ŒCSS å’Œ js æ–‡ä»¶è¦æ”¾åœ¨ä¸»é¢˜çš„æºæ–‡ä»¶è·¯å¾„/themes/butterfly/source/ ä¸‹çš„çš„ css æˆ–è€… js æ–‡ä»¶å¤¹ä¸‹ã€‚åœ¨ Markdowné‡Œçš„è¯­æ³•ä¸ºï¼š</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">href</span>=<span class="string">&quot;/css/grid.css&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    </span></span><br><span class="line"><span class="code">&lt;div class=&quot;container1&quot;&gt;  </span></span><br><span class="line"><span class="code">    &lt;iframe class=&quot;container-iframe&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;  </span></span><br><span class="line"><span class="code">&lt;/div&gt;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/js/grid.js&quot;</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h1 id="bilibiliè§†é¢‘é€‚é…">Bilibiliè§†é¢‘é€‚é…</h1><div class="note purple no-icon flat"><p>å‚è€ƒæ–‡ç« ï¼š<ahref="https://www.fomal.cc/posts/5389e93f.html">Bilibiliè§†é¢‘é€‚é…</a></p></div><ol type="1"><li>åœ¨[BlogRoot].cssè‡ªå®šä¹‰æ ·å¼çš„æ–‡ä»¶ä¸­å¼•å…¥å¦‚ä¸‹ä»£ç ï¼ˆè¿™æ˜¯æˆ‘çš„ï¼Œä½ å¯ä»¥è‡ªè¡Œå¾®è°ƒï¼‰ï¼š</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*å“”å“©å“”å“©è§†é¢‘é€‚é…*/</span></span><br><span class="line"><span class="selector-class">.aspect-ratio</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">90%</span>;</span><br><span class="line">  <span class="attribute">height</span>: auto;</span><br><span class="line">  <span class="attribute">padding-bottom</span>: <span class="number">75%</span>;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">3%</span> auto;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.aspect-ratio</span> <span class="selector-tag">iframe</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: absolute;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">86%</span>;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>ç›´æ¥å¤åˆ¶æ’å…¥ä½ çš„ md æ–‡ç« å°±è¡Œï¼Œä¿®æ”¹é‡Œé¢çš„ src æºä¸ºä½ çš„è§†é¢‘ï¼š</li></ol><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">center</span> <span class="attr">class</span>=<span class="string">&quot;aspect-ratio&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    &lt;iframe src=&quot;https://player.bilibili.com/player.html?aid=474023258&amp;&amp;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;autoplay=0 &quot; </span></span><br><span class="line"><span class="code">    scrolling=&quot;no&quot; </span></span><br><span class="line"><span class="code">    border=&quot;0&quot; </span></span><br><span class="line"><span class="code">    frameborder=&quot;no&quot; </span></span><br><span class="line"><span class="code">    framespacing=&quot;0&quot; </span></span><br><span class="line"><span class="code">    high_quality=1</span></span><br><span class="line"><span class="code">    danmaku=1 </span></span><br><span class="line"><span class="code">    allowfullscreen=&quot;true&quot;&gt; </span></span><br><span class="line"><span class="code">    &lt;/iframe&gt;</span></span><br><span class="line"><span class="code">&lt;/div&gt;</span></span><br></pre></td></tr></table></figure><p>æºè§†é¢‘çš„é“¾æ¥è·å–æ–¹æ³•ä¸ºï¼šåœ¨bç«™å®˜ç½‘åˆ†äº«è§†é¢‘æ—¶ï¼Œé€‰æ‹©<code>åµŒå…¥ä»£ç </code>ã€‚è‹¥è¦å…³é—­è§†é¢‘è‡ªåŠ¨æ’­æ”¾ï¼Œåœ¨åé¢æ·»åŠ å‚æ•°ï¼š</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&amp;autoplay=0</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">ğŸ”æœ¬æ–‡è®°å½•åšå®¢æ–‡ç« å†…æ’å…¥çš„ä¸ªæ€§åŒ–åŠŸèƒ½</summary>
    
    
    
    <category term="åšå®¢" scheme="https://www.adunas.top/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
    <category term="hexo" scheme="https://www.adunas.top/tags/hexo/"/>
    
    <category term="html" scheme="https://www.adunas.top/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>è¿åŠ¨å¥åº·ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</title>
    <link href="https://www.adunas.top/posts/20240131a.html"/>
    <id>https://www.adunas.top/posts/20240131a.html</id>
    <published>2024-01-31T14:47:09.000Z</published>
    <updated>2024-02-02T11:54:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><ahref="./20240221a.html#æ—¥å¸¸åŸºç¡€ç¯‡">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª">è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol type="1"><li><ahref="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li><li><a href="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a></li></ol></blockquote><h1 id="é¢ˆæ¤">é¢ˆæ¤</h1><p>â€ƒâ€ƒ<ahref="https://www.bilibili.com/video/BV1Yb411b7nd/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€æœ‰æ¥åŒ»ç”Ÿ8æ‹›é¢ˆæ¤æ“å…¨æ•™ç¨‹ã€‘</a></p><div align=center class="aspect-ratio">    <iframe src="https://player.bilibili.com/player.html?aid=45039749&bvid=BV1Yb411b7nd&cid=78880311&p=1&autoplay=0 "     scrolling="no"     border="0"     frameborder="no"     framespacing="0"     high_quality=1    danmaku=1     allowfullscreen="true">     </iframe></div><h1 id="è…°æ¤">è…°æ¤</h1><p>â€ƒâ€ƒ<ahref="https://www.bilibili.com/video/BV1fp4y1U7qG/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€æ¯å¤©5åˆ†é’Ÿ<em>å‘Šåˆ«éª¨ç›†å‰å€¾ï¼Œå°è‚šå­çªå‡ºï¼Œå¤§å±è‚¡</em>ã€‘</a></p><div align=center class="aspect-ratio">    <iframe src="https://player.bilibili.com/player.html?aid=968747403&bvid=BV1fp4y1U7qG&cid=205794890&p=1&autoplay=0 "     scrolling="no"     border="0"     frameborder="no"     framespacing="0"     high_quality=1    danmaku=1     allowfullscreen="true">     </iframe></div><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª-1">è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol type="1"><li><ahref="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li><li><a href="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a></li></ol></blockquote>]]></content>
    
    
    <summary type="html">ğŸˆæœ¬æ–‡æ±‡æ€»æ—¥å¸¸çƒ­èº«çš„å†…å®¹</summary>
    
    
    
    <category term="è¿åŠ¨å¥åº·" scheme="https://www.adunas.top/categories/%E8%BF%90%E5%8A%A8%E5%81%A5%E5%BA%B7/"/>
    
    
    <category term="è¿åŠ¨" scheme="https://www.adunas.top/tags/%E8%BF%90%E5%8A%A8/"/>
    
    <category term="å¥èº«" scheme="https://www.adunas.top/tags/%E5%81%A5%E8%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>C++ æ‰“å°</title>
    <link href="https://www.adunas.top/posts/20240116a.html"/>
    <id>https://www.adunas.top/posts/20240116a.html</id>
    <published>2024-01-16T13:41:33.000Z</published>
    <updated>2024-02-21T11:20:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><a href="./20240221b.html#æ‰“å°">ç¼–ç¨‹å¯¼èˆª</a></h1><h1 id="c">C++</h1><h2 id="è¯­æ³•">è¯­æ³•</h2><h3 id="åŸºç¡€">åŸºç¡€</h3><h4 id="æ–¹æ³•1">æ–¹æ³•1</h4><p>â€ƒâ€ƒè°ƒç”¨åº“ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br></pre></td></tr></table></figure><p>è°ƒç”¨å‡½æ•°ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="æ–¹æ³•2">æ–¹æ³•2</h4><p>â€ƒâ€ƒå‘½åç©ºé—´ï¼Œçœç•¥ stdã€‚</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br></pre></td></tr></table></figure><p>è°ƒç”¨å‡½æ•°ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cout &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h3 id="ç»„åˆæ–¹å¼">ç»„åˆæ–¹å¼</h3><h4 id="ç»„åˆæ–¹å¼1">ç»„åˆæ–¹å¼1</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="ç»„åˆæ–¹å¼2">ç»„åˆæ–¹å¼2</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="ç»„åˆæ–¹å¼3">ç»„åˆæ–¹å¼3</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h3 id="ç‰¹æ®Šç¬¦å·">ç‰¹æ®Šç¬¦å·</h3><h4 id="å›è½¦">å›è½¦</h4><p>â€ƒâ€ƒå›è½¦è¡¨ç¤ºå°†å…‰æ ‡ç§»åŠ¨åˆ°è¡Œçš„å¼€å¤´ã€‚è¿™åº”è¯¥å’Œé”®ç›˜ä¸Šçš„å›è½¦æœ‰æ‰€åŒºåˆ†ã€‚</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;\r&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="æ¢è¡Œ">æ¢è¡Œ</h4><p>â€ƒâ€ƒæ¢è¡Œè¡¨ç¤ºå°†å…‰æ ‡ç§»åŠ¨åˆ°ä¸‹ä¸€è¡Œçš„å¼€å¤´ã€‚</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br></pre></td></tr></table></figure><p>æˆ–è€…ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h3 id="å˜é‡è°ƒç”¨">å˜é‡è°ƒç”¨</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> num = <span class="number">100</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;æ•°å­—æ˜¯ï¼š&quot;</span> &lt;&lt; num &lt;&lt; std::endl;</span><br><span class="line">std::string st = <span class="string">&quot;ä½ å¥½ï¼Œä¸–ç•Œï¼&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; st &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h3 id="æ¼”ç¤º">æ¼”ç¤º</h3><p>â€ƒâ€ƒæ¼”ç¤ºæ•ˆæœå¦‚ä¸‹ï¼š</p><div class="tabs" id="print"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#print-1">ç¤ºä¾‹æºç 1</button></li><li class="tab"><button type="button" data-href="#print-2">æ¼”ç¤ºç»“æœ1</button></li><li class="tab"><button type="button" data-href="#print-3">ç¤ºä¾‹æºç 2</button></li><li class="tab"><button type="button" data-href="#print-4">æ¼”ç¤ºç»“æœ2</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="print-1"><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Print\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;|_&quot;</span> &lt;&lt; <span class="string">&quot;è¯­æ³•\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;åŸºç¡€\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼1\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼2\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼3\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span>; std::cout &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;ç‰¹æ®Šç¬¦å·\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;å›è½¦\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;\r&quot;</span>; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;æ¢è¡Œ\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;æˆ–è€…\n&quot;</span>; </span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; std::endl; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;å˜é‡è°ƒç”¨\n&quot;</span>;</span><br><span class="line">    <span class="type">int</span> num = <span class="number">100</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;æ•°å­—æ˜¯ï¼š&quot;</span> &lt;&lt; num &lt;&lt; std::endl;</span><br><span class="line">    std::string st = <span class="string">&quot;ä½ å¥½ï¼Œä¸–ç•Œï¼&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; st &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-2"><p><imgsrc="https://picture.adunas.top/Program/PrintCppVs2022A.png" /></p><p>è¯´æ˜ï¼šæ¢è¡Œå’Œå›è½¦æœ‰æ˜æ˜¾åŒºåˆ«ã€‚</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-3"><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// æœ‰ä¸‰å¤„å¯ä»¥çœç•¥ std::</span></span><br><span class="line">    string st = <span class="string">&quot;ä½ å¥½ï¼Œä¸–ç•Œï¼&quot;</span>;</span><br><span class="line">    cout &lt;&lt; st &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-4"><p><imgsrc="https://picture.adunas.top/Program/PrintCppVs2022B.png" /></p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>]]></content>
    
    
    <summary type="html">ğŸ–æœ¬æ–‡æ±‡æ€» C++ æ‰“å°æ˜¾ç¤ºçš„åŠŸèƒ½</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="C++" scheme="https://www.adunas.top/tags/C/"/>
    
    <category term="print" scheme="https://www.adunas.top/tags/print/"/>
    
  </entry>
  
</feed>
