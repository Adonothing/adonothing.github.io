<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Adunas🍀の异世界</title>
  
  
  <link href="https://www.adunas.top/atom.xml" rel="self"/>
  
  <link href="https://www.adunas.top/"/>
  <updated>2024-03-04T02:09:14.000Z</updated>
  <id>https://www.adunas.top/</id>
  
  <author>
    <name>阿杜那斯🍀</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pandoc</title>
    <link href="https://www.adunas.top/posts/20240304b.html"/>
    <id>https://www.adunas.top/posts/20240304b.html</id>
    <published>2024-03-04T02:09:14.000Z</published>
    <updated>2024-03-04T02:09:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编程导航"><a href="./20240221b.html#Pandoc">编程导航</a></h1><p>  Pandoc 是一个开源的文本转换工具。</p>]]></content>
    
    
    <summary type="html">🥯本文为 Pandoc 的使用教程</summary>
    
    
    
    <category term="编程" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="Pandoc" scheme="https://www.adunas.top/tags/Pandoc/"/>
    
  </entry>
  
  <entry>
    <title>离骚（节选）</title>
    <link href="https://www.adunas.top/posts/20240304a.html"/>
    <id>https://www.adunas.top/posts/20240304a.html</id>
    <published>2024-03-04T00:55:25.000Z</published>
    <updated>2024-03-04T00:55:25.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="阅读导航"><ahref="./20240224b.html#离骚（节选）">阅读导航</a></h1><div class='poem'><div class='poem-title'>离骚（节选）</div><div class='poem-author'>屈原</div><p>长太息以掩涕兮，哀民生之多艰。余虽好修姱以鞿羁兮，謇朝谇而夕替。</p><p>既替余以蕙纕兮，又申之以揽茝。亦余心之所善兮，虽九死其犹未悔。</p><p>怨灵修之浩荡兮，终不察夫民心。众女嫉余之蛾眉兮，谣诼谓余以善淫。</p><p>固时俗之工巧兮，偭规矩而改错。背绳墨以追曲兮，竞周容以为度。</p><p>忳郁邑余侘傺兮，吾独穷困乎此时也。宁溘死以流亡兮，余不忍为此态也。</p><p>鸷鸟之不群兮，自前世而固然。何方圜之能周兮，夫孰异道而相安？</p><p>屈心而抑志兮，忍尤而攘诟。伏清白以死直兮，固前圣之所厚。</p><p>悔相道之不察兮，延伫乎吾将反。回朕车以复路兮，及行迷之未远。</p><p>步余马于兰皋兮，驰椒丘且焉止息。进不入以离尤兮，退将复修吾初服。</p><p>制芰荷以为衣兮，集芙蓉以为裳。不吾知其亦已兮，苟余情其信芳。</p><p>高余冠之岌岌兮，长余佩之陆离。芳与泽其杂糅兮，唯昭质其犹未亏。</p><p>忽反顾以游目兮，将往观乎四荒。佩缤纷其繁饰兮，芳菲菲其弥章。</p><p>民生各有所乐兮，余独好修以为常。虽体解吾犹未变兮，岂余心之可惩。</p></div><p>情感过头：</p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/Read/LiSaoAdunasA.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><p>朗读勘误：背绳墨以追曲兮，其中 “曲” 为二声，和直相对。</p><p>情感不足，改正读音错误，补全最后一句：</p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/Read/LiSaoAdunasB.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div>]]></content>
    
    
    <summary type="html">🥨本文为高中所学离骚（节选）的内容</summary>
    
    
    
    <category term="阅读" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="阅读方法" scheme="https://www.adunas.top/tags/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Latex</title>
    <link href="https://www.adunas.top/posts/20240225c.html"/>
    <id>https://www.adunas.top/posts/20240225c.html</id>
    <published>2024-02-25T03:38:02.000Z</published>
    <updated>2024-03-04T02:09:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编程导航"><a href="./20240221b.html#Latex">编程导航</a></h1><p>  易用难精。<ahref="https://youtu.be/HPSK7q13-40?si=-mt3QWOA63NQ4pvm">How to Convert aWord Document to Markdown for Free using Pandoc</a></p><h1 id="语法">语法</h1><p>\documentclass</p>]]></content>
    
    
    <summary type="html">🍙本文记录Latex语法</summary>
    
    
    
    <category term="编程" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="Latex" scheme="https://www.adunas.top/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式</title>
    <link href="https://www.adunas.top/posts/20240225a.html"/>
    <id>https://www.adunas.top/posts/20240225a.html</id>
    <published>2024-02-25T01:43:26.000Z</published>
    <updated>2024-02-25T01:43:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编程导航"><ahref="./20240221b.html#正则表达式">编程导航</a></h1>]]></content>
    
    
    <summary type="html">🍤本文是正则表达式的教程</summary>
    
    
    
    <category term="编程" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="正则表达式" scheme="https://www.adunas.top/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>思考该不该吃完一颗难吃的苹果</title>
    <link href="https://www.adunas.top/posts/20240224c.html"/>
    <id>https://www.adunas.top/posts/20240224c.html</id>
    <published>2024-02-24T07:51:08.000Z</published>
    <updated>2024-02-24T07:51:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文学导航"><ahref="./20240224d.html#思考该不该吃完一颗难吃的苹果">文学导航</a></h1><p>  每次难吃的苹果我都咽下去了，但是这次我决定不吃了。（未完待续）</p>]]></content>
    
    
    <summary type="html">🍎每次难吃的苹果我都咽下去了，这次我决定不吃了</summary>
    
    
    
    <category term="文学" scheme="https://www.adunas.top/categories/%E6%96%87%E5%AD%A6/"/>
    
    
    <category term="思考" scheme="https://www.adunas.top/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>文学导航</title>
    <link href="https://www.adunas.top/posts/20240224d.html"/>
    <id>https://www.adunas.top/posts/20240224d.html</id>
    <published>2024-02-24T07:42:23.000Z</published>
    <updated>2024-02-24T07:42:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#文学">文章导航总览</a></h1><h1 id="原创">原创</h1><h2 id="思考该不该吃完一颗难吃的苹果"><ahref="./20240224c.html">思考该不该吃完一颗难吃的苹果</a></h2><h1 id="授权发表">授权发表</h1><h2 id="关于爱莉西亚局长的个人回忆"><ahref="./20240222b.html">关于爱莉西亚局长的个人回忆</a></h2>]]></content>
    
    
    <summary type="html">🍛本文是文学分类的导航</summary>
    
    
    
    <category term="文章导航" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="文章导航" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>阅读导航</title>
    <link href="https://www.adunas.top/posts/20240224b.html"/>
    <id>https://www.adunas.top/posts/20240224b.html</id>
    <published>2024-02-23T17:17:02.000Z</published>
    <updated>2024-02-23T17:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#阅读">文章导航总览</a></h1><h1 id="论文">论文</h1><h2 id="论文阅读方法"><a href="./20240224a.html">论文阅读方法</a></h2><h2 id="一种基于目测的未知目标运动分析方位角方法"><ahref="./20240223a.html">一种基于目测的未知目标运动分析方位角方法</a></h2><h1 id="名著">名著</h1><h2 id="离骚节选"><a href="./20240304a.html">离骚（节选）</a></h2>]]></content>
    
    
    <summary type="html">🍜本文是阅读分类的导航</summary>
    
    
    
    <category term="文章导航" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="文章导航" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读方法</title>
    <link href="https://www.adunas.top/posts/20240224a.html"/>
    <id>https://www.adunas.top/posts/20240224a.html</id>
    <published>2024-02-23T17:17:02.000Z</published>
    <updated>2024-02-23T17:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="阅读导航"><ahref="./20240224b.html#论文阅读方法">阅读导航</a></h1><h1 id="资源下载">资源下载</h1><h2 id="arxiv">arXiv</h2><ol type="1"><li>官网：<a href="https://arxiv.org/">arXiv</a>。</li><li>视频介绍：<ahref="https://www.bilibili.com/video/BV1pT4y1m7AF/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">【推倒论文付费墙，救人新冠疫情里，这是“反向知网”arXiv的30年】</a>。</li></ol><p>  arXiv是免费的、可供下载的论文库。是一个论文预印版网站。预印本（Preprint）是指科研工作者的研究成果还未在正式出版物上发表，而出于和同行交流目的自愿先在学术会议上或通过互联网发布的科研论文、科技报告等文章。而另一方面，arXiv有独特的作用：为了防止自己的idea 在论文被收录前被别人剽窃，可以将预稿上传到 arXiv作为预收录，因此这就是个可以证明论文原创性（上传时间戳）的文档收录网站。</p>]]></content>
    
    
    <summary type="html">🎗本文记录学习论文的资源和方法</summary>
    
    
    
    <category term="阅读" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="阅读方法" scheme="https://www.adunas.top/tags/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读：一种基于目测的未知目标运动分析方位角方法</title>
    <link href="https://www.adunas.top/posts/20240223a.html"/>
    <id>https://www.adunas.top/posts/20240223a.html</id>
    <published>2024-02-23T14:30:12.000Z</published>
    <updated>2024-02-23T14:30:12.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note blue no-icon flat"><ol type="1"><li>b站视频：<ahref="https://www.bilibili.com/video/BV1EC411z7Lz/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">【【IJRR最新成果】利用被忽视的视觉信息大幅提升目标定位可观性】</a></li><li>论文资源：<a href="https://arxiv.org/abs/2401.17117">A Bearing-AngleApproach for Unknown Target Motion Analysis Based on VisualMeasurements</a></li></ol></div><h1 id="阅读导航"><ahref="./20240224b.html#一种基于目测的未知目标运动分析方位角方法">阅读导航</a></h1><h1 id="abstract">Abstract</h1><p>  Vision-based estimation of the motion of a moving target is usuallyformulated as a <em>bearing-only</em> estimation problem where thevisual measurement is modeled as a bearing vector. Although thebearing-only approach has been studied for decades, a <em>fundamentallimitation</em> of this approach is that it requires extra lateralmotion of the observer to enhance the target's observability.Unfortunately, the extra lateral motion conflicts with the desiredmotion of the observer in many tasks. It is well-known that, once atarget has been detected in an image, a bounding box that surrounds thetarget can be obtained. Surprisingly, this common visual measurementespecially its size information has not been well explored up to now. Inthis paper, we propose a new <em>bearing-angle</em> approach to estimatethe motion of a target by modeling its image bounding box asbearing-angle measurements. Both theoretical analysis and experimentalresults show that this approach can significantly enhance theobservability <em>without</em> relying on additional lateral motion ofthe observer. The benefit of the bearing-angle approach comes with noadditional cost because a bounding box is a standard output of objectdetection algorithms. The approach simply exploits the information thathas not been fully exploited in the past. No additional sensing devicesor special detection algorithms are required.</p><details class="folding-tag" blue><summary> 注解 </summary>              <div class='content'>              <div id="分栏" class="tabs"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#分栏-1">音频</button></li><li class="tab"><button type="button" data-href="#分栏-2">概括</button></li></ul><div class="tab-contents"><div id="分栏-1" class="tab-item-content active"><div id="aplayer20240223a"></div><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div id="分栏-2" class="tab-item-content"><p>这些文字很多废话。总结就是：没有利用多余的传感器，而是用视觉新的信息：物体框作为新的观测值，提高了方位角的精度。同时不需要运动物体做额外的横向运动。</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>              </div>            </details><h1 id="keywords">Keywords</h1><p>Bearing-only target motion estimation, Pseudo-linear Kalman filter,Observability enhancement</p><h1 id="introduction">Introduction</h1><p>  This paper studies the problem of estimating the motion of a movingtarget object using a moving monocular camera. The target's geometricinformation such as its physical size is <em>unknown</em> in advance.This problem is important in many fields . Our present work isparticularly motivated by the task of aerial target pursuit, where amicro aerial vehicle (MAV) uses its onboard camera to detect, localize,and then pursue another flying MAV. The task of aerial target pursuit,originally motivated by the interesting bird-catching-bird behaviors innature , potentially provides an effective approach to the defense ofmisused MAV.</p><figure id="fig_architecture_outdoor"></figure><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_outdoor.png" /><figcaption><b>Figure 1.</b> An observer MAV observes a target MAV with a monocular camera. The bearing $g$ and angle $\theta$ can be obtained from the bounding box that surrounds the target in the image.</figcaption><p>  When a target has been detected in an image by a vision detectionalgorithm, we usually obtain a <em>bounding box</em> that surrounds thetarget's image (see Fig. <a href="#fig_architecture_outdoor"data-reference-type="ref"data-reference="fig_architecture_outdoor">1</a>). The bounding boxcarries two types of useful information that can be used to estimate thetarget's motion.</p><p>  The first type of useful information is the <em>center point</em>of the bounding box. The pixel coordinate of the center point can beused to calculate the spatial <em>bearing vector</em> pointing from thecamera to the target based on the pin-hole camera model <spanclass="citation" data-cites="Ma2012">[@Ma2012]</span>. Using the bearingvector to estimate the target's motion is referred to as<em>bearing-only</em> target motion estimation <span class="citation"data-cites="Fogel1988 He2019 Li2022">[@Fogel1988; @He2019;@Li2022]</span>. As a problem that has been studied for more than 40years, bearing-only target motion estimation was originally studied toestimate the motion of ships on the ocean surface <span class="citation"data-cites="hoelzer1978modified">[@hoelzer1978modified]</span>, andregained increasing research attention in recent years in vision-basedtarget estimation tasks <span class="citation"data-cites="Ponda2009 Anjaly2018 He2019">[@Ponda2009; @Anjaly2018;@He2019]</span>.</p><p>  Bearing-only target motion estimation requires an <em>observabilitycondition</em>: The observer must have higher-order motion than thetarget and, more importantly, the higher-order motion must containcomponents that are orthogonal to the target's bearing vector <spanclass="citation" data-cites="Fogel1988">[@Fogel1988]</span>. Motivatedby this observability condition, enormous works have studied how anobserver should move to enhance the observability <span class="citation"data-cites="Hammel1989 Sabet2016 Anjaly2018 He2019">[@Hammel1989;@Sabet2016; @Anjaly2018; @He2019]</span>. For instance, in our recentwork <span class="citation" data-cites="Li2022">[@Li2022]</span>, weproposed a helical guidance law so that a MAV moves along a helicalcurve to optimize the observability in the 3D space.</p><p>  A <em>limitation</em> of the observability condition of the classicbearing-only approach is that the observer must move in the lateraldirections that are orthogonal to the bearing vector of the target. Suchadditional lateral motion is usually unfavorable because it may conflictwith the desired motion of the observer in many tasks. For example, inan aerial target pursuit task, the pursuer is desired to approach thetarget as fast as possible and then keep stationary relative to thetarget. Then, the additional lateral motion would conflict with thedesired motion. It is, therefore, important to study other ways that canenhance the observability while avoiding unfavorable lateral motion.</p><p>  The second type of useful information of a bounding box is its<em>size</em> (either width or height). The size of a bounding box isjointly determined by several factors such as the target's distance, thetarget's physical size, and the orientation of the camera. The target'sphysical size is usually unknown in many tasks, especially in thoseantagonistic ones such as aerial pursuit of misused MAVs. As a result,the size of the bounding box cannot directly infer the target'sdistance. Nevertheless, it carries valuable information for localizingthe target.</p><p>  Surprisingly, the size information of the bounding box has not beenwell explored so far. The work that is closely relevant to ours is thestate-of-the-art one in <span class="citation"data-cites="Griffin2021">[@Griffin2021]</span>, where the size of abounding box is used to localize unknown target objects. Although theapproach in <span class="citation"data-cites="Griffin2021">[@Griffin2021]</span> is inspiring, it relieson two assumptions: The target objects are stationary and the camera canonly translate without rotating. It is still an open problem how toestimate a target's motion when the two assumptions are not valid.Moreover, the theoretical role of the size of a bounding box in targetmotion estimation has not been fully understood so far. Although thework in <span class="citation" data-cites="Vrba2020">[@Vrba2020]</span>also utilizes the size of the bounding box to estimate the target'sposition, it is assumed that the target's physical size is known inadvance.</p><p>  Estimating the motion of moving objects is also a fundamentalproblem in dynamic SLAM. For example, the works in <spanclass="citation" data-cites="Yang2019 Qiu2019">[@Yang2019;@Qiu2019]</span> firstly estimate the camera's pose and secondlyestimate the target object's pose subject to a scale factor, and finallyestimate the scale factor from multi-view measurements. To estimate thetarget object's pose subject to a scale factor, <span class="citation"data-cites="Yang2019">[@Yang2019]</span> and <span class="citation"data-cites="Qiu2019">[@Qiu2019]</span> rely on detecting, respectively,a 3D bounding box and sufficient feature points inside the 2D boundingbox. Different from <span class="citation"data-cites="Yang2019 Qiu2019">[@Yang2019; @Qiu2019]</span>, our proposedapproach merely utilizes a 2D image bounding box without furtherextracting feature points or a 3D bounding box inside the 2D boundingbox. As a result, one benefit is that this approach is morecomputationally efficient. Moreover, this approach can handle thechallenging small-target case where the target object is far and henceits image is small. In this case, it would be unreliable to extractsufficient stable features or conduct 3D detection.</p><p>  The aforementioned approaches in <span class="citation"data-cites="Griffin2021 Yang2019 Qiu2019">[@Griffin2021; @Yang2019;@Qiu2019]</span> are all based on multiple views. It is also possible toestimate the target's depth from a single view/image <spanclass="citation" data-cites="Tekin2018 Vrba2020">[@Tekin2018;@Vrba2020]</span>. The single-view approach however requires priorinformation of the objects. Moreover, it would be unable to successfullylocalize target objects with different sizes but similar appearances. Inthis paper, we focus on the multi-view case.</p><p>  In this paper, we propose a novel <em>bearing-angle</em> targetmotion estimation approach that models a bounding box as bearing-anglemeasurements. This approach can enhance the observability by fullyexploiting the information in a bounding box rather than relying on theadditional lateral motion of the observer. The benefit of the proposedbearing-angle approach comes with no additional cost since the boundingbox is a standard output of object detection algorithms. The approachsimply exploits the angle information that has not been fully exploitedin the past. No additional sensing devices or special detectionalgorithms are required.</p><p>  The technical novelties of this approach are threefold.</p><p>1) The proposed approach does not directly use the size of a boundingbox because the size is variant to the orientation of the camera. Thatis, even if the target's relative position is unchanged, the size of thebounding box still varies when the camera rotates. Motivated by thisproblem, we convert the size of the bounding box to an angle subtendedby the target (see Fig. <a href="#fig_architecture_outdoor"data-reference-type="ref"data-reference="fig_architecture_outdoor">1</a>). The merit of using theangle measurement is that it is <em>invariant</em> to the camera'sorientation change (see Fig. <a href="#fig_cam_rotate"data-reference-type="ref" data-reference="fig_cam_rotate">2</a>) andhence can greatly facilitate the estimator design. In this way, theassumption in <span class="citation"data-cites="Griffin2021">[@Griffin2021]</span> that the camera can onlytranslate but not rotate can be avoided.</p><p>2) Although the bearing-angle approach incorporates an additionalangle measurement, it is nontrivial to see how to properly use thismeasurement because the angle does not directly infer the target'sdistance given that the target's size is unknown. We notice that theangle is a joint nonlinear function of the target's physical size andrelative distance. Hence, the state vector, which only consists of thetarget's position and velocity in the conventional bearing-onlyapproach, is augmented by the unknown target's physical size. Since thebearing and angle measurements are all nonlinear functions of thetarget's state, we establish a pseudo-linear Kalman filter to properlyutilize the measurements to enhance estimation stability. Bothsimulation and real-world experiments verify the effectiveness of theproposed estimator.</p><p>3) Although an additional angle measurement is used, an additionalunknown, the target's physical size, is also introduced into theestimator. It is, therefore, nontrivial to see how the additional anglemeasurement can help improve the observability. Motivated by thisproblem, we prove the necessary and sufficient observability conditionfor bearing-angle target motion estimation. In particular, we show thatthe target's motion can be recovered if and only if the observer has ahigher-order motion than the target. Different from the bearing-onlycase, the higher-order motion is <em>not</em> required to be in thelateral directions that are orthogonal to the bearing vector. This is animportant enhancement of the observability. As we show in variousexperiments, the bearing-angle approach can successfully recover thetarget's motion in many scenarios where the bearing-only approachfails.</p><h1 id="related-work">Related Work</h1><h2 id="algorithms-for-bearing-only-target-motion-estimation">Algorithmsfor bearing-only target motion estimation</h2><p>  Bearing-only target motion analysis aims to estimate the target'smotion states, such as position and velocity, using bearing measurementonly. It was originally motivated by ship localization and tracking inthe ocean <span class="citation"data-cites="hoelzer1978modified">[@hoelzer1978modified]</span>. With therapid development of small-scale mobile robots equipped with cameras,the bearing-only approach regained increasing attention in recent years<span class="citation"data-cites="Ponda2009 Anjaly2018 He2019">[@Ponda2009; @Anjaly2018;@He2019]</span>.</p><p>  Kalman filter-based estimators are widely used in the bearing-onlytarget motion. One challenge of applying the Kalman filter to thebearing-only estimation is the nonlinearity of the bearing measurement.The conventional extended Kalman filter (EKF) exhibits divergenceproblems when applied to bearing-only target motion estimation <spanclass="citation" data-cites="Aidala1979 Lin2002">[@Aidala1979;@Lin2002]</span>. Several methods have been proposed to solve thisproblem. They can be divided into two types. The first type is themodified polar EKF, which was first proposed in <span class="citation"data-cites="hoelzer1978modified">[@hoelzer1978modified]</span>. In thisapproach, three observable quantities are separated from theunobservable ones to prevent divergence. The work in <spanclass="citation" data-cites="Stallard1991">[@Stallard1991]</span>extends this approach to the case of spherical coordinates to tracktargets in 3D space. The second type is the pseudo-linear Kalman filter,which is first proposed in <span class="citation"data-cites="Lingren1978">[@Lingren1978]</span> to solve the instabilityproblem by transforming the nonlinear measurement equation into apseudo-linear one. However, this transformation makes the noise becomenon-Gaussian and highly correlated to the measurement matrix and thencauses estimation bias. Nevertheless, the work in <span class="citation"data-cites="Aidala1982">[@Aidala1982]</span> theoretically proves thatthe velocity estimation has no bias, and the position estimation biascan be removed by the observer's maneuvers.</p><p>  Recently, other estimation algorithms based on advanced but morecomplex filters have been proposed. The work in <span class="citation"data-cites="Farina1999">[@Farina1999]</span> uses the maximum likelihood(MLE) algorithm to estimate the target's motion using bearing-onlymeasurements. The comparison with the Cramer-Rao lower bound indicatesthat the MLE-based estimator is effective against measurement errors.The work in <span class="citation"data-cites="Dogancay2005">[@Dogancay2005]</span> proposes a constrainedtotal least-squares algorithm, which can improve the estimation accuracywhen the error of bearing measurement is large. Three differentalgorithms are used and compared in <span class="citation"data-cites="Lin2002">[@Lin2002]</span>. The results show that the EKF,the pseudo-linear filter, and the particle filter have similarperformances in most situations, while the EKF loses track when theinitial estimate error is large.</p><p>  Another type of approach, called bearing-only trajectorytriangulation <span class="citation"data-cites="Avidan2000">[@Avidan2000]</span>, estimates the target'sposition from the perspective of trajectory fitting. It reconstructs thetrajectory by intersecting parametric trajectory to a series of sightrays obtained from bearing measurement. Once the trajectory issuccessfully fitted, the target's position at each time instant can beestimated by the intersection of the bearing and the trajectory. Thetrajectory fitting relies on the assumption of the trajectory's shape.However, in many applications, the target's trajectory is complex andunknown in advance. Many consecutive studies aim to relax thisassumption in various ways based on hypersurfaces <span class="citation"data-cites="Kaminski2004">[@Kaminski2004]</span>, parametric temporalpolynomials <span class="citation" data-cites="Yu2009">[@Yu2009]</span>,or compact basis vectors <span class="citation"data-cites="Park2015">[@Park2015]</span>.</p><h2id="observability-analysis-of-bearing-only-target-motion-estimation">Observabilityanalysis of bearing-only target motion estimation</h2><p>  Observability is a fundamental problem in bearing-only targetmotion estimation. Early works mainly focus on whether the system isobservable or not. For example, the work in <span class="citation"data-cites="Lingren1978">[@Lingren1978]</span> uses the rank ofobservation matrix to determine the observability. The work in <spanclass="citation" data-cites="Fogel1988">[@Fogel1988]</span> extends theobservability criterion in <span class="citation"data-cites="Nardone1981">[@Nardone1981]</span> to the Nth-order targetdynamics and inspires us for the observability analysis in Section <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.All these conditions indicate that the observer must have extrahigh-order motion in the lateral direction. The observability conditioncan be significantly relaxed in our approach.</p><p>  Unlike the works on determining whether the system is observable ornot, some studies focus on quantifying the observability degree. Thework in <span class="citation"data-cites="Hammel1989">[@Hammel1989]</span> first introduces the Fisherinformation matrix (FIM) into the observability analysis. The works in<span class="citation" data-cites="Sabet2016">[@Sabet2016]</span> and<span class="citation" data-cites="Anjaly2018">[@Anjaly2018]</span> useFIM-based objective functions to maximize observability. We also use theFIM in our former work <span class="citation"data-cites="Li2022">[@Li2022]</span> to optimize the 3D helical guidancelaw for better observability. Another method called the geometric methoduses the geometric relationship between the target and the observer intwo consecutive time instants to derive the measure of observability<span class="citation" data-cites="He2019 Woffinden2009">[@He2019;@Woffinden2009]</span>, and the results are consistent with thosederived using FIM. Compared to the bearing-only approach, theobservability degree of our bearing-angle method is sufficient toestimate the target's motion in many common scenarios such as trackingand guidance (see experiment results in Figs. <a href="#fig_matlab_3"data-reference-type="ref"data-reference="fig_matlab_3">[fig_matlab_3]</a> and <ahref="#fig_outdoor_1" data-reference-type="ref"data-reference="fig_outdoor_1">[fig_outdoor_1]</a>).</p><h1 id="problem-formulation">Problem Formulation</h1><figure id="fig_cam_rotate"></figure><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_cam_rotate.png" /><figcaption><b>Figure 2.</b> The size of the bounding box varies when the camera rotates. By contrast, the angle subtended by the target object is invariant to the camera's orientation change.</figcaption><p>  Consider a target object moving in the 3D space. Its position andvelocity at time <span class="math inline">\(t_k\)</span> are denoted as<span class="math inline">\(p_T(t_k) \in\mathbb{R}^3\)</span> and <spanclass="math inline">\(v_T(t_k) \in\mathbb{R}^3\)</span>, respectively.Suppose there is an observer carrying a monocular camera to observe thetarget. The position of the observer is denoted as <spanclass="math inline">\(p_o(t_k) \in\mathbb{R}^3\)</span>. Here, we assumethat the observer/camera's pose including its position and orientationcan be obtained in other ways. For example, it can be measured directlyby RTK GPS <span class="citation" data-cites="Li2022">[@Li2022]</span>or estimated by visual inertial odometry <span class="citation"data-cites="Qiu2019">[@Qiu2019]</span>. In the rest of the paper, thedependence of a variable on <span class="math inline">\(t_k\)</span> isdropped when the context is clear.</p><p>  If the target object can be detected by a vision algorithm, we canobtain a bounding box surrounding the target object in the image. Twotypes of information carried by the bounding box can be used to estimatethe motion of the target.</p><p>  First, the center point of the bounding box can be used tocalculate the <em>bearing</em> vector of the target. In particular,denote <span class="math inline">\(g \in \mathbb{R}^3\)</span> as theunit bearing vector pointing from <spanclass="math inline">\(p_o\)</span> to <spanclass="math inline">\(p_T\)</span>. Suppose <spanclass="math inline">\(p_\text{cam}\in\mathbb{R}^{3\times3}\)</span> isthe intrinsic parameter matrix of the camera (<span class="citation"data-cites="Ma2012">@Ma2012</span> Section <ahref="#bearing-angle-target-motion-estimator">4</a>), and <spanclass="math inline">\({R}_\text{c}^\text{w} \in\mathbb{R}^{3\times3}\)</span> is the rotation from the camera frame to the worldframe.</p><p>Then, the bearing vector <span class="math inline">\(g\)</span> canbe calculated as</p><p><span class="math display">\[\begin{aligned}g =\dfrac{{R}_\text{c}^\text{w}p_\text{cam}^{-1}{q}_{\rm pix}}{\|{R}_\text{c}^\text{w}p_\text{cam}^{-1}{q}_{\rm pix}\|},\end{aligned}\]</span></p><p>where <span class="math inline">\({q}_{\rm pix} =[x_{\rm pix} ,y_{\rm pix} , 1]^\mathrm{T} \in \mathbb{R}^3\)</span>. Here, <spanclass="math inline">\((x_{\rm pix} ,y_{\rm pix})\)</span> is the pixelcoordinate of the center point of the bounding box.</p><p>  Second, the size of the bounding box can be used to calculate the<em>angle</em> subtended by the target in the camera's field of view.The reason that we convert the bounding box's size to the angle is thatthe angle is invariant to the camera's orientation change (see Fig. <ahref="#fig_cam_rotate" data-reference-type="ref"data-reference="fig_cam_rotate">2</a>). In particular, let <spanclass="math inline">\(s_{\rm pix}\)</span> denote the size of thebounding box. It can be either the width or the height. Let <spanclass="math inline">\(\theta \in (0,\pi/2)\)</span> be the angle.According to the pin-hole camera model <span class="citation"data-cites="Ma2012">[@Ma2012Section [4](#bearing-angle-target-motion-estimator)]</span> and the lawof cosine (see Fig. <a href="#fig_cam_rotate" data-reference-type="ref"data-reference="fig_cam_rotate">2</a>), the angle can be calculated as<span class="math display">\[\begin{aligned}\theta = \arccos\left(\dfrac{l_\mathrm{left}^2 + l_\mathrm{right}^2 -s_\mathrm{pix}^2}{2l_\mathrm{left}l_\mathrm{right}}\right),\end{aligned}\]</span> where <spanclass="math inline">\(l_\mathrm{left}=\sqrt{(f/\alpha)^2+(\deltax-s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}\)</span> and <spanclass="math inline">\(l_\mathrm{right}=\sqrt{(f/\alpha)^2+(\deltax+s_\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}\)</span> are thedistances in pixel from the camera center to the middle points of theleft and right sides of the bounding box, respectively (Fig. <ahref="#fig_architecture_outdoor" data-reference-type="ref"data-reference="fig_architecture_outdoor">1</a>). Moreover, <spanclass="math inline">\(f\)</span> and <spanclass="math inline">\(\alpha\)</span> denote the camera's focal lengthand single pixel size, respectively. <spanclass="math inline">\(i_{\text{width}}\)</span> and <spanclass="math inline">\(i_{\text{height}}\)</span> represent the width andthe height of the whole image in pixels, respectively. <spanclass="math inline">\(\deltax=\|x_\text{pix}-i_\text{width}/2\|\in\mathbb{R}\)</span> and <spanclass="math inline">\(\delta y =\|y_\text{pix}-i_\text{height}/2\|\in\mathbb{R}\)</span> are thedistances between the center of the bounding box and the center of theimage.</p><figure id="fig_architecture_algorithm"></figure><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_algorithm.png" /><figcaption><b>Figure 3.</b> The architecture of the proposed approach. All the simulation and real-world experiments in this paper follow this architecture.</figcaption><p>Our goal is to estimate the target's position and velocity, <spanclass="math inline">\(p_T\)</span> and <spanclass="math inline">\(v_T\)</span>, based on the noisy measurements ofthe bearing vector <span class="math inline">\(g\)</span> and the angle<span class="math inline">\(\theta\)</span> together with the observer'sown position <span class="math inline">\(p_o\)</span>. To achieve thisgoal, we propose a new bearing-angle target motion estimator (Fig. <ahref="#fig_architecture_algorithm">3</a>). The estimator is introducedin detail in Section <ahref="#bearing-angle-target-motion-estimator">4</a>. The observabilityof this estimator is analyzed based on Kalman's observability criterionin Section <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>.We further prove a necessary and sufficient observability condition ofthe observer in Section <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.Numerical simulation results are given in Section <ahref="#Numerical%20Simulation%20Results" data-reference-type="ref"data-reference="Numerical Simulation Results">7</a>. More realisticAirSim simulation results are given in Section <ahref="#AirSim%20Simulation%20Results" data-reference-type="ref"data-reference="AirSim Simulation Results">8</a>. Finally, real-worldexperiments are given in Section <ahref="#Real-World%20Experimental%20Results" data-reference-type="ref"data-reference="Real-World Experimental Results">9</a>.</p><p><a id="bearing-angle-target-motion-estimator"></a></p><h1 id="bearing-angle-target-motion-estimator">Bearing-Angle TargetMotion Estimator</h1><p>This section designs a bearing-angle target motion estimator based onthe framework of pseudo-linear Kalman filtering. The key here is toestablish appropriate measurement and state transition equations.</p><h2 id="states-transition-equation">States transition equation</h2><p>  The state vector of the target is designed as</p><p><span class="math display">\[\begin{aligned}{x}=\left[  \begin{array}{c}    p_T \\    v_T \\    \ell \\  \end{array}\right]\in \mathbb{R}^7,\end{aligned}\]</span> where <span class="math inline">\(p_T\)</span>and <span class="math inline">\(v_T\)</span> are target's globalposition and velocity, respectively. Here, <spanclass="math inline">\(\ell&gt;0\)</span> is a scalar that represents thephysical size of the target object in the dimension that is orthogonalto the bearing vector (Fig. <a href="#fig_cam_rotate"data-reference-type="ref" data-reference="fig_cam_rotate">2</a>). Inthis paper, <span class="math inline">\(\ell\)</span> is assumed to beconstant or varying slowly, which means that the physical size of thetarget object should be approximately invariant from different viewingangles. Here, <span class="math inline">\(\ell\)</span> corresponds to<span class="math inline">\(\theta\)</span>, which further correspondsto either the width or height of the bounding box. Whether <spanclass="math inline">\(\ell\)</span> should correspond to the width orheight depends on in which dimension the physical size of the targetobject is invariant when viewed from different angles. More explanationis given in Section <ahref="#Dynamic%20modeling%20of%20target&#39;s%20physical%20size"data-reference-type="ref"data-reference="Dynamic modeling of target&#39;s physical size">4.2</a>.</p><p>Different from the bearing-only case where the state merely consistsof the position and velocity, the state here is augmented by thetarget's physical size. This is due to the fact that the anglemeasurement is a function of the target's physical size, which should beestimated as well. One may wonder whether the state vector can alsoincorporate the target's acceleration. To estimate high-order motion(e.g., acceleration) of the target, the observer must have higher-ordermotion (e.g., nonzero jerk) according to the observability conditionpresented in Section <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.Otherwise, the estimation would diverge. Therefore, it is preferred toexclude the acceleration and merely estimate the position andvelocity.</p><p>If no information of the target's motion is available, it is commonto model the target's motion as a discrete-time noise-driven doubleintegrator: <span class="math display">\[\begin{aligned}\label{eq_state_transition}    {x}(t_{k+1})={F}{x}(t_k) +{q}(t_k) ,\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_matrix_A}{F}=\begin{bmatrix}{I}_{3\times3} &amp; \delta t{I}_{3\times3} &amp; {0}_{3\times1}  \\{0}_{3\times3} &amp; {I}_{3\times3}  &amp; {0}_{3\times1}   \\{0}_{1\times 3} &amp; {0}_{1\times 3} &amp; 1\end{bmatrix}\in\mathbb{R}^{7\times 7},\end{aligned}\]</span> with <span class="math inline">\(\deltat\)</span> as the sampling time, and <spanclass="math inline">\({I}\)</span> and <spanclass="math inline">\({0}\)</span> as the identity and zero matrices,respectively. Here, <span class="math inline">\({q}\in\mathbb{R}^7\)</span> is a zero-mean process noise satisfying <spanclass="math inline">\({q} \sim \mathcal{N}(0,{\Sigma}_q)\)</span>, wherethe covariance matrix is <span class="math display">\[\begin{aligned}{\Sigma}_q=\text{diag}(0, 0, 0, \sigma_v^2, \sigma_v^2, \sigma_v^2,\sigma_\ell^2)\in\mathbb{R}^{7\times7}.\end{aligned}\]</span> Here, <spanclass="math inline">\(\sigma_v\in\mathbb{R}\)</span> and <spanclass="math inline">\(\sigma_\ell\in\mathbb{R}\)</span> are the standarddeviations of the target's velocity and size, respectively. When thetarget's shape is irregular, <span class="math inline">\(\ell\)</span>may vary when viewed from different angles. By letting <spanclass="math inline">\(\sigma_\ell\ne0\)</span>, we can handle the casewhere <span class="math inline">\(\ell\)</span> varies slowly. Thedynamic modeling of <span class="math inline">\(\ell\)</span> isdiscussed in the following subsection.</p><h2 id="dynamic-modeling-of-targets-physical-size">Dynamic modeling oftarget's physical size</h2><p>  Since the target's physical size <spanclass="math inline">\(\ell\)</span> is a state variable to be estimated,it is important to discuss its dynamic model. In fact, the dynamic modelof <span class="math inline">\(\ell\)</span> in <ahref="#eq_state_transition" data-reference-type="eqref"data-reference="eq_state_transition">[eq_state_transition]</a> assumesthat <span class="math inline">\(\ell\)</span> varies slowly. We nextjustify this modeling and provide more discussion.</p><p>First of all, <span class="math inline">\(\ell\)</span> correspondsto the physical size of the target object in the dimension that isorthogonal to the bearing vector. Its dynamics can be categorized intothree cases.</p><p><em>1) <span class="math inline">\(\ell\)</span> is invariant.</em>In theory, when <span class="math inline">\(\ell\)</span> is invariant,a change of <span class="math inline">\(\theta\)</span> implies a changeof <span class="math inline">\(r\)</span>. As a result, the measurementof <span class="math inline">\(\theta\)</span> can help improve thesystem's observability, as proven in Section <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>.An ideal case where <span class="math inline">\(\ell\)</span> isinvariant is that the target object is a sphere or cylinder so that<span class="math inline">\(\ell\)</span> corresponds to its diameter<span class="citation" data-cites="Vrba2020">[@Vrba2020]</span>. Inpractice, the target object does not have to be the ideal case. Forexample, consider an autonomous driving scenario where a focal vehicleuses a camera to localize its surrounding vehicles in the 2D plane.Although the physical size of a surrounding vehicle changes greatly whenviewed from behind or side, the height of the vehicle is<em>invariant</em> from different side-view angles. In this case, <spanclass="math inline">\(\ell\)</span> corresponds to the height of thevehicle, and we need to use the height of the image bounding box tocalculate <span class="math inline">\(\theta\)</span>.</p><p><em>2) <span class="math inline">\(\ell\)</span> varies slowly.</em>If there does not exist any dimension in which the physical size of thetarget remains invariant, <span class="math inline">\(\ell\)</span> mayvary slowly when the target is viewed from different angles. Forexample, in the tasks of aerial target pursuit, if the target is aquadcopter or hexacopter, then <span class="math inline">\(\ell\)</span>is approximately equal to the wheelbase but may vary slightly whenviewed from different angles since the MAV is not a perfect cylinder. Inthis case, <span class="math inline">\(\ell\)</span> corresponds to thewheelbase of the MAV, and we need to use the width of the image boundingbox to calculate <span class="math inline">\(\theta\)</span>.</p><p>If <span class="math inline">\(\ell\)</span> varies slowly, it canstill be treated as invariant within short time intervals. As long asthe observability condition (Section <ahref="#Observability%20Analysis%20by%20Solving%20Linear%20Equations"data-reference-type="ref"data-reference="Observability Analysis by Solving Linear Equations">6</a>)is satisfied, the motion of the target as well as <spanclass="math inline">\(\ell\)</span> can be successfully estimated. Thisfact is supported by the experimental results in Section <ahref="#Scenario%202:%20Circular%20motion%20and%20varying%20$\ell$"data-reference-type="ref"data-reference="Scenario 2: Circular motion and varying $\ell$">8.4</a>.It is however worth nothing that the performance of the proposedbearing-angle approach would degenerate to the conventional bearing-onlyone because the additional information brought by <spanclass="math inline">\(\theta\)</span> is used to estimate thetime-varying <span class="math inline">\(\ell\)</span> rather thanhelping improve the system's observability.</p><p><em>3) <span class="math inline">\(\ell\)</span> varies rapidly.</em>If <span class="math inline">\(\ell\)</span> varies rapidly due tocertain reasons, it would be difficult to distinguish whether the changeof <span class="math inline">\(\theta\)</span> is caused by the changeof <span class="math inline">\(\ell\)</span> or the change of <spanclass="math inline">\(r\)</span>. For example, when a MAV is used totrack a ground vehicle, <span class="math inline">\(\ell\)</span> in anydimension may vary rapidly when the relative motion between the MAV andthe ground vehicle is highly dynamic. In such scenarios, the additionalinformation brought by <span class="math inline">\(\theta\)</span> is nolonger sufficient to estimate the rapidly varying <spanclass="math inline">\(\ell\)</span> in this case. Additional visualinformation such as a 3D bounding box that indicates the target's 3Dattitude is required. This is an important topic for future research butout of the scope of the present paper.</p><h2 id="nonlinear-measurement-equations">Nonlinear measurementequations</h2><p>The bearing vector <span class="math inline">\(g\)</span> and thesubtended angle <span class="math inline">\(\theta\)</span> are bothnonlinear functions of the target's position. In particular, <spanclass="math display">\[\label{eq_information}\begin{align}    g &amp;=\dfrac{p_T -p_o }{r },    \label{eq_bearing_measure} \\    \theta &amp;=2\arctan\left(\dfrac{\ell}{2r }\right)\approx\dfrac{\ell}{r },    \label{eq_theta_measure}\end{align}\]</span> where <span class="math display">\[r =\|p_T -p_o\|\]</span> is the distance between the target and the observer. It isnotable that there is an approximation in <a href="#eq_theta_measure"data-reference-type="eqref"data-reference="eq_theta_measure">[eq_theta_measure]</a>. Thisapproximation is accurate. Specifically, when <spanclass="math inline">\(r&gt;3\ell\)</span>, which is common in practice,it can be verified that the approximation error is less than <spanclass="math inline">\(0.08\%\)</span>. The approximation error furtherdecreases as <span class="math inline">\(r\)</span> increases.</p><p>In practice, measurements always contain noises. First, denote <spanclass="math inline">\(\hat{g} \in\mathbb{R}^3\)</span> as thenoise-corrupted bearing measurement. Then, we have <spanclass="math display">\[\begin{aligned}\label{eq_noised_g_mear}\hat{g}  = {R}\left({\eta} , \epsilon \right) g ,\end{aligned}\]</span> where <span class="math inline">\({R}\left({\eta}, \epsilon \right) \in \mathbb{R}^{3\times 3}\)</span> is a rotationmatrix that perturbs <span class="math inline">\(g\)</span>. Here, <spanclass="math inline">\({\eta} \in\mathbb{R}^3\)</span> is a unit vectorrepresenting a random rotation axis, and <spanclass="math inline">\(\epsilon \in \mathbb{R}\)</span> is a randomrotation angle. This rotation matrix would rotate the vector <spanclass="math inline">\(g\)</span> by an angle <spanclass="math inline">\(\epsilon\)</span> around the axis <spanclass="math inline">\({\eta}\)</span>. The productive noise in <ahref="#eq_noised_g_mear" data-reference-type="eqref"data-reference="eq_noised_g_mear">[eq_noised_g_mear]</a> can betransformed into an additive one: <spanclass="math display">\[\begin{aligned}\label{eq_noised_g_mear_add}    \hat{g}  = g  + {\mu} ,\end{aligned}\]</span> where <span class="math inline">\({\mu}=({R}\left({\eta} , \epsilon \right) - {I}_{3\times3})g\in\mathbb{R}^3\)</span> is the measurement noise of the bearing vector.The covariance of <span class="math inline">\(\mu\)</span> is derived inour previous work <span class="citation"data-cites="Li2022">[@Li2022]</span>. Since the covariance is complexand involves unknown true values, we can approximately treat it as aGaussian noise: <span class="math inline">\(\mu\sim\mathcal{N}(0,\sigma_\mu^2 I_{3\times 3})\)</span> <span class="citation"data-cites="Li2022">[@Li2022]</span>.</p><p>Substituting <a href="#eq_bearing_measure"data-reference-type="eqref"data-reference="eq_bearing_measure">[eq_bearing_measure]</a> into <ahref="#eq_noised_g_mear_add" data-reference-type="eqref"data-reference="eq_noised_g_mear_add">[eq_noised_g_mear_add]</a> givesthe <em>nonlinear bearing measurement equation:</em> <spanclass="math display">\[\begin{aligned}\label{eq_bearing_measure_noise}    \hat{g} &amp;=\dfrac{p_T -p_o }{r } + {\mu} .\end{aligned}\]</span></p><p>Second, denote <span class="math inline">\(\hat{\theta}\in\mathbb{R}\)</span> as the noise-corrupted measurement of thesubtended angle. Then, we have <spanclass="math display">\[\begin{aligned}\label{eq_noise_theta}    \hat{\theta} =\theta  + w ,\end{aligned}\]</span> where <span class="math inline">\(w \sim\mathcal{N}(0, \sigma^2_w)\)</span> is the measurement noise.Substituting <a href="#eq_theta_measure" data-reference-type="eqref"data-reference="eq_theta_measure">[eq_theta_measure]</a> into <ahref="#eq_noise_theta" data-reference-type="eqref"data-reference="eq_noise_theta">[eq_noise_theta]</a> yields the<em>nonlinear angle measurement equation:</em> <spanclass="math display">\[\begin{aligned}\label{eq_theta_measure_noise}    \hat{\theta} &amp;=\dfrac{\ell}{r } + w.\end{aligned}\]</span></p><h2 id="pseudo-linear-measurement-equations">Pseudo-linear measurementequations</h2><p>The measurement equations <a href="#eq_bearing_measure_noise"data-reference-type="eqref"data-reference="eq_bearing_measure_noise">[eq_bearing_measure_noise]</a>and <a href="#eq_theta_measure_noise" data-reference-type="eqref"data-reference="eq_theta_measure_noise">[eq_theta_measure_noise]</a> arenonlinear in the target's state. In the following, we convert the twoequations to be pseudo-linear and then apply pseudo-linear Kalmanfiltering to achieve better estimation stability <span class="citation"data-cites="Lin2002">[@Lin2002]</span>.</p><p>First, to convert the 3D bearing measurement to pseudo-linear, weintroduce a useful orthogonal projection matrix: <spanclass="math display">\[\begin{aligned}    p_{\hat{g} }\doteq{I}_{3\times 3}-\hat{g} \hat{g}^\mathrm{T}  \in\mathbb{R}^{3\times 3}.\end{aligned}\]</span> This matrix plays an important role in theanalysis of bearing-related estimation and control problems <spanclass="citation" data-cites="Zhao2019">[@Zhao2019]</span>. It has animportant property: <span class="math display">\[p_{\hat{g} }\hat{g}={0}_{3\times 1}.\]</span> As a result, multiplying <spanclass="math inline">\(rp_{\hat{g} }\)</span> on both side of <ahref="#eq_bearing_measure_noise" data-reference-type="eqref"data-reference="eq_bearing_measure_noise">[eq_bearing_measure_noise]</a>yields <span class="math display">\[\begin{aligned}{0}_{3\times 1}=p_{\hat{g} }(p_T -p_o) + rp_{\hat{g} }{\mu}\end{aligned}\]</span> and consequently <spanclass="math display">\[\begin{aligned}p_{\hat{g} }p_o =p_{\hat{g} }p_T  + rp_{\hat{g} }{\mu}.\end{aligned}\]</span> Rewriting this equation in terms of the target'sstate variables yields the <em>pseudo-linear bearing measurementequation:</em> <span class="math display">\[\begin{aligned}\label{eq_pseudo_linear_measurement_g_equation}p_{\hat{g} }p_o =\begin{bmatrix}p_{\hat{g} } &amp;{0}_{3\times4}\end{bmatrix}\left[  \begin{array}{c}    p_T \\    v_T \\    \ell \\  \end{array}\right]  +  rp_{\hat{g} }{\mu} .\end{aligned}\]</span> Here, <span class="math inline">\(p_{\hat{g}}p_o\)</span> on the left-hand side is the new measurement, which ispseudo-linear in the target's state variables. The reason that it iscalled "pseudo" is because the measurements also appear on theright-hand side of the equation, especially in the measurementmatrix.</p><p>Second, we convert the nonlinear angle measurement in <ahref="#eq_theta_measure_noise" data-reference-type="eqref"data-reference="eq_theta_measure_noise">[eq_theta_measure_noise]</a> tobe pseudo-linear. To that end, multiplying <span class="math inline">\(r{\hatg}\)</span> on both side of <a href="#eq_theta_measure_noise"data-reference-type="eqref"data-reference="eq_theta_measure_noise">[eq_theta_measure_noise]</a>yields <span class="math display">\[\begin{aligned}\label{eq_theta_pseudo_tem}\hat{\theta} r\hat{g}  = \ell\hat{g} +wr\hat{g} .\end{aligned}\]</span> It follows from <ahref="#eq_bearing_measure_noise" data-reference-type="eqref"data-reference="eq_bearing_measure_noise">[eq_bearing_measure_noise]</a>that <span class="math inline">\(r{\hatg}=p_T -p_o+r\mu\)</span>,substituting which into the left-hand side of <ahref="#eq_theta_pseudo_tem" data-reference-type="eqref"data-reference="eq_theta_pseudo_tem">[eq_theta_pseudo_tem]</a> gives<span class="math display">\[\begin{aligned}\hat{\theta} (p_T -p_o+r\mu)  = \ell\hat{g} +wr\hat{g}.\end{aligned}\]</span> Reorganizing the above equation gives <spanclass="math display">\[\begin{aligned}\hat{\theta} p_o  = &amp;\hat{\theta} p_T  - \ell\hat{g} +r(\hat{\theta}  {\mu}  - w \hat{g}).\end{aligned}\]</span> Rewriting this equation in terms of the target'sstate variables yields the <em>pseudo-linear angle measurementequation:</em> <span class="math display">\[\begin{aligned}\label{eq_pseudo_linear_measurement_theta_equation}\begin{aligned}\hat{\theta} p_o  =&amp;\begin{bmatrix}\hat{\theta} {I}_{3\times 3} &amp; {0}_{3\times 3}  &amp; -\hat{g}\end{bmatrix}\left[  \begin{array}{c}    p_T \\    v_T \\    \ell \\  \end{array}\right]+ r(\hat{\theta}  {\mu}  - w \hat{g} ),\end{aligned}\end{aligned}\]</span> where <span class="math inline">\(\hat{\theta}p_o\)</span> is the new measurement that is pseudo-linear in thetarget's state variables.</p><h2 id="bearing-angle-estimation-algorithm">Bearing-angle estimationalgorithm</h2><p>Combining <a href="#eq_pseudo_linear_measurement_g_equation"data-reference-type="eqref"data-reference="eq_pseudo_linear_measurement_g_equation">[eq_pseudo_linear_measurement_g_equation]</a>and <a href="#eq_pseudo_linear_measurement_theta_equation"data-reference-type="eqref"data-reference="eq_pseudo_linear_measurement_theta_equation">[eq_pseudo_linear_measurement_theta_equation]</a>gives the compact form of the measurement equation: <spanclass="math display">\[\begin{aligned}\label{eq_pseudo_linear_measurement_equations}{z} = {H} {x}  + {\nu} ,\end{aligned}\]</span> where <span class="math display">\[\begin{align}{z} &amp;=    \begin{bmatrix}    p_{\hatg} p_o   \\    \hat{\theta} p_o    \end{bmatrix}\in\mathbb{R}^6, \\{H}&amp; =    \begin{bmatrix}    p_{\hatg}  &amp; {0}_{3\times 3} &amp; {0}_{3\times 1} \\    \hat{\theta} {I}_{3\times 3} &amp; {0}_{3\times 3}  &amp; -\hat{g}    \end{bmatrix}\in\mathbb{R}^{6\times7},    \label{eq_matrix_H} \\{\nu}  &amp;=    \begin{bmatrix}    r p_{\hatg} {\mu}  \\    r (\hat{\theta}  {\mu}  - w \hat{g} )    \end{bmatrix}    \in\mathbb{R}^6.    \label{eq_final_measurement_noise}\end{align}\]</span> Here, <span class="math inline">\(\nu\)</span> canbe rewritten as a matrix form <spanclass="math display">\[\begin{aligned}    \nu=E    \begin{bmatrix}        \mu \\ w    \end{bmatrix},\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_E_mat}    E=r    \begin{bmatrix}        P_{\hatg} &amp; 0_{3\times 1}\\        \hat{\theta}I_{3\times 3} &amp; -\hatg    \end{bmatrix}\in\mathbb{R}^{6\times 4}.\end{aligned}\]</span> As a result, <spanclass="math inline">\(\nu\)</span> can be approximately treated as alinear transformation of Gaussian noises. Its covariance matrix can becalculated as <span class="math display">\[\begin{aligned}%\label{eq_final_measurement_noise_covariance}{\Sigma}_  = E\begin{bmatrix}\sigma_\mu^2 I_{3\times 3} &amp; 0_{3\times1}\\0_{1\times 3} &amp; \sigma_w^2\end{bmatrix}E^\mathrm{T}\in\mathbb{R}^{6\times6}.\end{aligned}\]</span> Although the quantities in <spanclass="math inline">\(E\)</span> such as <spanclass="math inline">\(\hatg\)</span> and <spanclass="math inline">\(\hat{\theta}\)</span> contain measurement noises,it is a common practice to treat them as deterministic quantities.Otherwise, if, for example, <span class="math inline">\(\hatg\)</span>is split to <span class="math inline">\(\hatg=g+\mu\)</span> and weconsider the noise separately, the expression of <spanclass="math inline">\(\nu\)</span> would be a complex function of thetrue values and the noises. Since the true values are unknown, thecovariance cannot be calculated. Moreover, <spanclass="math inline">\(r\)</span> in <a href="#eq_E_mat"data-reference-type="eqref" data-reference="eq_E_mat">[eq_E_mat]</a> isthe true target range, which is unknown. We can use the estimated value<span class="math inline">\(\hat{r} =\|\hat{p}_T -p_o \|\)</span> toreplace it in implementation. Here, <spanclass="math inline">\(\hatp_T\in\mathbb{R}^3\)</span> is the estimatedvalue of the target's position. This technique has been used inbearing-only target estimation <span class="citation"data-cites="He2018 Li2022">[@He2018; @Li2022]</span>.</p><p>With the state transition equation <a href="#eq_state_transition"data-reference-type="eqref"data-reference="eq_state_transition">[eq_state_transition]</a> and themeasurement equation <a href="#eq_pseudo_linear_measurement_equations"data-reference-type="eqref"data-reference="eq_pseudo_linear_measurement_equations">[eq_pseudo_linear_measurement_equations]</a>,the bearing-angle estimator can be realized by the Kalman filter. For aquick reference, we list the steps below. The prediction steps are <spanclass="math display">\[\begin{aligned}\hat^{-}(t_k) &amp;={F}\hat(t_{k-1}), \\p^{-}(t_k) &amp;= {F}p(t_{k-1}){F}^\mathrm{T} + {\Sigma}_q,\end{aligned}\]</span> where <spanclass="math inline">\(\hat^{-}(t_k)\in\mathbb{R}^7\)</span>and <spanclass="math inline">\(p^{-}(t_k)\in\mathbb{R}^{7\times7}\)</span> arethe prior estimated state and covariance matrix, respectively. Thecorrection steps are <span class="math display">\[\begin{aligned}{K}(t_k) &amp;=p^{-}(t_k){H}^\mathrm{T}(t_k)\left[{H}(t_k)p^{-}(t_k){H}^\mathrm{T}(t_k)+{\Sigma}_\nu\right]^{\dagger},\\\hat(t_k) &amp;= \hat^{-}(t_k) +{K}(t_k)\left[{z}(t_k)-{H}(t_k)\hat^{-}(t_k)\right],\\p(t_k) &amp;=\left[{I}_{7\times 7} -{K}(t_k){H}(t_k) \right]p^{-}(t_k),\end{aligned}\]</span> where <spanclass="math inline">\({K}(t_k)\in\mathbb{R}^{7\times6}\)</span> is theKalman gain matrix, <spanclass="math inline">\(\hat(t_k)\)</span> and <spanclass="math inline">\(p(t_k)\)</span> are posterior estimated state andcovariance matrix, and symbol <spanclass="math inline">\(\dagger\)</span> denotes the pseudoinverse. Theusage of pseudoinverse in the Kalman filter is a common practice toprevent the situation that <spanclass="math inline">\({H}(t_k)p^{-}(t_k){H}^\mathrm{T}(t_k)+{\Sigma}_\nu\)</span>is rank deficient <span class="citation"data-cites="YOSHIKAWA1972 Kulikov2018">[@YOSHIKAWA1972;@Kulikov2018]</span>.</p><h1 id="observability-analysis-by-kalmans-criterion">ObservabilityAnalysis by Kalman's Criterion</h1><p>Although an additional angle measurement is adopted in thebearing-angle estimator, it is nontrivial to see whether this additionalmeasurement can improve the system's observability because an additionalunknown variable, the target's physical size, is also required toestimate. It is therefore necessary to study the observabilityconditions under which the target's motion can be successfullyestimated.</p><p>In this and the next sections, we present two methods to analyze theobservability conditions. The first method, as presented in thissection, relies on Kalman's observability criterion, which is to checkthe rank of the observability matrix of a linear system. The secondmethod, as presented in the next section, relies on solving a set oflinear equations. Both methods have been adopted in the literature toanalyze the observability of estimators <span class="citation"data-cites="Zhao2015 Fogel1988">[@Zhao2015; @Fogel1988]</span>. For thebearing-angle estimator, the first method considers the specificdynamics of the filter but is not able to handle the case when thetarget's motion has a higher order. The second method can handle thehigh-order motion of the target but does not consider the dynamics ofthe filter. We will show that the conclusions given by the two methodsare consistent. In both of the methods, we consider the case where <spanclass="math inline">\(\ell\)</span> is invariant.</p><h2 id="the-observability-matrix">The observability matrix</h2><p>Consider a time horizon of <span class="math inline">\(k\geq3\)</span> consecutive steps. The observability matrix of the system of<a href="#eq_matrix_H" data-reference-type="eqref"data-reference="eq_matrix_H">[eq_matrix_H]</a> and <ahref="#eq_matrix_A" data-reference-type="eqref"data-reference="eq_matrix_A">[eq_matrix_A]</a> can be calculated as<span class="math display">\[\begin{aligned}\label{eq_Qo}    {Q}=    \begin{bmatrix}    {H}(t_1) \\    {H}(t_2){F} \\    {H}(t_3){F}^2 \\    \cdots \\    {H}(t_k){F}^{k-1} \\    \end{bmatrix}\in\mathbb{R}^{6k\times7}.\end{aligned}\]</span> Substituting the expressions of <spanclass="math inline">\(F\)</span> and <spanclass="math inline">\(H\)</span> in <a href="#eq_matrix_A"data-reference-type="eqref"data-reference="eq_matrix_A">[eq_matrix_A]</a> and <ahref="#eq_matrix_H" data-reference-type="eqref"data-reference="eq_matrix_H">[eq_matrix_H]</a> into <a href="#eq_Qo"data-reference-type="eqref" data-reference="eq_Qo">[eq_Qo]</a> yields<span class="math display">\[\begin{aligned}{Q}=\left[\begin{array}{ccc}p_g(t_1) &amp; {0}_{3\times 3} &amp; {0}_{3\times 1} \\\theta(t_1){I}_{3\times 3} &amp; {0}_{3\times 3}  &amp; -g(t_1) \\\hdashlinep_g(t_2) &amp; \delta tp_g(t_2) &amp; {0}_{3\times 1} \\\theta(t_2){I}_{3\times 3} &amp; \delta t\theta(t_2){I}_{3\times3}  &amp; -g(t_2) \\\hdashline\vdots &amp; \vdots &amp; \vdots \\\hdashlinep_g(t_k) &amp; (k-1)\delta tp_g(t_k) &amp; {0}_{3\times 1} \\\theta(t_k){I}_{3\times 3} &amp; (k-1)\delta t\theta(t_k){I}_{3\times3}  &amp; -g(t_k)\\\end{array}\right].\end{aligned}\]</span> Note that the noises in the bearing and anglemeasurements are neglected when we analyze the fundamental observabilityproperty. After a series of elementary row transformations in <spanclass="math inline">\({Q}\)</span>, we can obtain <spanclass="math display">\[\begin{aligned}\label{eq_Qo_2}{Q}\rightarrow\begin{bmatrix}{I}_{3\times 3} &amp; {0}_{3\times 3} &amp; -g(t_1)/\theta(t_1) \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav(t_2)/\ell \\\vdots &amp; \vdots &amp; \vdots \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav(t_k)/\ell \\\hdashline{0}_{3k\times 3} &amp; {0}_{3k\times 3} &amp; {0}_{3k\times 1}\end{bmatrix},\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\deltav(t_k) \doteq v_T(t_k) - v_o(t_k)\end{aligned}\]</span> is the relative velocity.</p><p>In the following two subsections, we analyze the rank of theobservability matrix in two scenarios where the observer moves with zeroand nonzero acceleration, respectively. In the two scenarios, the targetis always assumed to move with a constant velocity: <spanclass="math display">\[\begin{aligned}v_T(t_k) = v_T^\text{const}.\end{aligned}\]</span></p><h2 id="case-1-the-observers-velocity-is-constant">Case 1: theobserver's velocity is constant</h2><p>Denoted <span class="math inline">\(v_o\in \mathbb{R}^3\)</span> asthe velocity of the observer. Consider the case where the observer has aconstant velocity <spanclass="math inline">\(v_o^\text{case1}(t_i)=v_o^\text{const}\)</span>for any <span class="math inline">\(i\in\{1,\dots,k\}\)</span>. Then,the relative velocity is also constant: <spanclass="math display">\[\begin{aligned}\label{eq_delta_vel_case1}\delta v^\text{case1}(t_i) = v_T^\text{const} - v_o^\text{const} =\deltav^\text{const}.\end{aligned}\]</span> Substituting <a href="#eq_delta_vel_case1"data-reference-type="eqref"data-reference="eq_delta_vel_case1">[eq_delta_vel_case1]</a> into <ahref="#eq_Qo_2" data-reference-type="eqref"data-reference="eq_Qo_2">[eq_Qo_2]</a> and conducting elementary rowtransformation yields <span class="math display">\[\begin{aligned}\label{eq_Qo_3}{Q}^\text{case1}\rightarrow\left[\begin{array}{cc:c}{I}_{3\times 3} &amp; {0}_{3\times 3} &amp; -g(t_1)/\theta(t_1) \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav^\text{const}/\ell\\\hdashline{0}_{6(k-1)\times 3} &amp; {0}_{6(k-1)\times 3} &amp; {0}_{6(k-1)\times1}\end{array}\right].\end{aligned}\]</span> Since the upper <spanclass="math inline">\(6\times7\)</span> block of <a href="#eq_Qo_3"data-reference-type="eqref" data-reference="eq_Qo_3">[eq_Qo_3]</a> hasfull row rank and the lower block is zero, the rank of <spanclass="math inline">\({Q}^\text{case1}\)</span> is <spanclass="math display">\[\begin{aligned}\text{rank}\left({Q}^\text{case1}\right) = 6.\end{aligned}\]</span> Since the number of states is seven and the rankis six, we know there is <em>one unobservable mode</em>. To identifythis unobservable mode, we calculate the unobservable subspace, which isthe null space of <span class="math inline">\({Q}\)</span>: <spanclass="math display">\[\begin{aligned}\label{eq_unobservable_subspace}\text{Null}\left({Q}^\text{case1}\right) = \text{span}\left\{\begin{bmatrix}g(t_1)/\theta(t_1)  \\\deltav^\text{const}/\ell \\1\end{bmatrix}\right\}.\end{aligned}\]</span> According to <a href="#eq_unobservable_subspace"data-reference-type="eqref"data-reference="eq_unobservable_subspace">[eq_unobservable_subspace]</a>,the unobservable mode is <span class="math display">\[\begin{aligned}x^T\left[\begin{array}{c}g(t_1)/\theta(t_1)  \\\deltav^\text{const}/\ell \\1\end{array}\right]=p_T^\mathrm{T}\dfrac{g(t_1)}{\theta(t_1)}+v_T^\mathrm{T}\dfrac{\deltav^\text{const}}{\ell} + \ell.\label{eq_unobservable_mode}\end{aligned}\]</span> Although there is only one unobservable mode,this mode given in <a href="#eq_unobservable_mode"data-reference-type="eqref"data-reference="eq_unobservable_mode">[eq_unobservable_mode]</a>involves all the states including the target's position, velocity, andphysical size. It suggests that the estimation of the three quantitiesis coupled. In conclusion, we know that, if the target moves with aconstant velocity, its states are unobservable when the observer moveswith a constant velocity.</p><h2 id="case-2-the-observers-velocity-is-time-varying">Case 2: theobserver's velocity is time-varying</h2><p>We now consider the case where the observer has nonzero accelerationso that its velocity is time-varying across the time horizon from <spanclass="math inline">\(t_1\)</span> to <spanclass="math inline">\(t_k\)</span>.</p><p>Denote <span class="math inline">\({a}_o(t_i)\in\mathbb{R}\)</span>as the observer's acceleration, which can be approximated as <spanclass="math display">\[\begin{aligned}\label{eq_acc}{a}_o(t_i) &amp;\approx\dfrac{v_o(t_i) - v_o(t_{i-1})}{\delta t} \nonumber\\&amp;=-\dfrac{\left[v_T^\text{const} - v_o(t_i)\right] -\left[v_T^\text{const} - v_o(t_{i-1})\right]}{\delta t} \nonumber\\&amp;=-\dfrac{\delta v(t_i) - \delta v(t_{i-1})}{\delta t}.\end{aligned}\]</span> Substituting <a href="#eq_acc"data-reference-type="eqref" data-reference="eq_acc">[eq_acc]</a> into <ahref="#eq_Qo_2" data-reference-type="eqref"data-reference="eq_Qo_2">[eq_Qo_2]</a> and performing elementary rowtransformation yields <span class="math display">\[\begin{aligned}\label{eq_Q_case2_final}{Q}^\text{case2}\rightarrow\left[\begin{array}{ccc}{I}_{3\times 3} &amp; {0}_{3\times 3} &amp; -g(t_1)/\theta(t_1) \\{0}_{3\times 3} &amp; {I}_{3\times 3} &amp; -\deltav(t_2)/\ell \\{0}_{3\times 3} &amp; {0}_{3\times 3} &amp; \delta t {a}_o(t_3)/\ell \\\hdashline\vdots &amp; \vdots &amp;\vdots \\{0}_{3\times 3} &amp; {0}_{3\times 3} &amp; \delta t {a}_o(t_k)/\ell \\{0}_{3k\times 3} &amp; {0}_{3k\times 3} &amp; {0}_{3k\times 1}\end{array}\right].\end{aligned}\]</span> The upper <spanclass="math inline">\(6\times7\)</span> block in <ahref="#eq_Q_case2_final" data-reference-type="eqref"data-reference="eq_Q_case2_final">[eq_Q_case2_final]</a> has full columnrank. Therefore, if <span class="math inline">\(a_o(t_i)\ne0\)</span>for any <span class="math inline">\(i\geq3\)</span>, then <spanclass="math display">\[\begin{aligned}\text{rank}\left({Q}^\text{case2}\right) = 7,\end{aligned}\]</span> Which is the same as the number of estimatedstates. Therefore, the target's state is observable when the observermoves with nonzero acceleration.</p><h2 id="summary-of-this-section">Summary of this section</h2><p>From the above analysis, we know that when the target has a constantvelocity, its states including its position, velocity, and physical sizeare observable if and only if the observer has non-zeroaccelerations.</p><p>The critical difference of this condition from the bearing-only caseis that the target's states are still observable <em>even if theobserver moves along the bearing vector</em> towards or backward thetarget. By contrast, for a bearing-only estimator, moving along thebearing vector is insufficient to recover the target's motion.Therefore, the additional lateral motion of the observer required in thebearing-only case is <em>not</em> required in the bearing-angle caseanymore, which provides better flexibility for designing the observer'smotion.</p><h1id="observability-analysis-by-solving-linear-equations">ObservabilityAnalysis by Solving Linear Equations</h1><p>This section extends the observability condition obtained in the lastsection to more general cases where the target's velocity does not haveto be constant.</p><h2 id="problem-formulation-1">Problem formulation</h2><p>The observability problem that we aim to solve is to determinewhether <span class="math inline">\(p_T(t)\)</span> can be recoveredfrom <span class="math inline">\(p_o(t)\)</span> and <spanclass="math inline">\(g(t),\theta(t)\)</span>.</p><p>Suppose the target's motion can be described by an <spanclass="math inline">\(n\)</span>th-order polynomial during a timeinterval: <span class="math display">\[\begin{aligned}\label{eq_target_nth_Order}    p_T(t)={b}_0+{b}_1t+\cdots+{b}_nt^n,\end{aligned}\]</span> where <span class="math inline">\({b}_0, {b}_1,\cdots, {b}_n\in\mathbb{R}^3\)</span> are unknown constant vectors. Ifwe can determine the values of <spanclass="math inline">\(\{b_i\}_{i=0}^n\)</span>, then we can determinethe target's motion and hence it is observable. Although polynomialscannot represent all trajectories, they can effectively approximate amajority of them according to the method of Taylor expansion. This isespecially true if we consider a short time horizon. This kind oftechnique has been adopted in the observability analysis of bearing-onlytarget motion estimation tasks <span class="citation"data-cites="Nardone1981 Lee2010">[@Nardone1981; @Lee2010]</span>.</p><p>Suppose the observer's motion is described by <spanclass="math display">\[\begin{aligned}    p_o(t)={c}_0+{c}_1t+\cdots+{c}_nt^n+{h}(t),\end{aligned}\]</span> where <span class="math inline">\({c}_0, {c}_1,\cdots, {c}_n\in\mathbb{R}^3\)</span> are constant parameters, and <spanclass="math display">\[\begin{aligned}\label{eq_definition_h}{h}(t) = {d}_1 t^{n+1}+{d}_2t^{n+2}+\cdots\end{aligned}\]</span> represents <em>higher-order</em> motion with<span class="math inline">\({d}_1, {d}_2,\cdots\in\mathbb{R}^3\)</span>. It can be verified that the derivativesof <span class="math inline">\({h}(t)\)</span> satisfy <spanclass="math inline">\({h}^{(i)}(0)={0}_{3\times 1}\)</span> for <spanclass="math inline">\(i=0,1,\cdots, n\)</span>. Let <spanclass="math inline">\({s}(t)\in\mathbb{R}^3\)</span> be the relativemotion between the target and the observer: <spanclass="math display">\[\begin{aligned}\label{eq_relative_motion}    {s}(t)&amp;\doteqp_T(t)-p_o(t)  \nonumber\\    &amp;\doteq{s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t),\end{aligned}\]</span> where <span class="math inline">\({s}_i = {d}_i -{c}_i\in\mathbb{R}^3\)</span> for <span class="math inline">\(i =0,1,\cdots, n\)</span>.</p><p>If we can determine <spanclass="math inline">\(\{s_i\}_{i=0}^n\)</span>, then <spanclass="math inline">\(s(t)\)</span> and hence <spanclass="math inline">\(p_T(t)\)</span> can be determined. Therefore, wenext study under what conditions <spanclass="math inline">\(\{s_i\}_{i=0}^n\)</span> can be uniquelydetermined. Since <spanclass="math inline">\(p_T(t)-p_o(t)=g(t)r(t)\)</span> according to <ahref="#eq_bearing_measure" data-reference-type="eqref"data-reference="eq_bearing_measure">[eq_bearing_measure]</a> and <spanclass="math inline">\(r(t)=\ell/\theta(t)\)</span> according to <ahref="#eq_theta_measure" data-reference-type="eqref"data-reference="eq_theta_measure">[eq_theta_measure]</a>, we have <spanclass="math display">\[s(t)=p_T(t)-p_o(t)=g(t)r(t)=\frac{g(t)}{\theta(t)}\ell.\]</span>Substituting the above equation into <a href="#eq_relative_motion"data-reference-type="eqref"data-reference="eq_relative_motion">[eq_relative_motion]</a> yields<span class="math display">\[\begin{aligned}\label{eq_st_tem}{s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t)=\frac{g(t)}{\theta(t)}\ell.\end{aligned}\]</span> Here, <span class="math inline">\({s}_0, \cdots,{s}_n, \ell\)</span> are unknowns to be determined and <spanclass="math inline">\(g(t),\theta(t),{h}(t)\)</span> are known.Equation <a href="#eq_st_tem" data-reference-type="eqref"data-reference="eq_st_tem">[eq_st_tem]</a> can be reorganized to alinear equation: <span class="math display">\[\begin{aligned}\label{eq_linear_equations}    {A}(t){X} = {h}(t),\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}{X}&amp;=\begin{bmatrix}{s}_0^\mathrm{T}, {s}_1^\mathrm{T}, \cdots, {s}_n^\mathrm{T}, \ell\end{bmatrix}^\mathrm{T}\in\mathbb{R}^{3n+4},\end{aligned}\]</span> and <span class="math display">\[\begin{aligned}\label{eq_original_A}{A}(t)&amp;=\begin{bmatrix}{I}_{3\times3}, t{I}_{3\times3}, \cdots, t^n{I}_{3\times3}, \rho(t)\end{bmatrix}\in\mathbb{R}^{3\times(3n+4)},\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_rho_denote}\rho(t)&amp;\doteq-\dfrac{g(t)}{\theta(t)}\in\mathbb{R}^3.\end{aligned}\]</span> Therefore, the problem that we aim to solvebecomes determining whether <span class="math inline">\(X\)</span> canbe uniquely solved from <a href="#eq_linear_equations"data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a>.</p><h2 id="necessary-and-sufficient-observability-condition">Necessary andsufficient observability condition</h2><p>We next present a necessary and sufficient condition under which thesolution <span class="math inline">\(X\)</span> of <ahref="#eq_linear_equations" data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a> isunique.</p><p><Theorem id="theorem_observability_confition "></Theorem><strong>Theorem 1.</strong> ((Necessary and sufficient observabilitycondition)). <em>The target's motion <spanclass="math inline">\(p_T(t)\)</span> can be uniquely determined by theobserver's motion <span class="math inline">\(p_o(t)\)</span>, thebearing <span class="math inline">\(g(t)\)</span>, and the angle <spanclass="math inline">\(\theta(t)\)</span> if and only if <spanclass="math display">\[\begin{aligned}{h}(t)\neq{0}_{3\times1},\end{aligned}\]</span> which means that the order of the observer'smotion must be greater than the target.</em></p><p>Since the row number of <span class="math inline">\({A}(t)\)</span>is less than its column number, <a href="#eq_linear_equations"data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a> is anunder-determined system whose solution cannot be uniquely determined.However, in the continuous time domain, we can use additional higherderivatives of this equation to uniquely determine <spanclass="math inline">\(X\)</span>.</p><p>In particular, taking the <spanclass="math inline">\(i\)</span>th-order derivative on both sides of <ahref="#eq_linear_equations" data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a> gives<span class="math inline">\(A^{(i)}(t)X=h^{(i)}(t)\)</span>. Considerany integer <span class="math inline">\(N\)</span> satisfying <spanclass="math inline">\(N\ge n+1\)</span>. Combining the equations with<span class="math inline">\(i\in\{0,1,\dots,N\}\)</span> gives <spanclass="math display">\[\begin{aligned}\label{eq_new_linear_equtions}    \bar(t){X} = \bar(t),\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_new_A}    \bar(t) =\left[  \begin{array}{c}    {A}(t) \\    {A}^{&#39;}(t) \\    \vdots \\    {A}^{(N)}(t)  \end{array}\right],\qquad\bar(t)\left[  \begin{array}{c}    {h}(t)\\    {h}^{&#39;}(t)\\    \vdots\\    {h}^{(N)}(t)\\  \end{array}\right].\end{aligned}\]</span> Here, <spanclass="math inline">\(\bar(t)\in\mathbb{R}^{(3N+3)\times(3n+4)}\)</span> and <spanclass="math inline">\(\bar(t)\in\mathbb{R}^{3N+3}\)</span>.Since <span class="math inline">\(N\ge n+1\)</span>, <spanclass="math inline">\(\bar{A}(t)\)</span> is a tall matrix and <ahref="#eq_new_linear_equtions" data-reference-type="eqref"data-reference="eq_new_linear_equtions">[eq_new_linear_equtions]</a> isan over-determined system.</p><p>We next examine when <span class="math inline">\(\bar{A}(t)\)</span>has full column rank. Substituting <a href="#eq_original_A"data-reference-type="eqref"data-reference="eq_original_A">[eq_original_A]</a> into <spanclass="math inline">\(\bar{A}(t)\)</span> yields <spanclass="math display">\[\begin{aligned}\bar(t)=    \left[\begin{array}{cccc:c}    {I}_{3\times3}&amp; t{I}_{3\times3}&amp; \cdots&amp;t^n{I}_{3\times3}&amp; \rho(t) \\    {0}_{3\times3}&amp; {I}_{3\times3}&amp; \cdots&amp;nt^{n-1}{I}_{3\times3}&amp; \rho^{&#39;}(t) \\    \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\    {0}_{3\times3}&amp; {0}_{3\times3}&amp; \cdots&amp;n!{I}_{3\times3}&amp; \rho^{(n)}(t) \\    \hdashline    {0}_{3\times3}&amp; {0}_{3\times3}&amp; \cdots&amp;{0}_{3\times3}&amp; \rho^{(n+1)}(t) \\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \\{0}_{3\times3}&amp; {0}_{3\times3}&amp; \cdots&amp; {0}_{3\times3}&amp;\rho^{(N)}(t) \\%\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \\    \end{array}\right].\end{aligned}\]</span> Since the top-left block of <spanclass="math inline">\(\bar{A}(t)\)</span> is a full-rank square matrix,<span class="math inline">\(\bar(t)\)</span> hasfull column rank if and only if there exists <spanclass="math inline">\(i\in\{n+1,\dots,N\}\)</span> such that <spanclass="math display">\[\begin{aligned}\label{eq_observability_criteria_2}    \rho^{(i)}(t)\neq {0}_{3\times1}.\end{aligned}\]</span> Since <spanclass="math inline">\(\rho(t)=-g(t)/\theta(t)\)</span> as shown in <ahref="#eq_rho_denote" data-reference-type="eqref"data-reference="eq_rho_denote">[eq_rho_denote]</a> and <spanclass="math inline">\(g(t)/\theta(t)=({s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t))/\ell\)</span>as shown in <a href="#eq_st_tem" data-reference-type="eqref"data-reference="eq_st_tem">[eq_st_tem]</a>, we can rewrite <ahref="#eq_observability_criteria_2" data-reference-type="eqref"data-reference="eq_observability_criteria_2">[eq_observability_criteria_2]</a>to <span class="math display">\[\begin{aligned}\label{eq_critia_2}-\dfrac{1}{\ell}({s}_0+{s}_1t+\cdots+{s}_nt^n+{h}(t))^{(i)}\neq{0}_{3\times1}.\end{aligned}\]</span> Since <span class="math inline">\(i\gen+1\)</span>, <a href="#eq_critia_2" data-reference-type="eqref"data-reference="eq_critia_2">[eq_critia_2]</a> is equivalent to <spanclass="math display">\[\begin{aligned}\label{eq_observability_criteria_final}{h}^{(i)} (t) \neq {0}_{3\times1}.\end{aligned}\]</span> According to the definition of <spanclass="math inline">\({h}(t)\)</span> in <a href="#eq_definition_h"data-reference-type="eqref"data-reference="eq_definition_h">[eq_definition_h]</a>, the condition in<a href="#eq_observability_criteria_final" data-reference-type="eqref"data-reference="eq_observability_criteria_final">[eq_observability_criteria_final]</a>is equivalent to <span class="math display">\[\begin{aligned}{h}(t)\neq {0}_{3\times1}.\end{aligned}\]</span> The proof is complete.</p><p>Some important remarks about Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> are givenbelow.</p><p>1) The necessary and sufficient condition suggested by Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> is that theobserver should have higher-order motion than the target. For example,when the target is stationary, the observer should move with a nonzerovelocity. When the target moves with a constant velocity, the observershould move with a nonzero acceleration.</p><p>2) The necessary and sufficient condition given by Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> has a <em>keydifference</em> from the bearing-only case that the higher-order motionin the bearing-angle case is <em>not</em> required to be orthogonal tothe bearing vector, making the bearing-angle approach more flexible thanthe bearing-only one. For example, the bearing-angle approach canestimate the target's motion even if the observer simply moves along thebearing vector.</p><p>3) In the special case where the target moves with a constantvelocity, the condition in Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> is consistentwith the one obtained in Section <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>.Although the condition in Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> allows moregeneral target motion, the analysis in Section <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>is still meaningful since it is directly related to the dynamic modelused in the pseudo-linear Kalman filter.</p><p>4) In practice, we would not estimate the target's motion by usingthe method of solving an equation like <a href="#eq_new_linear_equtions"data-reference-type="eqref"data-reference="eq_new_linear_equtions">[eq_new_linear_equtions]</a>.That is because such a method involves calculating high-orderderivatives, which are challenging to obtain accurately in practice. Therole of this equation is to provide a fundamental perspective on whetherthere is sufficient information to uniquely recover the target'smotion.</p><h2 id="number-of-observations-required">Number of observationsrequired</h2><div class="figure*"><p><span class="math display">\[\begin{aligned}\label{eq_A_22}\tilde{A}\rightarrow\left[\begin{array}{ccccc:c}{I} &amp; t_1{I} &amp; \cdots &amp; t_1^{n-1}{I} &amp; t_1^n{I} &amp;\rho(t_1) \\{0} &amp; {I} &amp; \cdots &amp; {\Delta(t_2^{n-1}, t_1^{n-1})}{I} &amp;{\Delta(t_2^n, t_1^n)}{}{I} &amp; {\Delta(\rho(t_2),\rho(t_1) )}{} \\\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots\\{0} &amp; {0} &amp; \cdots &amp; (n-1)!{I} &amp; {\Delta^{n-1}(t_n^n,\cdots , t_1^n)}{} &amp; {\Delta^{n-1}(\rho(t_n),\cdots,\rho(t_1) )}{}\\{0} &amp; {0} &amp; \cdots &amp; {0} &amp; n!{I}&amp;  {\Delta^{n}(\rho(t_{n+1}),\cdots,\rho(t_1) )}{} \\\hdashline{0} &amp; {0} &amp; \cdots &amp; {0} &amp; {0} &amp;{\Delta^{n+1}(\rho(t_{n+2}),\cdots,\rho(t_1) )}{} \\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp;\vdots  \\{0} &amp; {0} &amp; \cdots &amp; {0} &amp; {0} &amp;{\Delta^{N-1}(\rho(t_N),\cdots,\rho(t_1) )}{} \\\end{array}\right]\end{aligned}\]</span></p></div><p>It is of practical importance to study how many discrete observationsare required to recover the target's motion. Although Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a> gives anobservability condition, it does not answer this question because it isbased on the continuous time domain. We next answer this question byexploring multiple discrete time steps.</p><p><Theorem id="theorem_observation_number"></Theorem> <strong>Theorem2.</strong> ((Number of discrete observations)). <em>If the observer'smotion satisfies the observability condition in Theorem <ahref="#theorem_observability_confition" data-reference-type="ref"data-reference="theorem_observability_confition">1</a>, it is necessaryand sufficient to use at least <span class="math inline">\(n+2\)</span>observations to recover the target's motion. Here, <spanclass="math inline">\(n\)</span> is the order of the target's polynomialmotion as shown in <a href="#eq_target_nth_Order"data-reference-type="eqref"data-reference="eq_target_nth_Order">[eq_target_nth_Order]</a>.</em></p><p>Consider <span class="math inline">\(t_1,\dots,t_N\)</span> timeinstances. Each time instance corresponds to an equation like <ahref="#eq_linear_equations" data-reference-type="eqref"data-reference="eq_linear_equations">[eq_linear_equations]</a>: <spanclass="math inline">\({A}(t_i){X} = {h}(t_i)\)</span> for <spanclass="math inline">\(i=1,\dots,N\)</span>. Combining these equationsgives <span class="math display">\[\begin{aligned}\label{eq_convergence_linear_eqs}\tilde{X}=\tilde,\end{aligned}\]</span> where <spanclass="math display">\[\begin{aligned}\label{eq_new_A_2}    \tilde =\left[  \begin{array}{c}    {A}(t_1) \\    \vdots \\    {A}(t_N)  \end{array}\right],\qquad\tilde\left[  \begin{array}{c}    {h}(t_1)\\    \vdots\\    {h}(t_N)\\  \end{array}\right].\end{aligned}\]</span> Here, <spanclass="math inline">\(\tilde\in\mathbb{R}^{(3N)\times (3n+4)}\)</span> and <spanclass="math inline">\(\tilde\in\mathbb{R}^{3N}\)</span>.</p><p>(<em>Necessity</em>) Since <spanclass="math inline">\(X\in\mathbb{R}^{3n+4}\)</span>, we need at least<span class="math inline">\(N\ge n+2\)</span> observations so that <spanclass="math inline">\(\tilde\)</span> is a tallmatrix and hence <a href="#eq_convergence_linear_eqs"data-reference-type="eqref"data-reference="eq_convergence_linear_eqs">[eq_convergence_linear_eqs]</a>is an over-determined system.</p><p>(<em>Sufficiency</em>) Suppose we have <spanclass="math inline">\(N\ge n+2\)</span> discrete observations.Substituting <a href="#eq_original_A" data-reference-type="eqref"data-reference="eq_original_A">[eq_original_A]</a> into <ahref="#eq_new_A_2" data-reference-type="eqref"data-reference="eq_new_A_2">[eq_new_A_2]</a> yields <spanclass="math display">\[\begin{aligned}\tilde{A} =\begin{bmatrix}{I}_{3\times 3} &amp; t_1{I}_{3\times 3} &amp; \cdots &amp;t_1^n{I}_{3\times 3} &amp; \rho(t_1) \\{I}_{3\times 3} &amp; t_2{I}_{3\times 3} &amp; \cdots &amp;t_2^n{I}_{3\times 3} &amp; \rho(t_2)  \\\vdots &amp; \vdots &amp;&amp; \vdots &amp; \vdots  \\{I}_{3\times 3} &amp; t_{n+1}{I}_{3\times 3} &amp; \cdots &amp;t_{n+1}^n{I}_{3\times 3} &amp; \rho(t_{n+1}) \\{I}_{3\times 3} &amp; t_{n+2}{I}_{3\times 3} &amp; \cdots &amp;t_{n+2}^n{I}_{3\times 3} &amp; \rho(t_{n+2})\\\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\{I}_{3\times 3} &amp; t_{N}{I}_{3\times 3} &amp; \cdots &amp;t_{N}^n{I}_{3\times 3} &amp; \rho(t_{N})\\\end{bmatrix}.\end{aligned}\]</span> Starting from the last line in <spanclass="math inline">\(\tilde{A}\)</span>, subtract the previous linefrom each subsequent line, and repeat this process. Finally, we canobtain <a href="#eq_A_22" data-reference-type="eqref"data-reference="eq_A_22">[eq_A_22]</a> (the equation is too long andlocated at the top of another page). Here, <spanclass="math inline">\(\Delta^n\)</span> represents the <spanclass="math inline">\(n\)</span>th-order time difference <spanclass="citation"data-cites="MilneThomson2000">[@MilneThomson2000]</span>. For example,<span class="math inline">\(\Delta (a_2, a_1)=(a_2-a_1)/\deltat\)</span>, <span class="math inline">\(\Delta^2 (a_3, a_2, a_1) =\Delta (\Delta(a_3, a_2), \Delta(a_2, a_1))=[(a_3-a_2)/\deltat-(a_2-a_1)/\delta t]/\delta t\)</span>. When <spanclass="math inline">\(\delta t\)</span> is sufficiently small, the timedifference is an approximation of the derivative. When the observabilitycondition in Theorem <a href="#theorem_observability_confition"data-reference-type="ref"data-reference="theorem_observability_confition">1</a> is satisfied,there exists <span class="math inline">\(i\ge n+1\)</span> such that<span class="math inline">\(\rho^{(i)}(t)\neq 0\)</span> as shown in <ahref="#eq_observability_criteria_2" data-reference-type="eqref"data-reference="eq_observability_criteria_2">[eq_observability_criteria_2]</a>.As a result, there exists <span class="math inline">\(i\ge n+1\)</span>such that <span class="math display">\[\begin{aligned}\Delta^{i}(\rho(t_{i+1}),\cdots,\rho(t_1))\neq {0}.\end{aligned}\]</span> The above implication is valid because <spanclass="math inline">\(\Delta^{i}\)</span> is an approximation of the<span class="math inline">\(i\)</span>th-order derivative when <spanclass="math inline">\(\delta t\)</span> is sufficiently small. Then,<span class="math inline">\(\tilde{A}\)</span> in <a href="#eq_A_22"data-reference-type="eqref" data-reference="eq_A_22">[eq_A_22]</a> hasfull column rank and hence <a href="#eq_convergence_linear_eqs"data-reference-type="eqref"data-reference="eq_convergence_linear_eqs">[eq_convergence_linear_eqs]</a>has a unique solution.</p><p>Theorem <a href="#theorem_observation_number"data-reference-type="ref"data-reference="theorem_observation_number">2</a> suggests that when thetarget is stationary and hence <span class="math inline">\(n=0\)</span>,at least two discrete observations are sufficient to localize thetarget. This is true even if the two observations are acquired when theobserver moves along the bearing vector. When the target moves with aconstant velocity and hence <span class="math inline">\(n=1\)</span>, atleast three discrete observations are sufficient to localize the target,which is consistent with the results in Section <ahref="#Observability%20Analysis%20by%20Kalman&#39;s%20Criterion"data-reference-type="ref"data-reference="Observability Analysis by Kalman&#39;s Criterion">5</a>.</p><h1 id="numerical-simulation-results">Numerical Simulation Results</h1><figure id="sec_matlab_simulation">  <figure id="fig_matlab_1"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_1.png" />  <figcaption><b>(a)</b> Scenario 1: Circular motion around the target. Both the bearing-only and bearing-angle approaches work well, but the bearing-angle one converges faster.</figcaption>  <figure id="fig_matlab_2"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_2.png" />  <figcaption><b>(b)</b> Scenario 2: Straight motion towards and backwards the target. The bearing-only approach fails, but the bearing-angle approach works effectively.</figcaption>  <figure id="fig_matlab_3"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_3.png" />  <figcaption><b>(c)</b> Scenario 3: Approaching the target by a guidance law. The bearing-only approach works unstably, but the bearing-angle approach works effectively.</figcaption><figcaption><b>Figure 4.</b> Numerical simulation results based on 100 Monte Carlo runs in three scenarios.</figcaption></figure><figure id="fig_matlab_varying_ell">  <figure id="fig_cam_rotate"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_4.png" />  <figcaption><b>(a)</b> The observer moves around the square-shaped target. The target spins rapidly at $2\pi$~rad/s.</figcaption>  <figure id="fig_matlab_pi_8"></figure>  <img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_matlab_pi_8.png" />  <figcaption><b>(c)</b>The observer moves along the bearing vector. The target's spinning speed is $\pi/8$~rad/s.</figcaption><figcaption><b>Figure 5.</b> Numerical simulation results for time-varying $\ell$.</figcaption></figure><p>This section presents a set of numerical simulation results todemonstrate the effectiveness of the proposed bearing-angleapproach.</p><p>The values of the parameters in two estimators are selected as <spanclass="math inline">\(\sigma_v=10^{-3}\)</span>, <spanclass="math inline">\(\sigma_l=10^{-4}\)</span>, <spanclass="math inline">\(\sigma_\mu=0.01\)</span>, and <spanclass="math inline">\(\sigma_w=0.01\)</span>. The selection of thesevalues is inspired by the measurement noises obtained in the AirSimsimulation and real-world experiments as shown later. The initialcovariance matrix of the estimated states is set to <spanclass="math inline">\(P(t_0)=0.1I\)</span>. The target is a circle whosediameter is <span class="math inline">\(\ell=1\)</span>. The update rateof the system is <span class="math inline">\(50\)</span> Hz. Inaddition, we use the same parameter values across all the simulationexamples to verify the robustness of the algorithm. Better performancescan be achieved if the parameters are well-tuned for specific scenarios.We perform <span class="math inline">\(N_x=100\)</span> Monte Carlosimulations for each scenario.</p><p>We use the normalized-estimation error squared (NEES) <spanclass="citation"data-cites="bar1998estimation">[@bar1998estimation]</span> to analyzethe consistency of the estimation algorithms. In particular, the valueof the average NEES is</p><p><span class="math display">\[\begin{aligned}    \bar{\epsilon}_{\text{NEES}}=\dfrac{1}{N_x}\sum_{i=1}^{N_x}(x-\hat{x}_i)^\mathrm{T}P_i^{-1}(x-\hat{x}_i),    \label{eq_nees}\end{aligned}\]</span> where <spanclass="math inline">\(\hat{x}_i\)</span> is the estimated states in the<span class="math inline">\(i\)</span>th simulation, and <spanclass="math inline">\(P_i\)</span> is the covariance matrix obtainedfrom the estimator in the <span class="math inline">\(i\)</span>thsimulation.</p><p>Finally, image acquisition and visual detection are not considered inthese numerical simulation scenarios. They will be considered inSection <a href="#AirSim%20Simulation%20Results"data-reference-type="ref"data-reference="AirSim Simulation Results">8</a> and Section <ahref="#Real-World%20Experimental%20Results" data-reference-type="ref"data-reference="Real-World Experimental Results">9</a>.</p><h2 id="scenario-1-circular-motion-around-the-target">Scenario 1:Circular motion around the target</h2><p>In the first scenario, the target is stationary and located at <spanclass="math inline">\(p_T=[0, 10]^\mathrm{T}\)</span>. The observermoves on a circle centered at the target with the speed of <spanclass="math inline">\(3\)</span> m/s (see Fig. <a href="#fig_matlab_1"data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a>). The radius of thecircle is <span class="math inline">\(5\)</span> m. The initialestimates are <span class="math inline">\(\hatp_o(t_0) = [0,13]^\mathrm{T}\)</span>, <span class="math inline">\(\hat{v_o}(t_0)=[0,0]^\mathrm{T}\)</span>, <spanclass="math inline">\(\hat{\ell}(t_0)=1.6\)</span>. During this process,the bearing vector varies while the angle subtended by the targetremains constant. The angle measurement varies slightly due to themeasurement noise. This scenario is favorable to the conventionalbearing-only approach because its observability condition that thetarget should be viewed from different angles is well satisfied <spanclass="citation" data-cites="Li2022">[@Li2022]</span>.</p><p>Fig. <a href="#fig_matlab_1" data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a> shows the estimationresults by the two approaches of bearing-only and bearing-angle. As canbe seen, both algorithms perform well. The convergence of thebearing-angle approach is faster than the bearing-only one, as shown inthe middle and right subfigures of Fig. <a href="#fig_matlab_1"data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a>, due to the additionalangle measurement. The bearing-angle approach can successfully estimatethe size of the target as shown in the right subfigure of Fig. <ahref="#fig_matlab_1" data-reference-type="ref"data-reference="fig_matlab_1">[fig_matlab_1]</a>.</p><h2id="scenario-2-straight-motion-towards-and-backwards-the-target-repeatedly">Scenario2: Straight motion towards and backwards the target repeatedly</h2><p>In the second scenario, the target is also stationary but theobserver moves along a straight line towards and backwards the targetrepeatedly (Fig. <a href="#fig_matlab_2" data-reference-type="ref"data-reference="fig_matlab_2">[fig_matlab_2]</a>). During this process,the bearing vector remains constant while the angle varies. Thisscenario is most challenging for the bearing-only approach because itsobservability condition is not fulfilled.</p><p>In this simulation scenario, the target is stationary and located at<span class="math inline">\(p_T(t_0)=[0, 10]^\mathrm{T}\)</span>. Theobserver moves along a straight line towards and backwards the targetwith a constant acceleration of <spanclass="math inline">\(-2\)</span> <spanclass="math inline">\(\text{m/s}^2\)</span>. The initial conditions are<span class="math inline">\(v_o(t_0)=[0, 4]^\mathrm{T}\)</span> and<span class="math inline">\(p_o (t_0)= [0,5]^\mathrm{T}\)</span>. Theinitial estimates are <span class="math inline">\(\hatp_o(t_0) = [0,8]^\mathrm{T}\)</span>, <span class="math inline">\(\hat{v_o}(t_0)=[0,0]^\mathrm{T}\)</span>, <spanclass="math inline">\(\hat{\ell}(t_0)=0.8\)</span>. In this scenario,the true bearing of the target relative to the observer remainsunchanged though the bearing measurement may vary slightly due to themeasurement noise.</p><p>Fig. <a href="#fig_matlab_2" data-reference-type="ref"data-reference="fig_matlab_2">[fig_matlab_2]</a> shows the estimationresults of the bearing-only and bearing-angle approaches. As can beseen, the bearing-only approach diverges since its observabilitycondition is not satisfied. By contrast, the proposed bearing-angleapproach converges, and is able to localize the target and estimate itssize, which demonstrates the strong observability of the bearing-angleapproach. One may notice that the estimated size and the NEES value getworse first before converging. This is because the noise level of theangle is set to be constant. Since the angle is small in the beginning,the noise-angle ratio is large, causing a relatively large NEESvalue.</p><div class="figure*"></div><div class="figure*"><figure><img src="fig_box_airsim" alt="image" /><figcaption aria-hidden="true">image</figcaption></figure></div><h2 id="scenario-3-approaching-the-target-by-a-guidance-law">Scenario 3:Approaching the target by a guidance law</h2><p>The third scenario is more complex than the first two. Here, thetarget moves with a constant velocity where the observer is controlledby a proportional navigation guidance (PNG) law to approach the target(Fig. <a href="#fig_matlab_3" data-reference-type="ref"data-reference="fig_matlab_3">[fig_matlab_3]</a>). During this process,both the bearing and angle vary. This scenario is also challenging forthe bearing-only approach because its observability is weak due to thefact that the lateral motion of the observer is small. Many researchershave studied how to add extra control commands to the PNG to enhance theobservability based on the bearing-only approach <span class="citation"data-cites="Song1996 Seo2015 Lee2015">[@Song1996; @Seo2015;@Lee2015]</span>.</p><p>In this simulation scenario, the target moves along a straight linewith a constant velocity <span class="math inline">\(v_T=[1/\sqrt{2},1/\sqrt{2}]^\mathrm{T}\)</span>. The observer's velocity magnitude isconstantly <span class="math inline">\(3\)</span> m/s while the velocitydirection is controlled by a PNG law. The navigation gain of the PNG lawis selected as one. The initial estimates of the target's states are thesame as Scenario 1. The simulation stops just before the observercollides with the target.</p><p>Fig. <a href="#fig_matlab_3" data-reference-type="ref"data-reference="fig_matlab_3">[fig_matlab_3]</a> shows the estimationresults by the bearing-only and bearing-angle approaches. As can beseen, the bearing-angle algorithm successfully converges before thecollision occurs, but the bearing-only algorithm fails to estimate thetarget's states due to its weak observability. This simulation exampledemonstrates that the bearing-angle algorithm can be used directly inthe guidance scenario without extra maneuvers required by thebearing-only approach <span class="citation"data-cites="Song1996 Seo2015 Lee2015">[@Song1996; @Seo2015;@Lee2015]</span>.</p><h2 id="simulation-results-for-time-varying-ell">Simulation results fortime-varying <span class="math inline">\(\ell\)</span></h2><p>Although <span class="math inline">\(\ell\)</span> is assumed to beinvariant, it is meaningful to challenge the proposed bearing-angleapproach by considering time-varying <spanclass="math inline">\(\ell\)</span>. We will see through simulationexamples that the bearing-angle approach is still effective when <spanclass="math inline">\(\ell\)</span> varies slowly. It becomes unstablewhen <span class="math inline">\(\ell\)</span> varies rapidly since theassumption of invariant <span class="math inline">\(\ell\)</span> isseverely invalid.</p><p>Suppose that the target object has a square shape. Then, <spanclass="math inline">\(\ell\)</span> varies when the object is observedfrom different viewing angles or the object spins. Fig. <ahref="#fig_matlab_4" data-reference-type="ref"data-reference="fig_matlab_4">[fig_matlab_4]</a> shows a scenario wherethe observer moves around the target, whose spinning speed is <spanclass="math inline">\(2\pi\)</span> rad/s. The red curve in the rightsubfigure represents the true value of <spanclass="math inline">\(\ell\)</span>, which varies rapidly. As can beseen, the bearing-angle algorithm works effectively though there is asmall estimation bias. Fig. <a href="#fig_matlab_pi_8"data-reference-type="ref"data-reference="fig_matlab_pi_8">[fig_matlab_pi_8]</a> shows a scenariowhere the observer moves along the bearing vector. The spinning speed ofthe target object is <span class="math inline">\(\pi/8\)</span> rad/s.As can be seen, the bearing-only approach diverges due to the lack ofobservability. The bearing-angle algorithm can still converge since<span class="math inline">\(\ell\)</span> varies slowly. When we furtherincrease the spinning speed of the target, the bearing-angle algorithmwill also diverge because the algorithm cannot distinguish whether thechange of <span class="math inline">\(\theta\)</span> is caused by thechange of <span class="math inline">\(\ell\)</span> or the change of<span class="math inline">\(r\)</span>.</p><h1 id="airsim-simulation-results">AirSim Simulation Results</h1><p>In this section, we show simulation results under a more realisticsetup. In particular, the simulation is based on AirSim, a simulatorthat can provide high-quality visual simulation <span class="citation"data-cites="Shah2017">[@Shah2017]</span>. Nonlinear MAV dynamics andcontrol are also considered.</p><div class="figure*"></div><h2 id="simulation-setup">Simulation setup</h2><div class="figure*"></div><p>Fig. <a href="#fig_architecture_airsim" data-reference-type="ref"data-reference="fig_architecture_airsim">[fig_architecture_airsim]</a>shows an AirSim simulation scenario. As can be seen, there are twoflying quadcopter MAVs. The observer MAV can capture images of thetarget MAV using its simulated onboard camera. A simple gimbal cameracontroller is implemented so that the target MAV is always locatedinside the field of view of the camera. The visual environment used inthe simulation is called Landscape Mountains, which includes realisticmountains, lakes, trees, and roads. Other environments can also be usedif needed.</p><p>The bearing and angle measurements are obtained from the boundingboxes generated by a Yolo-based detection algorithm. A tiny-YOLO v4network <span class="citation"data-cites="Bochkovskiy2020">[@Bochkovskiy2020]</span> is trained todetect the target MAV in the images. Although the visual detector can bereplaced by other state-of-the-art ones, the tiny-YOLO v4 network isalready sufficient to verify our proposed approach. The architecture ofthe entire simulation system is shown in Fig. <a href="#fig_box_airsim"data-reference-type="ref"data-reference="fig_box_airsim">[fig_box_airsim]</a>. The systemconsists of the modules of automatic image dataset collection,Yolo-based target detection, gimbal camera control, nonlinear quadcopterdynamics, and quadcopter flight control. The quadcopter dynamics andflight control used in the simulation are similar to <spanclass="citation" data-cites="Meier2011 Shah2017">[@Meier2011;@Shah2017]</span> and omitted here due to space limitation. Thequadcopter's physical size varies slightly when viewed from differentdirections, although it is assumed to be invariant. All of these factorsmake the Airsim simulation more realistic and challenging.</p><h2 id="automatic-dataset-collection">Automatic dataset collection</h2><p>To train the Yolo-based detector, we developed a module toautomatically collect an image dataset. This module has some advantages.First, it is efficient. More than ten thousand labeled images can becollected automatically in 24 hours. Second, it is flexible. It canacquire images with random target's positions, random target'sattitudes, random camera's view angles, and random background scenes.These images are beneficial to achieve a good generalization ability ofthe detector. Third, the image labels are of high quality. Since theground truth of the target's image is known in the simulation, thegenerated bounding box is tight. The collected dataset contains 17,000labeled images (see Fig. <a href="#fig_airsim_dataset"data-reference-type="ref"data-reference="fig_airsim_dataset">[fig_airsim_dataset]</a>). Theresolution of the images is <span class="math inline">\(1536\times864\)</span> pixels. The simulation system was deployed on a DellPrecision 7920 Tower Workstation with two NVIDIA Quadro GV100 graphiccards. Since the dataset is sufficient and high-quality, the detectioncan achieve the accuracy of mAP=99.5%.</p><h2 id="scenario-1-approaching-and-following-the-target">Scenario 1:Approaching and following the target</h2><p>We first consider the scenarios where the observer MAV approaches orfollows a target MAV. These scenarios widely exist in practicalapplications such as aerial target pursuit.</p><p>We show two simulation examples in Fig. <a href="#fig_airsim_1"data-reference-type="ref"data-reference="fig_airsim_1">[fig_airsim_1]</a> and Fig. <ahref="#fig_airsim_2" data-reference-type="ref"data-reference="fig_airsim_2">[fig_airsim_2]</a>, respectively. In bothexamples, the observer is controlled by a controller so that it canapproach the target and maintain a desired separation. In particular,the controller is <span class="math display">\[\begin{aligned}\label{eq_tracking_control}v_o^\text{cmd}(t)&amp;=v_T(t)+k^\text{track}\dfrac{r^2(t)-r_d^2}{r^2(t)}g(t),\end{aligned}\]</span> where <spanclass="math inline">\(v_o^\text{cmd}(t)\)</span> is the velocity commandof the observer MAV, <spanclass="math inline">\(k^\text{track}=3\)</span> is the control gain, and<span class="math inline">\(r_d=3\)</span> is the desired separation.The magnitude of the observer's velocity is bounded from above by <spanclass="math inline">\(3\)</span> m/s. It should be noted that <ahref="#eq_tracking_control" data-reference-type="eqref"data-reference="eq_tracking_control">[eq_tracking_control]</a> relies onthe true position and velocity of the target MAV in the simulation.Therefore, the data is collected first and then processed offline sothat we can compare the performances of the bearing-only andbearing-angle approaches.</p><p>In the first example, the target MAV hovers constantly at <spanclass="math inline">\(p_T(t_0)=[0, 10, 10]^\mathrm{T}\)</span>. Theobserver MAV moves along a straight line toward the target with adecreasing velocity command. Since the bearing of the target MAV remainsthe same, this example is challenging for the bearing-only approach. Asshown in Fig. <a href="#fig_airsim_1" data-reference-type="ref"data-reference="fig_airsim_1">[fig_airsim_1]</a>, the bearing-onlyapproach fails to converge while the bearing-angle approach cansuccessfully estimate the target's motion.</p><p>In the second example, the target MAV moves with a constant velocityof <span class="math inline">\(v_T=[1/\sqrt{2}, 1/\sqrt{2},0]^\mathrm{T}\)</span>. The trajectory of the observer MAV under thecontrol of <a href="#eq_tracking_control" data-reference-type="eqref"data-reference="eq_tracking_control">[eq_tracking_control]</a> is stillclose to (though not strictly) a straight line. As a result, theobservability is weak by the bearing-only approach. As shown in Fig. <ahref="#fig_airsim_2" data-reference-type="ref"data-reference="fig_airsim_2">[fig_airsim_2]</a>, the bearing-angleapproach successfully converges while the bearing-only one fails. It isnotable that <span class="math inline">\(\ell\)</span> is invariant inthe first example and varies slowly in the second example.</p><p>It is worth mentioning that the detection results used in theestimation algorithms are obtained from the Yolo-based estimator. Theground truth obtained from AirSim is only used to calculate the errorsof measurements, as shown in the right figures of Figs. <ahref="#fig_airsim_1" data-reference-type="ref"data-reference="fig_airsim_1">[fig_airsim_1]</a> and <ahref="#fig_airsim_2" data-reference-type="ref"data-reference="fig_airsim_2">[fig_airsim_2]</a>. It is not surprisingthat the measurement noises are not strictly Gaussian since the 2Dbounding box is generated by a deep learning vision algorithm. It isnoticed that the noises are inversely correlated to the observer-targetrange. This is reasonable because, when the target is close to thecamera and hence its image is large, the center point and the size ofthe bounding box usually vary for a few pixels.</p><p>The NEES values are also shown in Fig. <a href="#fig_airsim"data-reference-type="ref" data-reference="fig_airsim">[fig_airsim]</a>.As can be seen, the NEES value of the bearing-only approach diverges.The NEES value of the bearing-angle approach oscillates and convergesslowly. The reasons are analyzed as follows. Compared to theMatlab-based numerical simulation, the visual measurements here aregenerated by deep learning algorithms, and the measurement noises arenon-Gaussian. The non-Gaussian noises propagate into <spanclass="math inline">\(P\)</span> in <a href="#eq_nees"data-reference-type="eqref" data-reference="eq_nees">[eq_nees]</a> sincethe calculation of <span class="math inline">\(P\)</span> relies onnoisy measurements. The noises may also cause an estimation bias thatcan further aggravate the NEES error. Moreover, although the system isobservable in the two simulation examples, the observability isrelatively weak compared to the case where the observer movessurrounding the target. As a result, the matrix <spanclass="math inline">\(P\)</span> may not be able to perfectly describethe estimation accuracy. These elements may jointly cause theconvergence behavior of the NEES values shown in Fig. <ahref="#fig_airsim" data-reference-type="ref"data-reference="fig_airsim">[fig_airsim]</a>.</p><h2 id="scenario-2-circular-motion-and-varying-ell">Scenario 2: Circularmotion and varying <span class="math inline">\(\ell\)</span></h2><p>We next examine a case where <spanclass="math inline">\(\ell\)</span> is time-varying. In particular,suppose a target quadcopter MAV hovers constantly at <spanclass="math inline">\(p_T(t_0)=[0, 10, 10]^\mathrm{T}\)</span>. Theobserver MAV moves on a circle centered at the target (Fig. <ahref="#fig_airsim_6_1" data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a>). Since the targetquadcopter MAV has a square shape from the top view, its size <spanclass="math inline">\(\ell\)</span> is time-varying when viewed fromside angles (see the red curves in the middle subfigure of Fig. <ahref="#fig_airsim_6_1" data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a>).</p><p>We show two simulation examples in Fig. <a href="#fig_airsim_6_1"data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a> and Fig. <ahref="#fig_airsim_6_2" data-reference-type="ref"data-reference="fig_airsim_6_2">[fig_airsim_6_2]</a>, respectively. Thetwo simulation examples share the same measurement data but differentvalues of <span class="math inline">\(\sigma_\ell\)</span>. Moreover,the other parameters are the same as those in Section <ahref="#Scenario%201:%20Approaching%20and%20following%20the%20target"data-reference-type="ref"data-reference="Scenario 1: Approaching and following the target">8.3</a>.</p><div class="figure*"></div><p>In the first simulation example, <spanclass="math inline">\(\sigma_\ell\)</span> is set to be a small value:<span class="math inline">\(\sigma_\ell=10^{-4}\)</span>. Itsinterpretation is that <span class="math inline">\(\ell\)</span> istreated as invariant during the process. In this case, the performanceof the bearing-angle approach is almost the same as the bearing-only oneas shown in Fig. <a href="#fig_airsim_6_1" data-reference-type="ref"data-reference="fig_airsim_6_1">[fig_airsim_6_1]</a>. Since <spanclass="math inline">\(\ell\)</span> is treated to be invariant, theestimated value <span class="math inline">\(\hat{\ell}\)</span>converges to a constant which is the mean value of the time-varying<span class="math inline">\(\ell\)</span>.</p><p>In the second simulation example, the value of <spanclass="math inline">\(\sigma_\ell\)</span> is larger than the firstexample: <span class="math inline">\(\sigma_\ell = 0.01\)</span>. Itsinterpretation is that <span class="math inline">\(\ell\)</span> isbelieved to be time-varying during the process. In this case, theperformance of the bearing-angle approach is still almost the same asthe bearing-only one. Moreover, since <spanclass="math inline">\(\sigma_\ell\)</span> is large, the bearing-angleapproach can successfully estimate the true time-varying value of <spanclass="math inline">\(\ell\)</span>.</p><p>In summary, in the case where <spanclass="math inline">\(\ell\)</span> varies slowly, the bearing-angleapproach would degenerate to the bearing-only one. The fundamentalreason is that the extra information embedded in the angle measurementis used to estimate the time-varying <spanclass="math inline">\(\ell\)</span> rather than improving theobservability of the target's motion.</p><div class="figure*"></div><h1 id="real-world-experimental-results">Real-World ExperimentalResults</h1><p>In this section, two sets of real-world experiments are presented tofurther verify the effectiveness of the approach. The first is based ona hand-held camera and a ground robot. The second is based on twoquadcopter MAVs. The second experimental scenario is motivated by aerialtarget pursuit tasks.</p><h2 id="experiment-1-hand-held-camera">Experiment 1: Hand-heldcamera</h2><p>The experimental setup is shown in Fig. <ahref="#fig_architecture_indoor" data-reference-type="ref"data-reference="fig_architecture_indoor">[fig_architecture_indoor]</a>.The observer is a hand-held camera (Hik Vision DS-E14S) connected to alaptop. The camera's intrinsic parameters are calibrated beforehand. Therobot built on Mecanum wheels can move in any direction on the groundunder velocity control. The ground truth of the states of the camera andthe robot are provided by a Vicon indoor motion capture system. The keyexperimental specifications are listed in Table <ahref="#table_indoor_hardware" data-reference-type="ref"data-reference="table_indoor_hardware">[table_indoor_hardware]</a>.</p><p>A dataset of 5,514 images was collected and used to train a tiny-YOLOv4 network to detect the target robot (see Fig. <ahref="#fig_car_dataset" data-reference-type="ref"data-reference="fig_car_dataset">[fig_car_dataset]</a>). The detectionprecision of the trained network is mAP=99.8%. In the experiment, thetarget robot is commanded to move with a constant velocity. In themeantime, a person holding the camera moves along some trajectories. Twodifferent cases are studied. In both of the cases, the target robotmoves with a constant velocity <span class="math inline">\(v_T=[-0.1,0.1 ,0]^\mathrm{T}\)</span>. The noises of the measurements arecalculated based on the ground truth provided by the Vicon system. Thenoises are shown in the right subfigures of Fig. <a href="#fig_indoor_9"data-reference-type="ref"data-reference="fig_indoor_9">[fig_indoor_9]</a> and Fig. <ahref="#fig_indoor_6" data-reference-type="ref"data-reference="fig_indoor_6">[fig_indoor_6]</a>.</p><p>In the first case, the camera is held about 1.5 meters above theground and moves around the target robot. In this case, the bearingvector varies sufficiently and hence the observability conditions forthe bearing-only and bearing-angle approaches are both well satisfied.As shown in Fig. <a href="#fig_indoor_9" data-reference-type="ref"data-reference="fig_indoor_9">[fig_indoor_9]</a>, both approachesperform well in this case while the bearing-angle approach performsslightly better than the bearing-only one.</p><p>In the second case, the camera moves along the trajectory of therobot by getting close or far from it periodically. In this case, theangle varies significantly, but the bearing does not. Without surprise,the bearing-only approach performs poorly in this case due to weakobservability (Fig. <a href="#fig_indoor_6" data-reference-type="ref"data-reference="fig_indoor_6">[fig_indoor_6]</a>). By contrast, thebearing-angle approach can perform stably due to its enhancedobservability.</p><div class="center"><div class="tabular"><p>l|lll &amp; Parameter &amp; Value &amp; Unit<br />*Camera &amp; Resolution &amp; 640<spanclass="math inline">\(\times\)</span> 480 &amp; pixel<br />  &amp; Max frequency &amp; 30 &amp;fps<br />*Robot &amp; Max speed &amp; 1&amp; m/s<br />  &amp; Diameter size &amp; 295 &amp; mm<br />*Vicon &amp; Localization accuracy &amp; 1 &amp; mm<br />  &amp; Max frequency &amp; 100 &amp; Hz<br /></p></div></div><h2 id="experiment-2-mav-following-mav">Experiment 2:MAV-following-MAV</h2><div class="center"><div class="tabular"><p>c|lll &amp; Parameter &amp; Value &amp; Unit<br />&amp; Diagonal size &amp; 895 &amp; mm<br /> &amp;Total mass &amp; 7.4 &amp; kg<br /> &amp;Max pitch/roll &amp; 30 &amp; degree<br /> &amp;Max flight time &amp; 30 &amp; minutes<br />&amp; Accuracy &amp; 1 &amp; cm<br /> &amp; Max frequency &amp; 10 &amp; Hz<br />&amp; Resolution &amp;1920<spanclass="math inline">\(\times\)</span><!-- -->1080 &amp; pixel<br /> &amp; Frequency &amp; 15 &amp; Hz<br />  &amp; Max angular rate &amp; 180 &amp; deg/s<br /></p></div></div><div class="figure*"></div><div class="figure*"><figure><img src="fig_outdoor_1" alt="image" /><figcaption aria-hidden="true">image</figcaption></figure></div><p>Two MAV platforms were developed based on DJI M300 quadcopters(Fig. <a href="#fig_M300" data-reference-type="ref"data-reference="fig_M300">[fig_M300]</a>). The MAV platforms areequipped with RTK GPS modules for accurate self-localization, an H20camera for visual detection, a Manifold 2G onboard computer for onboardflight control, and a Zigbee module for wireless communication. Some keyspecifications of the MAV platforms are listed in Table <ahref="#table_M300" data-reference-type="ref"data-reference="table_M300">[table_M300]</a>. The structure of thehardware perception and communication system is illustrated in Fig. <ahref="#fig_outdoor_hardware" data-reference-type="ref"data-reference="fig_outdoor_hardware">[fig_outdoor_hardware]</a>. Thetarget MAV is also equipped with an RTK GPS module, whose measurementsare used as the ground truth to calculate the noises of the visualmeasurements. The noises are shown in the right subfigure of Fig. <ahref="#fig_outdoor_1" data-reference-type="ref"data-reference="fig_outdoor_1">[fig_outdoor_1]</a>.</p><p>The experiment consists of two stages: data acquisition and offlinedata processing. In the data acquisition stage, the target MAV iscommanded to fly with a constant velocity, and the observer MAV isautomatically controlled to follow the target MAV to maintain a constantdistance from the target. More specifically, the procedure of the flightexperiment is as follows. Initially, the observer MAV is placed about 20meters behind the target MAV on the ground. Then, the two MAVs take offand fly to the same specified height automatically upon a takeoffcommand sent from the ground control station. After they have reachedthe desired height, all deployed algorithms are activated. Then, thetarget MAV moves with a constant velocity of <spanclass="math inline">\(v_T=[1/\sqrt{2}, 1/\sqrt{2},0]^\mathrm{T}\)</span>. The observer MAV approaches the target by thecontroller in <a href="#eq_tracking_control" data-reference-type="eqref"data-reference="eq_tracking_control">[eq_tracking_control]</a>. It takesthe observer MAV about eight seconds to reach the desired relativedistance. Then, the two MAVs fly with the same velocity and remainrelatively stationary for another 20 seconds. Finally, the groundstation sends a stop command and the two MAVs return and landautomatically.</p><p>During the flight, the gimbal camera of the observer MAV isautomatically controlled so that the target MAV is maintained in thefield of view. It is noted that the control of the gimbal camera and theobserver MAV is not based on the visual detection results. Instead, thecontrol is based on the measurements provided by the RKT GPS andinter-MAV wireless communication. In this way, we can analyze the imageand flight data offline and compare the performance of the twoapproaches of bearing-angle and bearing-only. The acquired images andflight data are saved on the onboard computer during the flight. Adataset of 5,341 images was collected (Fig. <a href="#fig_M300_dataset"data-reference-type="ref"data-reference="fig_M300_dataset">[fig_M300_dataset]</a>) and used totrain a tiny-YOLO v4 network. The detection precision of the trainednetwork reaches mAP=99.8%.</p><p>The experimental results are shown in Fig. <a href="#fig_outdoor_1"data-reference-type="ref"data-reference="fig_outdoor_1">[fig_outdoor_1]</a>. As can be seen, thebearing-angle approach performs well. By contrast, the bearing-onlyapproach only works well before the observer MAV reached the desiredposition relative to the target MAV. That is because the bearing variessignificantly during this process due to the fluctuation of theobserver's motion caused by the flight control. However, thebearing-only approach diverges quickly thereafter when the bearing stopsvarying significantly.</p><h1 id="conclusion">Conclusion</h1><p>Motivated by the limitation of the existing bearing-only approach,this paper proposed and analyzed a novel bearing-angle approach forvision-based target motion estimation. We showed that the observabilityby the bearing-angle approach is significantly enhanced compared to thebearing-only one. As a result, the requirement of the observer's extramotion for observability enhancement can be significantly relaxed. As weshowed in various experiments, the bearing-angle approach cansuccessfully estimate the target's motion in many scenarios where thebearing-only approach fails. The enhanced observability of thebearing-angle approach comes with no additional cost since almost allvision detection algorithms can generate bounding boxes. One assumptionadopted in the bearing-angle approach is that the target's physical sizeis invariant to different viewing angles. Although this assumption isapproximately valid in many tasks as demonstrated in this paper, it ismeaningful to study how to relax or remove this assumption in thefuture.</p><h1 id="declaration-of-conflicting-interests">Declaration of conflictinginterests</h1><p>The author(s) declared no potential conflicts of interest withrespect to the research, authorship, and/or publication of thisarticle.</p><h1 id="funding">Funding</h1><p>The author(s) disclosed receipt of the following financial supportfor the research, authorship, and/or publication of this artical: Thiswork was supported by the Hangzhou Key Technology Research andDevelopment Program (Grant 20212013B09), and the Research Center forIndustries of the Future at Westlake University (Grant WU2022C027).</p>]]></content>
    
    
    <summary type="html">🧵本文研究了使用移动单目相机估计移动目标物体运动的问题</summary>
    
    
    
    <category term="阅读" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="视觉导航" scheme="https://www.adunas.top/tags/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>关于爱莉西亚局长的个人回忆</title>
    <link href="https://www.adunas.top/posts/20240222b.html"/>
    <id>https://www.adunas.top/posts/20240222b.html</id>
    <published>2024-02-22T11:12:03.000Z</published>
    <updated>2024-02-22T13:46:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文学导航"><ahref="./20240224d.html#关于爱莉西亚局长的个人回忆">文学导航</a></h1><blockquote><p>警察局档案编号：2024-01-11-001</p><p>档案名称：关于爱莉西亚局长的个人回忆</p><p>档案作者：英仙座，警察局副局长</p></blockquote><p>  我与爱莉西亚局长的相识，要追溯到三年前的一起奇怪的案件。当时，我还是一个银行劫匪，和我的同伙一起策划了一次大规模的抢劫。我们打算在杰拉德·弗雷泽的银行里装上炸弹，然后趁着混乱，抢走所有的钱。我们以为我们的计划十分完美，没想到，遇到了爱莉西亚，也因此认识了银行家。</p><p>  她当时还不是局长，只是一个刚刚调来的刑警，负责调查一起涉及黑社会的枪击案。她恰巧在那家银行里，发现了我们的炸弹，就立刻通知了警方，然后冲进了我们的藏身处，一个接一个地把我们制服了。她的动作十分迅速，几乎没有给我们反应的机会。我是最后一个被她抓住的，她用枪指着我的头，说：“你们这些无耻的家伙，竟敢威胁无辜的人民，应该受到惩罚。”她的眼神十分冷酷，让我感到一阵寒意。</p><p>  但是，就在她准备扣动扳机的时候，她突然停住了，她的眼神变得柔和，她说：“不过，你还有救赎的机会，你可以选择跟我走，或者留在这里等死。”我不知道她为什么会突然改变主意，也不知道她要带我去哪里，但是我觉得我没有别的选择，就跟着她走了。</p><p>  从那以后，我就成了爱莉西亚局长的得力助手，也是她唯一的朋友。她对我很好，总是给我讲一些有趣的故事，还教我一些奇怪的知识。她说她是从一个叫做“逐火之蛾” 的组织来的，那里有很多奇妙的事物，还有一些她的战友。</p><p>  我不知道她说的这些是真是假，但我觉得她很可信，也很有魅力。她在工作上很有能力，能够迅速解决各种棘手的案件，还能和各方打好关系。她在生活上很有趣，经常拉着我去逛街，让我帮她挑选衣服和化妆品，有时候我心不在焉，她又会拉着我的手对我说：“你快对我说，艾莉西亚穿什么都好看，好不好嘛？”有时候她也会拉着我去看恐怖电影，演到吓人的场景时她也会害怕的缩成一团，和之前勇敢无畏的局长判若两人。虽然我也很害怕，但还是会摸摸她的头，对她说：“我会永远保护你的。”而她会趁机靠在我的肩膀上说：“你可真是我的小英雄！”</p><p><img src="https://picture.adunas.top/Article/ElysiaA.png" /></p><p>  有一次我们解决了哈山的案子，中间和她分开了一段时间，结果听到她的一声惨叫，但是当我过来之后她只是一脸笑意的看着我，手上拿着一个奇怪的怀表。之后的日子里她有时候会突然消失一段时间，然后又突然出现在我的面前，她从不告诉我她去了哪里，做了什么，只是笑着说：“你不用担心，我只是有些私事要办。”我总是觉得她在隐瞒什么，但我不敢多问，只是默默地等待她的归来，只觉得她有一种神奇的力量。</p><p>  她经常让我陪她去一些危险的地方，说是为了调查一些案件，其实是为了寻找她的秘密。她总是让我遇到各种麻烦，比如被黑社会追杀，被邪恶的力量感染，等等。她每次都会在最后一刻出现，救我一命，然后对我说：“你真是个笨蛋，怎么总是让自己陷入危险，你不知道我有多担心你吗？”她的语气总是带着一种嘲讽，让我觉得她是在故意捉弄我，但是她的眼神却又充满了关切，让我觉得她是在真心保护我。我不知道她到底是怎么想的，但是我总是感激她，也总是原谅她。</p><p>  直到那一天，一切都改变了。那是一天晚上，我们在现场发现了一个小女孩，爱莉西亚看到她，就惊呼了一声，说：“是你！”然后，她就冲上去，抱住了那个女孩。接下来的事情，我就记不太清楚了。我只记得爱莉西亚局长和那个女孩说了一些话，然后她就对我说：“对不起，我要走了，我有很重要的事情要做，和她有关。”我问她要去哪里，她说：“去一个你无法跟随的地方，去完成我的使命。”而我无法抛下她不管，还是偷偷跟了过去。</p><p>  中间撕掉了很多页（）</p><p>  那一天的场景仍然无数次的出现在我的梦里，我仿佛置身充满了恐怖和绝望的地方，让人只能感受到疯狂和死亡。那里有无数的黑暗，无数的怪物，无数的尖叫，无数的血肉。那里没有光明，没有生命，没有希望，没有意义，没有规则。那里只有一个无尽的混沌，一个无边的疯狂，一个无名的恐惧，一个无法的崩坏。</p><p>  我只记得最后，艾莉西亚对我说：“傻瓜，你还是跟过来了呀，我的小英雄。”</p><details class="folding-tag" orange><summary> 点击查看语录 </summary>              <div class='content'>              <span class="p green">&gt;</span>粉色头发的迷人女孩是谁呀，哦，原来是我呀！<spanclass="p green">&lt;</span><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E7%88%B1%E8%8E%89%E5%B8%8C%E9%9B%85-%E8%AF%B4%E8%B5%B7%E7%B2%89%E8%89%B2%E5%A4%B4%E5%8F%91%E7%9A%84%E5%8F%AF%E7%88%B1%E5%A5%B3%E5%AD%A9%EF%BC%8C%E4%BD%A0%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BC%9A%E6%83%B3%E5%88%B0%E8%B0%81%EF%BC%9F%E4%B8%89%E4%BA%8C%E4%B8%80%E5%9B%9E%E7%AD%94%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><span class="p green">&gt;</span> 多夸夸我嘛，我会很开心的~<spanclass="p green">&lt;</span><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E7%88%B1%E8%8E%89%E5%B8%8C%E9%9B%85-%E5%97%A8%EF%BC%8C%E6%88%91%E5%8F%88%E6%9D%A5%E5%95%A6%E3%80%82%E5%A4%9A%E5%A4%B8%E5%A4%B8%E6%88%91%E5%A5%BD%E5%90%97%EF%BC%9F%E6%88%91%E4%BC%9A%E5%BE%88%E2%80%94%E2%80%94%E5%BC%80%E5%BF%83%E7%9A%84%E5%93%A6%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><span class="p green">&gt;</span> 可爱的少女心，可是无所不能的哦！<spanclass="p green">&lt;</span><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E4%BA%BA%E4%B9%8B%E5%BE%8B%E8%80%85-%E5%91%B5...%E7%9C%8B%EF%BC%8C%E5%8F%AF%E7%88%B1%E7%9A%84%E5%B0%91%E5%A5%B3%E5%BF%83%E5%8F%AF%E6%98%AF%E6%97%A0%E6%89%80%E4%B8%8D%E8%83%BD%E7%9A%84%E5%93%A6%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div>              </div>            </details>]]></content>
    
    
    <summary type="html">🧶傻瓜，你还是跟过来了呀，我的小英雄</summary>
    
    
    
    <category term="文学" scheme="https://www.adunas.top/categories/%E6%96%87%E5%AD%A6/"/>
    
    
    <category term="小说" scheme="https://www.adunas.top/tags/%E5%B0%8F%E8%AF%B4/"/>
    
    <category term="人物档案" scheme="https://www.adunas.top/tags/%E4%BA%BA%E7%89%A9%E6%A1%A3%E6%A1%88/"/>
    
    <category term="跑团" scheme="https://www.adunas.top/tags/%E8%B7%91%E5%9B%A2/"/>
    
  </entry>
  
  <entry>
    <title>日程表：2024年02月</title>
    <link href="https://www.adunas.top/posts/20240222a.html"/>
    <id>https://www.adunas.top/posts/20240222a.html</id>
    <published>2024-02-22T08:36:32.000Z</published>
    <updated>2024-02-22T08:36:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#2024年2月">文章导航总览</a></h1><h1 id="年2月23日">2024年2月23日</h1><div class='checkbox red checked'><input type="checkbox" checked="checked"/>            <p>运动1小时</p>            </div><ul class="task-list"><li><label><input type="checkbox" checked="" />羽毛球</label></li></ul><div class='checkbox red'><input type="checkbox" />            <p>写一篇阅读论文的博客</p>            </div><details class="folding-tag" blue><summary> 日程表 </summary>              <div class='content'>              <div class="timeline blue"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>时间轴</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>17点46分</p></div></div><div class="timeline-item-content"><ol type="1"><li>吃晚饭</li></ol></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>18点10分</p></div></div><div class="timeline-item-content"><ol type="1"><li>阅读论文</li></ol></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>18点40分-20点40分</p></div></div><div class="timeline-item-content"><ol type="1"><li>羽毛球</li></ol></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>21点56分</p></div></div><div class="timeline-item-content"><ol type="1"><li>阅读论文</li></ol></div></div></div>              </div>            </details>]]></content>
    
    
    <summary type="html">🥐本文记录 Adunas 2024年02月的日程安排和实施情况</summary>
    
    
    
    <category term="日程表" scheme="https://www.adunas.top/categories/%E6%97%A5%E7%A8%8B%E8%A1%A8/"/>
    
    
    <category term="日程表" scheme="https://www.adunas.top/tags/%E6%97%A5%E7%A8%8B%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>博客搭建导航</title>
    <link href="https://www.adunas.top/posts/20240221c.html"/>
    <id>https://www.adunas.top/posts/20240221c.html</id>
    <published>2024-02-21T11:26:31.000Z</published>
    <updated>2024-02-21T11:26:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#博客搭建">文章导航总览</a></h1><h1 id="博客文章语法笔记导航">博客文章语法笔记导航</h1><h2 id="markdown基础语法"><ahref="./20231201a.html">Markdown基础语法</a></h2><h2 id="markdown内置html语法"><ahref="./20231206b.html">Markdown内置Html语法</a></h2><h2 id="butterfly外挂标签"><ahref="./20231205b.html">Butterfly外挂标签</a></h2><h1 id="博客搭建教程导航">博客搭建教程导航</h1><h2 id="基础教程"><a href="./20231205d.html">基础教程</a></h2><h2 id="bug汇总"><a href="./20231204c.html">bug汇总</a></h2><h2 id="未来可期"><a href="./20231205c.html">未来可期</a></h2><h2 id="音频教程"><a href="./20231207a.html">音频教程</a></h2><h2 id="文章个性化功能"><ahref="./20240201a.html">文章个性化功能</a></h2><h2 id="首页美化"><a href="./20240202a.html">首页美化</a></h2>]]></content>
    
    
    <summary type="html">🧈本文是博客搭建的导航</summary>
    
    
    
    <category term="文章导航" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="文章导航" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>编程导航</title>
    <link href="https://www.adunas.top/posts/20240221b.html"/>
    <id>https://www.adunas.top/posts/20240221b.html</id>
    <published>2024-02-21T10:48:39.000Z</published>
    <updated>2024-02-21T10:49:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#编程">文章导航总览</a></h1><h1 id="c">C++</h1><h2 id="打印"><a href="./20240116a.html">打印</a></h2><h1 id="命令行">命令行</h1><h2 id="git"><a href="./20231206a.html">Git</a></h2><h1 id="java">Java</h1><h2 id="前端"><a href="./20231211a.html">前端</a></h2><h1 id="搜索">搜索</h1><h2 id="正则表达式"><a href="./20240225a.html">正则表达式</a></h2><h1 id="latex"><a href="./20240225c.html">Latex</a></h1><h1 id="pandoc"><a href="./20240304b.html">Pandoc</a></h1>]]></content>
    
    
    <summary type="html">🥞本文是编程分类的导航</summary>
    
    
    
    <category term="文章导航" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="文章导航" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>文章导航</title>
    <link href="https://www.adunas.top/posts/20240221a.html"/>
    <id>https://www.adunas.top/posts/20240221a.html</id>
    <published>2024-02-21T10:41:36.000Z</published>
    <updated>2024-02-21T10:41:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数学"><a href="./20240210a.html">数学</a></h1><h1 id="英语">英语</h1><h2 id="单词"><a href="./20231208a.html">单词</a></h2><h1 id="阅读"><a href="./20240224b.html">阅读</a></h1><h1 id="文学"><a href="./20240224d.html">文学</a></h1><h1 id="编程"><a href="./20240221b.html">编程</a></h1><h1 id="博客搭建"><a href="./20240221c.html">博客搭建</a></h1><h1 id="日程表">日程表</h1><h2 id="年2月"><a href="./20240222a.html">2024年2月</a></h2><h1 id="运动健康">运动健康</h1><h2 id="日常基础篇"><a href="./20240131a.html">日常基础篇</a></h2><h2 id="状态调整篇"><a href="./20240203a.html">状态调整篇</a></h2><h1 id="操作系统">操作系统</h1><h1 id="ios">IOS</h1><h2 id="ipa"><a href="./20240115a.html">ipa</a></h2><h1 id="游戏">游戏</h1><h2 id="adunas的游戏账号昵称和id"><ahref="./20231201b.html">Adunas的游戏账号昵称和ID</a></h2>]]></content>
    
    
    <summary type="html">🥞本文是文章分类导航的最顶层</summary>
    
    
    
    <category term="文章导航" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="文章导航" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>数学导航</title>
    <link href="https://www.adunas.top/posts/20240210a.html"/>
    <id>https://www.adunas.top/posts/20240210a.html</id>
    <published>2024-02-10T06:57:53.000Z</published>
    <updated>2024-02-21T10:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#数学">文章导航总览</a></h1><h1 id="矩阵">矩阵</h1><h2 id="迹"><a href="./20231210a.html">迹</a></h2><h2 id="协方差"><a href="./20231204a.html">协方差</a></h2><h1 id="滤波">滤波</h1><h2 id="卡尔曼滤波"><a href="./20231205a.html">卡尔曼滤波</a></h2><h1 id="绘图工具">绘图工具</h1><h2 id="动态数学软件"><a href="./20231210b.html">动态数学软件</a></h2><p>  动态数学软件GroGebra。</p>]]></content>
    
    
    <summary type="html">🥧本文是数学分类的导航</summary>
    
    
    
    <category term="文章导航" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="文章导航" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>运动健康（二）：状态调整篇</title>
    <link href="https://www.adunas.top/posts/20240203a.html"/>
    <id>https://www.adunas.top/posts/20240203a.html</id>
    <published>2024-02-03T04:32:11.000Z</published>
    <updated>2024-02-03T04:32:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#状态调整篇">文章导航总览</a></h1><blockquote><h1 id="运动健康的导航">运动健康的导航</h1><ol type="1"><li><a href="./20240131a.html">运动健康（一）：日常基础篇</a></li><li><ahref="./20240203a.html">运动健康（二）：状态调整篇</a>⇦当前位置🪂</li></ol></blockquote><div class="note info flat"></div><h1 id="独立自主">独立自主</h1><p>  学会自尊自爱，任何时候不能把自己的未来托付给别人。你最亲的父母不可以，最好的朋友不可以，最爱的女朋友不可以，最知心的老师也不可以。你唯一要值得托付的人只有自己，也只能是自己。自己是自己的父母，照顾自己衣食起居。自己是自己的孩子，纯真、理想、真心都在此。</p><h1 id="压力别人">压力别人</h1><p>  偶尔还是有这个坏习惯。压力别人典型是自卑的表现，想通过打压别人来体现自身的价值，这只是嫉妒，是很不健康的，特别是在两性关系上。生活已经很累啦，她要的是情绪价值，而不是又多一个压力的老师。多站在别人的角度去想想、去关心、去爱吧。学会<ahref="#赞美">赞美</a>别人。</p><h1 id="沉默与激情">沉默与激情</h1><p>  不求无功，但求无过。这句话说得真差！我来改改：不求无功，不怕犯错！这段时间免去了很多无用的社交、无用的焦虑。沉心静气地搞学习和研究，并不觉得孤独，反而觉得无比踏实、舒心。合适的社交，我会打破沉默，我要从激情地学习转变成热情地交流，真诚面对每一个人，和不同的人、合适的人交流才能让自己能够不让自己的思想和视野变得狭隘和偏颇。热情会被打击，但是那简直是挠痒痒，因为我们根本<ahref="#不生气不伤心">不生气不伤心</a>呀。</p><h1 id="不生气不伤心">不生气不伤心</h1><p>  你要始终明白自己在乎什么，什么是对你重要的。不论男女，最重要的是做好自己该做的事情。对于我，男生来说，最重要的是事业，事业做好了，她有可能跟你，事业做不好，她一定不会跟你。所以你想想，真的是别人让你心情不好了嘛？答案是否定的，而是自己把自己心情变得不好了。</p><p>  我跟老师聊过。我跟同学聊过。我跟家人聊过。我跟朋友聊过。我也跟自己聊过。如果我能跟她再聊一聊就更好了。开心地、努力地、自信地做手头上的事情，就是最棒了。有好身体、好工作、好心态就已经完胜啦。</p><h1 id="赞美">赞美</h1><p>  以前我很讨厌阿谀奉承，然而这种讨厌被无形地扩大了。扩大到不会由衷地欣赏赞美别人。而且阿谀奉承我现在根本不讨厌了，但我不会去阿谀奉承。如果我需要帮助，我会真诚地表达、寻求帮助。我的赞美也不会是阿谀奉承，而是要通过观察后，真的能发现这件事带给我们的美，以及那背后的故事~</p><p>  为什么我不讨厌阿谀奉承。因为我知道人的生活是艰难的，他只不过在艰难地在夹缝中生存着，他阿谀奉承几句，并不是出于恶意，而是可以保住自己的工作，保住自己的饭碗，有个更好的机会而已。说几句话能让大家都开心，这有什么不对吗？这样在工作中大家都很舒服，这是极其正确的。</p><p>  推荐用更好的 “阿谀奉承”的方法，那便是赞美。学会认可别人的工作，学会欣赏，学会赞美。比如她画了一个妆，男生可能看了并没有什么和之前感觉不一样，但是你不知道的是，她为了你化妆准备了多久。她平时一个人的时候可是懒得打扮呀，这时候，我觉得这个女生是真的很美，很可爱呀。我会仔细地看看她地眼睛、腮红，虽然我对化妆一窍不通，但是好像真的有些不一样，我一定会开心得看着她说：你今天真美！</p><p>所以你在和别人交流的时候，总有些东西你不太懂，但是对方极力讲的时候，一定是对他非常重要的东西吧！他一定为这件事付出了很多实实在在的努力，这个时候我会大方地赞美，因为我确实能被感染到，这个时候，我不认为是什么阿谀奉承。</p><blockquote><h1 id="运动健康的导航-1">运动健康的导航</h1><ol type="1"><li><a href="./20240131a.html">运动健康（一）：日常基础篇</a></li><li><ahref="./20240203a.html">运动健康（二）：状态调整篇</a>⇦当前位置🪂</li></ol></blockquote>]]></content>
    
    
    <summary type="html">🍫本文总结状态调整的方法</summary>
    
    
    
    <category term="运动健康" scheme="https://www.adunas.top/categories/%E8%BF%90%E5%8A%A8%E5%81%A5%E5%BA%B7/"/>
    
    
    <category term="健康" scheme="https://www.adunas.top/tags/%E5%81%A5%E5%BA%B7/"/>
    
    <category term="心态" scheme="https://www.adunas.top/tags/%E5%BF%83%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>博客搭建教程：首页美化</title>
    <link href="https://www.adunas.top/posts/20240202a.html"/>
    <id>https://www.adunas.top/posts/20240202a.html</id>
    <published>2024-02-02T15:36:47.000Z</published>
    <updated>2024-02-21T12:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="博客搭建教程导航"><ahref="./20240221c.html#首页美化">博客搭建教程导航</a></h1><h1 id="格言">格言</h1><p>  在[页脚配置文件]./themes/butterfly/layout/includes/footer.pug中，修改如下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.t-t-l</span><br><span class="line">          p.ft-t.t-l-t 格言🧬</span><br><span class="line">          .bg-ad</span><br><span class="line">            div</span><br><span class="line">              | 再看看那个光点，它就在这里，这是家园，这是我们 —— 你所爱的每一个人，你认识的一个人，你听说过的每一个人，曾经有过的每一个人，都在它上面度过他们的一生✨</span><br><span class="line">            .btn-xz-box</span><br><span class="line">              a.btn-xz(href=&#x27;https://stellarium.org/&#x27;) 点击开启星辰之旅</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">🍟本文记录博客首页美化的方法</summary>
    
    
    
    <category term="博客" scheme="https://www.adunas.top/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
    <category term="hexo" scheme="https://www.adunas.top/tags/hexo/"/>
    
    <category term="html" scheme="https://www.adunas.top/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>博客搭建教程：文章个性化功能</title>
    <link href="https://www.adunas.top/posts/20240201a.html"/>
    <id>https://www.adunas.top/posts/20240201a.html</id>
    <published>2024-02-01T03:30:06.000Z</published>
    <updated>2024-02-21T12:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="博客搭建教程导航"><ahref="./20240221c.html#文章个性化功能">博客搭建教程导航</a></h1><h1 id="文章页html标签">文章页Html标签</h1><p>  有时候我们想在博客文章里添加一些 hexo 不具有的特性时，就可以在markdown 文件中添加 Html 标签。</p><p>  html、CSS 和 js 可以分开写，也分三个文件写，html始终放在markdown文件里。分开写的话，CSS 和 js 文件要放在主题的源文件路径/themes/butterfly/source/ 下的的 css 或者 js 文件夹下。在 Markdown里的语法为：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">href</span>=<span class="string">&quot;/css/grid.css&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    </span></span><br><span class="line"><span class="code">&lt;div class=&quot;container1&quot;&gt;  </span></span><br><span class="line"><span class="code">    &lt;iframe class=&quot;container-iframe&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;  </span></span><br><span class="line"><span class="code">&lt;/div&gt;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/js/grid.js&quot;</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h1 id="bilibili视频适配">Bilibili视频适配</h1><div class="note purple no-icon flat"><p>参考文章：<ahref="https://www.fomal.cc/posts/5389e93f.html">Bilibili视频适配</a></p></div><ol type="1"><li>在[BlogRoot].css自定义样式的文件中引入如下代码（这是我的，你可以自行微调）：</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*哔哩哔哩视频适配*/</span></span><br><span class="line"><span class="selector-class">.aspect-ratio</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">90%</span>;</span><br><span class="line">  <span class="attribute">height</span>: auto;</span><br><span class="line">  <span class="attribute">padding-bottom</span>: <span class="number">75%</span>;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">3%</span> auto;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.aspect-ratio</span> <span class="selector-tag">iframe</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: absolute;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">86%</span>;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>直接复制插入你的 md 文章就行，修改里面的 src 源为你的视频：</li></ol><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">center</span> <span class="attr">class</span>=<span class="string">&quot;aspect-ratio&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    &lt;iframe src=&quot;https://player.bilibili.com/player.html?aid=474023258&amp;&amp;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;autoplay=0 &quot; </span></span><br><span class="line"><span class="code">    scrolling=&quot;no&quot; </span></span><br><span class="line"><span class="code">    border=&quot;0&quot; </span></span><br><span class="line"><span class="code">    frameborder=&quot;no&quot; </span></span><br><span class="line"><span class="code">    framespacing=&quot;0&quot; </span></span><br><span class="line"><span class="code">    high_quality=1</span></span><br><span class="line"><span class="code">    danmaku=1 </span></span><br><span class="line"><span class="code">    allowfullscreen=&quot;true&quot;&gt; </span></span><br><span class="line"><span class="code">    &lt;/iframe&gt;</span></span><br><span class="line"><span class="code">&lt;/div&gt;</span></span><br></pre></td></tr></table></figure><p>源视频的链接获取方法为：在b站官网分享视频时，选择<code>嵌入代码</code>。若要关闭视频自动播放，在后面添加参数：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&amp;autoplay=0</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">🍔本文记录博客文章内插入的个性化功能</summary>
    
    
    
    <category term="博客" scheme="https://www.adunas.top/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
    <category term="hexo" scheme="https://www.adunas.top/tags/hexo/"/>
    
    <category term="html" scheme="https://www.adunas.top/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>运动健康：日常基础篇</title>
    <link href="https://www.adunas.top/posts/20240131a.html"/>
    <id>https://www.adunas.top/posts/20240131a.html</id>
    <published>2024-01-31T14:47:09.000Z</published>
    <updated>2024-02-02T11:54:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文章导航总览"><ahref="./20240221a.html#日常基础篇">文章导航总览</a></h1><blockquote><h1 id="运动健康的导航">运动健康的导航</h1><ol type="1"><li><ahref="./20240131a.html">运动健康（一）：日常基础篇</a>⇦当前位置🪂</li><li><a href="./20240203a.html">运动健康（二）：状态调整篇</a></li></ol></blockquote><h1 id="颈椎">颈椎</h1><p>  <ahref="https://www.bilibili.com/video/BV1Yb411b7nd/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">【有来医生8招颈椎操全教程】</a></p><div align=center class="aspect-ratio">    <iframe src="https://player.bilibili.com/player.html?aid=45039749&bvid=BV1Yb411b7nd&cid=78880311&p=1&autoplay=0 "     scrolling="no"     border="0"     frameborder="no"     framespacing="0"     high_quality=1    danmaku=1     allowfullscreen="true">     </iframe></div><h1 id="腰椎">腰椎</h1><p>  <ahref="https://www.bilibili.com/video/BV1fp4y1U7qG/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">【每天5分钟<em>告别骨盆前倾，小肚子突出，大屁股</em>】</a></p><div align=center class="aspect-ratio">    <iframe src="https://player.bilibili.com/player.html?aid=968747403&bvid=BV1fp4y1U7qG&cid=205794890&p=1&autoplay=0 "     scrolling="no"     border="0"     frameborder="no"     framespacing="0"     high_quality=1    danmaku=1     allowfullscreen="true">     </iframe></div><blockquote><h1 id="运动健康的导航-1">运动健康的导航</h1><ol type="1"><li><ahref="./20240131a.html">运动健康（一）：日常基础篇</a>⇦当前位置🪂</li><li><a href="./20240203a.html">运动健康（二）：状态调整篇</a></li></ol></blockquote>]]></content>
    
    
    <summary type="html">🎈本文汇总日常热身的内容</summary>
    
    
    
    <category term="运动健康" scheme="https://www.adunas.top/categories/%E8%BF%90%E5%8A%A8%E5%81%A5%E5%BA%B7/"/>
    
    
    <category term="运动" scheme="https://www.adunas.top/tags/%E8%BF%90%E5%8A%A8/"/>
    
    <category term="健身" scheme="https://www.adunas.top/tags/%E5%81%A5%E8%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>C++ 打印</title>
    <link href="https://www.adunas.top/posts/20240116a.html"/>
    <id>https://www.adunas.top/posts/20240116a.html</id>
    <published>2024-01-16T13:41:33.000Z</published>
    <updated>2024-02-21T11:20:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编程导航"><a href="./20240221b.html#打印">编程导航</a></h1><h1 id="c">C++</h1><h2 id="语法">语法</h2><h3 id="基础">基础</h3><h4 id="方法1">方法1</h4><p>  调用库：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br></pre></td></tr></table></figure><p>调用函数：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="方法2">方法2</h4><p>  命名空间，省略 std。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br></pre></td></tr></table></figure><p>调用函数：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cout &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h3 id="组合方式">组合方式</h3><h4 id="组合方式1">组合方式1</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="组合方式2">组合方式2</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="组合方式3">组合方式3</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h3 id="特殊符号">特殊符号</h3><h4 id="回车">回车</h4><p>  回车表示将光标移动到行的开头。这应该和键盘上的回车有所区分。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;\r&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="换行">换行</h4><p>  换行表示将光标移动到下一行的开头。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h3 id="变量调用">变量调用</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> num = <span class="number">100</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;数字是：&quot;</span> &lt;&lt; num &lt;&lt; std::endl;</span><br><span class="line">std::string st = <span class="string">&quot;你好，世界！&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; st &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h3 id="演示">演示</h3><p>  演示效果如下：</p><div class="tabs" id="print"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#print-1">示例源码1</button></li><li class="tab"><button type="button" data-href="#print-2">演示结果1</button></li><li class="tab"><button type="button" data-href="#print-3">示例源码2</button></li><li class="tab"><button type="button" data-href="#print-4">演示结果2</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="print-1"><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Print\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;|_&quot;</span> &lt;&lt; <span class="string">&quot;语法\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;基础\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;组合方式\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;组合方式1\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;组合方式2\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;组合方式3\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span>; std::cout &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;特殊符号\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;回车\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;\r&quot;</span>; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;换行\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;或者\n&quot;</span>; </span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; std::endl; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;变量调用\n&quot;</span>;</span><br><span class="line">    <span class="type">int</span> num = <span class="number">100</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;数字是：&quot;</span> &lt;&lt; num &lt;&lt; std::endl;</span><br><span class="line">    std::string st = <span class="string">&quot;你好，世界！&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; st &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-2"><p><imgsrc="https://picture.adunas.top/Program/PrintCppVs2022A.png" /></p><p>说明：换行和回车有明显区别。</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-3"><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 有三处可以省略 std::</span></span><br><span class="line">    string st = <span class="string">&quot;你好，世界！&quot;</span>;</span><br><span class="line">    cout &lt;&lt; st &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-4"><p><imgsrc="https://picture.adunas.top/Program/PrintCppVs2022B.png" /></p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>]]></content>
    
    
    <summary type="html">🍖本文汇总 C++ 打印显示的功能</summary>
    
    
    
    <category term="编程" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="C++" scheme="https://www.adunas.top/tags/C/"/>
    
    <category term="print" scheme="https://www.adunas.top/tags/print/"/>
    
  </entry>
  
</feed>
