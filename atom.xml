<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AdunasğŸ€ã®å¼‚ä¸–ç•Œ</title>
  
  
  <link href="https://www.adunas.top/atom.xml" rel="self"/>
  
  <link href="https://www.adunas.top/"/>
  <updated>2024-03-04T00:55:25.000Z</updated>
  <id>https://www.adunas.top/</id>
  
  <author>
    <name>é˜¿æœé‚£æ–¯ğŸ€</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰</title>
    <link href="https://www.adunas.top/posts/20240304a.html"/>
    <id>https://www.adunas.top/posts/20240304a.html</id>
    <published>2024-03-04T00:55:25.000Z</published>
    <updated>2024-03-04T00:55:25.000Z</updated>
    
    <content type="html"><![CDATA[<div class='poem'><div class='poem-title'>ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰</div><div class='poem-author'>å±ˆåŸ</div><p>é•¿å¤ªæ¯ä»¥æ©æ¶•å…®ï¼Œå“€æ°‘ç”Ÿä¹‹å¤šè‰°ã€‚ä½™è™½å¥½ä¿®å§±ä»¥é¿ç¾å…®ï¼Œè¬‡æœè°‡è€Œå¤•æ›¿ã€‚</p><p>æ—¢æ›¿ä½™ä»¥è•™çº•å…®ï¼Œåˆç”³ä¹‹ä»¥æ½èŒã€‚äº¦ä½™å¿ƒä¹‹æ‰€å–„å…®ï¼Œè™½ä¹æ­»å…¶çŠ¹æœªæ‚”ã€‚</p><p>æ€¨çµä¿®ä¹‹æµ©è¡å…®ï¼Œç»ˆä¸å¯Ÿå¤«æ°‘å¿ƒã€‚ä¼—å¥³å«‰ä½™ä¹‹è›¾çœ‰å…®ï¼Œè°£è¯¼è°“ä½™ä»¥å–„æ·«ã€‚</p><p>å›ºæ—¶ä¿—ä¹‹å·¥å·§å…®ï¼Œå­è§„çŸ©è€Œæ”¹é”™ã€‚èƒŒç»³å¢¨ä»¥è¿½æ›²å…®ï¼Œç«å‘¨å®¹ä»¥ä¸ºåº¦ã€‚</p><p>å¿³éƒé‚‘ä½™ä¾˜å‚ºå…®ï¼Œå¾ç‹¬ç©·å›°ä¹æ­¤æ—¶ä¹Ÿã€‚å®æº˜æ­»ä»¥æµäº¡å…®ï¼Œä½™ä¸å¿ä¸ºæ­¤æ€ä¹Ÿã€‚</p><p>é¸·é¸Ÿä¹‹ä¸ç¾¤å…®ï¼Œè‡ªå‰ä¸–è€Œå›ºç„¶ã€‚ä½•æ–¹åœœä¹‹èƒ½å‘¨å…®ï¼Œå¤«å­°å¼‚é“è€Œç›¸å®‰ï¼Ÿ</p><p>å±ˆå¿ƒè€ŒæŠ‘å¿—å…®ï¼Œå¿å°¤è€Œæ”˜è¯Ÿã€‚ä¼æ¸…ç™½ä»¥æ­»ç›´å…®ï¼Œå›ºå‰åœ£ä¹‹æ‰€åšã€‚</p><p>æ‚”ç›¸é“ä¹‹ä¸å¯Ÿå…®ï¼Œå»¶ä¼«ä¹å¾å°†åã€‚å›æœ•è½¦ä»¥å¤è·¯å…®ï¼ŒåŠè¡Œè¿·ä¹‹æœªè¿œã€‚</p><p>æ­¥ä½™é©¬äºå…°çš‹å…®ï¼Œé©°æ¤’ä¸˜ä¸”ç„‰æ­¢æ¯ã€‚è¿›ä¸å…¥ä»¥ç¦»å°¤å…®ï¼Œé€€å°†å¤ä¿®å¾åˆæœã€‚</p><p>åˆ¶èŠ°è·ä»¥ä¸ºè¡£å…®ï¼Œé›†èŠ™è“‰ä»¥ä¸ºè£³ã€‚ä¸å¾çŸ¥å…¶äº¦å·²å…®ï¼Œè‹Ÿä½™æƒ…å…¶ä¿¡èŠ³ã€‚</p><p>é«˜ä½™å† ä¹‹å²Œå²Œå…®ï¼Œé•¿ä½™ä½©ä¹‹é™†ç¦»ã€‚èŠ³ä¸æ³½å…¶æ‚ç³…å…®ï¼Œå”¯æ˜­è´¨å…¶çŠ¹æœªäºã€‚</p><p>å¿½åé¡¾ä»¥æ¸¸ç›®å…®ï¼Œå°†å¾€è§‚ä¹å››è’ã€‚ä½©ç¼¤çº·å…¶ç¹é¥°å…®ï¼ŒèŠ³è²è²å…¶å¼¥ç« ã€‚</p><p>æ°‘ç”Ÿå„æœ‰æ‰€ä¹å…®ï¼Œä½™ç‹¬å¥½ä¿®ä»¥ä¸ºå¸¸ã€‚è™½ä½“è§£å¾çŠ¹æœªå˜å…®ï¼Œå²‚ä½™å¿ƒä¹‹å¯æƒ©ã€‚</p></div><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/Read/LiSaoAdunasA.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div>]]></content>
    
    
    <summary type="html">ğŸ—æœ¬æ–‡ä¸ºé«˜ä¸­æ‰€å­¦ç¦»éªšï¼ˆèŠ‚é€‰ï¼‰çš„å†…å®¹</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="é˜…è¯»æ–¹æ³•" scheme="https://www.adunas.top/tags/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Latex</title>
    <link href="https://www.adunas.top/posts/20240225c.html"/>
    <id>https://www.adunas.top/posts/20240225c.html</id>
    <published>2024-02-25T03:38:02.000Z</published>
    <updated>2024-02-25T03:38:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><a href="#ç¼–ç¨‹å¯¼èˆª" class="headerlink" title="ç¼–ç¨‹å¯¼èˆª"></a><a href="./20240221b.html#Latex">ç¼–ç¨‹å¯¼èˆª</a></h1><h1 id="è¯­æ³•"><a href="#è¯­æ³•" class="headerlink" title="è¯­æ³•"></a>è¯­æ³•</h1><p>\documentclass</p>]]></content>
    
    
    <summary type="html">ğŸ™æœ¬æ–‡è®°å½•Latexè¯­æ³•</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="Latex" scheme="https://www.adunas.top/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>æ­£åˆ™è¡¨è¾¾å¼</title>
    <link href="https://www.adunas.top/posts/20240225a.html"/>
    <id>https://www.adunas.top/posts/20240225a.html</id>
    <published>2024-02-25T01:43:26.000Z</published>
    <updated>2024-02-25T01:43:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><a href="#ç¼–ç¨‹å¯¼èˆª" class="headerlink" title="ç¼–ç¨‹å¯¼èˆª"></a><a href="./20240221b.html#æ­£åˆ™è¡¨è¾¾å¼">ç¼–ç¨‹å¯¼èˆª</a></h1>]]></content>
    
    
    <summary type="html">ğŸ¤æœ¬æ–‡æ˜¯æ­£åˆ™è¡¨è¾¾å¼çš„æ•™ç¨‹</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="æ­£åˆ™è¡¨è¾¾å¼" scheme="https://www.adunas.top/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ</title>
    <link href="https://www.adunas.top/posts/20240224c.html"/>
    <id>https://www.adunas.top/posts/20240224c.html</id>
    <published>2024-02-24T07:51:08.000Z</published>
    <updated>2024-02-24T07:51:08.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡å­¦å¯¼èˆª"><a href="#æ–‡å­¦å¯¼èˆª" class="headerlink" title="æ–‡å­¦å¯¼èˆª"></a><a href="./20240224d.html#æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ">æ–‡å­¦å¯¼èˆª</a></h1><p>&emsp;&emsp;æ¯æ¬¡éš¾åƒçš„è‹¹æœæˆ‘éƒ½å’½ä¸‹å»äº†ï¼Œä½†æ˜¯è¿™æ¬¡æˆ‘å†³å®šä¸åƒäº†ã€‚ï¼ˆæœªå®Œå¾…ç»­ï¼‰</p>]]></content>
    
    
    <summary type="html">ğŸæ¯æ¬¡éš¾åƒçš„è‹¹æœæˆ‘éƒ½å’½ä¸‹å»äº†ï¼Œè¿™æ¬¡æˆ‘å†³å®šä¸åƒäº†</summary>
    
    
    
    <category term="æ–‡å­¦" scheme="https://www.adunas.top/categories/%E6%96%87%E5%AD%A6/"/>
    
    
    <category term="æ€è€ƒ" scheme="https://www.adunas.top/tags/%E6%80%9D%E8%80%83/"/>
    
  </entry>
  
  <entry>
    <title>æ–‡å­¦å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240224d.html"/>
    <id>https://www.adunas.top/posts/20240224d.html</id>
    <published>2024-02-24T07:42:23.000Z</published>
    <updated>2024-02-24T07:42:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#æ–‡å­¦">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="åŸåˆ›"><a href="#åŸåˆ›" class="headerlink" title="åŸåˆ›"></a>åŸåˆ›</h1><h2 id="æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ"><a href="#æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ" class="headerlink" title="æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ"></a><a href="./20240224c.html">æ€è€ƒè¯¥ä¸è¯¥åƒå®Œä¸€é¢—éš¾åƒçš„è‹¹æœ</a></h2><h1 id="æˆæƒå‘è¡¨"><a href="#æˆæƒå‘è¡¨" class="headerlink" title="æˆæƒå‘è¡¨"></a>æˆæƒå‘è¡¨</h1><h2 id="å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†"><a href="#å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†" class="headerlink" title="å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†"></a><a href="./20240222b.html">å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†</a></h2>]]></content>
    
    
    <summary type="html">ğŸ›æœ¬æ–‡æ˜¯æ–‡å­¦åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡é˜…è¯»</title>
    <link href="https://www.adunas.top/posts/20240224b.html"/>
    <id>https://www.adunas.top/posts/20240224b.html</id>
    <published>2024-02-23T17:17:02.000Z</published>
    <updated>2024-02-23T17:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#é˜…è¯»">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="è®ºæ–‡"><a href="#è®ºæ–‡" class="headerlink" title="è®ºæ–‡"></a>è®ºæ–‡</h1><h2 id="è®ºæ–‡é˜…è¯»æ–¹æ³•"><a href="#è®ºæ–‡é˜…è¯»æ–¹æ³•" class="headerlink" title="è®ºæ–‡é˜…è¯»æ–¹æ³•"></a><a href="./20240224a.html">è®ºæ–‡é˜…è¯»æ–¹æ³•</a></h2><h2 id="ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•"><a href="#ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•" class="headerlink" title="ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•"></a><a href="./20240223a.html">ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•</a></h2>]]></content>
    
    
    <summary type="html">ğŸœæœ¬æ–‡æ˜¯é˜…è¯»åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡é˜…è¯»æ–¹æ³•</title>
    <link href="https://www.adunas.top/posts/20240224a.html"/>
    <id>https://www.adunas.top/posts/20240224a.html</id>
    <published>2024-02-23T17:17:02.000Z</published>
    <updated>2024-02-23T17:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="é˜…è¯»å¯¼èˆª"><a href="#é˜…è¯»å¯¼èˆª" class="headerlink" title="é˜…è¯»å¯¼èˆª"></a><a href="./20240224b.html#è®ºæ–‡é˜…è¯»æ–¹æ³•">é˜…è¯»å¯¼èˆª</a></h1><h1 id="èµ„æºä¸‹è½½"><a href="#èµ„æºä¸‹è½½" class="headerlink" title="èµ„æºä¸‹è½½"></a>èµ„æºä¸‹è½½</h1><h2 id="arXiv"><a href="#arXiv" class="headerlink" title="arXiv"></a>arXiv</h2><ol><li>å®˜ç½‘ï¼š<a href="https://arxiv.org/">arXiv</a>ã€‚</li><li>è§†é¢‘ä»‹ç»ï¼š<a href="https://www.bilibili.com/video/BV1pT4y1m7AF/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€æ¨å€’è®ºæ–‡ä»˜è´¹å¢™ï¼Œæ•‘äººæ–°å† ç–«æƒ…é‡Œï¼Œè¿™æ˜¯â€œåå‘çŸ¥ç½‘â€arXivçš„30å¹´ã€‘</a>ã€‚</li></ol><p>&emsp;&emsp;arXiv æ˜¯å…è´¹çš„ã€å¯ä¾›ä¸‹è½½çš„è®ºæ–‡åº“ã€‚æ˜¯ä¸€ä¸ªè®ºæ–‡é¢„å°ç‰ˆç½‘ç«™ã€‚é¢„å°æœ¬ï¼ˆPreprintï¼‰æ˜¯æŒ‡ç§‘ç ”å·¥ä½œè€…çš„ç ”ç©¶æˆæœè¿˜æœªåœ¨æ­£å¼å‡ºç‰ˆç‰©ä¸Šå‘è¡¨ï¼Œè€Œå‡ºäºå’ŒåŒè¡Œäº¤æµç›®çš„è‡ªæ„¿å…ˆåœ¨å­¦æœ¯ä¼šè®®ä¸Šæˆ–é€šè¿‡äº’è”ç½‘å‘å¸ƒçš„ç§‘ç ”è®ºæ–‡ã€ç§‘æŠ€æŠ¥å‘Šç­‰æ–‡ç« ã€‚è€Œå¦ä¸€æ–¹é¢ï¼ŒarXivæœ‰ç‹¬ç‰¹çš„ä½œç”¨ï¼šä¸ºäº†é˜²æ­¢è‡ªå·±çš„ idea åœ¨è®ºæ–‡è¢«æ”¶å½•å‰è¢«åˆ«äººå‰½çªƒï¼Œå¯ä»¥å°†é¢„ç¨¿ä¸Šä¼ åˆ° arXiv ä½œä¸ºé¢„æ”¶å½•ï¼Œå› æ­¤è¿™å°±æ˜¯ä¸ªå¯ä»¥è¯æ˜è®ºæ–‡åŸåˆ›æ€§ï¼ˆä¸Šä¼ æ—¶é—´æˆ³ï¼‰çš„æ–‡æ¡£æ”¶å½•ç½‘ç«™ã€‚</p>]]></content>
    
    
    <summary type="html">ğŸ—æœ¬æ–‡è®°å½•å­¦ä¹ è®ºæ–‡çš„èµ„æºå’Œæ–¹æ³•</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="é˜…è¯»æ–¹æ³•" scheme="https://www.adunas.top/tags/%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡é˜…è¯»ï¼šä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•</title>
    <link href="https://www.adunas.top/posts/20240225b.html"/>
    <id>https://www.adunas.top/posts/20240225b.html</id>
    <published>2024-02-23T14:30:12.000Z</published>
    <updated>2024-02-23T14:30:12.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note blue no-icon flat"><ol><li>bç«™è§†é¢‘ï¼š<a href="https://www.bilibili.com/video/BV1EC411z7Lz/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€ã€IJRRæœ€æ–°æˆæœã€‘åˆ©ç”¨è¢«å¿½è§†çš„è§†è§‰ä¿¡æ¯å¤§å¹…æå‡ç›®æ ‡å®šä½å¯è§‚æ€§ã€‘</a></li><li>è®ºæ–‡èµ„æºï¼š<a href="https://arxiv.org/abs/2401.17117">A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements</a></li></ol></div><h1 id="é˜…è¯»å¯¼èˆª"><a href="#é˜…è¯»å¯¼èˆª" class="headerlink" title="é˜…è¯»å¯¼èˆª"></a><a href="./20240224b.html#ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•">é˜…è¯»å¯¼èˆª</a></h1><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>This paper studies the problem of estimating the motion of a moving<br>target object using a moving monocular camera. The targetâ€™s geometric<br>information such as its physical size is <em>unknown</em> in advance. This<br>problem is important in many fields<br>[@Qiu2019; @Griffin2021; @Tekin2018]. Our present work is particularly<br>motivated by the task of aerial target pursuit, where a micro aerial<br>vehicle (MAV) uses its onboard camera to detect, localize, and then<br>pursue another flying MAV. The task of aerial target pursuit, originally<br>motivated by the interesting bird-catching-bird behaviors in nature<br>[@Brighton2019], potentially provides an effective approach to the<br>defense of misused MAV [@Rothe2019; @Dressel2019; @Vrba2020].</p><p>When a target has been detected in an image by a vision detection<br>algorithm, we usually obtain a <em>bounding box</em> that surrounds the<br>targetâ€™s image (see<br>Fig. <a href="#fig_architecture_outdoor">1</a>{reference-type=â€refâ€<br>reference=â€fig_architecture_outdoorâ€}). The bounding box carries two<br>types of useful information that can be used to estimate the targetâ€™s<br>motion.</p><p>The first type of useful information is the <em>center point</em> of the<br>bounding box. The pixel coordinate of the center point can be used to<br>calculate the spatial <em>bearing vector</em> pointing from the camera to the<br>target based on the pin-hole camera model [@Ma2012]. Using the bearing<br>vector to estimate the targetâ€™s motion is referred to as <em>bearing-only</em><br>target motion estimation [@Fogel1988; @He2019; @Li2022]. As a problem<br>that has been studied for more than 40 years, bearing-only target motion<br>estimation was originally studied to estimate the motion of ships on the<br>ocean surface [@hoelzer1978modified], and regained increasing research<br>attention in recent years in vision-based target estimation tasks<br>[@Ponda2009; @Anjaly2018; @He2019].</p><p>Bearing-only target motion estimation requires an <em>observability<br>condition</em>: The observer must have higher-order motion than the target<br>and, more importantly, the higher-order motion must contain components<br>that are orthogonal to the targetâ€™s bearing vector [@Fogel1988].<br>Motivated by this observability condition, enormous works have studied<br>how an observer should move to enhance the observability<br>[@Hammel1989; @Sabet2016; @Anjaly2018; @He2019]. For instance, in our<br>recent work [@Li2022], we proposed a helical guidance law so that a MAV<br>moves along a helical curve to optimize the observability in the 3D<br>space.</p><p>A <em>limitation</em> of the observability condition of the classic<br>bearing-only approach is that the observer must move in the lateral<br>directions that are orthogonal to the bearing vector of the target. Such<br>additional lateral motion is usually unfavorable because it may conflict<br>with the desired motion of the observer in many tasks. For example, in<br>an aerial target pursuit task, the pursuer is desired to approach the<br>target as fast as possible and then keep stationary relative to the<br>target. Then, the additional lateral motion would conflict with the<br>desired motion. It is, therefore, important to study other ways that can<br>enhance the observability while avoiding unfavorable lateral motion.</p><p>The second type of useful information of a bounding box is its <em>size</em><br>(either width or height). The size of a bounding box is jointly<br>determined by several factors such as the targetâ€™s distance, the<br>targetâ€™s physical size, and the orientation of the camera. The targetâ€™s<br>physical size is usually unknown in many tasks, especially in those<br>antagonistic ones such as aerial pursuit of misused MAVs. As a result,<br>the size of the bounding box cannot directly infer the targetâ€™s<br>distance. Nevertheless, it carries valuable information for localizing<br>the target.</p><p>Surprisingly, the size information of the bounding box has not been well<br>explored so far. The work that is closely relevant to ours is the<br>state-of-the-art one in [@Griffin2021], where the size of a bounding box<br>is used to localize unknown target objects. Although the approach in<br>[@Griffin2021] is inspiring, it relies on two assumptions: The target<br>objects are stationary and the camera can only translate without<br>rotating. It is still an open problem how to estimate a targetâ€™s motion<br>when the two assumptions are not valid. Moreover, the theoretical role<br>of the size of a bounding box in target motion estimation has not been<br>fully understood so far. Although the work in [@Vrba2020] also utilizes<br>the size of the bounding box to estimate the targetâ€™s position, it is<br>assumed that the targetâ€™s physical size is known in advance.</p><p>Estimating the motion of moving objects is also a fundamental problem in<br>dynamic SLAM. For example, the works in [@Yang2019; @Qiu2019] firstly<br>estimate the cameraâ€™s pose and secondly estimate the target objectâ€™s<br>pose subject to a scale factor, and finally estimate the scale factor<br>from multi-view measurements. To estimate the target objectâ€™s pose<br>subject to a scale factor, [@Yang2019] and [@Qiu2019] rely on detecting,<br>respectively, a 3D bounding box and sufficient feature points inside the<br>2D bounding box. Different from [@Yang2019; @Qiu2019], our proposed<br>approach merely utilizes a 2D image bounding box without further<br>extracting feature points or a 3D bounding box inside the 2D bounding<br>box. As a result, one benefit is that this approach is more<br>computationally efficient. Moreover, this approach can handle the<br>challenging small-target case where the target object is far and hence<br>its image is small. In this case, it would be unreliable to extract<br>sufficient stable features or conduct 3D detection.</p><p>The aforementioned approaches in [@Griffin2021; @Yang2019; @Qiu2019] are<br>all based on multiple views. It is also possible to estimate the<br>targetâ€™s depth from a single view/image [@Tekin2018; @Vrba2020]. The<br>single-view approach however requires prior information of the objects.<br>Moreover, it would be unable to successfully localize target objects<br>with different sizes but similar appearances. In this paper, we focus on<br>the multi-view case.</p><p>In this paper, we propose a novel <em>bearing-angle</em> target motion<br>estimation approach that models a bounding box as bearing-angle<br>measurements. This approach can enhance the observability by fully<br>exploiting the information in a bounding box rather than relying on the<br>additional lateral motion of the observer. The benefit of the proposed<br>bearing-angle approach comes with no additional cost since the bounding<br>box is a standard output of object detection algorithms. The approach<br>simply exploits the angle information that has not been fully exploited<br>in the past. No additional sensing devices or special detection<br>algorithms are required.</p><p>The technical novelties of this approach are threefold.</p><p>1) The proposed approach does not directly use the size of a bounding<br>box because the size is variant to the orientation of the camera. That<br>is, even if the targetâ€™s relative position is unchanged, the size of the<br>bounding box still varies when the camera rotates. Motivated by this<br>problem, we convert the size of the bounding box to an angle subtended<br>by the target (see<br>Fig. <a href="#fig_architecture_outdoor">1</a>{reference-type=â€refâ€<br>reference=â€fig_architecture_outdoorâ€}). The merit of using the angle<br>measurement is that it is <em>invariant</em> to the cameraâ€™s orientation change<br>(see Fig. <a href="#fig_cam_rotate">2</a>{reference-type=â€refâ€<br>reference=â€fig_cam_rotateâ€}) and hence can greatly facilitate the<br>estimator design. In this way, the assumption in [@Griffin2021] that the<br>camera can only translate but not rotate can be avoided.</p><p>2) Although the bearing-angle approach incorporates an additional angle<br>measurement, it is nontrivial to see how to properly use this<br>measurement because the angle does not directly infer the targetâ€™s<br>distance given that the targetâ€™s size is unknown. We notice that the<br>angle is a joint nonlinear function of the targetâ€™s physical size and<br>relative distance. Hence, the state vector, which only consists of the<br>targetâ€™s position and velocity in the conventional bearing-only<br>approach, is augmented by the unknown targetâ€™s physical size. Since the<br>bearing and angle measurements are all nonlinear functions of the<br>targetâ€™s state, we establish a pseudo-linear Kalman filter to properly<br>utilize the measurements to enhance estimation stability. Both<br>simulation and real-world experiments verify the effectiveness of the<br>proposed estimator.</p><p>3) Although an additional angle measurement is used, an additional<br>unknown, the targetâ€™s physical size, is also introduced into the<br>estimator. It is, therefore, nontrivial to see how the additional angle<br>measurement can help improve the observability. Motivated by this<br>problem, we prove the necessary and sufficient observability condition<br>for bearing-angle target motion estimation. In particular, we show that<br>the targetâ€™s motion can be recovered if and only if the observer has a<br>higher-order motion than the target. Different from the bearing-only<br>case, the higher-order motion is <em>not</em> required to be in the lateral<br>directions that are orthogonal to the bearing vector. This is an<br>important enhancement of the observability. As we show in various<br>experiments, the bearing-angle approach can successfully recover the<br>targetâ€™s motion in many scenarios where the bearing-only approach fails.</p><h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><h2 id="Algorithms-for-bearing-only-target-motion-estimation"><a href="#Algorithms-for-bearing-only-target-motion-estimation" class="headerlink" title="Algorithms for bearing-only target motion estimation"></a>Algorithms for bearing-only target motion estimation</h2><p>Bearing-only target motion analysis aims to estimate the targetâ€™s motion<br>states, such as position and velocity, using bearing measurement only.<br>It was originally motivated by ship localization and tracking in the<br>ocean [@hoelzer1978modified]. With the rapid development of small-scale<br>mobile robots equipped with cameras, the bearing-only approach regained<br>increasing attention in recent years [@Ponda2009; @Anjaly2018; @He2019].</p><p>Kalman filter-based estimators are widely used in the bearing-only<br>target motion. One challenge of applying the Kalman filter to the<br>bearing-only estimation is the nonlinearity of the bearing measurement.<br>The conventional extended Kalman filter (EKF) exhibits divergence<br>problems when applied to bearing-only target motion estimation<br>[@Aidala1979; @Lin2002]. Several methods have been proposed to solve<br>this problem. They can be divided into two types. The first type is the<br>modified polar EKF, which was first proposed in [@hoelzer1978modified].<br>In this approach, three observable quantities are separated from the<br>unobservable ones to prevent divergence. The work in [@Stallard1991]<br>extends this approach to the case of spherical coordinates to track<br>targets in 3D space. The second type is the pseudo-linear Kalman filter,<br>which is first proposed in [@Lingren1978] to solve the instability<br>problem by transforming the nonlinear measurement equation into a<br>pseudo-linear one. However, this transformation makes the noise become<br>non-Gaussian and highly correlated to the measurement matrix and then<br>causes estimation bias. Nevertheless, the work in [@Aidala1982]<br>theoretically proves that the velocity estimation has no bias, and the<br>position estimation bias can be removed by the observerâ€™s maneuvers.</p><p>Recently, other estimation algorithms based on advanced but more complex<br>filters have been proposed. The work in [@Farina1999] uses the maximum<br>likelihood (MLE) algorithm to estimate the targetâ€™s motion using<br>bearing-only measurements. The comparison with the Cramer-Rao lower<br>bound indicates that the MLE-based estimator is effective against<br>measurement errors. The work in [@Dogancay2005] proposes a constrained<br>total least-squares algorithm, which can improve the estimation accuracy<br>when the error of bearing measurement is large. Three different<br>algorithms are used and compared in [@Lin2002]. The results show that<br>the EKF, the pseudo-linear filter, and the particle filter have similar<br>performances in most situations, while the EKF loses track when the<br>initial estimate error is large.</p><p>Another type of approach, called bearing-only trajectory triangulation<br>[@Avidan2000], estimates the targetâ€™s position from the perspective of<br>trajectory fitting. It reconstructs the trajectory by intersecting<br>parametric trajectory to a series of sight rays obtained from bearing<br>measurement. Once the trajectory is successfully fitted, the targetâ€™s<br>position at each time instant can be estimated by the intersection of<br>the bearing and the trajectory. The trajectory fitting relies on the<br>assumption of the trajectoryâ€™s shape. However, in many applications, the<br>targetâ€™s trajectory is complex and unknown in advance. Many consecutive<br>studies aim to relax this assumption in various ways based on<br>hypersurfaces [@Kaminski2004], parametric temporal polynomials<br>[@Yu2009], or compact basis vectors [@Park2015].</p><h2 id="Observability-analysis-of-bearing-only-target-motion-estimation"><a href="#Observability-analysis-of-bearing-only-target-motion-estimation" class="headerlink" title="Observability analysis of bearing-only target motion estimation"></a>Observability analysis of bearing-only target motion estimation</h2><p>Observability is a fundamental problem in bearing-only target motion<br>estimation. Early works mainly focus on whether the system is observable<br>or not. For example, the work in [@Lingren1978] uses the rank of<br>observation matrix to determine the observability. The work in<br>[@Fogel1988] extends the observability criterion in [@Nardone1981] to<br>the Nth-order target dynamics and inspires us for the observability<br>analysis in<br>Section <a href="#sec_observability_criteria">6</a>{reference-type=â€refâ€<br>reference=â€sec_observability_criteriaâ€}. All these conditions indicate<br>that the observer must have extra high-order motion in the lateral<br>direction. The observability condition can be significantly relaxed in<br>our approach.</p><p>Unlike the works on determining whether the system is observable or not,<br>some studies focus on quantifying the observability degree. The work in<br>[@Hammel1989] first introduces the Fisher information matrix (FIM) into<br>the observability analysis. The works in [@Sabet2016] and [@Anjaly2018]<br>use FIM-based objective functions to maximize observability. We also use<br>the FIM in our former work [@Li2022] to optimize the 3D helical guidance<br>law for better observability. Another method called the geometric method<br>uses the geometric relationship between the target and the observer in<br>two consecutive time instants to derive the measure of observability<br>[@He2019; @Woffinden2009], and the results are consistent with those<br>derived using FIM. Compared to the bearing-only approach, the<br>observability degree of our bearing-angle method is sufficient to<br>estimate the targetâ€™s motion in many common scenarios such as tracking<br>and guidance (see experiment results in<br>Figs. <a href="#fig_matlab_3">[fig_matlab_3]</a>{reference-type=â€refâ€<br>reference=â€fig_matlab_3â€}<br>and <a href="#fig_outdoor_1">[fig_outdoor_1]</a>{reference-type=â€refâ€<br>reference=â€fig_outdoor_1â€}).</p><h1 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h1><p><img src="fig_cam_rotate" alt="The size of the bounding box varies when the camera rotates. Bycontrast, the angle subtended by the target object is invariant to thecamera&#39;s orientation change."></p><p>Consider a target object moving in the 3D space. Its position and<br>velocity at time $t_k$ are denoted as $p_T(t_k) \in\mathbb{R}^3$ and<br>$v_T(t_k) \in\mathbb{R}^3$, respectively. Suppose there is an observer<br>carrying a monocular camera to observe the target. The position of the<br>observer is denoted as $p_o(t_k) \in\mathbb{R}^3$. Here, we assume that<br>the observer/cameraâ€™s pose including its position and orientation can be<br>obtained in other ways. For example, it can be measured directly by RTK<br>GPS [@Li2022] or estimated by visual inertial odometry [@Qiu2019]. In<br>the rest of the paper, the dependence of a variable on $t_k$ is dropped<br>when the context is clear.</p><p>If the target object can be detected by a vision algorithm, we can<br>obtain a bounding box surrounding the target object in the image. Two<br>types of information carried by the bounding box can be used to estimate<br>the motion of the target.</p><p>First, the center point of the bounding box can be used to calculate the<br><em>bearing</em> vector of the target. In particular, denote<br>${g} \in \mathbb{R}^3$ as the unit bearing vector pointing from $p<em>o$ to<br>$p_T$. Suppose ${P}</em>\text{cam}\in\mathbb{R}^{3\times3}$ is the intrinsic<br>parameter matrix of the camera [@Ma2012<br>Section <a href="#section_bearing-angle-target-motion-estimator">4</a>{reference-type=â€refâ€<br>reference=â€section<em>bearing-angle-target-motion-estimatorâ€}], and<br>${R}</em>\text{c}^\text{w} \in\mathbb{R}^{3\times 3}$ is the rotation from<br>the camera frame to the world frame. Then, the bearing vector $g$ can be<br>calculated as <script type="math/tex">\begin{aligned}{g} =\dfrac{{R}_\text{c}^\text{w}{P}_\text{cam}^{-1}{q}_{\rm pix}}{\|{R}_\text{c}^\text{w}{P}_\text{cam}^{-1}{q}_{\rm pix}\|},\end{aligned}</script> where<br>${q}<em>{\rm pix} =[x</em>{\rm pix} , y<em>{\rm pix} , 1]^\mathrm{T} \in \mathbb{R}^3$.<br>Here, $(x</em>{\rm pix} ,y_{\rm pix})$ is the pixel coordinate of the center<br>point of the bounding box.</p><p>Second, the size of the bounding box can be used to calculate the<br><em>angle</em> subtended by the target in the cameraâ€™s field of view. The<br>reason that we convert the bounding boxâ€™s size to the angle is that the<br>angle is invariant to the cameraâ€™s orientation change (see<br>Fig. <a href="#fig_cam_rotate">2</a>{reference-type=â€refâ€<br>reference=â€fig<em>cam_rotateâ€}). In particular, let $s</em>{\rm pix}$ denote<br>the size of the bounding box. It can be either the width or the height.<br>Let $\theta \in (0,\pi/2)$ be the angle. According to the pin-hole<br>camera model [@Ma2012<br>Section <a href="#section_bearing-angle-target-motion-estimator">4</a>{reference-type=â€refâ€<br>reference=â€section_bearing-angle-target-motion-estimatorâ€}] and the law<br>of cosine (see Fig. <a href="#fig_cam_rotate">2</a>{reference-type=â€refâ€<br>reference=â€fig_cam_rotateâ€}), the angle can be calculated as</p><p><script type="math/tex">\begin{aligned}\theta = \arccos\left(\dfrac{l_\mathrm{left}^2 + l_\mathrm{right}^2 - s_\mathrm{pix}^2}{2l_\mathrm{left}l_\mathrm{right}}\right),\end{aligned}</script> where<br>$l<em>\mathrm{left}=\sqrt{(f/\alpha)^2+(\delta x-s</em>\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}$<br>and<br>$l<em>\mathrm{right}=\sqrt{(f/\alpha)^2+(\delta x+s</em>\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}$<br>are the distances in pixel from the camera center to the middle points<br>of the left and right sides of the bounding box, respectively<br>(Fig. <a href="#fig_architecture_outdoor">1</a>{reference-type=â€refâ€<br>reference=â€fig<em>architecture_outdoorâ€}). Moreover, $f$ and $\alpha$<br>denote the cameraâ€™s focal length and single pixel size, respectively.<br>$i</em>{\text{width}}$ and $i<em>{\text{height}}$ represent the width and the<br>height of the whole image in pixels, respectively.<br>$\delta x=|x</em>\text{pix}-i<em>\text{width}/2|\in\mathbb{R}$ and<br>$\delta y = |y</em>\text{pix}-i_\text{height}/2|\in\mathbb{R}$ are the<br>distances between the center of the bounding box and the center of the<br>image.</p><p>::: figure*<br><img src="fig_architecture_algorithm" alt="image">{width=â€1\linewidthâ€}<br>:::</p><p>Our goal is to estimate the targetâ€™s position and velocity, $p_T$ and<br>$v_T$, based on the noisy measurements of the bearing vector ${g}$ and<br>the angle $\theta$ together with the observerâ€™s own position $p_o$. To<br>achieve this goal, we propose a new bearing-angle target motion<br>estimator<br>(Fig. <a href="#fig_architecture_algorithm">[fig_architecture_algorithm]</a>{reference-type=â€refâ€<br>reference=â€fig_architecture_algorithmâ€}). The estimator is introduced in<br>detail in<br>Section <a href="#section_bearing-angle-target-motion-estimator">4</a>{reference-type=â€refâ€<br>reference=â€section_bearing-angle-target-motion-estimatorâ€}. The<br>observability of this estimator is analyzed based on Kalmanâ€™s<br>observability criterion in<br>Section <a href="#sec_analysis_of_observability_matrix">5</a>{reference-type=â€refâ€<br>reference=â€sec_analysis_of_observability_matrixâ€}. We further prove a<br>necessary and sufficient observability condition of the observer in<br>Section <a href="#sec_observability_criteria">6</a>{reference-type=â€refâ€<br>reference=â€sec_observability_criteriaâ€}. Numerical simulation results<br>are given in Section <a href="#sec_matlab_simulation">7</a>{reference-type=â€refâ€<br>reference=â€sec_matlab_simulationâ€}. More realistic AirSim simulation<br>results are given in<br>Section <a href="#sec_airsim_simulation">8</a>{reference-type=â€refâ€<br>reference=â€sec_airsim_simulationâ€}. Finally, real-world experiments are<br>given in<br>Section <a href="#sec_real_world_experimental_validation">9</a>{reference-type=â€refâ€<br>reference=â€sec_real_world_experimental_validationâ€}.</p><h1 id="Bearing-Angle-Target-Motion-Estimator"><a href="#Bearing-Angle-Target-Motion-Estimator" class="headerlink" title="Bearing-Angle Target Motion Estimator"></a>Bearing-Angle Target Motion Estimator</h1>]]></content>
    
    
    <summary type="html">ğŸ§µæœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨ç§»åŠ¨å•ç›®ç›¸æœºä¼°è®¡ç§»åŠ¨ç›®æ ‡ç‰©ä½“è¿åŠ¨çš„é—®é¢˜</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="è§†è§‰å¯¼èˆª" scheme="https://www.adunas.top/tags/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>è®ºæ–‡é˜…è¯»ï¼šä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•</title>
    <link href="https://www.adunas.top/posts/20240223a.html"/>
    <id>https://www.adunas.top/posts/20240223a.html</id>
    <published>2024-02-23T14:30:12.000Z</published>
    <updated>2024-02-23T14:30:12.000Z</updated>
    
    <content type="html"><![CDATA[<div class="note blue no-icon flat"><ol><li>bç«™è§†é¢‘ï¼š<a href="https://www.bilibili.com/video/BV1EC411z7Lz/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€ã€IJRRæœ€æ–°æˆæœã€‘åˆ©ç”¨è¢«å¿½è§†çš„è§†è§‰ä¿¡æ¯å¤§å¹…æå‡ç›®æ ‡å®šä½å¯è§‚æ€§ã€‘</a></li><li>è®ºæ–‡èµ„æºï¼š<a href="https://arxiv.org/abs/2401.17117">A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements</a></li></ol></div><h1 id="é˜…è¯»å¯¼èˆª"><a href="#é˜…è¯»å¯¼èˆª" class="headerlink" title="é˜…è¯»å¯¼èˆª"></a><a href="./20240224b.html#ä¸€ç§åŸºäºç›®æµ‹çš„æœªçŸ¥ç›®æ ‡è¿åŠ¨åˆ†ææ–¹ä½è§’æ–¹æ³•">é˜…è¯»å¯¼èˆª</a></h1><h1 id="A-Bearing-Angle-Approach-for-Unknown-Target-Motion-Analysis-Based-on-Visual-Measurements"><a href="#A-Bearing-Angle-Approach-for-Unknown-Target-Motion-Analysis-Based-on-Visual-Measurements" class="headerlink" title="A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements"></a>A Bearing-Angle Approach for Unknown Target Motion Analysis Based on Visual Measurements</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>&emsp;&emsp;Vision-based estimation of the motion of a moving target is usually formulated as a <em>bearing-only</em> estimation problem where the visual measurement is modeled as a bearing vector. Although the bearing-only approach has been studied for decades, a <em>fundamental limitation</em> of this approach is that it requires extra lateral motion of the observer to enhance the targetâ€™s observability. Unfortunately, the extra lateral motion conflicts with the desired motion of the observer in many tasks.<br>It is well-known that, once a target has been detected in an image, a bounding box that surrounds the target can be obtained.<br>Surprisingly, this common visual measurement especially its size information has not been well explored up to now.<br>In this paper, we propose a new <em>bearing-angle</em> approach to estimate the motion of a target by modeling its image bounding box as bearing-angle measurements.<br>Both theoretical analysis and experimental results show that this approach can significantly enhance the observability <em>without</em> relying on additional lateral motion of the observer.<br>The benefit of the bearing-angle approach comes with no additional cost because a bounding box is a standard output of object detection algorithms.<br>The approach simply exploits the information that has not been fully exploited in the past.<br>No additional sensing devices or special detection algorithms are required.</p><h2 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h2><p>Bearing-only target motion estimation, Pseudo-linear Kalman filter, Observability enhancement</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;This paper studies the problem of estimating the motion of a moving target object using a moving monocular camera. The targetâ€™s geometric information such as its physical size is <em>unknown</em> in advance. This problem is important in many fields<!--  \citep{Qiu2019, Griffin2021, Tekin2018} -->.<br>Our present work is particularly motivated by the task of aerial target pursuit, where a micro aerial vehicle (MAV) uses its onboard camera to detect, localize, and then pursue another flying MAV.<br>The task of aerial target pursuit, originally motivated by the interesting bird-catching-bird behaviors in nature<!--  \citep{Brighton2019} -->, potentially provides an effective approach to the defense of misused MAV<!--  \citep{Rothe2019, Dressel2019, Vrba2020} -->.</p><p><a id= "fig_architecture_outdoor"></a><br><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_architecture_outdoor.png" alt="Fig.1 An observer MAV observes a target MAV with a monocular camera. The bearing $g$ and angle $\theta$ can be obtained from the bounding box that surrounds the target in the image."></p><p>&emsp;&emsp;When a target has been detected in an image by a vision detection algorithm, we usually obtain a <em>bounding box</em> that surrounds the targetâ€™s image (see <a href="#fig_architecture_outdoor">Fig.1</a>).<br>The bounding box carries two types of useful information that can be used to estimate the targetâ€™s motion.</p><p>&emsp;&emsp;The first type of useful information is the <em>center point</em> of the bounding box.<br>The pixel coordinate of the center point can be used to calculate the spatial <em>bearing vector</em> pointing from the camera to the target based on the pin-hole camera model<!--  \citep{Ma2012} -->.<br>Using the bearing vector to estimate the targetâ€™s motion is referred to as <em>bearing-only</em> target motion estimation<!--  \citep{Fogel1988, He2019, Li2022} -->.<br>As a problem that has been studied for more than 40 years, bearing-only target motion estimation was originally studied to estimate the motion of ships on the ocean surface<!--  \citep{hoelzer1978modified} -->, and regained increasing research attention in recent years in vision-based target estimation tasks<!--  \citep{Ponda2009, Anjaly2018, He2019} -->.</p><p>&emsp;&emsp;Bearing-only target motion estimation requires an <em>observability condition</em>: The observer must have higher-order motion than the target and, more importantly, the higher-order motion must contain components that are orthogonal to the targetâ€™s bearing vector<!--  \citep{Fogel1988} -->.<br>Motivated by this observability condition, enormous works have studied how an observer should move to enhance the observability<!--  \citep{Hammel1989, Sabet2016, Anjaly2018, He2019} -->.<br>For instance, in our recent work<!--  \citep{Li2022} -->, we proposed a helical guidance law so that a MAV moves along a helical curve to optimize the observability in the 3D space.</p><p>&emsp;&emsp;A <em>limitation</em> of the observability condition of the classic bearing-only approach is that the observer must move in the lateral directions that are orthogonal to the bearing vector of the target.<br>Such additional lateral motion is usually unfavorable because it may conflict with the desired motion of the observer in many tasks.<br>For example, in an aerial target pursuit task, the pursuer is desired to approach the target as fast as possible and then keep stationary relative to the target. Then, the additional lateral motion would conflict with the desired motion.<br>It is, therefore, important to study other ways that can enhance the observability while avoiding unfavorable lateral motion.</p><p>&emsp;&emsp;The second type of useful information of a bounding box is its <em>size</em> (either width or height).<br>The size of a bounding box is jointly determined by several factors such as the targetâ€™s distance, the targetâ€™s physical size, and the orientation of the camera.<br>The targetâ€™s physical size is usually unknown in many tasks, especially in those antagonistic ones such as aerial pursuit of misused MAVs.<br>As a result, the size of the bounding box cannot directly infer the targetâ€™s distance.<br>Nevertheless, it carries valuable information for localizing the target.</p><p>&emsp;&emsp;Surprisingly, the size information of the bounding box has not been well explored so far.<br>The work that is closely relevant to ours is the state-of-the-art one in<!--  \citep{Griffin2021} -->, where the size of a bounding box is used to localize unknown target objects.<br>Although the approach in<!--  \citep{Griffin2021} --> is inspiring, it relies on two assumptions: The target objects are stationary and the camera can only translate without rotating.<br>It is still an open problem how to estimate a targetâ€™s motion when the two assumptions are not valid.<br>Moreover, the theoretical role of the size of a bounding box in target motion estimation has not been fully understood so far.<br>Although the work in<!--  \citep{Vrba2020} --> also utilizes the size of the bounding box to estimate the targetâ€™s position, it is assumed that the targetâ€™s physical size is known in advance.</p><p>&emsp;&emsp;Estimating the motion of moving objects is also a fundamental problem in dynamic SLAM.<br>For example, the works in<!--  \citep{Yang2019,Qiu2019} --> firstly estimate the cameraâ€™s pose and secondly estimate the target objectâ€™s pose subject to a scale factor, and finally estimate the scale factor from multi-view measurements.<br>To estimate the target objectâ€™s pose subject to a scale factor,<!--  \citep{Yang2019} --> and<!--  \citep{Qiu2019} --> rely on detecting, respectively, a 3D bounding box and sufficient feature points inside the 2D bounding box.<br>Different from<!--  \citep{Yang2019,Qiu2019} -->, our proposed approach merely utilizes a 2D image bounding box without further extracting feature points or a 3D bounding box inside the 2D bounding box.<br>As a result, one benefit is that this approach is more computationally efficient.<br>Moreover, this approach can handle the challenging small-target case where the target object is far and hence its image is small.<br>In this case, it would be unreliable to extract sufficient stable features or conduct 3D detection.</p><p>&emsp;&emsp;The aforementioned approaches in<!--  \citep{Griffin2021,Yang2019,Qiu2019} --> are all based on multiple views.<br>It is also possible to estimate the targetâ€™s depth from a single view/image<!--  \citep{Tekin2018, Vrba2020} -->.<br>The single-view approach however requires prior information of the objects.<br>Moreover, it would be unable to successfully localize target objects with different sizes but similar appearances.<br>In this paper, we focus on the multi-view case.</p><p>&emsp;&emsp;In this paper, we propose a novel <em>bearing-angle</em> target motion estimation approach that models a bounding box as bearing-angle measurements.<br>This approach can enhance the observability by fully exploiting the information in a bounding box rather than relying on the additional lateral motion of the observer.<br>The benefit of the proposed bearing-angle approach comes with no additional cost since the bounding box is a standard output of object detection algorithms.<br>The approach simply exploits the angle information that has not been fully exploited in the past.<br>No additional sensing devices or special detection algorithms are required.</p><p>&emsp;&emsp;The technical novelties of this approach are threefold.</p><ol><li><p>The proposed approach does not directly use the size of a bounding box because the size is variant to the orientation of the camera.<br>That is, even if the targetâ€™s relative position is unchanged, the size of the bounding box still varies when the camera rotates.<br>Motivated by this problem, we convert the size of the bounding box to an angle subtended by the target (see <a href="#fig_architecture_outdoor">Fig.1</a>).<br>The merit of using the angle measurement is that it is <em>invariant</em> to the cameraâ€™s orientation change (see <a href="#fig_cam_rotate">Fig.2</a>) and hence can greatly facilitate the estimator design.<br>In this way, the assumption in<!--  \citep{Griffin2021} --> that the camera can only translate but not rotate can be avoided.</p></li><li><p>Although the bearing-angle approach incorporates an additional angle measurement, it is nontrivial to see how to properly use this measurement because the angle does not directly infer the targetâ€™s distance given that the targetâ€™s size is unknown.<br>We notice that the angle is a joint nonlinear function of the targetâ€™s physical size and relative distance.<br>Hence, the state vector, which only consists of the targetâ€™s position and velocity in the conventional bearing-only approach, is augmented by the unknown targetâ€™s physical size.<br>Since the bearing and angle measurements are all nonlinear functions of the targetâ€™s state, we establish a pseudo-linear Kalman filter to properly utilize the measurements to enhance estimation stability.<br>Both simulation and real-world experiments verify the effectiveness of the proposed estimator.</p></li><li><p>Although an additional angle measurement is used, an additional unknown, the targetâ€™s physical size, is also introduced into the estimator.<br>It is, therefore, nontrivial to see how the additional angle measurement can help improve the observability.<br>Motivated by this problem, we prove the necessary and sufficient observability condition for bearing-angle target motion estimation.<br>In particular, we show that the targetâ€™s motion can be recovered if and only if the observer has a higher-order motion than the target.<br>Different from the bearing-only case, the higher-order motion is <em>not</em> required to be in the lateral directions that are orthogonal to the bearing vector.<br>This is an important enhancement of the observability. As we show in various experiments, the bearing-angle approach can successfully recover the targetâ€™s motion in many scenarios where the bearing-only approach fails.</p></li></ol><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Algorithms-for-bearing-only-target-motion-estimation"><a href="#Algorithms-for-bearing-only-target-motion-estimation" class="headerlink" title="Algorithms for bearing-only target motion estimation"></a>Algorithms for bearing-only target motion estimation</h3><p>&emsp;&emsp;Bearing-only target motion analysis aims to estimate the targetâ€™s motion states, such as position and velocity, using bearing measurement only.<br>It was originally motivated by ship localization and tracking in the ocean<!--  \citep{hoelzer1978modified} -->. With the rapid development of small-scale mobile robots equipped with cameras, the bearing-only approach regained increasing attention in recent years<!--  \citep{Ponda2009, Anjaly2018, He2019} -->.</p><p>&emsp;&emsp;Kalman filter-based estimators are widely used in the bearing-only target motion.<br>One challenge of applying the Kalman filter to the bearing-only estimation is the nonlinearity of the bearing measurement.<br>The conventional extended Kalman filter (EKF) exhibits divergence problems when applied to bearing-only target motion estimation<!--  \citep{Aidala1979, Lin2002} -->.<br>Several methods have been proposed to solve this problem.<br>They can be divided into two types.<br>The first type is the modified polar EKF, which was first proposed in<!--  \citep{hoelzer1978modified} -->.<br>In this approach, three observable quantities are separated from the unobservable ones to prevent divergence.<br>The work in<!--  \citep{Stallard1991} --> extends this approach to the case of spherical coordinates to track targets in 3D space.<br>The second type is the pseudo-linear Kalman filter, which is first proposed in<!--  \citep{Lingren1978} --> to solve the instability problem by transforming the nonlinear measurement equation into a pseudo-linear one.<br>However, this transformation makes the noise become non-Gaussian and highly correlated to the measurement matrix and then causes estimation bias.<br>Nevertheless, the work in<!--  \citep{Aidala1982} --> theoretically proves that the velocity estimation has no bias, and the position estimation bias can be removed by the observerâ€™s maneuvers.</p><p>&emsp;&emsp;Recently, other estimation algorithms based on advanced but more complex filters have been proposed.<br>The work in<!--  \citep{Farina1999} --> uses the maximum likelihood (MLE) algorithm to estimate the targetâ€™s motion using bearing-only measurements.<br>The comparison with the Cramer-Rao lower bound indicates that the MLE-based estimator is effective against measurement errors.<br>The work in<!--  \citep{Dogancay2005} --> proposes a constrained total least-squares algorithm, which can improve the estimation accuracy when the error of bearing measurement is large.<br>Three different algorithms are used and compared in<!--  \citep{Lin2002} -->.<br>The results show that the EKF, the pseudo-linear filter, and the particle filter have similar performances in most situations, while the EKF loses track when the initial estimate error is large.</p><p>&emsp;&emsp;Another type of approach, called bearing-only trajectory triangulation<!--  \citep{Avidan2000} -->, estimates the targetâ€™s position from the perspective of trajectory fitting.<br>It reconstructs the trajectory by intersecting parametric trajectory to a series of sight rays obtained from bearing measurement.<br>Once the trajectory is successfully fitted, the targetâ€™s position at each time instant can be estimated by the intersection of the bearing and the trajectory.<br>The trajectory fitting relies on the assumption of the trajectoryâ€™s shape.<br>However, in many applications, the targetâ€™s trajectory is complex and unknown in advance.<br>Many consecutive studies aim to relax this assumption in various ways based on hypersurfaces<!--  \citep{Kaminski2004} -->, parametric temporal polynomials<!--  \citep{Yu2009} -->, or compact basis vectors<!--  \citep{Park2015} -->.</p><h3 id="Observability-analysis-of-bearing-only-target-motion-estimation"><a href="#Observability-analysis-of-bearing-only-target-motion-estimation" class="headerlink" title="Observability analysis of bearing-only target motion estimation"></a>Observability analysis of bearing-only target motion estimation</h3><p>&emsp;&emsp;Observability is a fundamental problem in bearing-only target motion estimation.<br>Early works mainly focus on whether the system is observable or not.<br>For example, the work in<!--  \citep{Lingren1978} --> uses the rank of observation matrix to determine the observability.<br>The work in<!--  \citep{Fogel1988} --> extends the observability criterion in<!--  \citep{Nardone1981} --> to the Nth-order target dynamics and inspires us for the observability analysis in Section<!--  \ref{sec_observability_criteria} --> <a href="#sec_observability_criteria">Observability Analysis by Solving Linear Equations</a>.<br>All these conditions indicate that the observer must have extra high-order motion in the lateral direction.<br>The observability condition can be significantly relaxed in our approach.</p><p>&emsp;&emsp;Unlike the works on determining whether the system is observable or not, some studies focus on quantifying the observability degree.<br>The work in<!--  \citep{Hammel1989} --> first introduces the Fisher information matrix (FIM) into the observability analysis.<br>The works in<!--  \citep{Sabet2016} --> and<!--  \citep{Anjaly2018} --> use FIM-based objective functions to maximize observability.<br>We also use the FIM in our former work<!--  \citep{Li2022} --> to optimize the 3D helical guidance law for better observability.<br>Another method called the geometric method uses the geometric relationship between the target and the observer in two consecutive time instants to derive the measure of observability<!--  \citep{He2019, Woffinden2009} -->, and the results are consistent with those derived using FIM.<br>Compared to the bearing-only approach, the observability degree of our bearing-angle method is sufficient to estimate the targetâ€™s motion in many common scenarios such as tracking and guidance (see experiment results in Figs.~\ref{fig_matlab_3} and~\ref{fig_outdoor_1}).</p><h2 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><p><a id= "fig_cam_rotate"></a><br><img src="https://picture.adunas.top/Article/arXiv-2401.17117v1/fig_cam_rotate.png" alt="Fig.2 The size of the bounding box varies when the camera rotates. By contrast, the angle subtended by the target object is invariant to the camera&#39;s orientation change."></p><p>&emsp;&emsp;Consider a target object moving in the 3D space. Its position and velocity at time $t_k$ are denoted as $p_T(t_k) \in \mathbb{R}^3$ and $v_T(t_k) \in \mathbb{R}^3$, respectively.<br>Suppose there is an observer carrying a monocular camera to observe the target.<br>The position of the observer is denoted as $p_o(t_k) \in \mathbb{R}^3$.<br>Here, we assume that the observer/cameraâ€™s pose including its position and orientation can be obtained in other ways.<br>For example, it can be measured directly by RTK GPS<!--  \citep{Li2022} --> or estimated by visual inertial odometry<!--  \citep{Qiu2019} -->.<br>In the rest of the paper, the dependence of a variable on $t_k$ is dropped when the context is clear.</p><p>&emsp;&emsp;If the target object can be detected by a vision algorithm, we can obtain a bounding box surrounding the target object in the image.<br>Two types of information carried by the bounding box can be used to estimate the motion of the target.</p><p>&emsp;&emsp;First, the center point of the bounding box can be used to calculate the <em>bearing</em> vector of the target.<br>In particular, denote $g \in \mathbb{R}^3$ as the unit bearing vector pointing from $p<em>o $ to $p_T $.<br>Suppose $P</em>\text{cam}\in \mathbb{R}^{3\times3}$ is the intrinsic parameter matrix of the camera<!--  \citep[Section~\ref{section_bearing-angle-target-motion-estimator}]{Ma2012} -->, and $R_\text{c}^\text{w} \in \mathbb{R}^{3\times 3}$ is the rotation from the camera frame to the world frame.<br>Then, the bearing vector $g$ can be calculated as</p><script type="math/tex; mode=display">\begin{align*}g =\dfrac{R_\text{c}^\text{w}P_\text{cam}^{-1}q_{\rm pix}}{\|R_\text{c}^\text{w}P_\text{cam}^{-1}q_{\rm pix}\|},\end{align*}%\label{eq_bearing_information}</script><p>where $q<em>{\rm pix} =[x</em>{\rm pix} , y<em>{\rm pix} , 1]^\mathrm{T} \in \mathbb{R}^3$.<br>Here, $(x</em>{\rm pix} ,y_{\rm pix})$ is the pixel coordinate of the center point of the bounding box.</p><p>&emsp;&emsp;Second, the size of the bounding box can be used to calculate the <em>angle</em> subtended by the target in the cameraâ€™s field of view.<br>The reason that we convert the bounding boxâ€™s size to the angle is that the angle is invariant to the cameraâ€™s orientation change (see <a href="#fig_cam_rotate">Fig.2</a>).<br>In particular, let $s<em>{\rm pix} $ denote the size of the bounding box.<br>It can be either the width or the height.<br>Let $\theta \in (0,\pi/2)$ be the angle.<br>According to the pin-hole camera model<!--  \citep[Section~\ref{section_bearing-angle-target-motion-estimator}]{Ma2012} --> and the law of cosine (see <a href="#fig_cam_rotate">Fig.2</a>), the angle can be calculated as<br>\begin{align*}<br>\theta = \arccos\left(\dfrac{l</em>\mathrm{left}^2 + l<em>\mathrm{right}^2 - s</em>\mathrm{pix}^2}{2l<em>\mathrm{left}l</em>\mathrm{right}}\right),<br>\end{align*}%\label{eq<em>angle_information}<br>where $l</em>\mathrm{left}=\sqrt{(f/\alpha)^2+(\delta x-s<em>\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}$ and $l</em>\mathrm{right}=\sqrt{(f/\alpha)^2+(\delta x+s<em>\mathrm{pix}/2)^2+\delta y^2}\in\mathbb{R}$ are the distances in pixel from the camera center to the middle points of the left and right sides of the bounding box, respectively (Fig.~\ref{fig_architecture_outdoor}).<br>Moreover, $f$ and $\alpha$ denote the cameraâ€™s focal length and single pixel size, respectively.<br>$i</em>{\text{width}}$ and $i<em>{\text{height}}$ represent the width and the height of the whole image in pixels, respectively. $\delta x=|x</em>\text{pix}-i<em>\text{width}/2|\in\mathbb{R}$ and $\delta y = |y</em>\text{pix}-i_\text{height}/2|\in\mathbb{R}$ are the distances between the center of the bounding box and the center of the image.</p><p>\begin{figure<em>}[!t]<br>    \centering<br>    \includegraphics[width=1\linewidth]{fig_architecture_algorithm}<br>    \caption{The architecture of the proposed approach. All the simulation and real-world experiments in this paper follow this architecture.}<br>    \label{fig_architecture_algorithm}<br>\end{figure</em>}</p><p>&emsp;&emsp;Our goal is to estimate the targetâ€™s position and velocity, $p_T$ and $v_T$, based on the noisy measurements of the bearing vector $g$ and the angle $\theta$ together with the observerâ€™s own position $p_o$.<br>To achieve this goal, we propose a new bearing-angle target motion estimator (Fig.~\ref{fig_architecture_algorithm}).<br>The estimator is introduced in detail in Section~\ref{section_bearing-angle-target-motion-estimator}.<br>The observability of this estimator is analyzed based on Kalmanâ€™s observability criterion in Section~\ref{sec_analysis_of_observability_matrix}.<br>We further prove a necessary and sufficient observability condition of the observer in Section~\ref{sec_observability_criteria}.<br>Numerical simulation results are given in Section~\ref{sec_matlab_simulation}.<br>More realistic AirSim simulation results are given in Section~\ref{sec_airsim_simulation}.<br>Finally, real-world experiments are given in Section~\ref{sec_real_world_experimental_validation}.</p><p>\section{Bearing-Angle Target Motion Estimator}<br>\label{section_bearing-angle-target-motion-estimator}</p><p>This section designs a bearing-angle target motion estimator based on the framework of pseudo-linear Kalman filtering. The key here is to establish appropriate measurement and state transition equations.</p><h3 id="States-transition-equation"><a href="#States-transition-equation" class="headerlink" title="States transition equation"></a>States transition equation</h3><p>\label{sec_states_transition_equation}<br>The state vector of the target is designed as<br>\begin{align<em>}<br>x=<br>\left[<br>  \begin{array}{c}<br>    p_T \<br>    v_T \<br>    \ell \<br>  \end{array}<br>\right]\in \mathbb{R}^7,<br>\end{align</em>}%\label{eq_states_target}<br>where $p_T $ and $v_T $ are targetâ€™s global position and velocity, respectively.<br>Here, $\ell&gt;0$ is a scalar that represents the physical size of the target object in the dimension that is orthogonal to the bearing vector (see <a href="#fig_cam_rotate">Fig.2</a>). In this paper, $\ell$ is assumed to be constant or varying slowly, which means that the physical size of the target object should be approximately invariant from different viewing angles. Here, $\ell$ corresponds to $\theta$, which further corresponds to either the width or height of the bounding box. Whether $\ell$ should correspond to the width or height depends on in which dimension the physical size of the target object is invariant when viewed from different angles.<br>More explanation is given in Section~\ref{sec_dynamical_model_of_size}.</p><p>&emsp;&emsp;Different from the bearing-only case where the state merely consists of the position and velocity, the state here is augmented by the targetâ€™s physical size. This is due to the fact that the angle measurement is a function of the targetâ€™s physical size, which should be estimated as well. One may wonder whether the state vector can also incorporate the targetâ€™s acceleration. To estimate high-order motion (e.g., acceleration) of the target, the observer must have higher-order motion (e.g., nonzero jerk) according to the observability condition presented in Section~\ref{sec_observability_criteria}. Otherwise, the estimation would diverge. Therefore, it is preferred to exclude the acceleration and merely estimate the position and velocity.</p><p>&emsp;&emsp;If no information of the targetâ€™s motion is available, it is common to model the targetâ€™s motion as a discrete-time noise-driven double integrator:</p><script type="math/tex; mode=display">\begin{align}    x(t_{k+1})=Fx(t_k) +q(t_k) ,\end{align}$$\label{eq_state_transition}where</script><p>\begin{align}<br>F=<br>\begin{bmatrix}<br>I<em>{3\times3} &amp; \delta tI</em>{3\times3} &amp; 0<em>{3\times1}  \<br>0</em>{3\times3} &amp; I<em>{3\times3}  &amp; 0</em>{3\times1}   \<br>0<em>{1\times 3} &amp; 0</em>{1\times 3} &amp; 1<br>\end{bmatrix}\in\mathbb{R}^{7\times 7},<br>\end{align}</p><script type="math/tex; mode=display">\label{eq_matrix_A}with $\delta t$ as the sampling time, and $I$ and $0$ as the identity and zero matrices, respectively.Here, $q \in\mathbb{R}^7$ is a zero-mean process noise satisfying $q \sim \mathcal{N}(0,{\Sigma}_q)$, where the covariance matrix is</script><p>\begin{align}<br>{\Sigma}<em>q=\text{diag}(0, 0, 0, \sigma_v^2, \sigma_v^2, \sigma_v^2, \sigma</em>\ell^2)\in\mathbb{R}^{7\times7}.<br>\end{align}%\label{eq_covariance_q}</p><script type="math/tex; mode=display">Here, $\sigma_v\in\mathbb{R}$ and $\sigma_\ell\in\mathbb{R}$ are the standard deviations of the target's velocity and size, respectively.When the target's shape is irregular, $\ell$ may vary when viewed from different angles.By letting $\sigma_\ell\ne0$, we can handle the case where $\ell$ varies slowly.The dynamic modeling of $\ell$ is discussed in the following subsection.\subsection{Dynamic modeling of target's physical size}\label{sec_dynamical_model_of_size}&emsp;&emsp;Since the target's physical size $\ell$ is a state variable to be estimated, it is important to discuss its dynamic model. In fact, the dynamic model of $\ell$ in \eqref{eq_state_transition} assumes that $\ell$ varies slowly. We next justify this modeling and provide more discussion.First of all, $\ell$ corresponds to the physical size of the target object in the dimension that is orthogonal to the bearing vector. Its dynamics can be categorized into three cases.*1) $\ell$ is invariant.*In theory, when $\ell$ is invariant, a change of $\theta$ implies a change of $r$.As a result, the measurement of $\theta$ can help improve the system's observability, as proven in Section~\ref{sec_observability_criteria}.An ideal case where $\ell$ is invariant is that the target object is a sphere or cylinder so that $\ell$ corresponds to its diameter<!--  \citep{Vrba2020} -->.In practice, the target object does not have to be the ideal case. For example, consider an autonomous driving scenario where a focal vehicle uses a camera to localize its surrounding vehicles in the 2D plane.Although the physical size of a surrounding vehicle changes greatly when viewed from behind or side, the height of the vehicle is *invariant* from different side-view angles.In this case, $\ell$ corresponds to the height of the vehicle, and we need to use the height of the image bounding box to calculate $\theta$.*2) $\ell$ varies slowly.*If there does not exist any dimension in which the physical size of the target remains invariant, $\ell$ may vary slowly when the target is viewed from different angles. For example, in the tasks of aerial target pursuit, if the target is a quadcopter or hexacopter, then $\ell$ is approximately equal to the wheelbase but may vary slightly when viewed from different angles since the MAV is not a perfect cylinder.In this case, $\ell$ corresponds to the wheelbase of the MAV, and we need to use the width of the image bounding box to calculate $\theta$.If $\ell$ varies slowly, it can still be treated as invariant within short time intervals.As long as the observability condition (Section~\ref{sec_observability_criteria}) is satisfied, the motion of the target as well as $\ell$ can be successfully estimated.This fact is supported by the experimental results in Section~\ref{sec_sim_res_circular_scenario}.It is however worth nothing that the performance of the proposed bearing-angle approach would degenerate to the conventional bearing-only one because the additional information brought by $\theta$ is used to estimate the time-varying $\ell$ rather than helping improve the system's observability.*3) $\ell$ varies rapidly.*If $\ell$ varies rapidly due to certain reasons, it would be difficult to distinguish whether the change of $\theta$ is caused by the change of $\ell$ or the change of $r$.For example, when a MAV is used to track a ground vehicle, $\ell$ in any dimension may vary rapidly when the relative motion between the MAV and the ground vehicle is highly dynamic.In such scenarios, the additional information brought by $\theta$ is no longer sufficient to estimate the rapidly varying $\ell$ in this case. Additional visual information such as a 3D bounding box that indicates the target's 3D attitude is required. This is an important topic for future research but out of the scope of the present paper.\subsection{Nonlinear measurement equations}The bearing vector $g$ and the subtended angle $\theta $ are both nonlinear functions of the target's position. In particular,</script><p>\begin{align}<br>    g &amp;=\dfrac{p_T -p_o }{r },<br>    \theta &amp;=2\arctan\left(\dfrac{\ell}{2r }\right)\approx \dfrac{\ell}{r },<br>\end{align}</p><script type="math/tex; mode=display">\label{eq_information}    \label{eq_bearing_measure} \\\label{eq_theta_measure}where$$r =\|\my{p}_T -\my{p}_o \|</script><p>is the distance between the target and the observer.<br>It is notable that there is an approximation in \eqref{eq_theta_measure}. This approximation is accurate.<br>Specifically, when $r&gt;3\ell$, which is common in practice, it can be verified that the approximation error is less than $0.08\%$. The approximation error further decreases as $r$ increases.</p><p>In practice, measurements always contain noises.<br>First, denote $\hat{\my{g}} \in\mathbb{R}^3$ as the noise-corrupted bearing measurement. Then, we have<br>\begin{align}<br>\label{eq<em>noised_g_mear}<br>\hat{\my{g}}  = \my{R}\left(\my{\eta} , \epsilon \right) \my{g} ,<br>\end{align}<br>where $\my{R}\left(\my{\eta} , \epsilon \right) \in \mathbb{R}^{3\times 3}$ is a rotation matrix that perturbs $\my{g}$.<br>Here, $\my{\eta} \in\mathbb{R}^3$ is a unit vector representing a random rotation axis, and $\epsilon \in \mathbb{R}$ is a random rotation angle.<br>This rotation matrix would rotate the vector $\my{g} $ by an angle $\epsilon $ around the axis $\my{\eta} $.<br>The productive noise in \eqref{eq_noised_g_mear} can be transformed into an additive one:<br>\begin{align}\label{eq_noised_g_mear_add}<br>    \hat{\my{g}}  = \my{g}  + \my{\mu} ,<br>\end{align}<br>where $\my{\mu} =(\my{R}\left(\my{\eta} , \epsilon \right) - \my{I}</em>{3\times3})\my{g} \in\mathbb{R}^3$ is the measurement noise of the bearing vector.<br>The covariance of $\mu$ is derived in our previous work<!--  \citep{Li2022} -->. Since the covariance is complex and involves unknown true values, we can approximately treat it as a Gaussian noise: $\mu\sim\mathcal{N}(0, \sigma<em>\mu^2 I</em>{3\times 3})$<!--  \citep{Li2022} -->.</p><p>Substituting \eqref{eq_bearing_measure} into \eqref{eq_noised_g_mear_add} gives the <em>nonlinear bearing measurement equation:</em><br>\begin{align}\label{eq_bearing_measure_noise}<br>    \hat{\my{g}} &amp;=\dfrac{\my{p}_T -\my{p}_o }{r } + \my{\mu} .<br>\end{align}</p><p>Second, denote $\hat{\theta} \in\mathbb{R}$ as the noise-corrupted measurement of the subtended angle. Then, we have<br>\begin{align}\label{eq_noise_theta}<br>    \hat{\theta} =\theta  + w ,<br>\end{align}<br>where $w \sim \mathcal{N}(0, \sigma^2_w)$ is the measurement noise.<br>Substituting \eqref{eq_theta_measure} into \eqref{eq_noise_theta} yields the <em>nonlinear angle measurement equation:</em><br>\begin{align}\label{eq_theta_measure_noise}<br>    \hat{\theta} &amp;=\dfrac{\ell}{r } + w.<br>\end{align}</p><p>\subsection{Pseudo-linear measurement equations}</p><p>The measurement equations \eqref{eq_bearing_measure_noise} and \eqref{eq_theta_measure_noise} are nonlinear in the targetâ€™s state. In the following, we convert the two equations to be pseudo-linear and then apply pseudo-linear Kalman filtering to achieve better estimation stability<!--  \citep{Lin2002} -->.</p><p>First, to convert the 3D bearing measurement to pseudo-linear, we introduce a useful orthogonal projection matrix:<br>\begin{align<em>}<br>    \my{P}<em>{\hat{\my{g}} }\doteq\my{I}</em>{3\times 3}-\hat{\my{g}} \hat{\my{g}}^\mathrm{T}  \in \mathbb{R}^{3\times 3}.<br>\end{align</em>}%\label{eq<em>projMatrix}<br>This matrix plays an important role in the analysis of bearing-related estimation and control problems<!--  \citep{Zhao2019} -->. It has an important property: $$\my{P}</em>{\hat{\my{g}} }\hat{\my{g}} =\my{0}<em>{3\times 1}.$$<br>As a result, multiplying $r\my{P}</em>{\hat{\my{g}} }$ on both side of \eqref{eq<em>bearing_measure_noise} yields<br>\begin{align*}<br>\my{0}</em>{3\times 1}=\my{P}<em>{\hat{\my{g}} }(\my{p}_T -\my{p}_o) + r\my{P}</em>{\hat{\my{g}} }\my{\mu}<br>\end{align<em>}<br>and consequently<br>\begin{align</em>}<br>\my{P}<em>{\hat{\my{g}} }\my{p}_o =\my{P}</em>{\hat{\my{g}} }\my{p}<em>T  + r\my{P}</em>{\hat{\my{g}} }\my{\mu}.<br>\end{align<em>}%\label{eq_g_pseudo_linear_measurement}<br>Rewriting this equation in terms of the targetâ€™s state variables yields the </em>pseudo-linear bearing measurement equation:*<br>\begin{align}\label{eq<em>pseudo_linear_measurement_g_equation}<br>\my{P}</em>{\hat{\my{g}} }\my{p}<em>o =<br>\begin{bmatrix}<br>\my{P}</em>{\hat{\my{g}} } &amp;<br>\my{0}<em>{3\times4}<br>\end{bmatrix}<br>\left[<br>  \begin{array}{c}<br>    p_T \<br>    v_T \<br>    \ell \<br>  \end{array}<br>\right]  +  r\my{P}</em>{\hat{\my{g}} }\my{\mu} .<br>\end{align}<br>Here, $\my{P}_{\hat{\my{g}} }\my{p}_o $ on the left-hand side is the new measurement, which is pseudo-linear in the targetâ€™s state variables.<br>The reason that it is called â€œpseudoâ€ is because the measurements also appear on the right-hand side of the equation, especially in the measurement matrix.</p><p>Second, we convert the nonlinear angle measurement in \eqref{eq<em>theta_measure_noise} to be pseudo-linear.<br>To that end, multiplying $r \my{\hat{g}} $ on both side of \eqref{eq_theta_measure_noise} yields<br>\begin{align}\label{eq_theta_pseudo_tem}<br>\hat{\theta} r\hat{\my{g}}  = \ell\hat{\my{g}} +wr\hat{\my{g}} .<br>\end{align}<br>It follows from \eqref{eq_bearing_measure_noise} that $r\my{\hat{g}}=\my{p}_T -\my{p}_o+r\mu$, substituting which into the left-hand side of \eqref{eq_theta_pseudo_tem} gives<br>\begin{align<em>}<br>\hat{\theta} (\my{p}_T -\my{p}_o+r\mu)  = \ell\hat{\my{g}} +wr\hat{\my{g}}.<br>\end{align</em>}<br>Reorganizing the above equation gives<br>\begin{align<em>}<br>\hat{\theta} \my{p}_o  = &amp;\hat{\theta} \my{p}_T  - \ell\hat{\my{g}} + r(\hat{\theta}  \my{\mu}  - w \hat{\my{g}}).<br>\end{align</em>}<br>Rewriting this equation in terms of the targetâ€™s state variables yields the <em>pseudo-linear angle measurement equation:</em><br>\begin{align}\label{eq_pseudo_linear_measurement_theta_equation}<br>\begin{aligned}<br>\hat{\theta} \my{p}_o  =&amp;<br>\begin{bmatrix}<br>\hat{\theta} \my{I}</em>{3\times 3} &amp; \my{0}_{3\times 3}  &amp; -\hat{\my{g}}<br>\end{bmatrix}<br>\left[<br>  \begin{array}{c}<br>    p_T \<br>    v_T \<br>    \ell \<br>  \end{array}<br>\right]</p><ul><li>r(\hat{\theta}  \my{\mu}  - w \hat{\my{g}} ),<br>\end{aligned}<br>\end{align}<br>where $\hat{\theta} \my{p}_o $ is the new measurement that is pseudo-linear in the targetâ€™s state variables.</li></ul><p>\subsection{Bearing-angle estimation algorithm}</p><p>Combining  \eqref{eq<em>pseudo_linear_measurement_g_equation} and \eqref{eq_pseudo_linear_measurement_theta_equation} gives the compact form of the measurement equation:<br>\begin{align}\label{eq_pseudo_linear_measurement_equations}<br>\my{z} = \my{H} \my{x}  + \my{\nu} ,<br>\end{align}<br>where<br>\begin{subequations}<br>\begin{align}<br>\my{z} &amp;=<br>    \begin{bmatrix}<br>    \my{P}</em>{\hat{g}} \my{p}<em>o   \<br>    \hat{\theta} \my{p}_o<br>    \end{bmatrix}\in\mathbb{R}^6, \<br>\my{H}&amp; =<br>    \begin{bmatrix}<br>    \my{P}</em>{\hat{g}}  &amp; \my{0}<em>{3\times 3} &amp; \my{0}</em>{3\times 1} \<br>    \hat{\theta} \my{I}<em>{3\times 3} &amp; \my{0}</em>{3\times 3}  &amp; -\hat{\my{g}}<br>    \end{bmatrix}\in\mathbb{R}^{6\times7},<br>    \label{eq<em>matrix_H}    \<br>\my{\nu}  &amp;=<br>    \begin{bmatrix}<br>    r \my{P}</em>{\hat{g}} \my{\mu}  \<br>    r (\hat{\theta}  \my{\mu}  - w \hat{\my{g}} )<br>    \end{bmatrix}<br>    \in\mathbb{R}^6.<br>    \label{eq<em>final_measurement_noise}<br>\end{align}<br>\end{subequations}<br>Here, $\nu$ can be rewritten as a matrix form<br>\begin{align<em>}<br>    \nu=E<br>    \begin{bmatrix}<br>        \mu \ w<br>    \end{bmatrix},<br>\end{align</em>}<br>where<br>\begin{align}\label{eq_E_mat}<br>    E=r<br>    \begin{bmatrix}<br>        P</em>{\hat{g}} &amp; 0<em>{3\times 1}\<br>        \hat{\theta}I</em>{3\times 3} &amp; -\hat{g}<br>    \end{bmatrix}\in\mathbb{R}^{6\times 4}.<br>\end{align}<br>As a result, $\nu$ can be approximately treated as a linear transformation of Gaussian noises.<br>Its covariance matrix can be calculated as<br>\begin{align<em>}%\label{eq<em>final_measurement_noise_covariance}<br>\my{\Sigma}</em>{\my{\nu}}  = E<br>\begin{bmatrix}<br>\sigma<em>\mu^2 I</em>{3\times 3} &amp; 0<em>{3\times1}\<br>0</em>{1\times 3} &amp; \sigma_w^2<br>\end{bmatrix}<br>E^\mathrm{T}\in\mathbb{R}^{6\times6}.<br>\end{align</em>}<br>Although the quantities in $E$ such as $\hat{g}$ and $\hat{\theta}$ contain measurement noises, it is a common practice to treat them as deterministic quantities. Otherwise, if, for example, $\hat{g}$ is split to $\hat{g}=g+\mu$ and we consider the noise separately, the expression of $\nu$ would be a complex function of the true values and the noises. Since the true values are unknown, the covariance cannot be calculated.<br>Moreover, $r $ in \eqref{eq_E_mat} is the true target range, which is unknown. We can use the estimated value $\hat{r} =|\hat{\my{p}}_T -\my{p}_o |$ to replace it in implementation. Here, $\hat{p}_T\in\mathbb{R}^3$ is the estimated value of the targetâ€™s position. This technique has been used in bearing-only target estimation \citep{He2018, Li2022}.</p><p>With the state transition equation \eqref{eq<em>state_transition} and the measurement equation \eqref{eq_pseudo_linear_measurement_equations}, the bearing-angle estimator can be realized by the Kalman filter.<br>For a quick reference, we list the steps below.<br>The prediction steps are<br>\begin{align*}<br>\hat{\my{x}}^{-}(t_k) &amp;= \my{F}\hat{\my{x}}(t</em>{k-1}), \<br>\my{P}^{-}(t<em>k) &amp;= \my{F}\my{P}(t</em>{k-1})\my{F}^\mathrm{T} + \my{\Sigma}<em>q,<br>\end{align<em>}<br>where $\hat{\my{x}}^{-}(t_k)\in\mathbb{R}^7$ and $\my{P}^{-}(t_k)\in\mathbb{R}^{7\times7}$ are the prior estimated state and covariance matrix, respectively.<br>The correction steps are<br>\begin{align</em>}<br>\my{K}(t_k) &amp;= \my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)\left[\my{H}(t_k)\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)+\my{\Sigma}</em>\nu\right]^{\dagger}, \<br>\hat{\my{x}}(t<em>k) &amp;= \hat{\my{x}}^{-}(t_k) + \my{K}(t_k)\left[\my{z}(t_k)-\my{H}(t_k)\hat{\my{x}}^{-}(t_k)\right], \<br>\my{P}(t_k) &amp;=\left[\my{I}</em>{7\times 7} -\my{K}(t<em>k)\my{H}(t_k) \right]\my{P}^{-}(t_k),<br>\end{align*}<br>where $\my{K}(t_k)\in\mathbb{R}^{7\times6}$ is the Kalman gain matrix, $\hat{\my{x}}(t_k) $  and $\my{P}(t_k)$ are posterior estimated state and covariance matrix, and symbol $\dagger$ denotes the pseudoinverse.<br>The usage of pseudoinverse in the Kalman filter is a common practice to prevent the situation that $\my{H}(t_k)\my{P}^{-}(t_k)\my{H}^\mathrm{T}(t_k)+\my{\Sigma}</em>\nu$ is rank deficient \citep{YOSHIKAWA1972,Kulikov2018}.</p><p>\section{Observability Analysis by Kalmanâ€™s Criterion}\label{sec_analysis_of_observability_matrix}</p><p>Although an additional angle measurement is adopted in the bearing-angle estimator, it is nontrivial to see whether this additional measurement can improve the systemâ€™s observability because an additional unknown variable, the targetâ€™s physical size, is also required to estimate. It is therefore necessary to study the observability conditions under which the targetâ€™s motion can be successfully estimated.</p><p>In this and the next sections, we present two methods to analyze the observability conditions. The first method, as presented in this section, relies on Kalmanâ€™s observability criterion, which is to check the rank of the observability matrix of a linear system. The second method, as presented in the next section, relies on solving a set of linear equations.<br>Both methods have been adopted in the literature to analyze the observability of estimators \citep{Zhao2015, Fogel1988}.<br>For the bearing-angle estimator, the first method considers the specific dynamics of the filter but is not able to handle the case when the targetâ€™s motion has a higher order.<br>The second method can handle the high-order motion of the target but does not consider the dynamics of the filter. We will show that the conclusions given by the two methods are consistent.<br>In both of the methods, we consider the case where $\ell$ is invariant.</p><p>\subsection{The observability matrix}</p><p>Consider a time horizon of $k\geq 3$ consecutive steps.<br>The observability matrix of the system of \eqref{eq<em>matrix_H} and \eqref{eq_matrix_A} can be calculated as<br>\begin{align}\label{eq_Qo}<br>    \my{Q}=<br>    \begin{bmatrix}<br>    \my{H}(t_1) \<br>    \my{H}(t_2)\my{F} \<br>    \my{H}(t_3)\my{F}^2 \<br>    \cdots \<br>    \my{H}(t_k)\my{F}^{k-1} \<br>    \end{bmatrix}\in\mathbb{R}^{6k\times7}.<br>\end{align}<br>Substituting the expressions of $F$ and $H$ in \eqref{eq_matrix_A} and \eqref{eq_matrix_H} into \eqref{eq_Qo} yields<br>\begin{align*}<br>\my{Q}=<br>\left[<br>\begin{array}{ccc}<br>\my{P}_g(t_1) &amp; \my{0}</em>{3\times 3} &amp; \my{0}<em>{3\times 1} \<br>\theta(t_1)\my{I}</em>{3\times 3} &amp; \my{0}<em>{3\times 3}  &amp; -\my{g}(t_1) \<br>\hdashline<br>\my{P}_g(t_2) &amp; \delta t\my{P}</em>{g}(t<em>2) &amp; \my{0}</em>{3\times 1} \<br>\theta(t<em>2)\my{I}</em>{3\times 3} &amp; \delta t\theta(t<em>2)\my{I}</em>{3\times 3}  &amp; -\my{g}(t<em>2) \<br>\hdashline<br>\vdots &amp; \vdots &amp; \vdots \<br>\hdashline<br>\my{P}_g(t_k) &amp; (k-1)\delta t\my{P}</em>{g}(t<em>k) &amp; \my{0}</em>{3\times 1} \<br>\theta(t<em>k)\my{I}</em>{3\times 3} &amp; (k-1)\delta t\theta(t<em>k)\my{I}</em>{3\times 3}  &amp; -\my{g}(t<em>k)\<br>\end{array}<br>\right].<br>\end{align*}<br>Note that the noises in the bearing and angle measurements are neglected when we analyze the fundamental observability property.<br>After a series of elementary row transformations in $\my{Q}$, we can obtain<br>\begin{align}\label{eq_Qo_2}<br>\my{Q}<br>\rightarrow<br>\begin{bmatrix}<br>\my{I}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; -\my{g}(t_1)/\theta(t_1) \<br>\my{0}</em>{3\times 3} &amp; \my{I}<em>{3\times 3} &amp; -\delta\my{v}(t_2)/\ell \<br>\vdots &amp; \vdots &amp; \vdots \<br>\my{0}</em>{3\times 3} &amp; \my{I}<em>{3\times 3} &amp; -\delta\my{v}(t_k)/\ell \<br>\hdashline<br>\my{0}</em>{3k\times 3} &amp; \my{0}<em>{3k\times 3} &amp; \my{0}</em>{3k\times 1}<br>\end{bmatrix},<br>\end{align}<br>where<br>\begin{align<em>}<br>\delta\my{v}(t_k) \doteq \my{v}_T(t_k) - \my{v}_o(t_k)<br>\end{align</em>}%\label{eq_delta_vel}<br>is the relative velocity.</p><p>In the following two subsections, we analyze the rank of the observability matrix in two scenarios where the observer moves with zero and nonzero acceleration, respectively. In the two scenarios, the target is always assumed to move with a constant velocity:<br>\begin{align<em>}<br>\my{v}_T(t_k) = \my{v}_T^\text{const}.<br>\end{align</em>}</p><p>\subsection{Case 1: the observerâ€™s velocity is constant}<br>Denoted $\my{v}<em>o\in \mathbb{R}^3$ as the velocity of the observer.<br>Consider the case where the observer has a constant velocity $\my{v}_o^\text{case1}(t_i)=\my{v}_o^\text{const}$ for any $i\in{1,\dots,k}$.<br>Then, the relative velocity is also constant:<br>\begin{align}\label{eq_delta_vel_case1}<br>\delta \my{v}^\text{case1}(t_i) = \my{v}_T^\text{const} - \my{v}_o^\text{const} = \delta\my{v}^\text{const}.<br>\end{align}<br>Substituting \eqref{eq_delta_vel_case1} into \eqref{eq_Qo_2} and conducting elementary row transformation yields<br>\begin{align}\label{eq_Qo_3}<br>\my{Q}^\text{case1}<br>\rightarrow<br>\left[<br>\begin{array}{cc:c}<br>\my{I}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; -\my{g}(t_1)/\theta(t_1) \<br>\my{0}</em>{3\times 3} &amp; \my{I}<em>{3\times 3} &amp; -\delta\my{v}^\text{const}/\ell \<br>\hdashline<br>\my{0}</em>{6(k-1)\times 3} &amp; \my{0}<em>{6(k-1)\times 3} &amp; \my{0}</em>{6(k-1)\times 1}<br>\end{array}\right].<br>\end{align}<br>Since the upper $6\times7$ block of \eqref{eq_Qo_3} has full row rank and the lower block is zero, the rank of $\my{Q}^\text{case1}$ is<br>\begin{align<em>}<br>\text{rank}\left(\my{Q}^\text{case1}\right) = 6.<br>\end{align</em>}<br>Since the number of states is seven and the rank is six, we know there is \emph{one unobservable mode}.<br>To identify this unobservable mode, we calculate the unobservable subspace, which is the null space of $\my{Q}$:<br>\begin{align}\label{eq_unobservable_subspace}<br>\text{Null}\left(\my{Q}^\text{case1}\right) = \text{span}\left{<br>\begin{bmatrix}<br>\my{g}(t_1)/\theta(t_1)  \<br>\delta\my{v}^\text{const}/\ell \<br>1<br>\end{bmatrix}\right}.<br>\end{align}<br>According to \eqref{eq_unobservable_subspace}, the unobservable mode is<br>\begin{align}<br>x^T<br>\left[<br>\begin{array}{c}<br>\my{g}(t_1)/\theta(t_1)  \<br>\delta\my{v}^\text{const}/\ell \<br>1<br>\end{array}<br>\right]<br>=<br>\my{p}_T^\mathrm{T}\dfrac{\my{g}(t_1)}{\theta(t_1)}+<br>\my{v}_T^\mathrm{T}\dfrac{\delta\my{v}^\text{const}}{\ell} + \ell.<br>\label{eq_unobservable_mode}<br>\end{align}%<br>Although there is only one unobservable mode, this mode given in \eqref{eq_unobservable_mode} involves all the states including the targetâ€™s position, velocity, and physical size. It suggests that the estimation of the three quantities is coupled. In conclusion, we know that, if the target moves with a constant velocity, its states are unobservable when the observer moves with a constant velocity.</p><p>\subsection{Case 2: the observerâ€™s velocity is time-varying}</p><p>We now consider the case where the observer has nonzero acceleration so that its velocity is time-varying across the time horizon from $t_1$ to $t_k$.</p><p>Denote $\my{a}<em>o(t_i)\in\mathbb{R}$ as the observerâ€™s acceleration, which can be approximated as<br>\begin{align}\label{eq_acc}<br>\my{a}_o(t_i) &amp;\approx<br>\dfrac{\my{v}_o(t_i) - \my{v}_o(t</em>{i-1})}{\delta t} \nonumber\<br>&amp;=-\dfrac{\left[\my{v}<em>T^\text{const} - \my{v}_o(t_i)\right] - \left[\my{v}_T^\text{const} - \my{v}_o(t</em>{i-1})\right]}{\delta t} \nonumber\<br>&amp;=-\dfrac{\delta \my{v}(t<em>i) - \delta \my{v}(t</em>{i-1})}{\delta t}.<br>\end{align}<br>Substituting \eqref{eq<em>acc} into \eqref{eq_Qo_2} and performing elementary row transformation yields<br>\begin{align}\label{eq_Q_case2_final}<br>\my{Q}^\text{case2}<br>\rightarrow<br>\left[\begin{array}{ccc}<br>\my{I}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; -\my{g}(t_1)/\theta(t_1) \<br>\my{0}</em>{3\times 3} &amp; \my{I}<em>{3\times 3} &amp; -\delta\my{v}(t_2)/\ell \<br>\my{0}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; \delta t \my{a}_o(t_3)/\ell \<br>\hdashline<br>\vdots &amp; \vdots &amp;\vdots \<br>\my{0}</em>{3\times 3} &amp; \my{0}<em>{3\times 3} &amp; \delta t \my{a}_o(t_k)/\ell \<br>\my{0}</em>{3k\times 3} &amp; \my{0}<em>{3k\times 3} &amp; \my{0}</em>{3k\times 1}<br>\end{array}\right].<br>\end{align}<br>The upper $6\times7$ block in \eqref{eq_Q_case2_final} has full column rank.<br>Therefore, if $a_o(t_i)\ne0$ for any $i\geq3$, then<br>\begin{align<em>}<br>\text{rank}\left(\my{Q}^\text{case2}\right) = 7,<br>\end{align</em>}<br>Which is the same as the number of estimated states.<br>Therefore, the targetâ€™s state is observable when the observer moves with nonzero acceleration.</p><p>\subsection{Summary of this section}</p><p>From the above analysis, we know that when the target has a constant velocity, its states including its position, velocity, and physical size are observable if and only if the observer has non-zero accelerations.</p><p>The critical difference of this condition from the bearing-only case is that the targetâ€™s states are still observable \emph{even if the observer moves along the bearing vector} towards or backward the target.<br>By contrast, for a bearing-only estimator, moving along the bearing vector is insufficient to recover the targetâ€™s motion. Therefore, the additional lateral motion of the observer required in the bearing-only case is \emph{not} required in the bearing-angle case anymore, which provides better flexibility for designing the observerâ€™s motion.</p><p>\section{Observability Analysis by Solving Linear Equations}\label{sec_observability_criteria}</p><p>This section extends the observability condition obtained in the last section to more general cases where the targetâ€™s velocity does not have to be constant.</p><p>\subsection{Problem formulation}</p><p>The observability problem that we aim to solve is to determine whether $\my{p}_T(t)$ can be recovered from $\my{p}_o(t)$ and $g(t),\theta(t)$.</p><p>Suppose the targetâ€™s motion can be described by an $n$th-order polynomial during a time interval:<br>\begin{align}\label{eq<em>target_nth_Order}<br>    \my{p}_T(t)=\my{b}_0+\my{b}_1t+\cdots+\my{b}_nt^n,<br>\end{align}<br>where $\my{b}_0, \my{b}_1, \cdots, \my{b}_n\in\mathbb{R}^3$ are unknown constant vectors.<br>If we can determine the values of ${b_i}</em>{i=0}^n$, then we can determine the targetâ€™s motion and hence it is observable.<br>Although polynomials cannot represent all trajectories, they can effectively approximate a majority of them according to the method of Taylor expansion. This is especially true if we consider a short time horizon. This kind of technique has been adopted in the observability analysis of bearing-only target motion estimation tasks~\citep{Nardone1981, Lee2010}.</p><p>Suppose the observerâ€™s motion is described by<br>\begin{align<em>}<br>    \my{p}_o(t)=\my{c}_0+\my{c}_1t+\cdots+\my{c}_nt^n+\my{h}(t),<br>\end{align</em>}%\label{eq<em>c_nth_Order}<br>where $\my{c}_0, \my{c}_1, \cdots, \my{c}_n\in\mathbb{R}^3$ are constant parameters, and<br>\begin{align}\label{eq_definition_h}<br>\my{h}(t) = \my{d}_1 t^{n+1}+\my{d}_2t^{n+2}+\cdots<br>\end{align}<br>represents \emph{higher-order} motion with $\my{d}_1, \my{d}_2, \cdots\in\mathbb{R}^3$.<br>It can be verified that the derivatives of $\my{h}(t)$ satisfy $\my{h}^{(i)}(0)=\my{0}</em>{3\times 1}$ for $i=0,1,\cdots, n$.<br>%<br>Let $\my{s}(t)\in\mathbb{R}^3$ be the relative motion between the target and the observer:<br>\begin{align}\label{eq_relative_motion}<br>    \my{s}(t)&amp;\doteq\my{p}_T(t)-\my{p}_o(t)  \nonumber\<br>    &amp;\doteq\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t),<br>\end{align}<br>where $\my{s}_i = \my{d}_i - \my{c}_i\in\R^3$ for $i = 0,1,\cdots, n$.</p><p>If we can determine ${s<em>i}</em>{i=0}^n$, then $s(t)$ and hence $p<em>T(t)$ can be determined.<br>Therefore, we next study under what conditions ${s_i}</em>{i=0}^n$ can be uniquely determined.<br>Since $\my{p}_T(t)-\my{p}_o(t)=g(t)r(t)$ according to \eqref{eq_bearing_measure} and $r(t)=\ell/\theta(t)$ according to \eqref{eq_theta_measure}, we have</p><script type="math/tex; mode=display">s(t)=\my{p}_T(t)-\my{p}_o(t)=g(t)r(t)=\frac{g(t)}{\theta(t)}\ell.</script><p>Substituting the above equation into \eqref{eq<em>relative_motion} yields<br>\begin{align}\label{eq_st_tem}<br>\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t)=\frac{g(t)}{\theta(t)}\ell.<br>\end{align}<br>Here, $\my{s}_0, \cdots, \my{s}_n, \ell$ are unknowns to be determined and $\my{g}(t),\theta(t),\my{h}(t)$ are known.<br>Equation~\eqref{eq_st_tem} can be reorganized to a linear equation:<br>\begin{align}\label{eq_linear_equations}<br>    \my{A}(t)\my{X} = \my{h}(t),<br>\end{align}<br>where<br>\begin{align<em>}<br>\my{X}&amp;=<br>\begin{bmatrix}<br>\my{s}_0^\mathrm{T}, \my{s}_1^\mathrm{T}, \cdots, \my{s}_n^\mathrm{T}, \ell<br>\end{bmatrix}^\mathrm{T}\in\mathbb{R}^{3n+4},<br>\end{align</em>}<br>and<br>\begin{align}\label{eq_original_A}<br>\my{A}(t)&amp;=<br>\begin{bmatrix}<br>\my{I}</em>{3\times3}, t\my{I}<em>{3\times3}, \cdots, t^n\my{I}</em>{3\times3}, \rho(t)<br>\end{bmatrix}\in\mathbb{R}^{3\times(3n+4)},<br>\end{align}<br>where<br>\begin{align}\label{eq_rho_denote}<br>\rho(t)&amp;\doteq-\dfrac{\my{g}(t)}{\theta(t)}\in\R^3.<br>\end{align}<br>Therefore, the problem that we aim to solve becomes determining whether $X$ can be uniquely solved from \eqref{eq_linear_equations}.</p><p>\subsection{Necessary and sufficient observability condition}</p><p>We next present a necessary and sufficient condition under which the solution $X$ of \eqref{eq_linear_equations} is unique.</p><p>\begin{theorem}[(Necessary and sufficient observability condition)]<br>\label{theorem<em>observability_confition}<br>The targetâ€™s motion $p_T(t)$ can be uniquely determined by the observerâ€™s motion $p_o(t)$, the bearing $g(t)$, and the angle $\theta(t)$ if and only if<br>\begin{align*}<br>\my{h}(t)\neq\my{0}</em>{3\times1},<br>\end{align*}<br>which means that the order of the observerâ€™s motion must be greater than the target.<br>\end{theorem}<br>\begin{proof}<br>Since the row number of $\my{A}(t)$ is less than its column number, \eqref{eq_linear_equations} is an under-determined system whose solution cannot be uniquely determined.<br>However, in the continuous time domain, we can use additional higher derivatives of this equation to uniquely determine $X$.</p><p>In particular, taking the $i$th-order derivative on both sides of \eqref{eq_linear_equations} gives $A^{(i)}(t)X=h^{(i)}(t)$. Consider any integer $N$ satisfying $N\ge n+1$. Combining the equations with $i\in{0,1,\dots,N}$  gives<br>\begin{align}\label{eq_new_linear_equtions}<br>    \bar{\my{A}}(t)\my{X} = \bar{\my{h}}(t),<br>\end{align}<br>where<br>\begin{align}\label{eq_new_A}<br>    \bar{\my{A}}(t) =<br>\left[<br>  \begin{array}{c}<br>    \my{A}(t) \<br>    \my{A}^{â€˜}(t) \<br>    \vdots \<br>    \my{A}^{(N)}(t)<br>  \end{array}<br>\right],\qquad<br>\bar{\my{h}}(t)\left[<br>  \begin{array}{c}<br>    \my{h}(t)\<br>    \my{h}^{â€˜}(t)\<br>    \vdots\<br>    \my{h}^{(N)}(t)\<br>  \end{array}<br>\right].<br>\end{align}<br>Here, $\bar{\my{A}}(t)\in\mathbb{R}^{(3N+3)\times (3n+4)}$ and $\bar{\my{h}}(t)\in\mathbb{R}^{3N+3}$.<br>Since $N\ge n+1$, $\bar{A}(t)$ is a tall matrix and \eqref{eq_new_linear_equtions} is an over-determined system.</p><p>We next examine when $\bar{A}(t)$ has full column rank.<br>Substituting \eqref{eq<em>original_A} into $\bar{A}(t)$ yields<br>\begin{align*}<br>\bar{\my{A}}(t)=<br>    \left[\begin{array}{cccc:c}<br>    \my{I}</em>{3\times3}&amp; t\my{I}<em>{3\times3}&amp; \cdots&amp; t^n\my{I}</em>{3\times3}&amp; \rho(t) \<br>    \my{0}<em>{3\times3}&amp; \my{I}</em>{3\times3}&amp; \cdots&amp; nt^{n-1}\my{I}<em>{3\times3}&amp; \rho^{â€˜}(t) \<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \<br>    \my{0}</em>{3\times3}&amp; \my{0}<em>{3\times3}&amp; \cdots&amp; n!\my{I}</em>{3\times3}&amp; \rho^{(n)}(t) \<br>    \hdashline<br>    \my{0}<em>{3\times3}&amp; \my{0}</em>{3\times3}&amp; \cdots&amp; \my{0}<em>{3\times3}&amp; \rho^{(n+1)}(t) \<br>\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \<br>\my{0}</em>{3\times3}&amp; \my{0}<em>{3\times3}&amp; \cdots&amp; \my{0}</em>{3\times3}&amp; \rho^{(N)}(t) \<br>%\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \<br>    \end{array}\right].<br>\end{align<em>}%\label{eq<em>expanded_tilde_A}<br>Since the top-left block of $\bar{A}(t)$ is a full-rank square matrix, $\bar{\my{A}}(t)$ has full column rank if and only if there exists $i\in{n+1,\dots,N}$ such that<br>\begin{align}\label{eq_observability_criteria_2}<br>    \rho^{(i)}(t)\neq \my{0}</em>{3\times1}.<br>\end{align}<br>Since $\rho(t)=-g(t)/\theta(t)$ as shown in \eqref{eq<em>rho_denote} and $g(t)/\theta(t)=(\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t))/\ell$ as shown in \eqref{eq_st_tem}, we can rewrite \eqref{eq_observability_criteria_2} to<br>\begin{align}\label{eq_critia_2}<br>-\dfrac{1}{\ell}(\my{s}_0+\my{s}_1t+\cdots+\my{s}_nt^n+\my{h}(t))^{(i)}\neq \my{0}</em>{3\times1}.<br>\end{align}<br>Since $i\ge n+1$, \eqref{eq<em>critia_2} is equivalent to<br>\begin{align}\label{eq_observability_criteria_final}<br>\my{h}^{(i)} (t) \neq \my{0}</em>{3\times1}.<br>\end{align}<br>According to the definition of $\my{h}(t)$ in \eqref{eq_definition_h}, the condition in \eqref{eq_observability_criteria_final} is equivalent to<br>\begin{align</em>}<br>\my{h}(t)\neq \my{0}_{3\times1}.<br>\end{align*}<br>The proof is complete.<br>\end{proof}</p><p>Some important remarks about Theorem~\ref{theorem_observability_confition} are given below.</p><p>1) The necessary and sufficient condition suggested by Theorem~\ref{theorem_observability_confition} is that the observer should have higher-order motion than the target.<br>For example, when the target is stationary, the observer should move with a nonzero velocity. When the target moves with a constant velocity, the observer should move with a nonzero acceleration.</p><p>2) The necessary and sufficient condition given by Theorem~\ref{theorem_observability_confition} has a \emph{key difference} from the bearing-only case that the higher-order motion in the bearing-angle case is \emph{not} required to be orthogonal to the bearing vector, making the bearing-angle approach more flexible than the bearing-only one.<br>For example, the bearing-angle approach can estimate the targetâ€™s motion even if the observer simply moves along the bearing vector.</p><p>3) In the special case where the target moves with a constant velocity, the condition in Theorem~\ref{theorem_observability_confition} is consistent with the one obtained in Section~\ref{sec_analysis_of_observability_matrix}. Although the condition in Theorem~\ref{theorem_observability_confition} allows more general target motion, the analysis in Section~\ref{sec_analysis_of_observability_matrix} is still meaningful since it is directly related to the dynamic model used in the pseudo-linear Kalman filter.</p><p>4) In practice, we would not estimate the targetâ€™s motion by using the method of solving an equation like \eqref{eq_new_linear_equtions}. That is because such a method involves calculating high-order derivatives, which are challenging to obtain accurately in practice. The role of this equation is to provide a fundamental perspective on whether there is sufficient information to uniquely recover the targetâ€™s motion.</p><p>\subsection{Number of observations required}</p><p>\begin{figure<em>}[!ht]<br>\normalsize<br>\begin{align}<br>\label{eq<em>A_22}<br>\tilde{A}<br>\rightarrow<br>\left[\begin{array}{ccccc:c}<br>\my{I} &amp; t_1\my{I} &amp; \cdots &amp; t_1^{n-1}\my{I} &amp; t_1^n\my{I} &amp; \rho(t_1) \<br>\my{0} &amp; \my{I} &amp; \cdots &amp; {\Delta(t_2^{n-1}, t_1^{n-1})}\my{I} &amp; {\Delta(t_2^n, t_1^n)}{}\my{I} &amp; {\Delta(\rho(t_2),\rho(t_1) )}{} \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots &amp; \vdots \<br>\my{0} &amp; \my{0} &amp; \cdots &amp; (n-1)!\my{I} &amp; {\Delta^{n-1}(t_n^n, \cdots , t_1^n)}{} &amp; {\Delta^{n-1}(\rho(t_n),\cdots,\rho(t_1) )}{} \<br>\my{0} &amp; \my{0} &amp; \cdots &amp; \my{0} &amp; n!\my{I} &amp;  {\Delta^{n}(\rho(t</em>{n+1}),\cdots,\rho(t<em>1) )}{} \<br>\hdashline<br>\my{0} &amp; \my{0} &amp; \cdots &amp; \my{0} &amp; \my{0} &amp; {\Delta^{n+1}(\rho(t</em>{n+2}),\cdots,\rho(t_1) )}{} \<br>\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots  \<br>\my{0} &amp; \my{0} &amp; \cdots &amp; \my{0} &amp; \my{0} &amp; {\Delta^{N-1}(\rho(t_N),\cdots,\rho(t_1) )}{} \<br>\end{array}<br>\right]<br>\end{align}<br>\hrulefill<br>\vspace</em>{4pt}<br>\end{figure*}</p><p>It is of practical importance to study how many discrete observations are required to recover the targetâ€™s motion. Although Theorem~\ref{theorem_observability_confition} gives an observability condition, it does not answer this question because it is based on the continuous time domain. We next answer this question by exploring multiple discrete time steps.</p><p>\begin{theorem}[(Number of discrete observations)]\label{theorem_observation_number}<br>If the observerâ€™s motion satisfies the observability condition in Theorem~\ref{theorem_observability_confition}, it is necessary and sufficient to use at least $n+2$ observations to recover the targetâ€™s motion. Here, $n$ is the order of the targetâ€™s polynomial motion as shown in \eqref{eq_target_nth_Order}.<br>\end{theorem}<br>\begin{proof}<br>Consider $t_1,\dots,t_N$ time instances. Each time instance corresponds to an equation like \eqref{eq_linear_equations}: $\my{A}(t_i)\my{X} = \my{h}(t_i)$ for $i=1,\dots,N$.<br>Combining these equations gives<br>\begin{align}\label{eq_convergence_linear_eqs}<br>\tilde{\my{A}}\my{X}=\tilde{\my{h}},<br>\end{align}<br>where<br>\begin{align}\label{eq_new_A_2}<br>    \tilde{\my{A}} =<br>\left[<br>  \begin{array}{c}<br>    \my{A}(t_1) \<br>    \vdots \<br>    \my{A}(t_N)<br>  \end{array}<br>\right],\qquad<br>\tilde{\my{h}}\left[<br>  \begin{array}{c}<br>    \my{h}(t_1)\<br>    \vdots\<br>    \my{h}(t_N)\<br>  \end{array}<br>\right].<br>\end{align}<br>Here, $\tilde{\my{A}}\in\mathbb{R}^{(3N) \times (3n+4)}$ and $\tilde{\my{h}}\in\mathbb{R}^{3N}$.</p><p>(\emph{Necessity}) Since $X\in\R^{3n+4}$, we need at least $N\ge n+2$ observations so that $\tilde{\my{A}}$ is a tall matrix and hence \eqref{eq_convergence_linear_eqs} is an over-determined system.</p><p>(\emph{Sufficiency})<br>Suppose we have $N\ge n+2$ discrete observations.<br>Substituting \eqref{eq<em>original_A} into \eqref{eq_new_A_2} yields<br>\begin{align*}<br>\tilde{A} =<br>\begin{bmatrix}<br>\my{I}</em>{3\times 3} &amp; t<em>1\my{I}</em>{3\times 3} &amp; \cdots &amp; t<em>1^n\my{I}</em>{3\times 3} &amp; \rho(t<em>1) \<br>\my{I}</em>{3\times 3} &amp; t<em>2\my{I}</em>{3\times 3} &amp; \cdots &amp; t<em>2^n\my{I}</em>{3\times 3} &amp; \rho(t<em>2)  \<br>\vdots &amp; \vdots &amp;&amp; \vdots &amp; \vdots  \<br>\my{I}</em>{3\times 3} &amp; t<em>{n+1}\my{I}</em>{3\times 3} &amp; \cdots &amp; t<em>{n+1}^n\my{I}</em>{3\times 3} &amp; \rho(t<em>{n+1}) \<br>\my{I}</em>{3\times 3} &amp; t<em>{n+2}\my{I}</em>{3\times 3} &amp; \cdots &amp; t<em>{n+2}^n\my{I}</em>{3\times 3} &amp; \rho(t<em>{n+2})\<br>\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots\<br>\my{I}</em>{3\times 3} &amp; t<em>{N}\my{I}</em>{3\times 3} &amp; \cdots &amp; t<em>{N}^n\my{I}</em>{3\times 3} &amp; \rho(t<em>{N})\<br>\end{bmatrix}.<br>\end{align<em>}<br>Starting from the last line in $\tilde{A}$, subtract the previous line from each subsequent line, and repeat this process.<br>Finally, we can obtain \eqref{eq_A_22} (the equation is too long and located at the top of another page).<br>Here, $\Delta^n$ represents the $n$th-order time difference \citep{MilneThomson2000}.<br>For example, $\Delta (a_2, a_1)=(a_2-a_1)/\delta t$, $\Delta^2 (a_3, a_2, a_1) = \Delta (\Delta(a_3, a_2), \Delta(a_2, a_1))=[(a_3-a_2)/\delta t-(a_2-a_1)/\delta t]/\delta t$.<br>When $\delta t$ is sufficiently small, the time difference is an approximation of the derivative.<br>When the observability condition in Theorem~\ref{theorem_observability_confition} is satisfied, there exists $i\ge n+1$ such that $\rho^{(i)}(t)\neq 0$ as shown in \eqref{eq_observability_criteria_2}. As a result, there exists $i\ge n+1$ such that<br>\begin{align</em>}<br>\Delta^{i}(\rho(t</em>{i+1}),\cdots,\rho(t_1))\neq \my{0}.<br>\end{align*}<br>The above implication is valid because $\Delta^{i}$ is an approximation of the $i$th-order derivative when $\delta t$ is sufficiently small.<br>Then, $\tilde{A}$ in \eqref{eq_A_22} has full column rank and hence \eqref{eq_convergence_linear_eqs} has a unique solution.<br>\end{proof}</p><p>Theorem~\ref{theorem_observation_number} suggests that when the target is stationary and hence $n=0$, at least two discrete observations are sufficient to localize the target. This is true even if the two observations are acquired when the observer moves along the bearing vector.<br>When the target moves with a constant velocity and hence $n=1$, at least three discrete observations are sufficient to localize the target, which is consistent with the results in Section~\ref{sec_analysis_of_observability_matrix}.</p><p>\section{Numerical Simulation Results}\label{sec_matlab_simulation}<br>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[Scenario 1: Circular motion around the target. Both the bearing-only and bearing-angle approaches work well, but the bearing-angle one converges faster.]{<br>\includegraphics[width=1 \linewidth]{fig_matlab_1}<br>\label{fig_matlab_1}<br>}<br>\hfill<br>\subfloat[Scenario 2: Straight motion towards and backwards the target. The bearing-only approach fails, but the bearing-angle approach works effectively.]{<br>\includegraphics[width=1 \linewidth]{fig_matlab_2}<br>\label{fig_matlab_2}<br>}<br>\hfill<br>\subfloat[<br>Scenario 3: Approaching the target by a guidance law. The bearing-only approach works unstably, but the bearing-angle approach works effectively.]{<br>\includegraphics[width=1 \linewidth]{fig_matlab_3}<br>\label{fig_matlab_3}<br>}<br>\caption{Numerical simulation results based on 100 Monte Carlo runs in three scenarios.}<br>\end{figure</em>}</p><p>\begin{figure<em>}[!t]<br>\label{fig_matlab_varying_ell}<br>\centering<br>\subfloat[<br>The observer moves around the square-shaped target. The target spins rapidly at $2\pi$~rad/s.]{<br>\includegraphics[width=1 \linewidth]{fig_matlab_4}<br>\label{fig_matlab_4}<br>}<br>\hfill<br>\subfloat[<br>The observer moves along the bearing vector. The targetâ€™s spinning speed is $\pi/8$~rad/s.]{<br>\includegraphics[width=1 \linewidth]{fig_matlab_pi_8}<br>\label{fig_matlab_pi_8}<br>}<br>\caption{Numerical simulation results for time-varying $\ell$.}<br>\end{figure</em>}<br>This section presents a set of numerical simulation results to demonstrate the effectiveness of the proposed bearing-angle approach.</p><p>The values of the parameters in two estimators are selected as $\sigma<em>v=10^{-3}$, $\sigma_l=10^{-4}$, $\sigma</em>\mu=0.01$, and $\sigma_w=0.01$.<br>The selection of these values is inspired by the measurement noises obtained in the AirSim simulation and real-world experiments as shown later.<br>The initial covariance matrix of the estimated states is set to $P(t_0)=0.1I$.<br>The target is a circle whose diameter is $\ell=1$.<br>The update rate of the system is $50$~Hz.<br>In addition, we use the same parameter values across all the simulation examples to verify the robustness of the algorithm.<br>Better performances can be achieved if the parameters are well-tuned for specific scenarios.<br>We perform $N_x=100$ Monte Carlo simulations for each scenario.</p><p>We use the normalized-estimation error squared (NEES) \citep{bar1998estimation} to analyze the consistency of the estimation algorithms.<br>In particular, the value of the average NEES is</p><p>\begin{align}<br>    \bar{\epsilon}<em>{\text{NEES}}=\dfrac{1}{N_x}\sum</em>{i=1}^{N_x}(x-\hat{x}_i)^\mathrm{T}P_i^{-1}(x-\hat{x}_i),<br>    \label{eq_nees}<br>\end{align}<br>%where $n_x\in\mathbb{R}$ is the dimension of the estimated states ($n_x=6$ for bearing-only, and $n_x=7$ for bearing-angle).<br>where $\hat{x}_i$ is the estimated states in the $i$th simulation, and $P_i$ is the covariance matrix obtained from the estimator in the $i$th simulation.<br>%The expectation of the average NEES value would be equal to the number of the estimated states.</p><p>Finally, image acquisition and visual detection are not considered in these numerical simulation scenarios. They will be considered in Section~\ref{sec_airsim_simulation} and Section~\ref{sec_real_world_experimental_validation}.</p><p>\subsection{Scenario 1: Circular motion around the target}<br>In the first scenario, the target is stationary and located at $\my{p}_T=[0, 10]^\mathrm{T}$.<br>The observer moves on a circle centered at the target with the speed of $3$~m/s (see Fig.~\ref{fig_matlab_1}).<br>The radius of the circle is $5$~m.<br>The initial estimates are $\hat{p}_o(t_0) = [0, 13]^\mathrm{T}$, $\hat{v_o}(t_0)=[0, 0]^\mathrm{T}$, $\hat{\ell}(t_0)=1.6$.<br>During this process, the bearing vector varies while the angle subtended by the target remains constant.<br>The angle measurement varies slightly due to the measurement noise.<br>This scenario is favorable to the conventional bearing-only approach because its observability condition that the target should be viewed from different angles is well satisfied \citep{Li2022}.</p><p>Fig.~\ref{fig_matlab_1} shows the estimation results by the two approaches of bearing-only and bearing-angle.<br>As can be seen, both algorithms perform well.<br>The convergence of the bearing-angle approach is faster than the bearing-only one, as shown in the middle and right subfigures of Fig.~\ref{fig_matlab_1}, due to the additional angle measurement.<br>The bearing-angle approach can successfully estimate the size of the target as shown in the right subfigure of Fig.~\ref{fig_matlab_1}.</p><p>\subsection{Scenario 2: Straight motion towards and backwards the target repeatedly}<br>In the second scenario, the target is also stationary but the observer moves along a straight line towards and backwards the target repeatedly (Fig.~\ref{fig_matlab_2}).<br>During this process, the bearing vector remains constant while the angle varies.<br>This scenario is most challenging for the bearing-only approach because its observability condition is not fulfilled.</p><p>In this simulation scenario, the target is stationary and located at $\my{p}_T(t_0)=[0, 10]^\mathrm{T}$.<br>The observer moves along a straight line towards and backwards the target with a constant acceleration of $-2$~$\text{m/s}^2$. The initial conditions are $v_o(t_0)=[0, 4]^\mathrm{T}$ and $\my{p}_o (t_0)= [0,5]^\mathrm{T}$.<br>The initial estimates are $\hat{p}_o(t_0) = [0, 8]^\mathrm{T}$, $\hat{v_o}(t_0)=[0, 0]^\mathrm{T}$, $\hat{\ell}(t_0)=0.8$.<br>In this scenario, the true bearing of the target relative to the observer remains unchanged though the bearing measurement may vary slightly due to the measurement noise.</p><p>Fig.~\ref{fig_matlab_2} shows the estimation results of the bearing-only and bearing-angle approaches.<br>As can be seen, the bearing-only approach diverges since its observability condition is not satisfied.<br>By contrast, the proposed bearing-angle approach converges, and is able to localize the target and estimate its size, which demonstrates the strong observability of the bearing-angle approach.<br>One may notice that the estimated size and the NEES value get worse first before converging.<br>This is because the noise level of the angle is set to be constant. Since the angle is small in the beginning, the noise-angle ratio is large, causing a relatively large NEES value.</p><p>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[An AirSim simulation experimental scenario.]{<br>\includegraphics[width=0.5 \linewidth]{fig_architecture_airsim}<br>\label{fig_architecture_airsim}<br>}<br>\subfloat[Samples of the dataset collected automatically in AirSim.]{<br>\includegraphics[width=0.5 \linewidth]{fig_airsim_dataset}<br>\label{fig_airsim_dataset}<br>}<br>\caption{The setup of the AirSim simulation experiments.}<br>\end{figure</em>}</p><p>\begin{figure<em>}[!t]<br>    \centering<br>    \includegraphics[width=1\linewidth]{fig_box_airsim}<br>    \caption{The software architecture of the AirSim simulation system. AirSim is a plugin for Unreal Engine. Three programmed modules (Offline training, Online estimation, and MAV control) communicate with the AirSim plugin through APIs.}<br>    \label{fig_box_airsim}<br>\end{figure</em>}</p><p>\subsection{Scenario 3: Approaching the target by a guidance law}<br>The third scenario is more complex than the first two. Here, the target moves with a constant velocity where the observer is controlled by a proportional navigation guidance (PNG) law to approach the target (Fig.~\ref{fig_matlab_3}).<br>During this process, both the bearing and angle vary.<br>This scenario is also challenging for the bearing-only approach because its observability is weak due to the fact that the lateral motion of the observer is small.<br>Many researchers have studied how to add extra control commands to the PNG to enhance the observability based on the bearing-only approach \citep{Song1996, Seo2015, Lee2015}.</p><p>In this simulation scenario, the target moves along a straight line with a constant velocity $\my{v}_T=[1/\sqrt{2}, 1/\sqrt{2}]^\mathrm{T}$.<br>The observerâ€™s velocity magnitude is constantly $3$~m/s while the velocity direction is controlled by a PNG law.<br>The navigation gain of the PNG law is selected as one.<br>The initial estimates of the targetâ€™s states are the same as Scenario~1.<br>The simulation stops just before the observer collides with the target.</p><p>Fig.~\ref{fig_matlab_3} shows the estimation results by the bearing-only and bearing-angle approaches. As can be seen, the bearing-angle algorithm successfully converges before the collision occurs, but the bearing-only algorithm fails to estimate the targetâ€™s states due to its weak observability.<br>This simulation example demonstrates that the bearing-angle algorithm can be used directly in the guidance scenario without extra maneuvers required by the bearing-only approach \citep{Song1996, Seo2015, Lee2015}.</p><p>\subsection{Simulation results for time-varying $\ell$}<br>\label{sec_matlab_varying_ell}<br>Although $\ell$ is assumed to be invariant, it is meaningful to challenge the proposed bearing-angle approach by considering time-varying $\ell$.<br>We will see through simulation examples that the bearing-angle approach is still effective when $\ell$ varies slowly. It becomes unstable when $\ell$ varies rapidly since the assumption of invariant $\ell$ is severely invalid.</p><p>Suppose that the target object has a square shape. Then, $\ell$ varies when the object is observed from different viewing angles or the object spins.<br>Fig.~\ref{fig_matlab_4} shows a scenario where the observer moves around the target, whose spinning speed is $2\pi$~rad/s.<br>The red curve in the right subfigure represents the true value of $\ell$, which varies rapidly.<br>As can be seen, the bearing-angle algorithm works effectively though there is a small estimation bias.<br>Fig.~\ref{fig_matlab_pi_8} shows a scenario where the observer moves along the bearing vector. The spinning speed of the target object is $\pi/8$~rad/s.<br>As can be seen, the bearing-only approach diverges due to the lack of observability. The bearing-angle algorithm can still converge since $\ell$ varies slowly.<br>When we further increase the spinning speed of the target, the bearing-angle algorithm will also diverge because the algorithm cannot distinguish whether the change of $\theta$ is caused by the change of $\ell$ or the change of $r$.</p><p>\section{AirSim Simulation Results}\label{sec_airsim_simulation}<br>In this section, we show simulation results under a more realistic setup. In particular, the simulation is based on AirSim, a simulator that can provide high-quality visual simulation \citep{Shah2017}. Nonlinear MAV dynamics and control are also considered.</p><p>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[The target MAV hovers stationarily, while the observer MAV approaches the target MAV under the control of \eqref{eq_tracking_control}.]{<br>\includegraphics[width=1 \linewidth]{fig_airsim_1}<br>\label{fig_airsim_1}<br>}<br>\hfill<br>\subfloat[The target MAV moves with a constant velocity, while the observer MAV follows the target MAV under the control of \eqref{eq_tracking_control}.]{<br>\includegraphics[width=1 \linewidth]{fig_airsim_2}<br>\label{fig_airsim_2}<br>}<br>\caption{AirSim simulation results in the approaching and following scenarios.}<br>\label{fig_airsim}<br>\end{figure</em>}</p><p>\subsection{Simulation setup}</p><p>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[Estimation results when $\sigma_l=10^{-4}$ and the other parameters are the same as those in Section~\ref{sec_sim_res_for_tracking}.]{<br>\includegraphics[width=1 \linewidth]{fig_airsim_6_1}<br>\label{fig_airsim_6_1}<br>}<br>\hfill<br>\subfloat[Estimation results when $\sigma_l=0.01$ and the other parameters are the same as those in Section~\ref{sec_sim_res_for_tracking}.]{<br>\includegraphics[width=1 \linewidth]{fig_airsim_6_2}<br>\label{fig_airsim_6_2}<br>}<br>\caption{AirSim simulation results in the circular motion scenario where $\ell$ varies.}<br>\label{fig_airsim_6}<br>\end{figure</em>}</p><p>Fig.~\ref{fig_architecture_airsim} shows an AirSim simulation scenario.<br>As can be seen, there are two flying quadcopter MAVs. The observer MAV can capture images of the target MAV using its simulated onboard camera.<br>A simple gimbal camera controller is implemented so that the target MAV is always located inside the field of view of the camera.<br>The visual environment used in the simulation is called Landscape Mountains, which includes realistic mountains, lakes, trees, and roads. Other environments can also be used if needed.</p><p>The bearing and angle measurements are obtained from the bounding boxes generated by a Yolo-based detection algorithm.<br>A tiny-YOLO v4 network \citep{Bochkovskiy2020} is trained to detect the target MAV in the images. Although the visual detector can be replaced by other state-of-the-art ones, the tiny-YOLO v4 network is already sufficient to verify our proposed approach.<br>The architecture of the entire simulation system is shown in Fig.~\ref{fig_box_airsim}.<br>The system consists of the modules of automatic image dataset collection, Yolo-based target detection, gimbal camera control, nonlinear quadcopter dynamics, and quadcopter flight control.<br>The quadcopter dynamics and flight control used in the simulation are similar to \citep{Meier2011, Shah2017} and omitted here due to space limitation.<br>The quadcopterâ€™s physical size varies slightly when viewed from different directions, although it is assumed to be invariant.<br>All of these factors make the Airsim simulation more realistic and challenging.</p><p>\subsection{Automatic dataset collection}<br>To train the Yolo-based detector, we developed a module to automatically collect an image dataset.<br>This module has some advantages.<br>First, it is efficient. More than ten thousand labeled images can be collected automatically in 24 hours.<br>Second, it is flexible.<br>It can acquire images with random targetâ€™s positions, random targetâ€™s attitudes, random cameraâ€™s view angles, and random background scenes.<br>These images are beneficial to achieve a good generalization ability of the detector.<br>Third, the image labels are of high quality. Since the ground truth of the targetâ€™s image is known in the simulation, the generated bounding box is tight.<br>The collected dataset contains 17,000 labeled images (see Fig.~\ref{fig_airsim_dataset}).<br>The resolution of the images is $1536\times 864$ pixels.<br>The simulation system was deployed on a Dell Precision 7920 Tower Workstation with two NVIDIA Quadro GV100 graphic cards.<br>Since the dataset is sufficient and high-quality, the detection can achieve the accuracy of mAP=99.5\%.</p><p>\subsection{Scenario 1: Approaching and following the target}<br>\label{sec_sim_res_for_tracking}<br>We first consider the scenarios where the observer MAV approaches or follows a target MAV.<br>These scenarios widely exist in practical applications such as aerial target pursuit.</p><p>We show two simulation examples in Fig.~\ref{fig_airsim_1} and Fig.~\ref{fig_airsim_2}, respectively.<br>In both examples, the observer is controlled by a controller so that it can approach the target and maintain a desired separation. In particular, the controller is<br>\begin{align}<br>\label{eq_tracking_control}<br>v_o^\text{cmd}(t)&amp;=v_T(t)+k^\text{track}\dfrac{r^2(t)-r_d^2}{r^2(t)}g(t),<br>\end{align}<br>where $v_o^\text{cmd}(t)$ is the velocity command of the observer MAV, $k^\text{track}=3$ is the control gain, and $r_d=3$ is the desired separation.<br>The magnitude of the observerâ€™s velocity is bounded from above by $3$~m/s.<br>It should be noted that \eqref{eq_tracking_control} relies on the true position and velocity of the target MAV in the simulation. Therefore, the data is collected first and then processed offline so that we can compare the performances of the bearing-only and bearing-angle approaches.</p><p>In the first example, the target MAV hovers constantly at $p_T(t_0)=[0, 10, 10]^\mathrm{T}$.<br>The observer MAV moves along a straight line toward the target with a decreasing velocity command.<br>Since the bearing of the target MAV remains the same, this example is challenging for the bearing-only approach.<br>As shown in Fig.~\ref{fig_airsim_1}, the bearing-only approach fails to converge while the bearing-angle approach can successfully estimate the targetâ€™s motion.</p><p>In the second example, the target MAV moves with a constant velocity of $v_T=[1/\sqrt{2}, 1/\sqrt{2}, 0]^\mathrm{T}$.<br>The trajectory of the observer MAV under the control of \eqref{eq_tracking_control} is still close to (though not strictly) a straight line. As a result, the observability is weak by the bearing-only approach.<br>As shown in Fig.~\ref{fig_airsim_2}, the bearing-angle approach successfully converges while the bearing-only one fails.<br>It is notable that $\ell$ is invariant in the first example and varies slowly in the second example.</p><p>It is worth mentioning that the detection results used in the estimation algorithms are obtained from the Yolo-based estimator.<br>The ground truth obtained from AirSim is only used to calculate the errors of measurements, as shown in the right figures of Figs.~\ref{fig_airsim_1} and \ref{fig_airsim_2}.<br>It is not surprising that the measurement noises are not strictly Gaussian since the 2D bounding box is generated by a deep learning vision algorithm. It is noticed that the noises are inversely correlated to the observer-target range.<br>This is reasonable because, when the target is close to the camera and hence its image is large, the center point and the size of the bounding box usually vary for a few pixels.</p><p>The NEES values are also shown in Fig.~\ref{fig_airsim}.<br>As can be seen, the NEES value of the bearing-only approach diverges. The NEES value of the bearing-angle approach oscillates and converges slowly. The reasons are analyzed as follows. Compared to the Matlab-based numerical simulation, the visual measurements here are generated by deep learning algorithms, and the measurement noises are non-Gaussian. The non-Gaussian noises propagate into $P$ in \eqref{eq_nees} since the calculation of $P$ relies on noisy measurements. The noises may also cause an estimation bias that can further aggravate the NEES error. Moreover, although the system is observable in the two simulation examples, the observability is relatively weak compared to the case where the observer moves surrounding the target. As a result, the matrix $P$ may not be able to perfectly describe the estimation accuracy. These elements may jointly cause the convergence behavior of the NEES values shown in Fig.~\ref{fig_airsim}.</p><p>\subsection{Scenario 2: Circular motion and varying $\ell$}<br>\label{sec_sim_res_circular_scenario}</p><p>We next examine a case where $\ell$ is time-varying.<br>In particular, suppose a target quadcopter MAV hovers constantly at $p_T(t_0)=[0, 10, 10]^\mathrm{T}$.<br>The observer MAV moves on a circle centered at the target (Fig.~\ref{fig_airsim_6_1}).<br>Since the target quadcopter MAV has a square shape from the top view, its size $\ell$ is time-varying when viewed from side angles (see the red curves in the middle subfigure of Fig.~\ref{fig_airsim_6_1}).</p><p>We show two simulation examples in Fig.~\ref{fig<em>airsim_6_1} and Fig.~\ref{fig_airsim_6_2}, respectively.<br>The two simulation examples share the same measurement data but different values of $\sigma</em>\ell$.<br>Moreover, the other parameters are the same as those in Section~\ref{sec_sim_res_for_tracking}.</p><p>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[Experimental setup]{<br>\includegraphics[width=0.48 \linewidth]{fig_architecture_indoor}<br>\label{fig_architecture_indoor}<br>}<br>\subfloat[Samples in the dataset]{<br>\includegraphics[width=0.48 \linewidth]{fig_car_dataset1}<br>\label{fig_car_dataset}<br>}<br>\caption{The setup of the experiments based on a hand-held camera.}<br>\end{figure</em>}</p><p>In the first simulation example, $\sigma<em>\ell$ is set to be a small value: $\sigma</em>\ell=10^{-4}$.<br>Its interpretation is that $\ell$ is treated as invariant during the process.<br>In this case, the performance of the bearing-angle approach is almost the same as the bearing-only one as shown in Fig.~\ref{fig_airsim_6_1}.<br>Since $\ell$ is treated to be invariant, the estimated value $\hat{\ell}$ converges to a constant which is the mean value of the time-varying $\ell$.</p><p>In the second simulation example, the value of $\sigma<em>\ell$ is larger than the first example: $\sigma</em>\ell = 0.01$.<br>Its interpretation is that $\ell$ is believed to be time-varying during the process.<br>In this case, the performance of the bearing-angle approach is still almost the same as the bearing-only one.<br>Moreover, since $\sigma_\ell$ is large, the bearing-angle approach can successfully estimate the true time-varying value of $\ell$.</p><p>In summary, in the case where $\ell$ varies slowly, the bearing-angle approach would degenerate to the bearing-only one.<br>The fundamental reason is that the extra information embedded in the angle measurement is used to estimate the time-varying $\ell$ rather than improving the observability of the targetâ€™s motion.</p><p>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[Case 1: The observer moves around the target. Both the bearing-only and bearing-angle approaches work well.]{<br>\includegraphics[width=1 \linewidth]{fig_indoor_9}<br>\label{fig_indoor_9}<br>}<br>\hfill<br>\subfloat[Case 2: The observer moves close or far from the target periodically. The bearing-angle approach performs effectively, but the bearing-only approach works unstably.]{<br>\includegraphics[width=1 \linewidth]{fig_indoor_6}<br>\label{fig_indoor_6}<br>}<br>\caption{Experimental results based on a hand-held camera.}<br>\end{figure</em>}</p><p>\section{Real-World Experimental Results}\label{sec_real_world_experimental_validation}</p><p>In this section, two sets of real-world experiments are presented to further verify the effectiveness of the approach. The first is based on a hand-held camera and a ground robot.<br>The second is based on two quadcopter MAVs. The second experimental scenario is motivated by aerial target pursuit tasks.</p><p>\subsection{Experiment 1: Hand-held camera}</p><p>The experimental setup is shown in Fig.~\ref{fig_architecture_indoor}.<br>The observer is a hand-held camera (Hik Vision DS-E14S) connected to a laptop. The cameraâ€™s intrinsic parameters are calibrated beforehand.<br>The robot built on Mecanum wheels can move in any direction on the ground under velocity control.<br>The ground truth of the states of the camera and the robot are provided by a Vicon indoor motion capture system.<br>The key experimental specifications are listed in Table~\ref{table_indoor_hardware}.</p><p>A dataset of 5,514 images was collected and used to train a tiny-YOLO v4 network to detect the target robot (see Fig.~\ref{fig_car_dataset}).<br>The detection precision of the trained network is mAP=99.8\%.<br>In the experiment, the target robot is commanded to move with a constant velocity.<br>In the meantime, a person holding the camera moves along some trajectories.<br>Two different cases are studied. In both of the cases, the target robot moves with a constant velocity $v_T=[-0.1, 0.1 ,0]^\mathrm{T}$.<br>The noises of the measurements are calculated based on the ground truth provided by the Vicon system. The noises are shown in the right subfigures of Fig.~\ref{fig_indoor_9} and Fig.~\ref{fig_indoor_6}.</p><p>In the first case, the camera is held about 1.5 meters above the ground and moves around the target robot. In this case, the bearing vector varies sufficiently and hence the observability conditions for the bearing-only and bearing-angle approaches are both well satisfied. As shown in Fig.~\ref{fig_indoor_9}, both approaches perform well in this case while the bearing-angle approach performs slightly better than the bearing-only one.</p><p>In the second case, the camera moves along the trajectory of the robot by getting close or far from it periodically.<br>In this case, the angle varies significantly, but the bearing does not.<br>Without surprise, the bearing-only approach performs poorly in this case due to weak observability  (Fig.~\ref{fig_indoor_6}).<br>By contrast, the bearing-angle approach can perform stably due to its enhanced observability.<br>\begin{table}<br>\begin{center}<br>\caption{Key specifications of the \emph{indoor} hardware system.}<br>\label{table_indoor_hardware}<br>\begin{tabular}{l|lll}<br>\hline<br> &amp; Parameter &amp; Value &amp; Unit \<br>\hline<br>\multirow{2}<em>{Camera} &amp; Resolution &amp; 640$\times$ 480 &amp; pixel\<br>~ &amp; Max frequency &amp; 30 &amp;fps\<br>\hline<br>\multirow{2}</em>{Robot} &amp; Max speed &amp; 1&amp; m/s \<br>~ &amp; Diameter size &amp; 295 &amp; mm\<br>\hline<br>\multirow{2}*{Vicon} &amp; Localization accuracy &amp; 1 &amp; mm \<br>~ &amp; Max frequency &amp; 100 &amp; Hz\<br>\hline<br>\end{tabular}<br>\end{center}<br>\end{table}</p><p>\subsection{Experiment 2: MAV-following-MAV}<br>\label{sec_mav_following_mav}</p><p>\begin{table}<br>\begin{center}<br>\caption{Key specifications of the \emph{outdoor} hardware system.}<br>\label{table_M300}<br>\begin{tabular}{c|lll}<br>\hline<br> &amp; Parameter &amp; Value &amp; Unit \<br>\hline<br>\multirow{5}{<em>}{\makecell[c]{M300 \quadcopter}} &amp; Diagonal size &amp; 895 &amp; mm\<br>~&amp;Total mass &amp; 7.4 &amp; kg \<br>~&amp;Max pitch/roll &amp; 30 &amp; degree \<br>~&amp;Max flight time &amp; 30 &amp; minutes\<br>\hline<br>\multirow{2}{</em>}{RTK} &amp; Accuracy &amp; 1 &amp; cm \<br>~&amp; Max frequency &amp; 10 &amp; Hz\<br>\hline<br>\multirow{3}{*}{\makecell[c]{H20 \ gimbal \&amp; \ camera} } &amp; Resolution &amp;1920$\times$1080  &amp; pixel\<br>~&amp; Frequency &amp; 15 &amp; Hz \<br>~ &amp; Max angular rate &amp; 180 &amp; deg/s\<br>\hline<br>\end{tabular}<br>\end{center}<br>\end{table}</p><p>\begin{figure<em>}[!t]<br>\centering<br>\subfloat[Hardware platforms]{<br>\includegraphics[width=0.48 \linewidth]{fig_M300}<br>\label{fig_M300}<br>}<br>\subfloat[Samples of the images in the dataset]{<br>\includegraphics[width=0.48\linewidth]{fig_M300_dataset1}<br>\label{fig_M300_dataset}<br>}<br>\hfill<br>\subfloat[System architecture]{<br>\includegraphics[width=0.48 \linewidth]{fig_outdoor_hardware}<br>\label{fig_outdoor_hardware}<br>}<br>\caption{The setup of the MAV-following-MAV experiment.}<br>\end{figure</em>}</p><p>\begin{figure<em>}[!t]<br>    \centering<br>    \includegraphics[width=1\linewidth]{fig_outdoor_1}<br>    \caption{The results of the MAV-following-MAV experiments. The bearing-angle approach performs effectively, but the bearing-only approach works unstably.}<br>    \label{fig_outdoor_1}<br>\end{figure</em>}</p><p>Two MAV platforms were developed based on DJI M300 quadcopters (Fig.~\ref{fig_M300}).<br>The MAV platforms are equipped with RTK GPS modules for accurate self-localization, an H20 camera for visual detection, a Manifold 2G onboard computer for onboard flight control, and a Zigbee module for wireless communication.<br>Some key specifications of the MAV platforms are listed in Table~\ref{table_M300}.<br>The structure of the hardware perception and communication system is illustrated in Fig.~\ref{fig_outdoor_hardware}.<br>The target MAV is also equipped with an RTK GPS module, whose measurements are used as the ground truth to calculate the noises of the visual measurements. The noises are shown in the right subfigure of Fig.~\ref{fig_outdoor_1}.</p><p>The experiment consists of two stages: data acquisition and offline data processing.<br>In the data acquisition stage, the target MAV is commanded to fly with a constant velocity, and the observer MAV is automatically controlled to follow the target MAV to maintain a constant distance from the target.<br>More specifically, the procedure of the flight experiment is as follows. Initially, the observer MAV is placed about 20 meters behind the target MAV on the ground. Then, the two MAVs take off and fly to the same specified height automatically upon a takeoff command sent from the ground control station.<br>After they have reached the desired height, all deployed algorithms are activated.<br>Then, the target MAV moves with a constant velocity of $v_T=[1/\sqrt{2}, 1/\sqrt{2}, 0]^\mathrm{T}$. The observer MAV approaches the target by the controller in \eqref{eq_tracking_control}. It takes the observer MAV about eight seconds to reach the desired relative distance.<br>Then, the two MAVs fly with the same velocity and remain relatively stationary for another 20 seconds.<br>Finally, the ground station sends a stop command and the two MAVs return and land automatically.</p><p>During the flight, the gimbal camera of the observer MAV is automatically controlled so that the target MAV is maintained in the field of view.<br>It is noted that the control of the gimbal camera and the observer MAV is not based on the visual detection results. Instead, the control is based on the measurements provided by the RKT GPS and inter-MAV wireless communication. In this way, we can analyze the image and flight data offline and compare the performance of the two approaches of bearing-angle and bearing-only.<br>The acquired images and flight data are saved on the onboard computer during the flight. A dataset of 5,341 images was collected (Fig.~\ref{fig_M300_dataset}) and used to train a tiny-YOLO v4 network.<br>The detection precision of the trained network reaches mAP=99.8\%.</p><p>The experimental results are shown in Fig.~\ref{fig_outdoor_1}.<br>As can be seen, the bearing-angle approach performs well. By contrast, the bearing-only approach only works well before the observer MAV reached the desired position relative to the target MAV. That is because the bearing varies significantly during this process due to the fluctuation of the observerâ€™s motion caused by the flight control. However, the bearing-only approach diverges quickly thereafter when the bearing stops varying significantly.</p><p>\section{Conclusion}\label{section_conclusion}<br>Motivated by the limitation of the existing bearing-only approach, this paper proposed and analyzed a novel bearing-angle approach for vision-based target motion estimation. We showed that the observability by the bearing-angle approach is significantly enhanced compared to the bearing-only one.<br>As a result, the requirement of the observerâ€™s extra motion for observability enhancement can be significantly relaxed.<br>As we showed in various experiments, the bearing-angle approach can successfully estimate the targetâ€™s motion in many scenarios where the bearing-only approach fails.<br>The enhanced observability of the bearing-angle approach comes with no additional cost since almost all vision detection algorithms can generate bounding boxes.<br>One assumption adopted in the bearing-angle approach is that the targetâ€™s physical size is invariant to different viewing angles. Although this assumption is approximately valid in many tasks as demonstrated in this paper, it is meaningful to study how to relax or remove this assumption in the future.</p><p>%\section*{Acknowledgements}<br>%The authors would like to thank the anonymous reviewers and the editors for their helpful advice for improving this work.</p><p>\section*{Declaration of conflicting interests}<br>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p><p>\section*{Funding}<br>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this artical: This work was supported by the Hangzhou Key Technology Research and Development Program (Grant 20212013B09), and the Research Center for Industries of the Future at Westlake University (Grant WU2022C027).</p><p>\bibliographystyle{SageH}<br>%\bibliographystyle{SageV}<br>\bibliography{paper}</p><p>\end{document}</p>]]></content>
    
    
    <summary type="html">ğŸ§µæœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨ç§»åŠ¨å•ç›®ç›¸æœºä¼°è®¡ç§»åŠ¨ç›®æ ‡ç‰©ä½“è¿åŠ¨çš„é—®é¢˜</summary>
    
    
    
    <category term="é˜…è¯»" scheme="https://www.adunas.top/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="è§†è§‰å¯¼èˆª" scheme="https://www.adunas.top/tags/%E8%A7%86%E8%A7%89%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†</title>
    <link href="https://www.adunas.top/posts/20240222b.html"/>
    <id>https://www.adunas.top/posts/20240222b.html</id>
    <published>2024-02-22T11:12:03.000Z</published>
    <updated>2024-02-22T13:46:38.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡å­¦å¯¼èˆª"><a href="#æ–‡å­¦å¯¼èˆª" class="headerlink" title="æ–‡å­¦å¯¼èˆª"></a><a href="./20240224d.html#å…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†">æ–‡å­¦å¯¼èˆª</a></h1><blockquote><p>è­¦å¯Ÿå±€æ¡£æ¡ˆç¼–å·ï¼š2024-01-11-001</p><p>æ¡£æ¡ˆåç§°ï¼šå…³äºçˆ±è‰è¥¿äºšå±€é•¿çš„ä¸ªäººå›å¿†</p><p>æ¡£æ¡ˆä½œè€…ï¼šè‹±ä»™åº§ï¼Œè­¦å¯Ÿå±€å‰¯å±€é•¿</p></blockquote><p>&emsp;&emsp;æˆ‘ä¸çˆ±è‰è¥¿äºšå±€é•¿çš„ç›¸è¯†ï¼Œè¦è¿½æº¯åˆ°ä¸‰å¹´å‰çš„ä¸€èµ·å¥‡æ€ªçš„æ¡ˆä»¶ã€‚å½“æ—¶ï¼Œæˆ‘è¿˜æ˜¯ä¸€ä¸ªé“¶è¡ŒåŠ«åŒªï¼Œå’Œæˆ‘çš„åŒä¼™ä¸€èµ·ç­–åˆ’äº†ä¸€æ¬¡å¤§è§„æ¨¡çš„æŠ¢åŠ«ã€‚æˆ‘ä»¬æ‰“ç®—åœ¨æ°æ‹‰å¾·Â·å¼—é›·æ³½çš„é“¶è¡Œé‡Œè£…ä¸Šç‚¸å¼¹ï¼Œç„¶åè¶ç€æ··ä¹±ï¼ŒæŠ¢èµ°æ‰€æœ‰çš„é’±ã€‚æˆ‘ä»¬ä»¥ä¸ºæˆ‘ä»¬çš„è®¡åˆ’ååˆ†å®Œç¾ï¼Œæ²¡æƒ³åˆ°ï¼Œé‡åˆ°äº†çˆ±è‰è¥¿äºšï¼Œä¹Ÿå› æ­¤è®¤è¯†äº†é“¶è¡Œå®¶ã€‚</p><p>&emsp;&emsp;å¥¹å½“æ—¶è¿˜ä¸æ˜¯å±€é•¿ï¼Œåªæ˜¯ä¸€ä¸ªåˆšåˆšè°ƒæ¥çš„åˆ‘è­¦ï¼Œè´Ÿè´£è°ƒæŸ¥ä¸€èµ·æ¶‰åŠé»‘ç¤¾ä¼šçš„æªå‡»æ¡ˆã€‚å¥¹æ°å·§åœ¨é‚£å®¶é“¶è¡Œé‡Œï¼Œå‘ç°äº†æˆ‘ä»¬çš„ç‚¸å¼¹ï¼Œå°±ç«‹åˆ»é€šçŸ¥äº†è­¦æ–¹ï¼Œç„¶åå†²è¿›äº†æˆ‘ä»¬çš„è—èº«å¤„ï¼Œä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æŠŠæˆ‘ä»¬åˆ¶æœäº†ã€‚å¥¹çš„åŠ¨ä½œååˆ†è¿…é€Ÿï¼Œå‡ ä¹æ²¡æœ‰ç»™æˆ‘ä»¬ååº”çš„æœºä¼šã€‚æˆ‘æ˜¯æœ€åä¸€ä¸ªè¢«å¥¹æŠ“ä½çš„ï¼Œå¥¹ç”¨æªæŒ‡ç€æˆ‘çš„å¤´ï¼Œè¯´ï¼šâ€œä½ ä»¬è¿™äº›æ— è€»çš„å®¶ä¼™ï¼Œç«Ÿæ•¢å¨èƒæ— è¾œçš„äººæ°‘ï¼Œåº”è¯¥å—åˆ°æƒ©ç½šã€‚â€å¥¹çš„çœ¼ç¥ååˆ†å†·é…·ï¼Œè®©æˆ‘æ„Ÿåˆ°ä¸€é˜µå¯’æ„ã€‚</p><p>&emsp;&emsp;ä½†æ˜¯ï¼Œå°±åœ¨å¥¹å‡†å¤‡æ‰£åŠ¨æ‰³æœºçš„æ—¶å€™ï¼Œå¥¹çªç„¶åœä½äº†ï¼Œå¥¹çš„çœ¼ç¥å˜å¾—æŸ”å’Œï¼Œå¥¹è¯´ï¼šâ€œä¸è¿‡ï¼Œä½ è¿˜æœ‰æ•‘èµçš„æœºä¼šï¼Œä½ å¯ä»¥é€‰æ‹©è·Ÿæˆ‘èµ°ï¼Œæˆ–è€…ç•™åœ¨è¿™é‡Œç­‰æ­»ã€‚â€æˆ‘ä¸çŸ¥é“å¥¹ä¸ºä»€ä¹ˆä¼šçªç„¶æ”¹å˜ä¸»æ„ï¼Œä¹Ÿä¸çŸ¥é“å¥¹è¦å¸¦æˆ‘å»å“ªé‡Œï¼Œä½†æ˜¯æˆ‘è§‰å¾—æˆ‘æ²¡æœ‰åˆ«çš„é€‰æ‹©ï¼Œå°±è·Ÿç€å¥¹èµ°äº†ã€‚</p><p>&emsp;&emsp;ä»é‚£ä»¥åï¼Œæˆ‘å°±æˆäº†çˆ±è‰è¥¿äºšå±€é•¿çš„å¾—åŠ›åŠ©æ‰‹ï¼Œä¹Ÿæ˜¯å¥¹å”¯ä¸€çš„æœ‹å‹ã€‚å¥¹å¯¹æˆ‘å¾ˆå¥½ï¼Œæ€»æ˜¯ç»™æˆ‘è®²ä¸€äº›æœ‰è¶£çš„æ•…äº‹ï¼Œè¿˜æ•™æˆ‘ä¸€äº›å¥‡æ€ªçš„çŸ¥è¯†ã€‚å¥¹è¯´å¥¹æ˜¯ä»ä¸€ä¸ªå«åš â€œé€ç«ä¹‹è›¾â€ çš„ç»„ç»‡æ¥çš„ï¼Œé‚£é‡Œæœ‰å¾ˆå¤šå¥‡å¦™çš„äº‹ç‰©ï¼Œè¿˜æœ‰ä¸€äº›å¥¹çš„æˆ˜å‹ã€‚</p><p>&emsp;&emsp;æˆ‘ä¸çŸ¥é“å¥¹è¯´çš„è¿™äº›æ˜¯çœŸæ˜¯å‡ï¼Œä½†æˆ‘è§‰å¾—å¥¹å¾ˆå¯ä¿¡ï¼Œä¹Ÿå¾ˆæœ‰é­…åŠ›ã€‚å¥¹åœ¨å·¥ä½œä¸Šå¾ˆæœ‰èƒ½åŠ›ï¼Œèƒ½å¤Ÿè¿…é€Ÿè§£å†³å„ç§æ£˜æ‰‹çš„æ¡ˆä»¶ï¼Œè¿˜èƒ½å’Œå„æ–¹æ‰“å¥½å…³ç³»ã€‚å¥¹åœ¨ç”Ÿæ´»ä¸Šå¾ˆæœ‰è¶£ï¼Œç»å¸¸æ‹‰ç€æˆ‘å»é€›è¡—ï¼Œè®©æˆ‘å¸®å¥¹æŒ‘é€‰è¡£æœå’ŒåŒ–å¦†å“ï¼Œæœ‰æ—¶å€™æˆ‘å¿ƒä¸åœ¨ç„‰ï¼Œå¥¹åˆä¼šæ‹‰ç€æˆ‘çš„æ‰‹å¯¹æˆ‘è¯´ï¼šâ€œä½ å¿«å¯¹æˆ‘è¯´ï¼Œè‰¾è‰è¥¿äºšç©¿ä»€ä¹ˆéƒ½å¥½çœ‹ï¼Œå¥½ä¸å¥½å˜›ï¼Ÿâ€æœ‰æ—¶å€™å¥¹ä¹Ÿä¼šæ‹‰ç€æˆ‘å»çœ‹ææ€–ç”µå½±ï¼Œæ¼”åˆ°å“äººçš„åœºæ™¯æ—¶å¥¹ä¹Ÿä¼šå®³æ€•çš„ç¼©æˆä¸€å›¢ï¼Œå’Œä¹‹å‰å‹‡æ•¢æ— ç•çš„å±€é•¿åˆ¤è‹¥ä¸¤äººã€‚è™½ç„¶æˆ‘ä¹Ÿå¾ˆå®³æ€•ï¼Œä½†è¿˜æ˜¯ä¼šæ‘¸æ‘¸å¥¹çš„å¤´ï¼Œå¯¹å¥¹è¯´ï¼šâ€œæˆ‘ä¼šæ°¸è¿œä¿æŠ¤ä½ çš„ã€‚â€è€Œå¥¹ä¼šè¶æœºé åœ¨æˆ‘çš„è‚©è†€ä¸Šè¯´ï¼šâ€œä½ å¯çœŸæ˜¯æˆ‘çš„å°è‹±é›„ï¼â€</p><p><img src="https://picture.adunas.top/Article/ElysiaA.png" alt=""></p><p>&emsp;&emsp;æœ‰ä¸€æ¬¡æˆ‘ä»¬è§£å†³äº†å“ˆå±±çš„æ¡ˆå­ï¼Œä¸­é—´å’Œå¥¹åˆ†å¼€äº†ä¸€æ®µæ—¶é—´ï¼Œç»“æœå¬åˆ°å¥¹çš„ä¸€å£°æƒ¨å«ï¼Œä½†æ˜¯å½“æˆ‘è¿‡æ¥ä¹‹åå¥¹åªæ˜¯ä¸€è„¸ç¬‘æ„çš„çœ‹ç€æˆ‘ï¼Œæ‰‹ä¸Šæ‹¿ç€ä¸€ä¸ªå¥‡æ€ªçš„æ€€è¡¨ã€‚ä¹‹åçš„æ—¥å­é‡Œå¥¹æœ‰æ—¶å€™ä¼šçªç„¶æ¶ˆå¤±ä¸€æ®µæ—¶é—´ï¼Œç„¶ååˆçªç„¶å‡ºç°åœ¨æˆ‘çš„é¢å‰ï¼Œå¥¹ä»ä¸å‘Šè¯‰æˆ‘å¥¹å»äº†å“ªé‡Œï¼Œåšäº†ä»€ä¹ˆï¼Œåªæ˜¯ç¬‘ç€è¯´ï¼šâ€œä½ ä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘åªæ˜¯æœ‰äº›ç§äº‹è¦åŠã€‚â€æˆ‘æ€»æ˜¯è§‰å¾—å¥¹åœ¨éšç’ä»€ä¹ˆï¼Œä½†æˆ‘ä¸æ•¢å¤šé—®ï¼Œåªæ˜¯é»˜é»˜åœ°ç­‰å¾…å¥¹çš„å½’æ¥ï¼Œåªè§‰å¾—å¥¹æœ‰ä¸€ç§ç¥å¥‡çš„åŠ›é‡ã€‚</p><p>&emsp;&emsp;å¥¹ç»å¸¸è®©æˆ‘é™ªå¥¹å»ä¸€äº›å±é™©çš„åœ°æ–¹ï¼Œè¯´æ˜¯ä¸ºäº†è°ƒæŸ¥ä¸€äº›æ¡ˆä»¶ï¼Œå…¶å®æ˜¯ä¸ºäº†å¯»æ‰¾å¥¹çš„ç§˜å¯†ã€‚å¥¹æ€»æ˜¯è®©æˆ‘é‡åˆ°å„ç§éº»çƒ¦ï¼Œæ¯”å¦‚è¢«é»‘ç¤¾ä¼šè¿½æ€ï¼Œè¢«é‚ªæ¶çš„åŠ›é‡æ„ŸæŸ“ï¼Œç­‰ç­‰ã€‚å¥¹æ¯æ¬¡éƒ½ä¼šåœ¨æœ€åä¸€åˆ»å‡ºç°ï¼Œæ•‘æˆ‘ä¸€å‘½ï¼Œç„¶åå¯¹æˆ‘è¯´ï¼šâ€œä½ çœŸæ˜¯ä¸ªç¬¨è›‹ï¼Œæ€ä¹ˆæ€»æ˜¯è®©è‡ªå·±é™·å…¥å±é™©ï¼Œä½ ä¸çŸ¥é“æˆ‘æœ‰å¤šæ‹…å¿ƒä½ å—ï¼Ÿâ€å¥¹çš„è¯­æ°”æ€»æ˜¯å¸¦ç€ä¸€ç§å˜²è®½ï¼Œè®©æˆ‘è§‰å¾—å¥¹æ˜¯åœ¨æ•…æ„æ‰å¼„æˆ‘ï¼Œä½†æ˜¯å¥¹çš„çœ¼ç¥å´åˆå……æ»¡äº†å…³åˆ‡ï¼Œè®©æˆ‘è§‰å¾—å¥¹æ˜¯åœ¨çœŸå¿ƒä¿æŠ¤æˆ‘ã€‚æˆ‘ä¸çŸ¥é“å¥¹åˆ°åº•æ˜¯æ€ä¹ˆæƒ³çš„ï¼Œä½†æ˜¯æˆ‘æ€»æ˜¯æ„Ÿæ¿€å¥¹ï¼Œä¹Ÿæ€»æ˜¯åŸè°…å¥¹ã€‚</p><p>&emsp;&emsp;ç›´åˆ°é‚£ä¸€å¤©ï¼Œä¸€åˆ‡éƒ½æ”¹å˜äº†ã€‚é‚£æ˜¯ä¸€å¤©æ™šä¸Šï¼Œæˆ‘ä»¬åœ¨ç°åœºå‘ç°äº†ä¸€ä¸ªå°å¥³å­©ï¼Œçˆ±è‰è¥¿äºšçœ‹åˆ°å¥¹ï¼Œå°±æƒŠå‘¼äº†ä¸€å£°ï¼Œè¯´ï¼šâ€œæ˜¯ä½ ï¼â€ç„¶åï¼Œå¥¹å°±å†²ä¸Šå»ï¼ŒæŠ±ä½äº†é‚£ä¸ªå¥³å­©ã€‚æ¥ä¸‹æ¥çš„äº‹æƒ…ï¼Œæˆ‘å°±è®°ä¸å¤ªæ¸…æ¥šäº†ã€‚æˆ‘åªè®°å¾—çˆ±è‰è¥¿äºšå±€é•¿å’Œé‚£ä¸ªå¥³å­©è¯´äº†ä¸€äº›è¯ï¼Œç„¶åå¥¹å°±å¯¹æˆ‘è¯´ï¼šâ€œå¯¹ä¸èµ·ï¼Œæˆ‘è¦èµ°äº†ï¼Œæˆ‘æœ‰å¾ˆé‡è¦çš„äº‹æƒ…è¦åšï¼Œå’Œå¥¹æœ‰å…³ã€‚â€æˆ‘é—®å¥¹è¦å»å“ªé‡Œï¼Œå¥¹è¯´ï¼šâ€œå»ä¸€ä¸ªä½ æ— æ³•è·Ÿéšçš„åœ°æ–¹ï¼Œå»å®Œæˆæˆ‘çš„ä½¿å‘½ã€‚â€è€Œæˆ‘æ— æ³•æŠ›ä¸‹å¥¹ä¸ç®¡ï¼Œè¿˜æ˜¯å·å·è·Ÿäº†è¿‡å»ã€‚</p><p>&emsp;&emsp;ä¸­é—´æ’•æ‰äº†å¾ˆå¤šé¡µï¼ˆï¼‰</p><p>&emsp;&emsp;é‚£ä¸€å¤©çš„åœºæ™¯ä»ç„¶æ— æ•°æ¬¡çš„å‡ºç°åœ¨æˆ‘çš„æ¢¦é‡Œï¼Œæˆ‘ä»¿ä½›ç½®èº«å……æ»¡äº†ææ€–å’Œç»æœ›çš„åœ°æ–¹ï¼Œè®©äººåªèƒ½æ„Ÿå—åˆ°ç–¯ç‹‚å’Œæ­»äº¡ã€‚é‚£é‡Œæœ‰æ— æ•°çš„é»‘æš—ï¼Œæ— æ•°çš„æ€ªç‰©ï¼Œæ— æ•°çš„å°–å«ï¼Œæ— æ•°çš„è¡€è‚‰ã€‚é‚£é‡Œæ²¡æœ‰å…‰æ˜ï¼Œæ²¡æœ‰ç”Ÿå‘½ï¼Œæ²¡æœ‰å¸Œæœ›ï¼Œæ²¡æœ‰æ„ä¹‰ï¼Œæ²¡æœ‰è§„åˆ™ã€‚é‚£é‡Œåªæœ‰ä¸€ä¸ªæ— å°½çš„æ··æ²Œï¼Œä¸€ä¸ªæ— è¾¹çš„ç–¯ç‹‚ï¼Œä¸€ä¸ªæ— åçš„ææƒ§ï¼Œä¸€ä¸ªæ— æ³•çš„å´©åã€‚</p><p>&emsp;&emsp;æˆ‘åªè®°å¾—æœ€åï¼Œè‰¾è‰è¥¿äºšå¯¹æˆ‘è¯´ï¼šâ€œå‚»ç“œï¼Œä½ è¿˜æ˜¯è·Ÿè¿‡æ¥äº†å‘€ï¼Œæˆ‘çš„å°è‹±é›„ã€‚â€</p><details class="folding-tag" orange><summary> ç‚¹å‡»æŸ¥çœ‹è¯­å½• </summary>              <div class='content'>              <p><span class='p green'&gt;></span> ç²‰è‰²å¤´å‘çš„è¿·äººå¥³å­©æ˜¯è°å‘€ï¼Œå“¦ï¼ŒåŸæ¥æ˜¯æˆ‘å‘€ï¼&lt;span class='p green'><</span></p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E7%88%B1%E8%8E%89%E5%B8%8C%E9%9B%85-%E8%AF%B4%E8%B5%B7%E7%B2%89%E8%89%B2%E5%A4%B4%E5%8F%91%E7%9A%84%E5%8F%AF%E7%88%B1%E5%A5%B3%E5%AD%A9%EF%BC%8C%E4%BD%A0%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BC%9A%E6%83%B3%E5%88%B0%E8%B0%81%EF%BC%9F%E4%B8%89%E4%BA%8C%E4%B8%80%E5%9B%9E%E7%AD%94%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><p><span class='p green'&gt;></span> å¤šå¤¸å¤¸æˆ‘å˜›ï¼Œæˆ‘ä¼šå¾ˆå¼€å¿ƒçš„~&lt;span class='p green'><</span></p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E7%88%B1%E8%8E%89%E5%B8%8C%E9%9B%85-%E5%97%A8%EF%BC%8C%E6%88%91%E5%8F%88%E6%9D%A5%E5%95%A6%E3%80%82%E5%A4%9A%E5%A4%B8%E5%A4%B8%E6%88%91%E5%A5%BD%E5%90%97%EF%BC%9F%E6%88%91%E4%BC%9A%E5%BE%88%E2%80%94%E2%80%94%E5%BC%80%E5%BF%83%E7%9A%84%E5%93%A6%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div><p><span class='p green'&gt;></span> å¯çˆ±çš„å°‘å¥³å¿ƒï¼Œå¯æ˜¯æ— æ‰€ä¸èƒ½çš„å“¦ï¼&lt;span class='p green'><</span></p><div class="audio"><audio controls preload><source src='https://picture.adunas.top/Audio/%E4%BA%BA%E4%B9%8B%E5%BE%8B%E8%80%85-%E5%91%B5...%E7%9C%8B%EF%BC%8C%E5%8F%AF%E7%88%B1%E7%9A%84%E5%B0%91%E5%A5%B3%E5%BF%83%E5%8F%AF%E6%98%AF%E6%97%A0%E6%89%80%E4%B8%8D%E8%83%BD%E7%9A%84%E5%93%A6%E3%80%82.mp3' type='audio/mp3'>Your browser does not support the audio tag.</audio></div>              </div>            </details>]]></content>
    
    
    <summary type="html">ğŸ§¶å‚»ç“œï¼Œä½ è¿˜æ˜¯è·Ÿè¿‡æ¥äº†å‘€ï¼Œæˆ‘çš„å°è‹±é›„</summary>
    
    
    
    <category term="æ–‡å­¦" scheme="https://www.adunas.top/categories/%E6%96%87%E5%AD%A6/"/>
    
    
    <category term="å°è¯´" scheme="https://www.adunas.top/tags/%E5%B0%8F%E8%AF%B4/"/>
    
    <category term="äººç‰©æ¡£æ¡ˆ" scheme="https://www.adunas.top/tags/%E4%BA%BA%E7%89%A9%E6%A1%A3%E6%A1%88/"/>
    
    <category term="è·‘å›¢" scheme="https://www.adunas.top/tags/%E8%B7%91%E5%9B%A2/"/>
    
  </entry>
  
  <entry>
    <title>æ—¥ç¨‹è¡¨ï¼š2024å¹´02æœˆ</title>
    <link href="https://www.adunas.top/posts/20240222a.html"/>
    <id>https://www.adunas.top/posts/20240222a.html</id>
    <published>2024-02-22T08:36:32.000Z</published>
    <updated>2024-02-22T08:36:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#2024å¹´2æœˆ">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="2024å¹´2æœˆ23æ—¥"><a href="#2024å¹´2æœˆ23æ—¥" class="headerlink" title="2024å¹´2æœˆ23æ—¥"></a>2024å¹´2æœˆ23æ—¥</h1><div class='checkbox red checked'><input type="checkbox" checked="checked"/>            <p>è¿åŠ¨1å°æ—¶</p>            </div><ul><li>[x] ç¾½æ¯›çƒ</li></ul><div class='checkbox red'><input type="checkbox" />            <p>å†™ä¸€ç¯‡é˜…è¯»è®ºæ–‡çš„åšå®¢</p>            </div><details class="folding-tag" blue><summary> æ—¥ç¨‹è¡¨ </summary>              <div class='content'>              <div class="timeline blue"><div class='timeline-item headline'><div class='timeline-item-title'><div class='item-circle'><p>æ—¶é—´è½´</p></div></div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>17ç‚¹46åˆ†</p></div></div><div class='timeline-item-content'><ol><li>åƒæ™šé¥­</li></ol></div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>18ç‚¹10åˆ†</p></div></div><div class='timeline-item-content'><ol><li>é˜…è¯»è®ºæ–‡</li></ol></div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>18ç‚¹40åˆ†-20ç‚¹40åˆ†</p></div></div><div class='timeline-item-content'><ol><li>ç¾½æ¯›çƒ</li></ol></div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>21ç‚¹56åˆ†</p></div></div><div class='timeline-item-content'><ol><li>é˜…è¯»è®ºæ–‡</li></ol></div></div></div>              </div>            </details>]]></content>
    
    
    <summary type="html">ğŸ¥æœ¬æ–‡è®°å½• Adunas 2024å¹´02æœˆçš„æ—¥ç¨‹å®‰æ’å’Œå®æ–½æƒ…å†µ</summary>
    
    
    
    <category term="æ—¥ç¨‹è¡¨" scheme="https://www.adunas.top/categories/%E6%97%A5%E7%A8%8B%E8%A1%A8/"/>
    
    
    <category term="æ—¥ç¨‹è¡¨" scheme="https://www.adunas.top/tags/%E6%97%A5%E7%A8%8B%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>åšå®¢æ­å»ºå¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240221c.html"/>
    <id>https://www.adunas.top/posts/20240221c.html</id>
    <published>2024-02-21T11:26:31.000Z</published>
    <updated>2024-02-21T11:26:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#åšå®¢æ­å»º">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="åšå®¢æ–‡ç« è¯­æ³•ç¬”è®°å¯¼èˆª"><a href="#åšå®¢æ–‡ç« è¯­æ³•ç¬”è®°å¯¼èˆª" class="headerlink" title="åšå®¢æ–‡ç« è¯­æ³•ç¬”è®°å¯¼èˆª"></a>åšå®¢æ–‡ç« è¯­æ³•ç¬”è®°å¯¼èˆª</h1><h2 id="MarkdownåŸºç¡€è¯­æ³•"><a href="#MarkdownåŸºç¡€è¯­æ³•" class="headerlink" title="MarkdownåŸºç¡€è¯­æ³•"></a><a href="./20231201a.html">MarkdownåŸºç¡€è¯­æ³•</a></h2><h2 id="Markdownå†…ç½®Htmlè¯­æ³•"><a href="#Markdownå†…ç½®Htmlè¯­æ³•" class="headerlink" title="Markdownå†…ç½®Htmlè¯­æ³•"></a><a href="./20231206b.html">Markdownå†…ç½®Htmlè¯­æ³•</a></h2><h2 id="Butterflyå¤–æŒ‚æ ‡ç­¾"><a href="#Butterflyå¤–æŒ‚æ ‡ç­¾" class="headerlink" title="Butterflyå¤–æŒ‚æ ‡ç­¾"></a><a href="./20231205b.html">Butterflyå¤–æŒ‚æ ‡ç­¾</a></h2><h1 id="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"><a href="#åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª" class="headerlink" title="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"></a>åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª</h1><h2 id="åŸºç¡€æ•™ç¨‹"><a href="#åŸºç¡€æ•™ç¨‹" class="headerlink" title="åŸºç¡€æ•™ç¨‹"></a><a href="./20231205d.html">åŸºç¡€æ•™ç¨‹</a></h2><h2 id="bugæ±‡æ€»"><a href="#bugæ±‡æ€»" class="headerlink" title="bugæ±‡æ€»"></a><a href="./20231204c.html">bugæ±‡æ€»</a></h2><h2 id="æœªæ¥å¯æœŸ"><a href="#æœªæ¥å¯æœŸ" class="headerlink" title="æœªæ¥å¯æœŸ"></a><a href="./20231205c.html">æœªæ¥å¯æœŸ</a></h2><h2 id="éŸ³é¢‘æ•™ç¨‹"><a href="#éŸ³é¢‘æ•™ç¨‹" class="headerlink" title="éŸ³é¢‘æ•™ç¨‹"></a><a href="./20231207a.html">éŸ³é¢‘æ•™ç¨‹</a></h2><h2 id="æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½"><a href="#æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½" class="headerlink" title="æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½"></a><a href="./20240201a.html">æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½</a></h2><h2 id="é¦–é¡µç¾åŒ–"><a href="#é¦–é¡µç¾åŒ–" class="headerlink" title="é¦–é¡µç¾åŒ–"></a><a href="./20240202a.html">é¦–é¡µç¾åŒ–</a></h2>]]></content>
    
    
    <summary type="html">ğŸ§ˆæœ¬æ–‡æ˜¯åšå®¢æ­å»ºçš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>ç¼–ç¨‹å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240221b.html"/>
    <id>https://www.adunas.top/posts/20240221b.html</id>
    <published>2024-02-21T10:48:39.000Z</published>
    <updated>2024-02-21T10:49:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#ç¼–ç¨‹">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h1><h2 id="æ‰“å°"><a href="#æ‰“å°" class="headerlink" title="æ‰“å°"></a><a href="./20240116a.html">æ‰“å°</a></h2><h1 id="å‘½ä»¤è¡Œ"><a href="#å‘½ä»¤è¡Œ" class="headerlink" title="å‘½ä»¤è¡Œ"></a>å‘½ä»¤è¡Œ</h1><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a><a href="./20231206a.html">Git</a></h2><h1 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h1><h2 id="å‰ç«¯"><a href="#å‰ç«¯" class="headerlink" title="å‰ç«¯"></a><a href="./20231211a.html">å‰ç«¯</a></h2><h1 id="æœç´¢"><a href="#æœç´¢" class="headerlink" title="æœç´¢"></a>æœç´¢</h1><h2 id="æ­£åˆ™è¡¨è¾¾å¼"><a href="#æ­£åˆ™è¡¨è¾¾å¼" class="headerlink" title="æ­£åˆ™è¡¨è¾¾å¼"></a><a href="./20240225a.html">æ­£åˆ™è¡¨è¾¾å¼</a></h2><h1 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a><a href="./20240225c.html">Latex</a></h1>]]></content>
    
    
    <summary type="html">ğŸ¥æœ¬æ–‡æ˜¯ç¼–ç¨‹åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>æ–‡ç« å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240221a.html"/>
    <id>https://www.adunas.top/posts/20240221a.html</id>
    <published>2024-02-21T10:41:36.000Z</published>
    <updated>2024-02-21T10:41:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ•°å­¦"><a href="#æ•°å­¦" class="headerlink" title="æ•°å­¦"></a><a href="./20240210a.html">æ•°å­¦</a></h1><h1 id="è‹±è¯­"><a href="#è‹±è¯­" class="headerlink" title="è‹±è¯­"></a>è‹±è¯­</h1><h2 id="å•è¯"><a href="#å•è¯" class="headerlink" title="å•è¯"></a><a href="./20231208a.html">å•è¯</a></h2><h1 id="é˜…è¯»"><a href="#é˜…è¯»" class="headerlink" title="é˜…è¯»"></a><a href="./20240224b.html">é˜…è¯»</a></h1><h1 id="æ–‡å­¦"><a href="#æ–‡å­¦" class="headerlink" title="æ–‡å­¦"></a><a href="./20240224d.html">æ–‡å­¦</a></h1><h1 id="ç¼–ç¨‹"><a href="#ç¼–ç¨‹" class="headerlink" title="ç¼–ç¨‹"></a><a href="./20240221b.html">ç¼–ç¨‹</a></h1><h1 id="åšå®¢æ­å»º"><a href="#åšå®¢æ­å»º" class="headerlink" title="åšå®¢æ­å»º"></a><a href="./20240221c.html">åšå®¢æ­å»º</a></h1><h1 id="æ—¥ç¨‹è¡¨"><a href="#æ—¥ç¨‹è¡¨" class="headerlink" title="æ—¥ç¨‹è¡¨"></a>æ—¥ç¨‹è¡¨</h1><h2 id="2024å¹´2æœˆ"><a href="#2024å¹´2æœˆ" class="headerlink" title="2024å¹´2æœˆ"></a><a href="./20240222a.html">2024å¹´2æœˆ</a></h2><h1 id="è¿åŠ¨å¥åº·"><a href="#è¿åŠ¨å¥åº·" class="headerlink" title="è¿åŠ¨å¥åº·"></a>è¿åŠ¨å¥åº·</h1><h2 id="æ—¥å¸¸åŸºç¡€ç¯‡"><a href="#æ—¥å¸¸åŸºç¡€ç¯‡" class="headerlink" title="æ—¥å¸¸åŸºç¡€ç¯‡"></a><a href="./20240131a.html">æ—¥å¸¸åŸºç¡€ç¯‡</a></h2><h2 id="çŠ¶æ€è°ƒæ•´ç¯‡"><a href="#çŠ¶æ€è°ƒæ•´ç¯‡" class="headerlink" title="çŠ¶æ€è°ƒæ•´ç¯‡"></a><a href="./20240203a.html">çŠ¶æ€è°ƒæ•´ç¯‡</a></h2><h1 id="æ“ä½œç³»ç»Ÿ"><a href="#æ“ä½œç³»ç»Ÿ" class="headerlink" title="æ“ä½œç³»ç»Ÿ"></a>æ“ä½œç³»ç»Ÿ</h1><h1 id="IOS"><a href="#IOS" class="headerlink" title="IOS"></a>IOS</h1><h2 id="ipa"><a href="#ipa" class="headerlink" title="ipa"></a><a href="./20240115a.html">ipa</a></h2><h1 id="æ¸¸æˆ"><a href="#æ¸¸æˆ" class="headerlink" title="æ¸¸æˆ"></a>æ¸¸æˆ</h1><h2 id="Adunasçš„æ¸¸æˆè´¦å·æ˜µç§°å’ŒID"><a href="#Adunasçš„æ¸¸æˆè´¦å·æ˜µç§°å’ŒID" class="headerlink" title="Adunasçš„æ¸¸æˆè´¦å·æ˜µç§°å’ŒID"></a><a href="./20231201b.html">Adunasçš„æ¸¸æˆè´¦å·æ˜µç§°å’ŒID</a></h2>]]></content>
    
    
    <summary type="html">ğŸ¥æœ¬æ–‡æ˜¯æ–‡ç« åˆ†ç±»å¯¼èˆªçš„æœ€é¡¶å±‚</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>æ•°å­¦å¯¼èˆª</title>
    <link href="https://www.adunas.top/posts/20240210a.html"/>
    <id>https://www.adunas.top/posts/20240210a.html</id>
    <published>2024-02-10T06:57:53.000Z</published>
    <updated>2024-02-21T10:43:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#æ•°å­¦">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><h1 id="çŸ©é˜µ"><a href="#çŸ©é˜µ" class="headerlink" title="çŸ©é˜µ"></a>çŸ©é˜µ</h1><h2 id="è¿¹"><a href="#è¿¹" class="headerlink" title="è¿¹"></a><a href="./20231210a.html">è¿¹</a></h2><h2 id="åæ–¹å·®"><a href="#åæ–¹å·®" class="headerlink" title="åæ–¹å·®"></a><a href="./20231204a.html">åæ–¹å·®</a></h2><h1 id="æ»¤æ³¢"><a href="#æ»¤æ³¢" class="headerlink" title="æ»¤æ³¢"></a>æ»¤æ³¢</h1><h2 id="å¡å°”æ›¼æ»¤æ³¢"><a href="#å¡å°”æ›¼æ»¤æ³¢" class="headerlink" title="å¡å°”æ›¼æ»¤æ³¢"></a><a href="./20231205a.html">å¡å°”æ›¼æ»¤æ³¢</a></h2><h1 id="ç»˜å›¾å·¥å…·"><a href="#ç»˜å›¾å·¥å…·" class="headerlink" title="ç»˜å›¾å·¥å…·"></a>ç»˜å›¾å·¥å…·</h1><h2 id="åŠ¨æ€æ•°å­¦è½¯ä»¶"><a href="#åŠ¨æ€æ•°å­¦è½¯ä»¶" class="headerlink" title="åŠ¨æ€æ•°å­¦è½¯ä»¶"></a><a href="./20231210b.html">åŠ¨æ€æ•°å­¦è½¯ä»¶</a></h2><p>&emsp;&emsp;åŠ¨æ€æ•°å­¦è½¯ä»¶GroGebraã€‚</p>]]></content>
    
    
    <summary type="html">ğŸ¥§æœ¬æ–‡æ˜¯æ•°å­¦åˆ†ç±»çš„å¯¼èˆª</summary>
    
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/categories/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
    
    <category term="æ–‡ç« å¯¼èˆª" scheme="https://www.adunas.top/tags/%E6%96%87%E7%AB%A0%E5%AF%BC%E8%88%AA/"/>
    
  </entry>
  
  <entry>
    <title>è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</title>
    <link href="https://www.adunas.top/posts/20240203a.html"/>
    <id>https://www.adunas.top/posts/20240203a.html</id>
    <published>2024-02-03T04:32:11.000Z</published>
    <updated>2024-02-03T04:32:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#çŠ¶æ€è°ƒæ•´ç¯‡">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª"><a href="#è¿åŠ¨å¥åº·çš„å¯¼èˆª" class="headerlink" title="è¿åŠ¨å¥åº·çš„å¯¼èˆª"></a>è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol><li><a href="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a></li><li><a href="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li></ol></blockquote><div class="note info flat"></div><h1 id="ç‹¬ç«‹è‡ªä¸»"><a href="#ç‹¬ç«‹è‡ªä¸»" class="headerlink" title="ç‹¬ç«‹è‡ªä¸»"></a>ç‹¬ç«‹è‡ªä¸»</h1><p>&emsp;&emsp;å­¦ä¼šè‡ªå°Šè‡ªçˆ±ï¼Œä»»ä½•æ—¶å€™ä¸èƒ½æŠŠè‡ªå·±çš„æœªæ¥æ‰˜ä»˜ç»™åˆ«äººã€‚ä½ æœ€äº²çš„çˆ¶æ¯ä¸å¯ä»¥ï¼Œæœ€å¥½çš„æœ‹å‹ä¸å¯ä»¥ï¼Œæœ€çˆ±çš„å¥³æœ‹å‹ä¸å¯ä»¥ï¼Œæœ€çŸ¥å¿ƒçš„è€å¸ˆä¹Ÿä¸å¯ä»¥ã€‚ä½ å”¯ä¸€è¦å€¼å¾—æ‰˜ä»˜çš„äººåªæœ‰è‡ªå·±ï¼Œä¹Ÿåªèƒ½æ˜¯è‡ªå·±ã€‚è‡ªå·±æ˜¯è‡ªå·±çš„çˆ¶æ¯ï¼Œç…§é¡¾è‡ªå·±è¡£é£Ÿèµ·å±…ã€‚è‡ªå·±æ˜¯è‡ªå·±çš„å­©å­ï¼Œçº¯çœŸã€ç†æƒ³ã€çœŸå¿ƒéƒ½åœ¨æ­¤ã€‚</p><h1 id="å‹åŠ›åˆ«äºº"><a href="#å‹åŠ›åˆ«äºº" class="headerlink" title="å‹åŠ›åˆ«äºº"></a>å‹åŠ›åˆ«äºº</h1><p>&emsp;&emsp;å¶å°”è¿˜æ˜¯æœ‰è¿™ä¸ªåä¹ æƒ¯ã€‚å‹åŠ›åˆ«äººå…¸å‹æ˜¯è‡ªå‘çš„è¡¨ç°ï¼Œæƒ³é€šè¿‡æ‰“å‹åˆ«äººæ¥ä½“ç°è‡ªèº«çš„ä»·å€¼ï¼Œè¿™åªæ˜¯å«‰å¦’ï¼Œæ˜¯å¾ˆä¸å¥åº·çš„ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸¤æ€§å…³ç³»ä¸Šã€‚ç”Ÿæ´»å·²ç»å¾ˆç´¯å•¦ï¼Œå¥¹è¦çš„æ˜¯æƒ…ç»ªä»·å€¼ï¼Œè€Œä¸æ˜¯åˆå¤šä¸€ä¸ªå‹åŠ›çš„è€å¸ˆã€‚å¤šç«™åœ¨åˆ«äººçš„è§’åº¦å»æƒ³æƒ³ã€å»å…³å¿ƒã€å»çˆ±å§ã€‚å­¦ä¼š<a href="#èµç¾">èµç¾</a>åˆ«äººã€‚</p><h1 id="æ²‰é»˜ä¸æ¿€æƒ…"><a href="#æ²‰é»˜ä¸æ¿€æƒ…" class="headerlink" title="æ²‰é»˜ä¸æ¿€æƒ…"></a>æ²‰é»˜ä¸æ¿€æƒ…</h1><p>&emsp;&emsp;ä¸æ±‚æ— åŠŸï¼Œä½†æ±‚æ— è¿‡ã€‚è¿™å¥è¯è¯´å¾—çœŸå·®ï¼æˆ‘æ¥æ”¹æ”¹ï¼šä¸æ±‚æ— åŠŸï¼Œä¸æ€•çŠ¯é”™ï¼è¿™æ®µæ—¶é—´å…å»äº†å¾ˆå¤šæ— ç”¨çš„ç¤¾äº¤ã€æ— ç”¨çš„ç„¦è™‘ã€‚æ²‰å¿ƒé™æ°”åœ°æå­¦ä¹ å’Œç ”ç©¶ï¼Œå¹¶ä¸è§‰å¾—å­¤ç‹¬ï¼Œåè€Œè§‰å¾—æ— æ¯”è¸å®ã€èˆ’å¿ƒã€‚åˆé€‚çš„ç¤¾äº¤ï¼Œæˆ‘ä¼šæ‰“ç ´æ²‰é»˜ï¼Œæˆ‘è¦ä»æ¿€æƒ…åœ°å­¦ä¹ è½¬å˜æˆçƒ­æƒ…åœ°äº¤æµï¼ŒçœŸè¯šé¢å¯¹æ¯ä¸€ä¸ªäººï¼Œå’Œä¸åŒçš„äººã€åˆé€‚çš„äººäº¤æµæ‰èƒ½è®©è‡ªå·±èƒ½å¤Ÿä¸è®©è‡ªå·±çš„æ€æƒ³å’Œè§†é‡å˜å¾—ç‹­éš˜å’Œåé¢‡ã€‚çƒ­æƒ…ä¼šè¢«æ‰“å‡»ï¼Œä½†æ˜¯é‚£ç®€ç›´æ˜¯æŒ ç—’ç—’ï¼Œå› ä¸ºæˆ‘ä»¬æ ¹æœ¬<a href="#ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ">ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ</a>å‘€ã€‚</p><h1 id="ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ"><a href="#ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ" class="headerlink" title="ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ"></a>ä¸ç”Ÿæ°”ä¸ä¼¤å¿ƒ</h1><p>&emsp;&emsp;ä½ è¦å§‹ç»ˆæ˜ç™½è‡ªå·±åœ¨ä¹ä»€ä¹ˆï¼Œä»€ä¹ˆæ˜¯å¯¹ä½ é‡è¦çš„ã€‚ä¸è®ºç”·å¥³ï¼Œæœ€é‡è¦çš„æ˜¯åšå¥½è‡ªå·±è¯¥åšçš„äº‹æƒ…ã€‚å¯¹äºæˆ‘ï¼Œç”·ç”Ÿæ¥è¯´ï¼Œæœ€é‡è¦çš„æ˜¯äº‹ä¸šï¼Œäº‹ä¸šåšå¥½äº†ï¼Œå¥¹æœ‰å¯èƒ½è·Ÿä½ ï¼Œäº‹ä¸šåšä¸å¥½ï¼Œå¥¹ä¸€å®šä¸ä¼šè·Ÿä½ ã€‚æ‰€ä»¥ä½ æƒ³æƒ³ï¼ŒçœŸçš„æ˜¯åˆ«äººè®©ä½ å¿ƒæƒ…ä¸å¥½äº†å˜›ï¼Ÿç­”æ¡ˆæ˜¯å¦å®šçš„ï¼Œè€Œæ˜¯è‡ªå·±æŠŠè‡ªå·±å¿ƒæƒ…å˜å¾—ä¸å¥½äº†ã€‚</p><p>&emsp;&emsp;æˆ‘è·Ÿè€å¸ˆèŠè¿‡ã€‚æˆ‘è·ŸåŒå­¦èŠè¿‡ã€‚æˆ‘è·Ÿå®¶äººèŠè¿‡ã€‚æˆ‘è·Ÿæœ‹å‹èŠè¿‡ã€‚æˆ‘ä¹Ÿè·Ÿè‡ªå·±èŠè¿‡ã€‚å¦‚æœæˆ‘èƒ½è·Ÿå¥¹å†èŠä¸€èŠå°±æ›´å¥½äº†ã€‚å¼€å¿ƒåœ°ã€åŠªåŠ›åœ°ã€è‡ªä¿¡åœ°åšæ‰‹å¤´ä¸Šçš„äº‹æƒ…ï¼Œå°±æ˜¯æœ€æ£’äº†ã€‚æœ‰å¥½èº«ä½“ã€å¥½å·¥ä½œã€å¥½å¿ƒæ€å°±å·²ç»å®Œèƒœå•¦ã€‚</p><h1 id="èµç¾"><a href="#èµç¾" class="headerlink" title="èµç¾"></a>èµç¾</h1><p>&emsp;&emsp;ä»¥å‰æˆ‘å¾ˆè®¨åŒé˜¿è°€å¥‰æ‰¿ï¼Œç„¶è€Œè¿™ç§è®¨åŒè¢«æ— å½¢åœ°æ‰©å¤§äº†ã€‚æ‰©å¤§åˆ°ä¸ä¼šç”±è¡·åœ°æ¬£èµèµç¾åˆ«äººã€‚è€Œä¸”é˜¿è°€å¥‰æ‰¿æˆ‘ç°åœ¨æ ¹æœ¬ä¸è®¨åŒäº†ï¼Œä½†æˆ‘ä¸ä¼šå»é˜¿è°€å¥‰æ‰¿ã€‚å¦‚æœæˆ‘éœ€è¦å¸®åŠ©ï¼Œæˆ‘ä¼šçœŸè¯šåœ°è¡¨è¾¾ã€å¯»æ±‚å¸®åŠ©ã€‚æˆ‘çš„èµç¾ä¹Ÿä¸ä¼šæ˜¯é˜¿è°€å¥‰æ‰¿ï¼Œè€Œæ˜¯è¦é€šè¿‡è§‚å¯Ÿåï¼ŒçœŸçš„èƒ½å‘ç°è¿™ä»¶äº‹å¸¦ç»™æˆ‘ä»¬çš„ç¾ï¼Œä»¥åŠé‚£èƒŒåçš„æ•…äº‹~</p><p>&emsp;&emsp;ä¸ºä»€ä¹ˆæˆ‘ä¸è®¨åŒé˜¿è°€å¥‰æ‰¿ã€‚å› ä¸ºæˆ‘çŸ¥é“äººçš„ç”Ÿæ´»æ˜¯è‰°éš¾çš„ï¼Œä»–åªä¸è¿‡åœ¨è‰°éš¾åœ°åœ¨å¤¹ç¼ä¸­ç”Ÿå­˜ç€ï¼Œä»–é˜¿è°€å¥‰æ‰¿å‡ å¥ï¼Œå¹¶ä¸æ˜¯å‡ºäºæ¶æ„ï¼Œè€Œæ˜¯å¯ä»¥ä¿ä½è‡ªå·±çš„å·¥ä½œï¼Œä¿ä½è‡ªå·±çš„é¥­ç¢—ï¼Œæœ‰ä¸ªæ›´å¥½çš„æœºä¼šè€Œå·²ã€‚è¯´å‡ å¥è¯èƒ½è®©å¤§å®¶éƒ½å¼€å¿ƒï¼Œè¿™æœ‰ä»€ä¹ˆä¸å¯¹å—ï¼Ÿè¿™æ ·åœ¨å·¥ä½œä¸­å¤§å®¶éƒ½å¾ˆèˆ’æœï¼Œè¿™æ˜¯æå…¶æ­£ç¡®çš„ã€‚</p><p>&emsp;&emsp;æ¨èç”¨æ›´å¥½çš„ â€œé˜¿è°€å¥‰æ‰¿â€ çš„æ–¹æ³•ï¼Œé‚£ä¾¿æ˜¯èµç¾ã€‚å­¦ä¼šè®¤å¯åˆ«äººçš„å·¥ä½œï¼Œå­¦ä¼šæ¬£èµï¼Œå­¦ä¼šèµç¾ã€‚æ¯”å¦‚å¥¹ç”»äº†ä¸€ä¸ªå¦†ï¼Œç”·ç”Ÿå¯èƒ½çœ‹äº†å¹¶æ²¡æœ‰ä»€ä¹ˆå’Œä¹‹å‰æ„Ÿè§‰ä¸ä¸€æ ·ï¼Œä½†æ˜¯ä½ ä¸çŸ¥é“çš„æ˜¯ï¼Œå¥¹ä¸ºäº†ä½ åŒ–å¦†å‡†å¤‡äº†å¤šä¹…ã€‚å¥¹å¹³æ—¶ä¸€ä¸ªäººçš„æ—¶å€™å¯æ˜¯æ‡’å¾—æ‰“æ‰®å‘€ï¼Œè¿™æ—¶å€™ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªå¥³ç”Ÿæ˜¯çœŸçš„å¾ˆç¾ï¼Œå¾ˆå¯çˆ±å‘€ã€‚æˆ‘ä¼šä»”ç»†åœ°çœ‹çœ‹å¥¹åœ°çœ¼ç›ã€è…®çº¢ï¼Œè™½ç„¶æˆ‘å¯¹åŒ–å¦†ä¸€çªä¸é€šï¼Œä½†æ˜¯å¥½åƒçœŸçš„æœ‰äº›ä¸ä¸€æ ·ï¼Œæˆ‘ä¸€å®šä¼šå¼€å¿ƒå¾—çœ‹ç€å¥¹è¯´ï¼šä½ ä»Šå¤©çœŸç¾ï¼</p><p>æ‰€ä»¥ä½ åœ¨å’Œåˆ«äººäº¤æµçš„æ—¶å€™ï¼Œæ€»æœ‰äº›ä¸œè¥¿ä½ ä¸å¤ªæ‡‚ï¼Œä½†æ˜¯å¯¹æ–¹æåŠ›è®²çš„æ—¶å€™ï¼Œä¸€å®šæ˜¯å¯¹ä»–éå¸¸é‡è¦çš„ä¸œè¥¿å§ï¼ä»–ä¸€å®šä¸ºè¿™ä»¶äº‹ä»˜å‡ºäº†å¾ˆå¤šå®å®åœ¨åœ¨çš„åŠªåŠ›ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä¼šå¤§æ–¹åœ°èµç¾ï¼Œå› ä¸ºæˆ‘ç¡®å®èƒ½è¢«æ„ŸæŸ“åˆ°ï¼Œè¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä¸è®¤ä¸ºæ˜¯ä»€ä¹ˆé˜¿è°€å¥‰æ‰¿ã€‚</p><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª-1"><a href="#è¿åŠ¨å¥åº·çš„å¯¼èˆª-1" class="headerlink" title="è¿åŠ¨å¥åº·çš„å¯¼èˆª"></a>è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol><li><a href="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a></li><li><a href="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li></ol></blockquote>]]></content>
    
    
    <summary type="html">ğŸ«æœ¬æ–‡æ€»ç»“çŠ¶æ€è°ƒæ•´çš„æ–¹æ³•</summary>
    
    
    
    <category term="è¿åŠ¨å¥åº·" scheme="https://www.adunas.top/categories/%E8%BF%90%E5%8A%A8%E5%81%A5%E5%BA%B7/"/>
    
    
    <category term="å¥åº·" scheme="https://www.adunas.top/tags/%E5%81%A5%E5%BA%B7/"/>
    
    <category term="å¿ƒæ€" scheme="https://www.adunas.top/tags/%E5%BF%83%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>åšå®¢æ­å»ºæ•™ç¨‹ï¼šé¦–é¡µç¾åŒ–</title>
    <link href="https://www.adunas.top/posts/20240202a.html"/>
    <id>https://www.adunas.top/posts/20240202a.html</id>
    <published>2024-02-02T15:36:47.000Z</published>
    <updated>2024-02-21T12:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"><a href="#åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª" class="headerlink" title="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"></a><a href="./20240221c.html#é¦–é¡µç¾åŒ–">åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª</a></h1><h1 id="æ ¼è¨€"><a href="#æ ¼è¨€" class="headerlink" title="æ ¼è¨€"></a>æ ¼è¨€</h1><p>&emsp;&emsp;åœ¨[é¡µè„šé…ç½®æ–‡ä»¶]./themes/butterfly/layout/includes/footer.pug ä¸­ï¼Œä¿®æ”¹å¦‚ä¸‹ä»£ç ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.t-t-l</span><br><span class="line">          p.ft-t.t-l-t æ ¼è¨€ğŸ§¬</span><br><span class="line">          .bg-ad</span><br><span class="line">            div</span><br><span class="line">              | å†çœ‹çœ‹é‚£ä¸ªå…‰ç‚¹ï¼Œå®ƒå°±åœ¨è¿™é‡Œï¼Œè¿™æ˜¯å®¶å›­ï¼Œè¿™æ˜¯æˆ‘ä»¬ â€”â€” ä½ æ‰€çˆ±çš„æ¯ä¸€ä¸ªäººï¼Œä½ è®¤è¯†çš„ä¸€ä¸ªäººï¼Œä½ å¬è¯´è¿‡çš„æ¯ä¸€ä¸ªäººï¼Œæ›¾ç»æœ‰è¿‡çš„æ¯ä¸€ä¸ªäººï¼Œéƒ½åœ¨å®ƒä¸Šé¢åº¦è¿‡ä»–ä»¬çš„ä¸€ç”Ÿâœ¨</span><br><span class="line">            .btn-xz-box</span><br><span class="line">              a.btn-xz(href=&#x27;https://stellarium.org/&#x27;) ç‚¹å‡»å¼€å¯æ˜Ÿè¾°ä¹‹æ—…</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">ğŸŸæœ¬æ–‡è®°å½•åšå®¢é¦–é¡µç¾åŒ–çš„æ–¹æ³•</summary>
    
    
    
    <category term="åšå®¢" scheme="https://www.adunas.top/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
    <category term="hexo" scheme="https://www.adunas.top/tags/hexo/"/>
    
    <category term="html" scheme="https://www.adunas.top/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>åšå®¢æ­å»ºæ•™ç¨‹ï¼šæ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½</title>
    <link href="https://www.adunas.top/posts/20240201a.html"/>
    <id>https://www.adunas.top/posts/20240201a.html</id>
    <published>2024-02-01T03:30:06.000Z</published>
    <updated>2024-02-21T12:29:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"><a href="#åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª" class="headerlink" title="åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª"></a><a href="./20240221c.html#æ–‡ç« ä¸ªæ€§åŒ–åŠŸèƒ½">åšå®¢æ­å»ºæ•™ç¨‹å¯¼èˆª</a></h1><h1 id="æ–‡ç« é¡µHtmlæ ‡ç­¾"><a href="#æ–‡ç« é¡µHtmlæ ‡ç­¾" class="headerlink" title="æ–‡ç« é¡µHtmlæ ‡ç­¾"></a>æ–‡ç« é¡µHtmlæ ‡ç­¾</h1><p>&emsp;&emsp;æœ‰æ—¶å€™æˆ‘ä»¬æƒ³åœ¨åšå®¢æ–‡ç« é‡Œæ·»åŠ ä¸€äº› hexo ä¸å…·æœ‰çš„ç‰¹æ€§æ—¶ï¼Œå°±å¯ä»¥åœ¨ markdown æ–‡ä»¶ä¸­æ·»åŠ  Html æ ‡ç­¾ã€‚</p><p>&emsp;&emsp;htmlã€CSS å’Œ js å¯ä»¥åˆ†å¼€å†™ï¼Œä¹Ÿåˆ†ä¸‰ä¸ªæ–‡ä»¶å†™ï¼Œhtmlå§‹ç»ˆæ”¾åœ¨ markdownæ–‡ä»¶é‡Œã€‚åˆ†å¼€å†™çš„è¯ï¼ŒCSS å’Œ js æ–‡ä»¶è¦æ”¾åœ¨ä¸»é¢˜çš„æºæ–‡ä»¶è·¯å¾„ /themes/butterfly/source/ ä¸‹çš„çš„ css æˆ–è€… js æ–‡ä»¶å¤¹ä¸‹ã€‚åœ¨ Markdown é‡Œçš„è¯­æ³•ä¸ºï¼š</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">type</span>=<span class="string">&quot;text/css&quot;</span> <span class="attr">href</span>=<span class="string">&quot;/css/grid.css&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    </span></span><br><span class="line"><span class="code">&lt;div class=&quot;container1&quot;&gt;  </span></span><br><span class="line"><span class="code">    &lt;iframe class=&quot;container-iframe&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;  </span></span><br><span class="line"><span class="code">&lt;/div&gt;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/js/grid.js&quot;</span>&gt;</span></span><span class="language-xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h1 id="Bilibiliè§†é¢‘é€‚é…"><a href="#Bilibiliè§†é¢‘é€‚é…" class="headerlink" title="Bilibiliè§†é¢‘é€‚é…"></a>Bilibiliè§†é¢‘é€‚é…</h1><div class="note purple no-icon flat"><p>å‚è€ƒæ–‡ç« ï¼š<a href="https://www.fomal.cc/posts/5389e93f.html">Bilibiliè§†é¢‘é€‚é…</a></p></div><ol><li>åœ¨[BlogRoot]\source\css\custom.cssè‡ªå®šä¹‰æ ·å¼çš„æ–‡ä»¶ä¸­å¼•å…¥å¦‚ä¸‹ä»£ç ï¼ˆè¿™æ˜¯æˆ‘çš„ï¼Œä½ å¯ä»¥è‡ªè¡Œå¾®è°ƒï¼‰ï¼š</li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*å“”å“©å“”å“©è§†é¢‘é€‚é…*/</span></span><br><span class="line"><span class="selector-class">.aspect-ratio</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">90%</span>;</span><br><span class="line">  <span class="attribute">height</span>: auto;</span><br><span class="line">  <span class="attribute">padding-bottom</span>: <span class="number">75%</span>;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">3%</span> auto;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.aspect-ratio</span> <span class="selector-tag">iframe</span> &#123;</span><br><span class="line">  <span class="attribute">position</span>: absolute;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">86%</span>;</span><br><span class="line">  <span class="attribute">left</span>: <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>ç›´æ¥å¤åˆ¶æ’å…¥ä½ çš„ md æ–‡ç« å°±è¡Œï¼Œä¿®æ”¹é‡Œé¢çš„ src æºä¸ºä½ çš„è§†é¢‘ï¼š</li></ol><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">center</span> <span class="attr">class</span>=<span class="string">&quot;aspect-ratio&quot;</span>&gt;</span></span></span><br><span class="line"><span class="code">    &lt;iframe src=&quot;https://player.bilibili.com/player.html?aid=474023258&amp;&amp;page=1&amp;as_wide=1&amp;high_quality=1&amp;danmaku=0&amp;autoplay=0 &quot; </span></span><br><span class="line"><span class="code">    scrolling=&quot;no&quot; </span></span><br><span class="line"><span class="code">    border=&quot;0&quot; </span></span><br><span class="line"><span class="code">    frameborder=&quot;no&quot; </span></span><br><span class="line"><span class="code">    framespacing=&quot;0&quot; </span></span><br><span class="line"><span class="code">    high_quality=1</span></span><br><span class="line"><span class="code">    danmaku=1 </span></span><br><span class="line"><span class="code">    allowfullscreen=&quot;true&quot;&gt; </span></span><br><span class="line"><span class="code">    &lt;/iframe&gt;</span></span><br><span class="line"><span class="code">&lt;/div&gt;</span></span><br></pre></td></tr></table></figure><p>æºè§†é¢‘çš„é“¾æ¥è·å–æ–¹æ³•ä¸ºï¼šåœ¨bç«™å®˜ç½‘åˆ†äº«è§†é¢‘æ—¶ï¼Œé€‰æ‹© <code>åµŒå…¥ä»£ç </code>ã€‚è‹¥è¦å…³é—­è§†é¢‘è‡ªåŠ¨æ’­æ”¾ï¼Œåœ¨åé¢æ·»åŠ å‚æ•°ï¼š</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&amp;autoplay=0</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">ğŸ”æœ¬æ–‡è®°å½•åšå®¢æ–‡ç« å†…æ’å…¥çš„ä¸ªæ€§åŒ–åŠŸèƒ½</summary>
    
    
    
    <category term="åšå®¢" scheme="https://www.adunas.top/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
    <category term="hexo" scheme="https://www.adunas.top/tags/hexo/"/>
    
    <category term="html" scheme="https://www.adunas.top/tags/html/"/>
    
  </entry>
  
  <entry>
    <title>è¿åŠ¨å¥åº·ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</title>
    <link href="https://www.adunas.top/posts/20240131a.html"/>
    <id>https://www.adunas.top/posts/20240131a.html</id>
    <published>2024-01-31T14:47:09.000Z</published>
    <updated>2024-02-02T11:54:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ–‡ç« å¯¼èˆªæ€»è§ˆ"><a href="#æ–‡ç« å¯¼èˆªæ€»è§ˆ" class="headerlink" title="æ–‡ç« å¯¼èˆªæ€»è§ˆ"></a><a href="./20240221a.html#æ—¥å¸¸åŸºç¡€ç¯‡">æ–‡ç« å¯¼èˆªæ€»è§ˆ</a></h1><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª"><a href="#è¿åŠ¨å¥åº·çš„å¯¼èˆª" class="headerlink" title="è¿åŠ¨å¥åº·çš„å¯¼èˆª"></a>è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol><li><a href="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li><li><a href="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a></li></ol></blockquote><h1 id="é¢ˆæ¤"><a href="#é¢ˆæ¤" class="headerlink" title="é¢ˆæ¤"></a>é¢ˆæ¤</h1><p>&emsp;&emsp;<a href="https://www.bilibili.com/video/BV1Yb411b7nd/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€æœ‰æ¥åŒ»ç”Ÿ 8æ‹›é¢ˆæ¤æ“å…¨æ•™ç¨‹ã€‘</a></p><div align=center class="aspect-ratio">    <iframe src="https://player.bilibili.com/player.html?aid=45039749&bvid=BV1Yb411b7nd&cid=78880311&p=1&autoplay=0 "     scrolling="no"     border="0"     frameborder="no"     framespacing="0"     high_quality=1    danmaku=1     allowfullscreen="true">     </iframe></div><h1 id="è…°æ¤"><a href="#è…°æ¤" class="headerlink" title="è…°æ¤"></a>è…°æ¤</h1><p>&emsp;&emsp;<a href="https://www.bilibili.com/video/BV1fp4y1U7qG/?share_source=copy_web&amp;vd_source=6b55cb6788b1952e04c06b095d772810">ã€æ¯å¤©5åˆ†é’Ÿ <em>å‘Šåˆ«éª¨ç›†å‰å€¾ï¼Œå°è‚šå­çªå‡ºï¼Œå¤§å±è‚¡</em>ã€‘</a></p><div align=center class="aspect-ratio">    <iframe src="https://player.bilibili.com/player.html?aid=968747403&bvid=BV1fp4y1U7qG&cid=205794890&p=1&autoplay=0 "     scrolling="no"     border="0"     frameborder="no"     framespacing="0"     high_quality=1    danmaku=1     allowfullscreen="true">     </iframe></div><blockquote><h1 id="è¿åŠ¨å¥åº·çš„å¯¼èˆª-1"><a href="#è¿åŠ¨å¥åº·çš„å¯¼èˆª-1" class="headerlink" title="è¿åŠ¨å¥åº·çš„å¯¼èˆª"></a>è¿åŠ¨å¥åº·çš„å¯¼èˆª</h1><ol><li><a href="./20240131a.html">è¿åŠ¨å¥åº·ï¼ˆä¸€ï¼‰ï¼šæ—¥å¸¸åŸºç¡€ç¯‡</a>â‡¦å½“å‰ä½ç½®ğŸª‚</li><li><a href="./20240203a.html">è¿åŠ¨å¥åº·ï¼ˆäºŒï¼‰ï¼šçŠ¶æ€è°ƒæ•´ç¯‡</a></li></ol></blockquote>]]></content>
    
    
    <summary type="html">ğŸˆæœ¬æ–‡æ±‡æ€»æ—¥å¸¸çƒ­èº«çš„å†…å®¹</summary>
    
    
    
    <category term="è¿åŠ¨å¥åº·" scheme="https://www.adunas.top/categories/%E8%BF%90%E5%8A%A8%E5%81%A5%E5%BA%B7/"/>
    
    
    <category term="è¿åŠ¨" scheme="https://www.adunas.top/tags/%E8%BF%90%E5%8A%A8/"/>
    
    <category term="å¥èº«" scheme="https://www.adunas.top/tags/%E5%81%A5%E8%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>C++ æ‰“å°</title>
    <link href="https://www.adunas.top/posts/20240116a.html"/>
    <id>https://www.adunas.top/posts/20240116a.html</id>
    <published>2024-01-16T13:41:33.000Z</published>
    <updated>2024-02-21T11:20:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ç¼–ç¨‹å¯¼èˆª"><a href="#ç¼–ç¨‹å¯¼èˆª" class="headerlink" title="ç¼–ç¨‹å¯¼èˆª"></a><a href="./20240221b.html#æ‰“å°">ç¼–ç¨‹å¯¼èˆª</a></h1><h1 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h1><h2 id="è¯­æ³•"><a href="#è¯­æ³•" class="headerlink" title="è¯­æ³•"></a>è¯­æ³•</h2><h3 id="åŸºç¡€"><a href="#åŸºç¡€" class="headerlink" title="åŸºç¡€"></a>åŸºç¡€</h3><h4 id="æ–¹æ³•1"><a href="#æ–¹æ³•1" class="headerlink" title="æ–¹æ³•1"></a>æ–¹æ³•1</h4><p>&emsp;&emsp;è°ƒç”¨åº“ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br></pre></td></tr></table></figure><p>è°ƒç”¨å‡½æ•°ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="æ–¹æ³•2"><a href="#æ–¹æ³•2" class="headerlink" title="æ–¹æ³•2"></a>æ–¹æ³•2</h4><p>&emsp;&emsp;å‘½åç©ºé—´ï¼Œçœç•¥ stdã€‚</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br></pre></td></tr></table></figure><p>è°ƒç”¨å‡½æ•°ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cout &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h3 id="ç»„åˆæ–¹å¼"><a href="#ç»„åˆæ–¹å¼" class="headerlink" title="ç»„åˆæ–¹å¼"></a>ç»„åˆæ–¹å¼</h3><h4 id="ç»„åˆæ–¹å¼1"><a href="#ç»„åˆæ–¹å¼1" class="headerlink" title="ç»„åˆæ–¹å¼1"></a>ç»„åˆæ–¹å¼1</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="ç»„åˆæ–¹å¼2"><a href="#ç»„åˆæ–¹å¼2" class="headerlink" title="ç»„åˆæ–¹å¼2"></a>ç»„åˆæ–¹å¼2</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="ç»„åˆæ–¹å¼3"><a href="#ç»„åˆæ–¹å¼3" class="headerlink" title="ç»„åˆæ–¹å¼3"></a>ç»„åˆæ–¹å¼3</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br></pre></td></tr></table></figure><h3 id="ç‰¹æ®Šç¬¦å·"><a href="#ç‰¹æ®Šç¬¦å·" class="headerlink" title="ç‰¹æ®Šç¬¦å·"></a>ç‰¹æ®Šç¬¦å·</h3><h4 id="å›è½¦"><a href="#å›è½¦" class="headerlink" title="å›è½¦"></a>å›è½¦</h4><p>&emsp;&emsp;å›è½¦è¡¨ç¤ºå°†å…‰æ ‡ç§»åŠ¨åˆ°è¡Œçš„å¼€å¤´ã€‚è¿™åº”è¯¥å’Œé”®ç›˜ä¸Šçš„å›è½¦æœ‰æ‰€åŒºåˆ†ã€‚</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;\r&quot;</span>;</span><br></pre></td></tr></table></figure><h4 id="æ¢è¡Œ"><a href="#æ¢è¡Œ" class="headerlink" title="æ¢è¡Œ"></a>æ¢è¡Œ</h4><p>&emsp;&emsp;æ¢è¡Œè¡¨ç¤ºå°†å…‰æ ‡ç§»åŠ¨åˆ°ä¸‹ä¸€è¡Œçš„å¼€å¤´ã€‚</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br></pre></td></tr></table></figure><p>æˆ–è€…ï¼š</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h3 id="å˜é‡è°ƒç”¨"><a href="#å˜é‡è°ƒç”¨" class="headerlink" title="å˜é‡è°ƒç”¨"></a>å˜é‡è°ƒç”¨</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> num = <span class="number">100</span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;æ•°å­—æ˜¯ï¼š&quot;</span> &lt;&lt; num &lt;&lt; std::endl;</span><br><span class="line">std::string st = <span class="string">&quot;ä½ å¥½ï¼Œä¸–ç•Œï¼&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; st &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><h3 id="æ¼”ç¤º"><a href="#æ¼”ç¤º" class="headerlink" title="æ¼”ç¤º"></a>æ¼”ç¤º</h3><p>&emsp;&emsp;æ¼”ç¤ºæ•ˆæœå¦‚ä¸‹ï¼š</p><div class="tabs" id="print"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#print-1">ç¤ºä¾‹æºç 1</button></li><li class="tab"><button type="button" data-href="#print-2">æ¼”ç¤ºç»“æœ1</button></li><li class="tab"><button type="button" data-href="#print-3">ç¤ºä¾‹æºç 2</button></li><li class="tab"><button type="button" data-href="#print-4">æ¼”ç¤ºç»“æœ2</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="print-1"><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Print\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;|_&quot;</span> &lt;&lt; <span class="string">&quot;è¯­æ³•\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;åŸºç¡€\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼1\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼2\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | | |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span> &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;ç»„åˆæ–¹å¼3\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;Hello&quot;</span>; std::cout &lt;&lt; <span class="string">&quot; World!\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;ç‰¹æ®Šç¬¦å·\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;å›è½¦\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;\r&quot;</span>; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;æ¢è¡Œ\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; <span class="string">&quot;æˆ–è€…\n&quot;</span>; </span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |   |_&quot;</span> &lt;&lt; std::endl; std::cout &lt;&lt; <span class="string">&quot;*\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |&quot;</span> &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| |_&quot;</span> &lt;&lt; <span class="string">&quot;å˜é‡è°ƒç”¨\n&quot;</span>;</span><br><span class="line">    <span class="type">int</span> num = <span class="number">100</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; <span class="string">&quot;æ•°å­—æ˜¯ï¼š&quot;</span> &lt;&lt; num &lt;&lt; std::endl;</span><br><span class="line">    std::string st = <span class="string">&quot;ä½ å¥½ï¼Œä¸–ç•Œï¼&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;| | |_&quot;</span> &lt;&lt; st &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-2"><p><img src="https://picture.adunas.top/Program/PrintCppVs2022A.png" alt=""></p><p>è¯´æ˜ï¼šæ¢è¡Œå’Œå›è½¦æœ‰æ˜æ˜¾åŒºåˆ«ã€‚</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-3"><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// æœ‰ä¸‰å¤„å¯ä»¥çœç•¥ std::</span></span><br><span class="line">    string st = <span class="string">&quot;ä½ å¥½ï¼Œä¸–ç•Œï¼&quot;</span>;</span><br><span class="line">    cout &lt;&lt; st &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="print-4"><p><img src="https://picture.adunas.top/Program/PrintCppVs2022B.png" alt=""></p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>]]></content>
    
    
    <summary type="html">ğŸ–æœ¬æ–‡æ±‡æ€» C++ æ‰“å°æ˜¾ç¤ºçš„åŠŸèƒ½</summary>
    
    
    
    <category term="ç¼–ç¨‹" scheme="https://www.adunas.top/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="C++" scheme="https://www.adunas.top/tags/C/"/>
    
    <category term="print" scheme="https://www.adunas.top/tags/print/"/>
    
  </entry>
  
</feed>
